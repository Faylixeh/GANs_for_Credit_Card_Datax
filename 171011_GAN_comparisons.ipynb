{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To Do:\n",
    "    Redo conditional CGANs to supply class as input to both G and D, not in output from G\n",
    "    Redo tests with larger xgboost test sets\n",
    "    Confirm WGAN architecture\n",
    "    Change figures to dots and dashes\n",
    "    Add testing of fraud detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> GAN comparison on Kaggle Credit Card Fraud Data </h1><br>\n",
    "\n",
    "Cody Nash<br>\n",
    "Development notebook<br>\n",
    "<hr>\n",
    "\n",
    "<a id=\"TOC\"></a><h2>Table of Contents</h2>\n",
    "<br>\n",
    "<a href='#Setup'> Setup</a><br>\n",
    "<br>\n",
    "<a href=\"#Waya.ai GAN dense\"> Waya.ai GAN dense</a><br>\n",
    "<br>\n",
    "<a href=\"#Waya.ai CGAN dense\"> Waya.ai CGAN dense</a><br>\n",
    "<br>\n",
    "<a href=\"#Waya.ai WGAN dense\"> Waya.ai WGAN dense</a><br>\n",
    "<br>\n",
    "<a href=\"#Waya.ai WCGAN dense\"> Waya.ai WCGAN dense</a><br>\n",
    "<br>\n",
    "<a href=\"#Summary\"> Summary</a><br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Setup\"><h1>Setup</h1></a>\n",
    "\n",
    "<a href='#TOC'>Table of contents</a>\n",
    "<br><br>\n",
    "\n",
    "- Load basic libraries\n",
    "- Load common functions\n",
    "- Load stored datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linux for xgboost and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4041883648, 3443154944]\n",
      "[4041883648, 3383119872]\n"
     ]
    }
   ],
   "source": [
    "import psutil ; print(list(psutil.virtual_memory())[0:2])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "print(list(psutil.virtual_memory())[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BaseMetrics(y_pred,y_true):\n",
    "    TP = np.sum( (y_pred == 1) & (y_true == 1) )\n",
    "    TN = np.sum( (y_pred == 0) & (y_true == 0) )\n",
    "    FP = np.sum( (y_pred == 1) & (y_true == 0) )\n",
    "    FN = np.sum( (y_pred == 0) & (y_true == 1) )\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def SimpleMetrics(y_pred,y_true):\n",
    "    TP, TN, FP, FN = BaseMetrics(y_pred,y_true)\n",
    "    ACC = ( TP + TN ) / ( TP + TN + FP + FN )\n",
    "    \n",
    "    # Reporting\n",
    "    from IPython.display import display\n",
    "    print( 'Confusion Matrix')\n",
    "    display( pd.DataFrame( [[TN,FP],[FN,TP]], columns=['Pred 0','Pred 1'], index=['True 0', 'True 1'] ) )\n",
    "    print( 'Accuracy : {}'.format( ACC ))\n",
    "    \n",
    "def SimpleAccuracy(y_pred,y_true):\n",
    "    TP, TN, FP, FN = BaseMetrics(y_pred,y_true)\n",
    "    ACC = ( TP + TN ) / ( TP + TN + FP + FN )\n",
    "    return ACC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_batch(train, batch_size, data_dim):\n",
    "    x = train.loc[ np.random.choice(train.index, batch_size) ].values\n",
    "    return np.reshape(x, (batch_size, data_dim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CheckAccuracy( generator_model, n_samples, train ):\n",
    "    np.random.seed(0)\n",
    "    temp_noise = np.random.normal(size=(n_samples*2, rand_dim)) \n",
    "    test_samples = generator_model.predict(temp_noise)\n",
    "\n",
    "    test_samples = np.reshape(test_samples, (n_samples*2, data_dim))\n",
    "    \n",
    "    test_samples = pd.DataFrame(test_samples,columns=train.columns)\n",
    "    test_samples['syn_label'] = 1\n",
    "    try:\n",
    "        test_samples['Class'] = (test_samples['Class'] > 0.5)*1\n",
    "    except:\n",
    "        None\n",
    "\n",
    "    real_samples = train.sample(n_samples*2,replace=False)\n",
    "    real_samples['syn_label'] = 0\n",
    "    train_df = pd.concat([real_samples[:n_samples],test_samples[:n_samples]],axis=0)\n",
    "    test_df = pd.concat([real_samples[n_samples:],test_samples[n_samples:]],axis=0)\n",
    "\n",
    "    X_col = test_df.columns[:-1]\n",
    "    y_col = test_df.columns[-1]\n",
    "    dtrain = xgb.DMatrix(train_df[X_col], train_df[y_col], feature_names=X_col)\n",
    "    dtest = xgb.DMatrix(test_df[X_col], feature_names=X_col)\n",
    "\n",
    "    xgb_params = {\n",
    "        'max_depth': 4,\n",
    "        'objective': 'binary:logistic',\n",
    "        'random_state': 0 }\n",
    "    xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "    y_pred = np.round(xgb_test.predict(dtest))\n",
    "    y_true = test_df['syn_label']\n",
    "#     print('ACC: {:.3f}'.format(SimpleAccuracy(y_pred, y_true)))\n",
    "    return '{:.2f}'.format(SimpleAccuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# Conversion of Waya.ai GAN and WGAN\n",
    "\n",
    "Remove convolutional layers\n",
    "Remove ResNeXt\n",
    "Convert WGAN back to simple GAN\n",
    "\n",
    "Add simple matrix multiplication output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from keras import applications\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "# from keras.preprocessing import image\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# # from dlutils import plot_image_batch_w_labels\n",
    "\n",
    "# import ResNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# directory paths\n",
    "#\n",
    "\n",
    "path = '' # os.path.dirname(os.path.abspath(__file__))\n",
    "cache_dir = os.path.join(path, 'cache')\n",
    "\n",
    "#\n",
    "# generator input params\n",
    "#\n",
    "\n",
    "rand_dim = 32 # 64  # dimension of the generator's input tensor (gaussian noise)\n",
    "\n",
    "#\n",
    "# image dimensions\n",
    "#\n",
    "\n",
    "data_dim = 28\n",
    "\n",
    "#\n",
    "# training params\n",
    "#\n",
    "\n",
    "nb_steps = 5001 # 50000\n",
    "batch_size = 64 # 64\n",
    "k_d = 5 # 5  # number of critic network updates per adversarial training step\n",
    "k_g = 1  # number of generator network updates per adversarial training step\n",
    "critic_pre_train_steps = 100 # 100  # number of steps to pre-train the critic before starting adversarial training\n",
    "\n",
    "#\n",
    "# logging params\n",
    "#\n",
    "\n",
    "log_interval = 10 # 100  # interval (in steps) at which to log loss summaries and save plots of image samples to disc\n",
    "fixed_noise = np.random.normal(size=(batch_size, rand_dim))  # fixed noise to generate batches of generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# generator and discriminator architecture from: https://github.com/buriburisuri/ac-gan\n",
    "#\n",
    "\n",
    "neurons_per_layer = 32\n",
    "\n",
    "def add_common_layers(y):\n",
    "#     y = layers.LeakyReLU()(y)\n",
    "    y = layers.advanced_activations.LeakyReLU()(y)\n",
    "    y = layers.Dropout(0.25)(y)\n",
    "    return y\n",
    "\n",
    "def generator_network(x):\n",
    "    x = layers.Dense(neurons_per_layer)(x)\n",
    "    x = add_common_layers(x)\n",
    "\n",
    "    x = layers.Dense(neurons_per_layer)(x)\n",
    "    x = add_common_layers(x)\n",
    "\n",
    "    x = layers.Dense(data_dim)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def discriminator_network(x):\n",
    "\n",
    "    x = layers.Dense(data_dim)(x)\n",
    "    x = add_common_layers(x)\n",
    "\n",
    "    x = layers.Dense(neurons_per_layer)(x)\n",
    "    x = add_common_layers(x)\n",
    "    \n",
    "    x = layers.Dense(neurons_per_layer)(x)\n",
    "    x = add_common_layers(x)\n",
    "\n",
    "    return layers.Dense(1)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "CPU times: user 3.86 s, sys: 570 ms, total: 4.43 s\n",
      "Wall time: 5.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test loading credit card data\n",
    "# https://www.kaggle.com/dalpozz/creditcardfraud\n",
    "\n",
    "data = pd.read_csv(\"data/creditcard.csv.zip\")\n",
    "print(data.shape)\n",
    "# data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of data columns:  28\n"
     ]
    }
   ],
   "source": [
    "data_cols = [ i for i in data.columns if 'V' in i ]\n",
    "print('# of data columns: ',len(data_cols))\n",
    "label_cols = ['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Center on 0.5 with N standard deviations covering the range from 0 to 1\n",
    "\n",
    "# N = 20\n",
    "# data[ data_cols ] = data[ data_cols ] / data[ data_cols ].std() / N + 0.5\n",
    "# data[ data_cols ] = data[ data_cols ].clip(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Scale to 0 to 1 with no filtering\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# MMS = MinMaxScaler()\n",
    "# MMS.fit(train)\n",
    "# train = pd.DataFrame( MMS.transform(train), columns=train.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# padding = 4 # To get 32 columns for 4 x 8 for convolutions\n",
    "\n",
    "# # Generators will waste time learning these values.\n",
    "\n",
    "# pad0 = pd.DataFrame(np.ones((train.shape[0],padding))/2,columns=[ 'p'+str(i) for i in range(padding) ])\n",
    "# train = pd.concat([train,pad0],axis=1)\n",
    "# print(train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select all fraud data and a random sample of non-fraud data of the same size for a balanced dataset\n",
    "\n",
    "train_fraction = 1\n",
    "\n",
    "np.random.seed(5)\n",
    "train = data.loc[ data['Class']==1, data_cols ].copy().reset_index(drop=True)\n",
    "# train_int = int(len(train)*train_fraction)\n",
    "\n",
    "# test = train[train_int:]\n",
    "# train = train[:train_int]\n",
    "\n",
    "normal = data.loc[ data['Class']==0, data_cols ]\n",
    "# train_normal = normal.loc[ np.random.choice(normal.index, (len(train)+len(test))*100, replace=False) ].reset_index(drop=True)\n",
    "train_normal = normal.loc[ np.random.choice(normal.index, len(train), replace=False) ].reset_index(drop=True)\n",
    "\n",
    "# train = pd.concat( [ train, train_normal[:train_int] ] ).reset_index(drop=True)\n",
    "# test = pd.concat( [ test, train_normal[train_int:] ] ).reset_index(drop=True)\n",
    "train = pd.concat( [ train, train_normal ] ).reset_index(drop=True)\n",
    "\n",
    "print(train.shape)\n",
    "# print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 29)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select all fraud data and a random sample of non-fraud data of the same size for a balanced dataset\n",
    "data_cols_w_class = data_cols + ['Class']\n",
    "\n",
    "np.random.seed(5)\n",
    "train_w_class = data.loc[ data['Class']==1, data_cols_w_class ].copy().reset_index(drop=True)\n",
    "# test_w_class = train_w_class[train_int:]\n",
    "# train_w_class = train_w_class[:train_int]\n",
    "\n",
    "normal_w_class = data.loc[ data['Class']==0, data_cols_w_class ]\n",
    "# train_normal_w_class = normal_w_class.loc[ np.random.choice(normal_w_class.index, (len(train_w_class)+len(test_w_class))*100, replace=False) ].reset_index(drop=True)\n",
    "train_normal_w_class = normal_w_class.loc[ np.random.choice(normal_w_class.index, len(train_w_class), replace=False) ].reset_index(drop=True)\n",
    "\n",
    "# train_w_class = pd.concat( [ train_w_class, train_normal_w_class[:train_int] ] ).reset_index(drop=True)\n",
    "# test_w_class = pd.concat( [ test_w_class, train_normal_w_class[train_int:] ] ).reset_index(drop=True)\n",
    "train_w_class = pd.concat( [ train_w_class, train_normal_w_class ] ).reset_index(drop=True)\n",
    "\n",
    "print(train_w_class.shape)\n",
    "# print(test_w_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Select all fraud data and a random sample of non-fraud data of the same size for a balanced dataset\n",
    "\n",
    "# train_fraction = 1\n",
    "\n",
    "# np.random.seed(5)\n",
    "# train = data.loc[ data['Class']==1, data_cols ].copy().reset_index(drop=True)\n",
    "# train_int = int(len(train)*train_fraction)\n",
    "\n",
    "# test = train[train_int:]\n",
    "# train = train[:train_int]\n",
    "\n",
    "# normal = data.loc[ data['Class']==0, data_cols ]\n",
    "# train_normal = normal.loc[ np.random.choice(normal.index, len(train)+len(test), replace=False) ].reset_index(drop=True)\n",
    "\n",
    "# train = pd.concat( [ train, train_normal[:train_int] ] ).reset_index(drop=True)\n",
    "# test = pd.concat( [ test, train_normal[train_int:] ] ).reset_index(drop=True)\n",
    "\n",
    "# print(train.shape)\n",
    "# print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Select all fraud data and a random sample of non-fraud data of the same size for a balanced dataset\n",
    "# data_cols_w_class = data_cols + ['Class']\n",
    "\n",
    "# np.random.seed(5)\n",
    "# train_w_class = data.loc[ data['Class']==1, data_cols_w_class ].copy().reset_index(drop=True)\n",
    "# test_w_class = train_w_class[train_int:]\n",
    "# train_w_class = train_w_class[:train_int]\n",
    "\n",
    "# normal_w_class = data.loc[ data['Class']==0, data_cols_w_class ]\n",
    "# train_normal_w_class = normal_w_class.loc[ np.random.choice(normal_w_class.index, len(train_w_class)+len(test_w_class), replace=False) ].reset_index(drop=True)\n",
    "\n",
    "# train_w_class = pd.concat( [ train_w_class, train_normal_w_class[:train_int] ] ).reset_index(drop=True)\n",
    "# test_w_class = pd.concat( [ test_w_class, train_normal_w_class[train_int:] ] ).reset_index(drop=True)\n",
    "\n",
    "# print(train_w_class.shape)\n",
    "# print(test_w_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EDA\"><h1>EDA</h1></a>\n",
    "\n",
    "<a href='#TOC'>Table of contents</a>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "CPU times: user 3.57 s, sys: 340 ms, total: 3.91 s\n",
      "Wall time: 4.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test loading credit card data\n",
    "# https://www.kaggle.com/dalpozz/creditcardfraud\n",
    "\n",
    "data = pd.read_csv(\"data/creditcard.csv.zip\")\n",
    "print(data.shape)\n",
    "# data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of data columns:  28\n"
     ]
    }
   ],
   "source": [
    "data_cols = [ i for i in data.columns if 'V' in i ]\n",
    "print('# of data columns: ',len(data_cols))\n",
    "label_cols = ['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class\n",
       "Class        \n",
       "0      284315\n",
       "1         492"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(label_cols)[label_cols].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total nulls in dataset\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d2a3ddd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are outliers\n",
    "# plt.plot( np.log10( data[ data_cols ].abs().max().values ) )\n",
    "# plt.plot( data[ data_cols ].abs().max().values / data[ data_cols ].std().values / 10, label='max z/10' )\n",
    "plt.plot( data.loc[ data.Class==1, data_cols ].abs().max().values / data[ data_cols ].std().values / 10, label='1 max z/10' )\n",
    "plt.plot( data.loc[ data.Class==0, data_cols ].abs().max().values / data[ data_cols ].std().values / 10, label='0 max z/10' )\n",
    "plt.plot( data[ data_cols ].mean().values, label='mean' )\n",
    "# plt.plot( data[ data_cols ].abs().mean().values, label='abs mean' )\n",
    "plt.plot( data[ data_cols ].std().values, label='std' )\n",
    "plt.legend() ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicates?\n",
    "sum( data.duplicated() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1062, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( data.loc[ data.Class==0 ].duplicated() ), \\\n",
    "sum( data.loc[ data.Class==1 ].duplicated() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6d273564a8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKYVfJFIKv0ik/g/0NgxE5LRHxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d2a3b8a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Check Correlations\n",
    "corr0 = data.corr()\n",
    "plt.imshow(corr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.round(corr0[['Time','Amount','Class']],3)\n",
    "# corr0[data_cols]\n",
    "# np.round(corr0[data_cols],1)\n",
    "# np.round(corr0[data_cols],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# MIS = []\n",
    "# # for i in range(len(data_cols)):\n",
    "# for i in range(len(data.columns)):\n",
    "#     temp = []\n",
    "# #     for j in range(i+1,len(data_cols)):\n",
    "#     for j in range(i+1,len(data.columns)):\n",
    "# #         temp += [ metrics.mutual_info_score( data[data_cols[i]], data[data_cols[j]] )]\n",
    "#         temp += [ metrics.mutual_info_score( data[data.columns[i]], data[data.columns[j]] )]\n",
    "#     MIS += [temp]\n",
    "#     print(data_cols[i],np.round(temp,1))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/22227165/catch-matplotlib-warning\n",
    "# # import warnings\n",
    "# # with warnings.catch_warnings():\n",
    "# # #     warnings.simplefilter(\"ignore\")    \n",
    "# #     warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "\n",
    "# f, axarr = plt.subplots(7, 4, figsize=(14,10) )\n",
    "# for i, col in enumerate(data_cols):\n",
    "#     axarr[i//4, i%4].hist( data[col], bins=20 )\n",
    "#     axarr[i//4, i%4].set_title( '{}'.format(col) )\n",
    "# #     axarr[i//4, i%4].set_xlim([-0.1,1.1])\n",
    "# #     axarr[i//4, i%4].set_ylim([0,40])\n",
    "# f.set_tight_layout(True)\n",
    "\n",
    "# # data[ data_cols ].plot.hist( subplots=True, bins=20, figsize=(14,5) )\n",
    "# # plt.tight_layout(True) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/figure.py:1742: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA98AAAQwCAYAAAD8Ru1pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSJKlk/x/CCi9d0nwd7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5ccd02550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(7, 4, figsize=(14,15) )\n",
    "for i, col in enumerate(data_cols):\n",
    "    axarr[i//4, i%4].hist( [ data.loc[ data.Class == 1, col ], data.loc[ data.Class == 0, col ] ], label=['fraud','non-fraud'], bins=20, normed=True )\n",
    "    axarr[i//4, i%4].set_title( '{}'.format(col) )\n",
    "    axarr[i//4, i%4].legend()\n",
    "    if i//4 != 6: axarr[i//4, i%4].tick_params(axis='x',labelbottom='off')\n",
    "    if i%4 != 0 : axarr[i//4, i%4].tick_params(axis='y',labelleft='off')\n",
    "    axarr[i//4, i%4].set_xlim([0,1])\n",
    "    axarr[i//4, i%4].set_ylim([0,10])\n",
    "f.set_tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.groupby('Class')[ data_cols ].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_fraud = np.sum(data['Class']==1)\n",
    "\n",
    "# f, axarr = plt.subplots(7, 4, figsize=(14,15) )\n",
    "# for i, col in enumerate(data_cols):\n",
    "#     axarr[i//4, i%4].hist( [train[col][:n_fraud], train[col][n_fraud:]], label=['fraud','non-fraud'], bins=20, normed=True )\n",
    "#     axarr[i//4, i%4].set_title( '{}'.format(col) )\n",
    "#     axarr[i//4, i%4].legend()\n",
    "#     if i//4 != 6: axarr[i//4, i%4].tick_params(axis='x',labelbottom='off')\n",
    "#     if i%4 != 0 : axarr[i//4, i%4].tick_params(axis='y',labelleft='off')\n",
    "#     axarr[i//4, i%4].set_xlim([0,1])\n",
    "#     axarr[i//4, i%4].set_ylim([0,10])\n",
    "# f.set_tight_layout(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Waya.ai GAN dense\"><h1>Waya.ai GAN dense</h1></a>\n",
    "\n",
    "<a href='#TOC'>Table of contents</a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Standard GAN implemented on top of keras/tensorflow.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adversarial_training(data_dir, generator_model_path, discriminator_model_path, evaluate=False):\n",
    "    \"\"\"\n",
    "    Adversarial training of the generator network Gθ and discriminator network Dφ.\n",
    "\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(5)\n",
    "    \n",
    "    #\n",
    "    # define model input and output tensors\n",
    "    #\n",
    "\n",
    "    generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "    generated_image_tensor = generator_network(generator_input_tensor)\n",
    "\n",
    "    generated_or_real_image_tensor = layers.Input(shape=(data_dim,))\n",
    "    discriminator_output = discriminator_network(generated_or_real_image_tensor)\n",
    "\n",
    "    #\n",
    "    # define models\n",
    "    #\n",
    "\n",
    "    generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "    discriminator_model = models.Model(inputs=[generated_or_real_image_tensor],\n",
    "                                       outputs=[discriminator_output],\n",
    "                                       name='discriminator')\n",
    "\n",
    "    combined_output = discriminator_model(generator_model(generator_input_tensor))\n",
    "    combined_model = models.Model(inputs=[generator_input_tensor], outputs=[combined_output], name='combined')\n",
    "\n",
    "    #\n",
    "    # compile models\n",
    "    #\n",
    "\n",
    "    adam = optimizers.Adam(lr=.0001, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "    generator_model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    discriminator_model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    \n",
    "    discriminator_model.trainable = False\n",
    "#     combined_model.compile(optimizer=adam, loss=[em_loss])\n",
    "    combined_model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    \n",
    "    print(generator_model.summary())\n",
    "    print(discriminator_model.summary())\n",
    "    print(combined_model.summary())\n",
    "\n",
    "\n",
    "#     disc_loss = []\n",
    "#     combined_loss = []\n",
    "    combined_loss = np.empty(shape=1)\n",
    "    disc_loss_real = np.empty(shape=1)\n",
    "    disc_loss_generated = np.empty(shape=1)\n",
    "    xgb_losses = np.empty(shape=1)\n",
    "    \n",
    "    if generator_model_path:\n",
    "        generator_model.load_weights(generator_model_path, by_name=True)\n",
    "    if discriminator_model_path:\n",
    "        discriminator_model.load_weights(discriminator_model_path, by_name=True)\n",
    "    \n",
    "    for i in range(nb_steps):\n",
    "        print('Step: {} of {}.'.format(i, nb_steps))\n",
    "        K.set_learning_phase(1) # 1 = train\n",
    "\n",
    "        # train the discriminator\n",
    "        for _ in range(k_d):\n",
    "            # sample a mini-batch of noise (generator input)\n",
    "            z = np.random.normal(size=(batch_size, rand_dim))\n",
    "\n",
    "            # sample a mini-batch of real images\n",
    "            x = get_data_batch(train, batch_size, data_dim)\n",
    "\n",
    "            # generate a batch of images with the current generator\n",
    "            g_z = generator_model.predict(z)\n",
    "\n",
    "            # update φ by taking an SGD step on mini-batch loss LD(φ)\n",
    "            disc_loss_real = np.append(disc_loss_real, discriminator_model.train_on_batch(x, np.random.uniform(\n",
    "                low=0.7, high=1.2, size=batch_size)))\n",
    "            disc_loss_generated = np.append(disc_loss_generated, discriminator_model.train_on_batch(g_z,\n",
    "                np.random.uniform(low=0.0, high=0.3, size=batch_size)))\n",
    "\n",
    "\n",
    "        # train the generator\n",
    "        for _ in range(k_g):\n",
    "            z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, rand_dim))\n",
    "            # update θ by taking an SGD step on mini-batch loss LR(θ)\n",
    "            combined_loss = np.append(combined_loss, combined_model.train_on_batch(z, np.random.uniform(\n",
    "                low=0.7, high=1.2, size=batch_size)))\n",
    "\n",
    "        if not i % log_interval and i != 0:\n",
    "            K.set_learning_phase(0) # 0 = test\n",
    "\n",
    "#             g_z = generator_model.predict(fixed_noise)\n",
    "\n",
    "#             x = get_data_batch(train, batch_size, data_dim)\n",
    "\n",
    "            # log loss summary\n",
    "            print('Generator model loss: {}.'.format(np.mean(combined_loss[-log_interval:], axis=0)))\n",
    "            print('Discriminator model loss real: {}.'.format(np.mean(disc_loss_real[-log_interval:], axis=0)))\n",
    "            print('Discriminator model loss generated: {}.'.format(np.mean(disc_loss_generated[-log_interval:], axis=0)))\n",
    "            \n",
    "            \n",
    "            xgb_loss = CheckAccuracy( generator_model, 100, train )\n",
    "#             xgb_loss = CheckAccuracy( generator_model, 100, test )\n",
    "            xgb_losses = np.append(xgb_losses, xgb_loss)\n",
    "            print('xgboost accuracy: {}'.format(xgb_loss) )\n",
    "\n",
    "            # save model checkpoints\n",
    "            model_checkpoint_base_name = os.path.join(cache_dir, 'GAN_{}_model_weights_step_{}.h5')\n",
    "            generator_model.save_weights(model_checkpoint_base_name.format('generator', i))\n",
    "            discriminator_model.save_weights(model_checkpoint_base_name.format('discriminator', i))\n",
    "    \n",
    "    pickle.dump([combined_loss, disc_loss_real, disc_loss_generated, xgb_losses], \n",
    "                open(os.path.join(cache_dir, 'GAN_losses.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_111 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_112 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 28)                924       \n",
      "=================================================================\n",
      "Total params: 3,036\n",
      "Trainable params: 3,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_113 (LeakyReLU)  (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 32)                928       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_114 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_115 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,829\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,829\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            (None, 28)                3036      \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 2829      \n",
      "=================================================================\n",
      "Total params: 5,865\n",
      "Trainable params: 3,036\n",
      "Non-trainable params: 2,829\n",
      "_________________________________________________________________\n",
      "None\n",
      "Step: 0 of 5001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.4-py3.6.egg/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 of 5001.\n",
      "Step: 2 of 5001.\n",
      "Step: 3 of 5001.\n",
      "Step: 4 of 5001.\n",
      "Step: 5 of 5001.\n",
      "Step: 6 of 5001.\n",
      "Step: 7 of 5001.\n",
      "Step: 8 of 5001.\n",
      "Step: 9 of 5001.\n",
      "Step: 10 of 5001.\n",
      "Generator model loss: 8.52297601699829.\n",
      "Discriminator model loss real: 5.481720447540283.\n",
      "Discriminator model loss generated: 2.5841670632362366.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 11 of 5001.\n",
      "Step: 12 of 5001.\n",
      "Step: 13 of 5001.\n",
      "Step: 14 of 5001.\n",
      "Step: 15 of 5001.\n",
      "Step: 16 of 5001.\n",
      "Step: 17 of 5001.\n",
      "Step: 18 of 5001.\n",
      "Step: 19 of 5001.\n",
      "Step: 20 of 5001.\n",
      "Generator model loss: 7.576701498031616.\n",
      "Discriminator model loss real: 4.11926531791687.\n",
      "Discriminator model loss generated: 2.2801565647125246.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 21 of 5001.\n",
      "Step: 22 of 5001.\n",
      "Step: 23 of 5001.\n",
      "Step: 24 of 5001.\n",
      "Step: 25 of 5001.\n",
      "Step: 26 of 5001.\n",
      "Step: 27 of 5001.\n",
      "Step: 28 of 5001.\n",
      "Step: 29 of 5001.\n",
      "Step: 30 of 5001.\n",
      "Generator model loss: 7.320602130889893.\n",
      "Discriminator model loss real: 3.8863959074020387.\n",
      "Discriminator model loss generated: 2.309456706047058.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 31 of 5001.\n",
      "Step: 32 of 5001.\n",
      "Step: 33 of 5001.\n",
      "Step: 34 of 5001.\n",
      "Step: 35 of 5001.\n",
      "Step: 36 of 5001.\n",
      "Step: 37 of 5001.\n",
      "Step: 38 of 5001.\n",
      "Step: 39 of 5001.\n",
      "Step: 40 of 5001.\n",
      "Generator model loss: 6.243462991714478.\n",
      "Discriminator model loss real: 3.352349138259888.\n",
      "Discriminator model loss generated: 2.610639441013336.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 41 of 5001.\n",
      "Step: 42 of 5001.\n",
      "Step: 43 of 5001.\n",
      "Step: 44 of 5001.\n",
      "Step: 45 of 5001.\n",
      "Step: 46 of 5001.\n",
      "Step: 47 of 5001.\n",
      "Step: 48 of 5001.\n",
      "Step: 49 of 5001.\n",
      "Step: 50 of 5001.\n",
      "Generator model loss: 6.817150259017945.\n",
      "Discriminator model loss real: 2.768255519866943.\n",
      "Discriminator model loss generated: 2.4705485224723818.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 51 of 5001.\n",
      "Step: 52 of 5001.\n",
      "Step: 53 of 5001.\n",
      "Step: 54 of 5001.\n",
      "Step: 55 of 5001.\n",
      "Step: 56 of 5001.\n",
      "Step: 57 of 5001.\n",
      "Step: 58 of 5001.\n",
      "Step: 59 of 5001.\n",
      "Step: 60 of 5001.\n",
      "Generator model loss: 5.818758964538574.\n",
      "Discriminator model loss real: 2.61767897605896.\n",
      "Discriminator model loss generated: 2.2949303150177003.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 61 of 5001.\n",
      "Step: 62 of 5001.\n",
      "Step: 63 of 5001.\n",
      "Step: 64 of 5001.\n",
      "Step: 65 of 5001.\n",
      "Step: 66 of 5001.\n",
      "Step: 67 of 5001.\n",
      "Step: 68 of 5001.\n",
      "Step: 69 of 5001.\n",
      "Step: 70 of 5001.\n",
      "Generator model loss: 5.262163496017456.\n",
      "Discriminator model loss real: 2.3686058640480043.\n",
      "Discriminator model loss generated: 2.123641812801361.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 71 of 5001.\n",
      "Step: 72 of 5001.\n",
      "Step: 73 of 5001.\n",
      "Step: 74 of 5001.\n",
      "Step: 75 of 5001.\n",
      "Step: 76 of 5001.\n",
      "Step: 77 of 5001.\n",
      "Step: 78 of 5001.\n",
      "Step: 79 of 5001.\n",
      "Step: 80 of 5001.\n",
      "Generator model loss: 5.1482401371002195.\n",
      "Discriminator model loss real: 2.3415998816490173.\n",
      "Discriminator model loss generated: 2.29139107465744.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 81 of 5001.\n",
      "Step: 82 of 5001.\n",
      "Step: 83 of 5001.\n",
      "Step: 84 of 5001.\n",
      "Step: 85 of 5001.\n",
      "Step: 86 of 5001.\n",
      "Step: 87 of 5001.\n",
      "Step: 88 of 5001.\n",
      "Step: 89 of 5001.\n",
      "Step: 90 of 5001.\n",
      "Generator model loss: 5.537790083885193.\n",
      "Discriminator model loss real: 2.2477116703987123.\n",
      "Discriminator model loss generated: 2.2880311489105223.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 91 of 5001.\n",
      "Step: 92 of 5001.\n",
      "Step: 93 of 5001.\n",
      "Step: 94 of 5001.\n",
      "Step: 95 of 5001.\n",
      "Step: 96 of 5001.\n",
      "Step: 97 of 5001.\n",
      "Step: 98 of 5001.\n",
      "Step: 99 of 5001.\n",
      "Step: 100 of 5001.\n",
      "Generator model loss: 5.080210828781128.\n",
      "Discriminator model loss real: 2.3200456142425536.\n",
      "Discriminator model loss generated: 2.2091296553611754.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 101 of 5001.\n",
      "Step: 102 of 5001.\n",
      "Step: 103 of 5001.\n",
      "Step: 104 of 5001.\n",
      "Step: 105 of 5001.\n",
      "Step: 106 of 5001.\n",
      "Step: 107 of 5001.\n",
      "Step: 108 of 5001.\n",
      "Step: 109 of 5001.\n",
      "Step: 110 of 5001.\n",
      "Generator model loss: 4.486161994934082.\n",
      "Discriminator model loss real: 1.8638703227043152.\n",
      "Discriminator model loss generated: 2.1245404958724974.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 111 of 5001.\n",
      "Step: 112 of 5001.\n",
      "Step: 113 of 5001.\n",
      "Step: 114 of 5001.\n",
      "Step: 115 of 5001.\n",
      "Step: 116 of 5001.\n",
      "Step: 117 of 5001.\n",
      "Step: 118 of 5001.\n",
      "Step: 119 of 5001.\n",
      "Step: 120 of 5001.\n",
      "Generator model loss: 4.786600255966187.\n",
      "Discriminator model loss real: 1.9637007474899293.\n",
      "Discriminator model loss generated: 2.002250611782074.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 121 of 5001.\n",
      "Step: 122 of 5001.\n",
      "Step: 123 of 5001.\n",
      "Step: 124 of 5001.\n",
      "Step: 125 of 5001.\n",
      "Step: 126 of 5001.\n",
      "Step: 127 of 5001.\n",
      "Step: 128 of 5001.\n",
      "Step: 129 of 5001.\n",
      "Step: 130 of 5001.\n",
      "Generator model loss: 4.571520876884461.\n",
      "Discriminator model loss real: 2.0709953546524047.\n",
      "Discriminator model loss generated: 2.0646620750427247.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 131 of 5001.\n",
      "Step: 132 of 5001.\n",
      "Step: 133 of 5001.\n",
      "Step: 134 of 5001.\n",
      "Step: 135 of 5001.\n",
      "Step: 136 of 5001.\n",
      "Step: 137 of 5001.\n",
      "Step: 138 of 5001.\n",
      "Step: 139 of 5001.\n",
      "Step: 140 of 5001.\n",
      "Generator model loss: 4.772676086425781.\n",
      "Discriminator model loss real: 1.6750060677528382.\n",
      "Discriminator model loss generated: 1.9173168301582337.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 141 of 5001.\n",
      "Step: 142 of 5001.\n",
      "Step: 143 of 5001.\n",
      "Step: 144 of 5001.\n",
      "Step: 145 of 5001.\n",
      "Step: 146 of 5001.\n",
      "Step: 147 of 5001.\n",
      "Step: 148 of 5001.\n",
      "Step: 149 of 5001.\n",
      "Step: 150 of 5001.\n",
      "Generator model loss: 4.248958015441895.\n",
      "Discriminator model loss real: 1.6882396340370178.\n",
      "Discriminator model loss generated: 1.7619063138961792.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 151 of 5001.\n",
      "Step: 152 of 5001.\n",
      "Step: 153 of 5001.\n",
      "Step: 154 of 5001.\n",
      "Step: 155 of 5001.\n",
      "Step: 156 of 5001.\n",
      "Step: 157 of 5001.\n",
      "Step: 158 of 5001.\n",
      "Step: 159 of 5001.\n",
      "Step: 160 of 5001.\n",
      "Generator model loss: 4.085634350776672.\n",
      "Discriminator model loss real: 1.6856592655181886.\n",
      "Discriminator model loss generated: 1.7610179901123046.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 161 of 5001.\n",
      "Step: 162 of 5001.\n",
      "Step: 163 of 5001.\n",
      "Step: 164 of 5001.\n",
      "Step: 165 of 5001.\n",
      "Step: 166 of 5001.\n",
      "Step: 167 of 5001.\n",
      "Step: 168 of 5001.\n",
      "Step: 169 of 5001.\n",
      "Step: 170 of 5001.\n",
      "Generator model loss: 4.123955321311951.\n",
      "Discriminator model loss real: 1.585937488079071.\n",
      "Discriminator model loss generated: 1.7538129806518554.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 171 of 5001.\n",
      "Step: 172 of 5001.\n",
      "Step: 173 of 5001.\n",
      "Step: 174 of 5001.\n",
      "Step: 175 of 5001.\n",
      "Step: 176 of 5001.\n",
      "Step: 177 of 5001.\n",
      "Step: 178 of 5001.\n",
      "Step: 179 of 5001.\n",
      "Step: 180 of 5001.\n",
      "Generator model loss: 3.598471260070801.\n",
      "Discriminator model loss real: 1.575414252281189.\n",
      "Discriminator model loss generated: 1.9158530831336975.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 181 of 5001.\n",
      "Step: 182 of 5001.\n",
      "Step: 183 of 5001.\n",
      "Step: 184 of 5001.\n",
      "Step: 185 of 5001.\n",
      "Step: 186 of 5001.\n",
      "Step: 187 of 5001.\n",
      "Step: 188 of 5001.\n",
      "Step: 189 of 5001.\n",
      "Step: 190 of 5001.\n",
      "Generator model loss: 3.7598177433013915.\n",
      "Discriminator model loss real: 1.3799487829208374.\n",
      "Discriminator model loss generated: 1.8967277526855468.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 191 of 5001.\n",
      "Step: 192 of 5001.\n",
      "Step: 193 of 5001.\n",
      "Step: 194 of 5001.\n",
      "Step: 195 of 5001.\n",
      "Step: 196 of 5001.\n",
      "Step: 197 of 5001.\n",
      "Step: 198 of 5001.\n",
      "Step: 199 of 5001.\n",
      "Step: 200 of 5001.\n",
      "Generator model loss: 3.732723045349121.\n",
      "Discriminator model loss real: 1.484638863801956.\n",
      "Discriminator model loss generated: 1.6931998491287232.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 201 of 5001.\n",
      "Step: 202 of 5001.\n",
      "Step: 203 of 5001.\n",
      "Step: 204 of 5001.\n",
      "Step: 205 of 5001.\n",
      "Step: 206 of 5001.\n",
      "Step: 207 of 5001.\n",
      "Step: 208 of 5001.\n",
      "Step: 209 of 5001.\n",
      "Step: 210 of 5001.\n",
      "Generator model loss: 3.9961193561553956.\n",
      "Discriminator model loss real: 1.306263703107834.\n",
      "Discriminator model loss generated: 1.4908689260482788.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 211 of 5001.\n",
      "Step: 212 of 5001.\n",
      "Step: 213 of 5001.\n",
      "Step: 214 of 5001.\n",
      "Step: 215 of 5001.\n",
      "Step: 216 of 5001.\n",
      "Step: 217 of 5001.\n",
      "Step: 218 of 5001.\n",
      "Step: 219 of 5001.\n",
      "Step: 220 of 5001.\n",
      "Generator model loss: 3.5876781940460205.\n",
      "Discriminator model loss real: 1.3445351481437684.\n",
      "Discriminator model loss generated: 1.6502992749214171.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 221 of 5001.\n",
      "Step: 222 of 5001.\n",
      "Step: 223 of 5001.\n",
      "Step: 224 of 5001.\n",
      "Step: 225 of 5001.\n",
      "Step: 226 of 5001.\n",
      "Step: 227 of 5001.\n",
      "Step: 228 of 5001.\n",
      "Step: 229 of 5001.\n",
      "Step: 230 of 5001.\n",
      "Generator model loss: 3.510370302200317.\n",
      "Discriminator model loss real: 1.344847846031189.\n",
      "Discriminator model loss generated: 1.4164404273033142.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 231 of 5001.\n",
      "Step: 232 of 5001.\n",
      "Step: 233 of 5001.\n",
      "Step: 234 of 5001.\n",
      "Step: 235 of 5001.\n",
      "Step: 236 of 5001.\n",
      "Step: 237 of 5001.\n",
      "Step: 238 of 5001.\n",
      "Step: 239 of 5001.\n",
      "Step: 240 of 5001.\n",
      "Generator model loss: 3.534187340736389.\n",
      "Discriminator model loss real: 1.4442891240119935.\n",
      "Discriminator model loss generated: 1.749246394634247.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 241 of 5001.\n",
      "Step: 242 of 5001.\n",
      "Step: 243 of 5001.\n",
      "Step: 244 of 5001.\n",
      "Step: 245 of 5001.\n",
      "Step: 246 of 5001.\n",
      "Step: 247 of 5001.\n",
      "Step: 248 of 5001.\n",
      "Step: 249 of 5001.\n",
      "Step: 250 of 5001.\n",
      "Generator model loss: 3.2957210540771484.\n",
      "Discriminator model loss real: 1.1779528200626372.\n",
      "Discriminator model loss generated: 1.5471951842308045.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 251 of 5001.\n",
      "Step: 252 of 5001.\n",
      "Step: 253 of 5001.\n",
      "Step: 254 of 5001.\n",
      "Step: 255 of 5001.\n",
      "Step: 256 of 5001.\n",
      "Step: 257 of 5001.\n",
      "Step: 258 of 5001.\n",
      "Step: 259 of 5001.\n",
      "Step: 260 of 5001.\n",
      "Generator model loss: 2.940138804912567.\n",
      "Discriminator model loss real: 1.3293468594551086.\n",
      "Discriminator model loss generated: 1.3383763313293457.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 261 of 5001.\n",
      "Step: 262 of 5001.\n",
      "Step: 263 of 5001.\n",
      "Step: 264 of 5001.\n",
      "Step: 265 of 5001.\n",
      "Step: 266 of 5001.\n",
      "Step: 267 of 5001.\n",
      "Step: 268 of 5001.\n",
      "Step: 269 of 5001.\n",
      "Step: 270 of 5001.\n",
      "Generator model loss: 3.013799548149109.\n",
      "Discriminator model loss real: 1.2356634438037872.\n",
      "Discriminator model loss generated: 1.4120009660720825.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 271 of 5001.\n",
      "Step: 272 of 5001.\n",
      "Step: 273 of 5001.\n",
      "Step: 274 of 5001.\n",
      "Step: 275 of 5001.\n",
      "Step: 276 of 5001.\n",
      "Step: 277 of 5001.\n",
      "Step: 278 of 5001.\n",
      "Step: 279 of 5001.\n",
      "Step: 280 of 5001.\n",
      "Generator model loss: 2.9530068397521974.\n",
      "Discriminator model loss real: 1.1887374937534332.\n",
      "Discriminator model loss generated: 1.3623972713947297.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 281 of 5001.\n",
      "Step: 282 of 5001.\n",
      "Step: 283 of 5001.\n",
      "Step: 284 of 5001.\n",
      "Step: 285 of 5001.\n",
      "Step: 286 of 5001.\n",
      "Step: 287 of 5001.\n",
      "Step: 288 of 5001.\n",
      "Step: 289 of 5001.\n",
      "Step: 290 of 5001.\n",
      "Generator model loss: 3.048613739013672.\n",
      "Discriminator model loss real: 1.1463745832443237.\n",
      "Discriminator model loss generated: 1.2713619410991668.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 291 of 5001.\n",
      "Step: 292 of 5001.\n",
      "Step: 293 of 5001.\n",
      "Step: 294 of 5001.\n",
      "Step: 295 of 5001.\n",
      "Step: 296 of 5001.\n",
      "Step: 297 of 5001.\n",
      "Step: 298 of 5001.\n",
      "Step: 299 of 5001.\n",
      "Step: 300 of 5001.\n",
      "Generator model loss: 2.779985773563385.\n",
      "Discriminator model loss real: 1.2056176722049714.\n",
      "Discriminator model loss generated: 1.2899482607841493.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 301 of 5001.\n",
      "Step: 302 of 5001.\n",
      "Step: 303 of 5001.\n",
      "Step: 304 of 5001.\n",
      "Step: 305 of 5001.\n",
      "Step: 306 of 5001.\n",
      "Step: 307 of 5001.\n",
      "Step: 308 of 5001.\n",
      "Step: 309 of 5001.\n",
      "Step: 310 of 5001.\n",
      "Generator model loss: 2.7422549962997436.\n",
      "Discriminator model loss real: 0.9975640177726746.\n",
      "Discriminator model loss generated: 1.3749713540077209.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 311 of 5001.\n",
      "Step: 312 of 5001.\n",
      "Step: 313 of 5001.\n",
      "Step: 314 of 5001.\n",
      "Step: 315 of 5001.\n",
      "Step: 316 of 5001.\n",
      "Step: 317 of 5001.\n",
      "Step: 318 of 5001.\n",
      "Step: 319 of 5001.\n",
      "Step: 320 of 5001.\n",
      "Generator model loss: 2.698746621608734.\n",
      "Discriminator model loss real: 1.2784451842308044.\n",
      "Discriminator model loss generated: 1.2499096751213075.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 321 of 5001.\n",
      "Step: 322 of 5001.\n",
      "Step: 323 of 5001.\n",
      "Step: 324 of 5001.\n",
      "Step: 325 of 5001.\n",
      "Step: 326 of 5001.\n",
      "Step: 327 of 5001.\n",
      "Step: 328 of 5001.\n",
      "Step: 329 of 5001.\n",
      "Step: 330 of 5001.\n",
      "Generator model loss: 2.29193629026413.\n",
      "Discriminator model loss real: 0.859802109003067.\n",
      "Discriminator model loss generated: 1.271907490491867.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 331 of 5001.\n",
      "Step: 332 of 5001.\n",
      "Step: 333 of 5001.\n",
      "Step: 334 of 5001.\n",
      "Step: 335 of 5001.\n",
      "Step: 336 of 5001.\n",
      "Step: 337 of 5001.\n",
      "Step: 338 of 5001.\n",
      "Step: 339 of 5001.\n",
      "Step: 340 of 5001.\n",
      "Generator model loss: 2.37664874792099.\n",
      "Discriminator model loss real: 0.9043059796094894.\n",
      "Discriminator model loss generated: 1.1136099338531493.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 341 of 5001.\n",
      "Step: 342 of 5001.\n",
      "Step: 343 of 5001.\n",
      "Step: 344 of 5001.\n",
      "Step: 345 of 5001.\n",
      "Step: 346 of 5001.\n",
      "Step: 347 of 5001.\n",
      "Step: 348 of 5001.\n",
      "Step: 349 of 5001.\n",
      "Step: 350 of 5001.\n",
      "Generator model loss: 2.4536890506744387.\n",
      "Discriminator model loss real: 0.8962283283472061.\n",
      "Discriminator model loss generated: 1.1719061374664306.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 351 of 5001.\n",
      "Step: 352 of 5001.\n",
      "Step: 353 of 5001.\n",
      "Step: 354 of 5001.\n",
      "Step: 355 of 5001.\n",
      "Step: 356 of 5001.\n",
      "Step: 357 of 5001.\n",
      "Step: 358 of 5001.\n",
      "Step: 359 of 5001.\n",
      "Step: 360 of 5001.\n",
      "Generator model loss: 2.053477644920349.\n",
      "Discriminator model loss real: 1.1174024105072022.\n",
      "Discriminator model loss generated: 1.0053309082984925.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 361 of 5001.\n",
      "Step: 362 of 5001.\n",
      "Step: 363 of 5001.\n",
      "Step: 364 of 5001.\n",
      "Step: 365 of 5001.\n",
      "Step: 366 of 5001.\n",
      "Step: 367 of 5001.\n",
      "Step: 368 of 5001.\n",
      "Step: 369 of 5001.\n",
      "Step: 370 of 5001.\n",
      "Generator model loss: 2.0901856780052186.\n",
      "Discriminator model loss real: 0.981558832526207.\n",
      "Discriminator model loss generated: 1.1649864792823792.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 371 of 5001.\n",
      "Step: 372 of 5001.\n",
      "Step: 373 of 5001.\n",
      "Step: 374 of 5001.\n",
      "Step: 375 of 5001.\n",
      "Step: 376 of 5001.\n",
      "Step: 377 of 5001.\n",
      "Step: 378 of 5001.\n",
      "Step: 379 of 5001.\n",
      "Step: 380 of 5001.\n",
      "Generator model loss: 2.243101453781128.\n",
      "Discriminator model loss real: 0.9168304830789566.\n",
      "Discriminator model loss generated: 1.1084551095962525.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 381 of 5001.\n",
      "Step: 382 of 5001.\n",
      "Step: 383 of 5001.\n",
      "Step: 384 of 5001.\n",
      "Step: 385 of 5001.\n",
      "Step: 386 of 5001.\n",
      "Step: 387 of 5001.\n",
      "Step: 388 of 5001.\n",
      "Step: 389 of 5001.\n",
      "Step: 390 of 5001.\n",
      "Generator model loss: 2.224876368045807.\n",
      "Discriminator model loss real: 0.8984819233417511.\n",
      "Discriminator model loss generated: 0.9223970592021942.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 391 of 5001.\n",
      "Step: 392 of 5001.\n",
      "Step: 393 of 5001.\n",
      "Step: 394 of 5001.\n",
      "Step: 395 of 5001.\n",
      "Step: 396 of 5001.\n",
      "Step: 397 of 5001.\n",
      "Step: 398 of 5001.\n",
      "Step: 399 of 5001.\n",
      "Step: 400 of 5001.\n",
      "Generator model loss: 2.0953875541687013.\n",
      "Discriminator model loss real: 0.9338661789894104.\n",
      "Discriminator model loss generated: 0.932848471403122.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 401 of 5001.\n",
      "Step: 402 of 5001.\n",
      "Step: 403 of 5001.\n",
      "Step: 404 of 5001.\n",
      "Step: 405 of 5001.\n",
      "Step: 406 of 5001.\n",
      "Step: 407 of 5001.\n",
      "Step: 408 of 5001.\n",
      "Step: 409 of 5001.\n",
      "Step: 410 of 5001.\n",
      "Generator model loss: 1.9699456810951232.\n",
      "Discriminator model loss real: 0.8217763334512711.\n",
      "Discriminator model loss generated: 0.945520156621933.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 411 of 5001.\n",
      "Step: 412 of 5001.\n",
      "Step: 413 of 5001.\n",
      "Step: 414 of 5001.\n",
      "Step: 415 of 5001.\n",
      "Step: 416 of 5001.\n",
      "Step: 417 of 5001.\n",
      "Step: 418 of 5001.\n",
      "Step: 419 of 5001.\n",
      "Step: 420 of 5001.\n",
      "Generator model loss: 1.8787430763244628.\n",
      "Discriminator model loss real: 0.9939504951238632.\n",
      "Discriminator model loss generated: 0.8078991770744324.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 421 of 5001.\n",
      "Step: 422 of 5001.\n",
      "Step: 423 of 5001.\n",
      "Step: 424 of 5001.\n",
      "Step: 425 of 5001.\n",
      "Step: 426 of 5001.\n",
      "Step: 427 of 5001.\n",
      "Step: 428 of 5001.\n",
      "Step: 429 of 5001.\n",
      "Step: 430 of 5001.\n",
      "Generator model loss: 1.8901675462722778.\n",
      "Discriminator model loss real: 0.9101979285478592.\n",
      "Discriminator model loss generated: 0.901184594631195.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 431 of 5001.\n",
      "Step: 432 of 5001.\n",
      "Step: 433 of 5001.\n",
      "Step: 434 of 5001.\n",
      "Step: 435 of 5001.\n",
      "Step: 436 of 5001.\n",
      "Step: 437 of 5001.\n",
      "Step: 438 of 5001.\n",
      "Step: 439 of 5001.\n",
      "Step: 440 of 5001.\n",
      "Generator model loss: 1.739468514919281.\n",
      "Discriminator model loss real: 0.7910294473171234.\n",
      "Discriminator model loss generated: 0.864565771818161.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 441 of 5001.\n",
      "Step: 442 of 5001.\n",
      "Step: 443 of 5001.\n",
      "Step: 444 of 5001.\n",
      "Step: 445 of 5001.\n",
      "Step: 446 of 5001.\n",
      "Step: 447 of 5001.\n",
      "Step: 448 of 5001.\n",
      "Step: 449 of 5001.\n",
      "Step: 450 of 5001.\n",
      "Generator model loss: 1.7056468725204468.\n",
      "Discriminator model loss real: 0.928022849559784.\n",
      "Discriminator model loss generated: 0.8370132386684418.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 451 of 5001.\n",
      "Step: 452 of 5001.\n",
      "Step: 453 of 5001.\n",
      "Step: 454 of 5001.\n",
      "Step: 455 of 5001.\n",
      "Step: 456 of 5001.\n",
      "Step: 457 of 5001.\n",
      "Step: 458 of 5001.\n",
      "Step: 459 of 5001.\n",
      "Step: 460 of 5001.\n",
      "Generator model loss: 1.8455758810043335.\n",
      "Discriminator model loss real: 0.829610800743103.\n",
      "Discriminator model loss generated: 0.8481625616550446.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 461 of 5001.\n",
      "Step: 462 of 5001.\n",
      "Step: 463 of 5001.\n",
      "Step: 464 of 5001.\n",
      "Step: 465 of 5001.\n",
      "Step: 466 of 5001.\n",
      "Step: 467 of 5001.\n",
      "Step: 468 of 5001.\n",
      "Step: 469 of 5001.\n",
      "Step: 470 of 5001.\n",
      "Generator model loss: 1.7142928004264832.\n",
      "Discriminator model loss real: 0.8901889830827713.\n",
      "Discriminator model loss generated: 0.7972848057746887.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 471 of 5001.\n",
      "Step: 472 of 5001.\n",
      "Step: 473 of 5001.\n",
      "Step: 474 of 5001.\n",
      "Step: 475 of 5001.\n",
      "Step: 476 of 5001.\n",
      "Step: 477 of 5001.\n",
      "Step: 478 of 5001.\n",
      "Step: 479 of 5001.\n",
      "Step: 480 of 5001.\n",
      "Generator model loss: 1.8530899643898011.\n",
      "Discriminator model loss real: 0.9510859563946724.\n",
      "Discriminator model loss generated: 0.7834637880325317.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 481 of 5001.\n",
      "Step: 482 of 5001.\n",
      "Step: 483 of 5001.\n",
      "Step: 484 of 5001.\n",
      "Step: 485 of 5001.\n",
      "Step: 486 of 5001.\n",
      "Step: 487 of 5001.\n",
      "Step: 488 of 5001.\n",
      "Step: 489 of 5001.\n",
      "Step: 490 of 5001.\n",
      "Generator model loss: 1.4547314763069152.\n",
      "Discriminator model loss real: 0.820111346244812.\n",
      "Discriminator model loss generated: 0.7189315497875214.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 491 of 5001.\n",
      "Step: 492 of 5001.\n",
      "Step: 493 of 5001.\n",
      "Step: 494 of 5001.\n",
      "Step: 495 of 5001.\n",
      "Step: 496 of 5001.\n",
      "Step: 497 of 5001.\n",
      "Step: 498 of 5001.\n",
      "Step: 499 of 5001.\n",
      "Step: 500 of 5001.\n",
      "Generator model loss: 1.4863083839416504.\n",
      "Discriminator model loss real: 0.877087190747261.\n",
      "Discriminator model loss generated: 0.7473493039608001.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 501 of 5001.\n",
      "Step: 502 of 5001.\n",
      "Step: 503 of 5001.\n",
      "Step: 504 of 5001.\n",
      "Step: 505 of 5001.\n",
      "Step: 506 of 5001.\n",
      "Step: 507 of 5001.\n",
      "Step: 508 of 5001.\n",
      "Step: 509 of 5001.\n",
      "Step: 510 of 5001.\n",
      "Generator model loss: 1.5690949082374572.\n",
      "Discriminator model loss real: 0.76091068983078.\n",
      "Discriminator model loss generated: 0.8345953583717346.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 511 of 5001.\n",
      "Step: 512 of 5001.\n",
      "Step: 513 of 5001.\n",
      "Step: 514 of 5001.\n",
      "Step: 515 of 5001.\n",
      "Step: 516 of 5001.\n",
      "Step: 517 of 5001.\n",
      "Step: 518 of 5001.\n",
      "Step: 519 of 5001.\n",
      "Step: 520 of 5001.\n",
      "Generator model loss: 1.4882859230041503.\n",
      "Discriminator model loss real: 0.8275203019380569.\n",
      "Discriminator model loss generated: 0.7015957236289978.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 521 of 5001.\n",
      "Step: 522 of 5001.\n",
      "Step: 523 of 5001.\n",
      "Step: 524 of 5001.\n",
      "Step: 525 of 5001.\n",
      "Step: 526 of 5001.\n",
      "Step: 527 of 5001.\n",
      "Step: 528 of 5001.\n",
      "Step: 529 of 5001.\n",
      "Step: 530 of 5001.\n",
      "Generator model loss: 1.6861690402030944.\n",
      "Discriminator model loss real: 0.8368069916963577.\n",
      "Discriminator model loss generated: 0.7055718302726746.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 531 of 5001.\n",
      "Step: 532 of 5001.\n",
      "Step: 533 of 5001.\n",
      "Step: 534 of 5001.\n",
      "Step: 535 of 5001.\n",
      "Step: 536 of 5001.\n",
      "Step: 537 of 5001.\n",
      "Step: 538 of 5001.\n",
      "Step: 539 of 5001.\n",
      "Step: 540 of 5001.\n",
      "Generator model loss: 1.2758893609046935.\n",
      "Discriminator model loss real: 0.6924358606338501.\n",
      "Discriminator model loss generated: 0.6850580751895905.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 541 of 5001.\n",
      "Step: 542 of 5001.\n",
      "Step: 543 of 5001.\n",
      "Step: 544 of 5001.\n",
      "Step: 545 of 5001.\n",
      "Step: 546 of 5001.\n",
      "Step: 547 of 5001.\n",
      "Step: 548 of 5001.\n",
      "Step: 549 of 5001.\n",
      "Step: 550 of 5001.\n",
      "Generator model loss: 1.425968098640442.\n",
      "Discriminator model loss real: 0.7592666983604431.\n",
      "Discriminator model loss generated: 0.6838148176670075.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 551 of 5001.\n",
      "Step: 552 of 5001.\n",
      "Step: 553 of 5001.\n",
      "Step: 554 of 5001.\n",
      "Step: 555 of 5001.\n",
      "Step: 556 of 5001.\n",
      "Step: 557 of 5001.\n",
      "Step: 558 of 5001.\n",
      "Step: 559 of 5001.\n",
      "Step: 560 of 5001.\n",
      "Generator model loss: 1.4784558176994325.\n",
      "Discriminator model loss real: 0.7530054181814194.\n",
      "Discriminator model loss generated: 0.689591258764267.\n",
      "xgboost accuracy: 0.98\n",
      "Step: 561 of 5001.\n",
      "Step: 562 of 5001.\n",
      "Step: 563 of 5001.\n",
      "Step: 564 of 5001.\n",
      "Step: 565 of 5001.\n",
      "Step: 566 of 5001.\n",
      "Step: 567 of 5001.\n",
      "Step: 568 of 5001.\n",
      "Step: 569 of 5001.\n",
      "Step: 570 of 5001.\n",
      "Generator model loss: 1.4101188421249389.\n",
      "Discriminator model loss real: 0.7402198776602745.\n",
      "Discriminator model loss generated: 0.6755314469337463.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 571 of 5001.\n",
      "Step: 572 of 5001.\n",
      "Step: 573 of 5001.\n",
      "Step: 574 of 5001.\n",
      "Step: 575 of 5001.\n",
      "Step: 576 of 5001.\n",
      "Step: 577 of 5001.\n",
      "Step: 578 of 5001.\n",
      "Step: 579 of 5001.\n",
      "Step: 580 of 5001.\n",
      "Generator model loss: 1.4473294854164123.\n",
      "Discriminator model loss real: 0.7960563361644745.\n",
      "Discriminator model loss generated: 0.6663766920566558.\n",
      "xgboost accuracy: 0.98\n",
      "Step: 581 of 5001.\n",
      "Step: 582 of 5001.\n",
      "Step: 583 of 5001.\n",
      "Step: 584 of 5001.\n",
      "Step: 585 of 5001.\n",
      "Step: 586 of 5001.\n",
      "Step: 587 of 5001.\n",
      "Step: 588 of 5001.\n",
      "Step: 589 of 5001.\n",
      "Step: 590 of 5001.\n",
      "Generator model loss: 1.2882099509239198.\n",
      "Discriminator model loss real: 0.8702651053667069.\n",
      "Discriminator model loss generated: 0.6468268632888794.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 591 of 5001.\n",
      "Step: 592 of 5001.\n",
      "Step: 593 of 5001.\n",
      "Step: 594 of 5001.\n",
      "Step: 595 of 5001.\n",
      "Step: 596 of 5001.\n",
      "Step: 597 of 5001.\n",
      "Step: 598 of 5001.\n",
      "Step: 599 of 5001.\n",
      "Step: 600 of 5001.\n",
      "Generator model loss: 1.3553272128105163.\n",
      "Discriminator model loss real: 0.8476737529039383.\n",
      "Discriminator model loss generated: 0.6506068050861359.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 601 of 5001.\n",
      "Step: 602 of 5001.\n",
      "Step: 603 of 5001.\n",
      "Step: 604 of 5001.\n",
      "Step: 605 of 5001.\n",
      "Step: 606 of 5001.\n",
      "Step: 607 of 5001.\n",
      "Step: 608 of 5001.\n",
      "Step: 609 of 5001.\n",
      "Step: 610 of 5001.\n",
      "Generator model loss: 1.4108888387680054.\n",
      "Discriminator model loss real: 0.8029669165611267.\n",
      "Discriminator model loss generated: 0.6195207297801971.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 611 of 5001.\n",
      "Step: 612 of 5001.\n",
      "Step: 613 of 5001.\n",
      "Step: 614 of 5001.\n",
      "Step: 615 of 5001.\n",
      "Step: 616 of 5001.\n",
      "Step: 617 of 5001.\n",
      "Step: 618 of 5001.\n",
      "Step: 619 of 5001.\n",
      "Step: 620 of 5001.\n",
      "Generator model loss: 1.3283655405044557.\n",
      "Discriminator model loss real: 0.7513634011149406.\n",
      "Discriminator model loss generated: 0.6631886601448059.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 621 of 5001.\n",
      "Step: 622 of 5001.\n",
      "Step: 623 of 5001.\n",
      "Step: 624 of 5001.\n",
      "Step: 625 of 5001.\n",
      "Step: 626 of 5001.\n",
      "Step: 627 of 5001.\n",
      "Step: 628 of 5001.\n",
      "Step: 629 of 5001.\n",
      "Step: 630 of 5001.\n",
      "Generator model loss: 1.2836630582809447.\n",
      "Discriminator model loss real: 0.7780219465494156.\n",
      "Discriminator model loss generated: 0.6008359730243683.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 631 of 5001.\n",
      "Step: 632 of 5001.\n",
      "Step: 633 of 5001.\n",
      "Step: 634 of 5001.\n",
      "Step: 635 of 5001.\n",
      "Step: 636 of 5001.\n",
      "Step: 637 of 5001.\n",
      "Step: 638 of 5001.\n",
      "Step: 639 of 5001.\n",
      "Step: 640 of 5001.\n",
      "Generator model loss: 1.3694447517395019.\n",
      "Discriminator model loss real: 0.7815813332796097.\n",
      "Discriminator model loss generated: 0.5858339786529541.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 641 of 5001.\n",
      "Step: 642 of 5001.\n",
      "Step: 643 of 5001.\n",
      "Step: 644 of 5001.\n",
      "Step: 645 of 5001.\n",
      "Step: 646 of 5001.\n",
      "Step: 647 of 5001.\n",
      "Step: 648 of 5001.\n",
      "Step: 649 of 5001.\n",
      "Step: 650 of 5001.\n",
      "Generator model loss: 1.3160518646240233.\n",
      "Discriminator model loss real: 0.8215075880289078.\n",
      "Discriminator model loss generated: 0.6561472415924072.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 651 of 5001.\n",
      "Step: 652 of 5001.\n",
      "Step: 653 of 5001.\n",
      "Step: 654 of 5001.\n",
      "Step: 655 of 5001.\n",
      "Step: 656 of 5001.\n",
      "Step: 657 of 5001.\n",
      "Step: 658 of 5001.\n",
      "Step: 659 of 5001.\n",
      "Step: 660 of 5001.\n",
      "Generator model loss: 1.3283908367156982.\n",
      "Discriminator model loss real: 0.6661577165126801.\n",
      "Discriminator model loss generated: 0.6624829590320587.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 661 of 5001.\n",
      "Step: 662 of 5001.\n",
      "Step: 663 of 5001.\n",
      "Step: 664 of 5001.\n",
      "Step: 665 of 5001.\n",
      "Step: 666 of 5001.\n",
      "Step: 667 of 5001.\n",
      "Step: 668 of 5001.\n",
      "Step: 669 of 5001.\n",
      "Step: 670 of 5001.\n",
      "Generator model loss: 1.326325488090515.\n",
      "Discriminator model loss real: 0.784641420841217.\n",
      "Discriminator model loss generated: 0.5676744103431701.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 671 of 5001.\n",
      "Step: 672 of 5001.\n",
      "Step: 673 of 5001.\n",
      "Step: 674 of 5001.\n",
      "Step: 675 of 5001.\n",
      "Step: 676 of 5001.\n",
      "Step: 677 of 5001.\n",
      "Step: 678 of 5001.\n",
      "Step: 679 of 5001.\n",
      "Step: 680 of 5001.\n",
      "Generator model loss: 1.3760586261749268.\n",
      "Discriminator model loss real: 0.7018296033143997.\n",
      "Discriminator model loss generated: 0.6030256807804107.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 681 of 5001.\n",
      "Step: 682 of 5001.\n",
      "Step: 683 of 5001.\n",
      "Step: 684 of 5001.\n",
      "Step: 685 of 5001.\n",
      "Step: 686 of 5001.\n",
      "Step: 687 of 5001.\n",
      "Step: 688 of 5001.\n",
      "Step: 689 of 5001.\n",
      "Step: 690 of 5001.\n",
      "Generator model loss: 1.326462984085083.\n",
      "Discriminator model loss real: 0.7431070566177368.\n",
      "Discriminator model loss generated: 0.5880660206079483.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 691 of 5001.\n",
      "Step: 692 of 5001.\n",
      "Step: 693 of 5001.\n",
      "Step: 694 of 5001.\n",
      "Step: 695 of 5001.\n",
      "Step: 696 of 5001.\n",
      "Step: 697 of 5001.\n",
      "Step: 698 of 5001.\n",
      "Step: 699 of 5001.\n",
      "Step: 700 of 5001.\n",
      "Generator model loss: 1.2198747277259827.\n",
      "Discriminator model loss real: 0.7020560920238494.\n",
      "Discriminator model loss generated: 0.5853248536586761.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 701 of 5001.\n",
      "Step: 702 of 5001.\n",
      "Step: 703 of 5001.\n",
      "Step: 704 of 5001.\n",
      "Step: 705 of 5001.\n",
      "Step: 706 of 5001.\n",
      "Step: 707 of 5001.\n",
      "Step: 708 of 5001.\n",
      "Step: 709 of 5001.\n",
      "Step: 710 of 5001.\n",
      "Generator model loss: 1.2966758012771606.\n",
      "Discriminator model loss real: 0.7928946584463119.\n",
      "Discriminator model loss generated: 0.572976166009903.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 711 of 5001.\n",
      "Step: 712 of 5001.\n",
      "Step: 713 of 5001.\n",
      "Step: 714 of 5001.\n",
      "Step: 715 of 5001.\n",
      "Step: 716 of 5001.\n",
      "Step: 717 of 5001.\n",
      "Step: 718 of 5001.\n",
      "Step: 719 of 5001.\n",
      "Step: 720 of 5001.\n",
      "Generator model loss: 1.287398386001587.\n",
      "Discriminator model loss real: 0.8013291612267495.\n",
      "Discriminator model loss generated: 0.556778559088707.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 721 of 5001.\n",
      "Step: 722 of 5001.\n",
      "Step: 723 of 5001.\n",
      "Step: 724 of 5001.\n",
      "Step: 725 of 5001.\n",
      "Step: 726 of 5001.\n",
      "Step: 727 of 5001.\n",
      "Step: 728 of 5001.\n",
      "Step: 729 of 5001.\n",
      "Step: 730 of 5001.\n",
      "Generator model loss: 1.23602055311203.\n",
      "Discriminator model loss real: 0.732834480702877.\n",
      "Discriminator model loss generated: 0.6072963178157806.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 731 of 5001.\n",
      "Step: 732 of 5001.\n",
      "Step: 733 of 5001.\n",
      "Step: 734 of 5001.\n",
      "Step: 735 of 5001.\n",
      "Step: 736 of 5001.\n",
      "Step: 737 of 5001.\n",
      "Step: 738 of 5001.\n",
      "Step: 739 of 5001.\n",
      "Step: 740 of 5001.\n",
      "Generator model loss: 1.2485524415969849.\n",
      "Discriminator model loss real: 0.7358617693185806.\n",
      "Discriminator model loss generated: 0.6006249904632568.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 741 of 5001.\n",
      "Step: 742 of 5001.\n",
      "Step: 743 of 5001.\n",
      "Step: 744 of 5001.\n",
      "Step: 745 of 5001.\n",
      "Step: 746 of 5001.\n",
      "Step: 747 of 5001.\n",
      "Step: 748 of 5001.\n",
      "Step: 749 of 5001.\n",
      "Step: 750 of 5001.\n",
      "Generator model loss: 1.2599077343940734.\n",
      "Discriminator model loss real: 0.6751113355159759.\n",
      "Discriminator model loss generated: 0.5742455542087554.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 751 of 5001.\n",
      "Step: 752 of 5001.\n",
      "Step: 753 of 5001.\n",
      "Step: 754 of 5001.\n",
      "Step: 755 of 5001.\n",
      "Step: 756 of 5001.\n",
      "Step: 757 of 5001.\n",
      "Step: 758 of 5001.\n",
      "Step: 759 of 5001.\n",
      "Step: 760 of 5001.\n",
      "Generator model loss: 1.2079784393310546.\n",
      "Discriminator model loss real: 0.7246526837348938.\n",
      "Discriminator model loss generated: 0.5874325037002563.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 761 of 5001.\n",
      "Step: 762 of 5001.\n",
      "Step: 763 of 5001.\n",
      "Step: 764 of 5001.\n",
      "Step: 765 of 5001.\n",
      "Step: 766 of 5001.\n",
      "Step: 767 of 5001.\n",
      "Step: 768 of 5001.\n",
      "Step: 769 of 5001.\n",
      "Step: 770 of 5001.\n",
      "Generator model loss: 1.2032342433929444.\n",
      "Discriminator model loss real: 0.8070013582706451.\n",
      "Discriminator model loss generated: 0.6145772457122802.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 771 of 5001.\n",
      "Step: 772 of 5001.\n",
      "Step: 773 of 5001.\n",
      "Step: 774 of 5001.\n",
      "Step: 775 of 5001.\n",
      "Step: 776 of 5001.\n",
      "Step: 777 of 5001.\n",
      "Step: 778 of 5001.\n",
      "Step: 779 of 5001.\n",
      "Step: 780 of 5001.\n",
      "Generator model loss: 1.3036252975463867.\n",
      "Discriminator model loss real: 0.7312052071094512.\n",
      "Discriminator model loss generated: 0.601682847738266.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 781 of 5001.\n",
      "Step: 782 of 5001.\n",
      "Step: 783 of 5001.\n",
      "Step: 784 of 5001.\n",
      "Step: 785 of 5001.\n",
      "Step: 786 of 5001.\n",
      "Step: 787 of 5001.\n",
      "Step: 788 of 5001.\n",
      "Step: 789 of 5001.\n",
      "Step: 790 of 5001.\n",
      "Generator model loss: 1.2332711577415467.\n",
      "Discriminator model loss real: 0.7757600247859955.\n",
      "Discriminator model loss generated: 0.5524900525808334.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 791 of 5001.\n",
      "Step: 792 of 5001.\n",
      "Step: 793 of 5001.\n",
      "Step: 794 of 5001.\n",
      "Step: 795 of 5001.\n",
      "Step: 796 of 5001.\n",
      "Step: 797 of 5001.\n",
      "Step: 798 of 5001.\n",
      "Step: 799 of 5001.\n",
      "Step: 800 of 5001.\n",
      "Generator model loss: 1.2547109007835389.\n",
      "Discriminator model loss real: 0.7197660088539124.\n",
      "Discriminator model loss generated: 0.5850659132003784.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 801 of 5001.\n",
      "Step: 802 of 5001.\n",
      "Step: 803 of 5001.\n",
      "Step: 804 of 5001.\n",
      "Step: 805 of 5001.\n",
      "Step: 806 of 5001.\n",
      "Step: 807 of 5001.\n",
      "Step: 808 of 5001.\n",
      "Step: 809 of 5001.\n",
      "Step: 810 of 5001.\n",
      "Generator model loss: 1.2682599782943726.\n",
      "Discriminator model loss real: 0.7762733548879623.\n",
      "Discriminator model loss generated: 0.5763884603977203.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 811 of 5001.\n",
      "Step: 812 of 5001.\n",
      "Step: 813 of 5001.\n",
      "Step: 814 of 5001.\n",
      "Step: 815 of 5001.\n",
      "Step: 816 of 5001.\n",
      "Step: 817 of 5001.\n",
      "Step: 818 of 5001.\n",
      "Step: 819 of 5001.\n",
      "Step: 820 of 5001.\n",
      "Generator model loss: 1.30082848072052.\n",
      "Discriminator model loss real: 0.7038450792431832.\n",
      "Discriminator model loss generated: 0.5437575578689575.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 821 of 5001.\n",
      "Step: 822 of 5001.\n",
      "Step: 823 of 5001.\n",
      "Step: 824 of 5001.\n",
      "Step: 825 of 5001.\n",
      "Step: 826 of 5001.\n",
      "Step: 827 of 5001.\n",
      "Step: 828 of 5001.\n",
      "Step: 829 of 5001.\n",
      "Step: 830 of 5001.\n",
      "Generator model loss: 1.2865818619728089.\n",
      "Discriminator model loss real: 0.79266227632761.\n",
      "Discriminator model loss generated: 0.5516640543937683.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 831 of 5001.\n",
      "Step: 832 of 5001.\n",
      "Step: 833 of 5001.\n",
      "Step: 834 of 5001.\n",
      "Step: 835 of 5001.\n",
      "Step: 836 of 5001.\n",
      "Step: 837 of 5001.\n",
      "Step: 838 of 5001.\n",
      "Step: 839 of 5001.\n",
      "Step: 840 of 5001.\n",
      "Generator model loss: 1.2140985965728759.\n",
      "Discriminator model loss real: 0.8382822483778.\n",
      "Discriminator model loss generated: 0.5398770451545716.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 841 of 5001.\n",
      "Step: 842 of 5001.\n",
      "Step: 843 of 5001.\n",
      "Step: 844 of 5001.\n",
      "Step: 845 of 5001.\n",
      "Step: 846 of 5001.\n",
      "Step: 847 of 5001.\n",
      "Step: 848 of 5001.\n",
      "Step: 849 of 5001.\n",
      "Step: 850 of 5001.\n",
      "Generator model loss: 1.2936970591545105.\n",
      "Discriminator model loss real: 0.7074135363101959.\n",
      "Discriminator model loss generated: 0.5388560861349105.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 851 of 5001.\n",
      "Step: 852 of 5001.\n",
      "Step: 853 of 5001.\n",
      "Step: 854 of 5001.\n",
      "Step: 855 of 5001.\n",
      "Step: 856 of 5001.\n",
      "Step: 857 of 5001.\n",
      "Step: 858 of 5001.\n",
      "Step: 859 of 5001.\n",
      "Step: 860 of 5001.\n",
      "Generator model loss: 1.3305753469467163.\n",
      "Discriminator model loss real: 0.7304471880197525.\n",
      "Discriminator model loss generated: 0.5736617505550384.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 861 of 5001.\n",
      "Step: 862 of 5001.\n",
      "Step: 863 of 5001.\n",
      "Step: 864 of 5001.\n",
      "Step: 865 of 5001.\n",
      "Step: 866 of 5001.\n",
      "Step: 867 of 5001.\n",
      "Step: 868 of 5001.\n",
      "Step: 869 of 5001.\n",
      "Step: 870 of 5001.\n",
      "Generator model loss: 1.2493664145469665.\n",
      "Discriminator model loss real: 0.6818094223737716.\n",
      "Discriminator model loss generated: 0.5374258309602737.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 871 of 5001.\n",
      "Step: 872 of 5001.\n",
      "Step: 873 of 5001.\n",
      "Step: 874 of 5001.\n",
      "Step: 875 of 5001.\n",
      "Step: 876 of 5001.\n",
      "Step: 877 of 5001.\n",
      "Step: 878 of 5001.\n",
      "Step: 879 of 5001.\n",
      "Step: 880 of 5001.\n",
      "Generator model loss: 1.2673055171966552.\n",
      "Discriminator model loss real: 0.7802793204784393.\n",
      "Discriminator model loss generated: 0.6097393155097961.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 881 of 5001.\n",
      "Step: 882 of 5001.\n",
      "Step: 883 of 5001.\n",
      "Step: 884 of 5001.\n",
      "Step: 885 of 5001.\n",
      "Step: 886 of 5001.\n",
      "Step: 887 of 5001.\n",
      "Step: 888 of 5001.\n",
      "Step: 889 of 5001.\n",
      "Step: 890 of 5001.\n",
      "Generator model loss: 1.1867114901542664.\n",
      "Discriminator model loss real: 0.6848731264472008.\n",
      "Discriminator model loss generated: 0.5503793269395828.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 891 of 5001.\n",
      "Step: 892 of 5001.\n",
      "Step: 893 of 5001.\n",
      "Step: 894 of 5001.\n",
      "Step: 895 of 5001.\n",
      "Step: 896 of 5001.\n",
      "Step: 897 of 5001.\n",
      "Step: 898 of 5001.\n",
      "Step: 899 of 5001.\n",
      "Step: 900 of 5001.\n",
      "Generator model loss: 1.2731305241584778.\n",
      "Discriminator model loss real: 0.7695605307817459.\n",
      "Discriminator model loss generated: 0.5389343619346618.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 901 of 5001.\n",
      "Step: 902 of 5001.\n",
      "Step: 903 of 5001.\n",
      "Step: 904 of 5001.\n",
      "Step: 905 of 5001.\n",
      "Step: 906 of 5001.\n",
      "Step: 907 of 5001.\n",
      "Step: 908 of 5001.\n",
      "Step: 909 of 5001.\n",
      "Step: 910 of 5001.\n",
      "Generator model loss: 1.1838731646537781.\n",
      "Discriminator model loss real: 0.7208248823881149.\n",
      "Discriminator model loss generated: 0.561106550693512.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 911 of 5001.\n",
      "Step: 912 of 5001.\n",
      "Step: 913 of 5001.\n",
      "Step: 914 of 5001.\n",
      "Step: 915 of 5001.\n",
      "Step: 916 of 5001.\n",
      "Step: 917 of 5001.\n",
      "Step: 918 of 5001.\n",
      "Step: 919 of 5001.\n",
      "Step: 920 of 5001.\n",
      "Generator model loss: 1.291433537006378.\n",
      "Discriminator model loss real: 0.7436726212501525.\n",
      "Discriminator model loss generated: 0.5459376007318497.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 921 of 5001.\n",
      "Step: 922 of 5001.\n",
      "Step: 923 of 5001.\n",
      "Step: 924 of 5001.\n",
      "Step: 925 of 5001.\n",
      "Step: 926 of 5001.\n",
      "Step: 927 of 5001.\n",
      "Step: 928 of 5001.\n",
      "Step: 929 of 5001.\n",
      "Step: 930 of 5001.\n",
      "Generator model loss: 1.2140806794166565.\n",
      "Discriminator model loss real: 0.7311764687299729.\n",
      "Discriminator model loss generated: 0.5384872615337372.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 931 of 5001.\n",
      "Step: 932 of 5001.\n",
      "Step: 933 of 5001.\n",
      "Step: 934 of 5001.\n",
      "Step: 935 of 5001.\n",
      "Step: 936 of 5001.\n",
      "Step: 937 of 5001.\n",
      "Step: 938 of 5001.\n",
      "Step: 939 of 5001.\n",
      "Step: 940 of 5001.\n",
      "Generator model loss: 1.2026072144508362.\n",
      "Discriminator model loss real: 0.684342734515667.\n",
      "Discriminator model loss generated: 0.6040425002574921.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 941 of 5001.\n",
      "Step: 942 of 5001.\n",
      "Step: 943 of 5001.\n",
      "Step: 944 of 5001.\n",
      "Step: 945 of 5001.\n",
      "Step: 946 of 5001.\n",
      "Step: 947 of 5001.\n",
      "Step: 948 of 5001.\n",
      "Step: 949 of 5001.\n",
      "Step: 950 of 5001.\n",
      "Generator model loss: 1.2117950558662414.\n",
      "Discriminator model loss real: 0.742834247648716.\n",
      "Discriminator model loss generated: 0.5335836708545685.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 951 of 5001.\n",
      "Step: 952 of 5001.\n",
      "Step: 953 of 5001.\n",
      "Step: 954 of 5001.\n",
      "Step: 955 of 5001.\n",
      "Step: 956 of 5001.\n",
      "Step: 957 of 5001.\n",
      "Step: 958 of 5001.\n",
      "Step: 959 of 5001.\n",
      "Step: 960 of 5001.\n",
      "Generator model loss: 1.2056371927261353.\n",
      "Discriminator model loss real: 0.7124723300337792.\n",
      "Discriminator model loss generated: 0.5399674445390701.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 961 of 5001.\n",
      "Step: 962 of 5001.\n",
      "Step: 963 of 5001.\n",
      "Step: 964 of 5001.\n",
      "Step: 965 of 5001.\n",
      "Step: 966 of 5001.\n",
      "Step: 967 of 5001.\n",
      "Step: 968 of 5001.\n",
      "Step: 969 of 5001.\n",
      "Step: 970 of 5001.\n",
      "Generator model loss: 1.2245235323905945.\n",
      "Discriminator model loss real: 0.7350717961788178.\n",
      "Discriminator model loss generated: 0.5568558931350708.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 971 of 5001.\n",
      "Step: 972 of 5001.\n",
      "Step: 973 of 5001.\n",
      "Step: 974 of 5001.\n",
      "Step: 975 of 5001.\n",
      "Step: 976 of 5001.\n",
      "Step: 977 of 5001.\n",
      "Step: 978 of 5001.\n",
      "Step: 979 of 5001.\n",
      "Step: 980 of 5001.\n",
      "Generator model loss: 1.2621341943740845.\n",
      "Discriminator model loss real: 0.7255858451128006.\n",
      "Discriminator model loss generated: 0.5820298254489898.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 981 of 5001.\n",
      "Step: 982 of 5001.\n",
      "Step: 983 of 5001.\n",
      "Step: 984 of 5001.\n",
      "Step: 985 of 5001.\n",
      "Step: 986 of 5001.\n",
      "Step: 987 of 5001.\n",
      "Step: 988 of 5001.\n",
      "Step: 989 of 5001.\n",
      "Step: 990 of 5001.\n",
      "Generator model loss: 1.1990358591079713.\n",
      "Discriminator model loss real: 0.6933463841676712.\n",
      "Discriminator model loss generated: 0.5333075582981109.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 991 of 5001.\n",
      "Step: 992 of 5001.\n",
      "Step: 993 of 5001.\n",
      "Step: 994 of 5001.\n",
      "Step: 995 of 5001.\n",
      "Step: 996 of 5001.\n",
      "Step: 997 of 5001.\n",
      "Step: 998 of 5001.\n",
      "Step: 999 of 5001.\n",
      "Step: 1000 of 5001.\n",
      "Generator model loss: 1.2319810390472412.\n",
      "Discriminator model loss real: 0.7538447886705398.\n",
      "Discriminator model loss generated: 0.5577194154262543.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1001 of 5001.\n",
      "Step: 1002 of 5001.\n",
      "Step: 1003 of 5001.\n",
      "Step: 1004 of 5001.\n",
      "Step: 1005 of 5001.\n",
      "Step: 1006 of 5001.\n",
      "Step: 1007 of 5001.\n",
      "Step: 1008 of 5001.\n",
      "Step: 1009 of 5001.\n",
      "Step: 1010 of 5001.\n",
      "Generator model loss: 1.210016942024231.\n",
      "Discriminator model loss real: 0.6874373257160187.\n",
      "Discriminator model loss generated: 0.5807076275348664.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1011 of 5001.\n",
      "Step: 1012 of 5001.\n",
      "Step: 1013 of 5001.\n",
      "Step: 1014 of 5001.\n",
      "Step: 1015 of 5001.\n",
      "Step: 1016 of 5001.\n",
      "Step: 1017 of 5001.\n",
      "Step: 1018 of 5001.\n",
      "Step: 1019 of 5001.\n",
      "Step: 1020 of 5001.\n",
      "Generator model loss: 1.2250552415847777.\n",
      "Discriminator model loss real: 0.6708529651165008.\n",
      "Discriminator model loss generated: 0.5960792362689972.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1021 of 5001.\n",
      "Step: 1022 of 5001.\n",
      "Step: 1023 of 5001.\n",
      "Step: 1024 of 5001.\n",
      "Step: 1025 of 5001.\n",
      "Step: 1026 of 5001.\n",
      "Step: 1027 of 5001.\n",
      "Step: 1028 of 5001.\n",
      "Step: 1029 of 5001.\n",
      "Step: 1030 of 5001.\n",
      "Generator model loss: 1.2217509865760803.\n",
      "Discriminator model loss real: 0.7525347501039505.\n",
      "Discriminator model loss generated: 0.5555376648902893.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1031 of 5001.\n",
      "Step: 1032 of 5001.\n",
      "Step: 1033 of 5001.\n",
      "Step: 1034 of 5001.\n",
      "Step: 1035 of 5001.\n",
      "Step: 1036 of 5001.\n",
      "Step: 1037 of 5001.\n",
      "Step: 1038 of 5001.\n",
      "Step: 1039 of 5001.\n",
      "Step: 1040 of 5001.\n",
      "Generator model loss: 1.2269420146942138.\n",
      "Discriminator model loss real: 0.7036932826042175.\n",
      "Discriminator model loss generated: 0.5368228018283844.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1041 of 5001.\n",
      "Step: 1042 of 5001.\n",
      "Step: 1043 of 5001.\n",
      "Step: 1044 of 5001.\n",
      "Step: 1045 of 5001.\n",
      "Step: 1046 of 5001.\n",
      "Step: 1047 of 5001.\n",
      "Step: 1048 of 5001.\n",
      "Step: 1049 of 5001.\n",
      "Step: 1050 of 5001.\n",
      "Generator model loss: 1.2297695875167847.\n",
      "Discriminator model loss real: 0.6859159499406815.\n",
      "Discriminator model loss generated: 0.5960083484649659.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1051 of 5001.\n",
      "Step: 1052 of 5001.\n",
      "Step: 1053 of 5001.\n",
      "Step: 1054 of 5001.\n",
      "Step: 1055 of 5001.\n",
      "Step: 1056 of 5001.\n",
      "Step: 1057 of 5001.\n",
      "Step: 1058 of 5001.\n",
      "Step: 1059 of 5001.\n",
      "Step: 1060 of 5001.\n",
      "Generator model loss: 1.2207660913467406.\n",
      "Discriminator model loss real: 0.6599751293659211.\n",
      "Discriminator model loss generated: 0.5769161641597748.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1061 of 5001.\n",
      "Step: 1062 of 5001.\n",
      "Step: 1063 of 5001.\n",
      "Step: 1064 of 5001.\n",
      "Step: 1065 of 5001.\n",
      "Step: 1066 of 5001.\n",
      "Step: 1067 of 5001.\n",
      "Step: 1068 of 5001.\n",
      "Step: 1069 of 5001.\n",
      "Step: 1070 of 5001.\n",
      "Generator model loss: 1.232969617843628.\n",
      "Discriminator model loss real: 0.7357960149645806.\n",
      "Discriminator model loss generated: 0.5270806193351746.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1071 of 5001.\n",
      "Step: 1072 of 5001.\n",
      "Step: 1073 of 5001.\n",
      "Step: 1074 of 5001.\n",
      "Step: 1075 of 5001.\n",
      "Step: 1076 of 5001.\n",
      "Step: 1077 of 5001.\n",
      "Step: 1078 of 5001.\n",
      "Step: 1079 of 5001.\n",
      "Step: 1080 of 5001.\n",
      "Generator model loss: 1.252684485912323.\n",
      "Discriminator model loss real: 0.693841964006424.\n",
      "Discriminator model loss generated: 0.6290723741054535.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1081 of 5001.\n",
      "Step: 1082 of 5001.\n",
      "Step: 1083 of 5001.\n",
      "Step: 1084 of 5001.\n",
      "Step: 1085 of 5001.\n",
      "Step: 1086 of 5001.\n",
      "Step: 1087 of 5001.\n",
      "Step: 1088 of 5001.\n",
      "Step: 1089 of 5001.\n",
      "Step: 1090 of 5001.\n",
      "Generator model loss: 1.2787118554115295.\n",
      "Discriminator model loss real: 0.7430217057466507.\n",
      "Discriminator model loss generated: 0.5680841565132141.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1091 of 5001.\n",
      "Step: 1092 of 5001.\n",
      "Step: 1093 of 5001.\n",
      "Step: 1094 of 5001.\n",
      "Step: 1095 of 5001.\n",
      "Step: 1096 of 5001.\n",
      "Step: 1097 of 5001.\n",
      "Step: 1098 of 5001.\n",
      "Step: 1099 of 5001.\n",
      "Step: 1100 of 5001.\n",
      "Generator model loss: 1.191484010219574.\n",
      "Discriminator model loss real: 0.708133316040039.\n",
      "Discriminator model loss generated: 0.5326662063598633.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1101 of 5001.\n",
      "Step: 1102 of 5001.\n",
      "Step: 1103 of 5001.\n",
      "Step: 1104 of 5001.\n",
      "Step: 1105 of 5001.\n",
      "Step: 1106 of 5001.\n",
      "Step: 1107 of 5001.\n",
      "Step: 1108 of 5001.\n",
      "Step: 1109 of 5001.\n",
      "Step: 1110 of 5001.\n",
      "Generator model loss: 1.2201130390167236.\n",
      "Discriminator model loss real: 0.7181908160448074.\n",
      "Discriminator model loss generated: 0.5501536428928375.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1111 of 5001.\n",
      "Step: 1112 of 5001.\n",
      "Step: 1113 of 5001.\n",
      "Step: 1114 of 5001.\n",
      "Step: 1115 of 5001.\n",
      "Step: 1116 of 5001.\n",
      "Step: 1117 of 5001.\n",
      "Step: 1118 of 5001.\n",
      "Step: 1119 of 5001.\n",
      "Step: 1120 of 5001.\n",
      "Generator model loss: 1.221534514427185.\n",
      "Discriminator model loss real: 0.6820285826921463.\n",
      "Discriminator model loss generated: 0.549739271402359.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1121 of 5001.\n",
      "Step: 1122 of 5001.\n",
      "Step: 1123 of 5001.\n",
      "Step: 1124 of 5001.\n",
      "Step: 1125 of 5001.\n",
      "Step: 1126 of 5001.\n",
      "Step: 1127 of 5001.\n",
      "Step: 1128 of 5001.\n",
      "Step: 1129 of 5001.\n",
      "Step: 1130 of 5001.\n",
      "Generator model loss: 1.2371400833129882.\n",
      "Discriminator model loss real: 0.7577715665102005.\n",
      "Discriminator model loss generated: 0.5922391980886459.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1131 of 5001.\n",
      "Step: 1132 of 5001.\n",
      "Step: 1133 of 5001.\n",
      "Step: 1134 of 5001.\n",
      "Step: 1135 of 5001.\n",
      "Step: 1136 of 5001.\n",
      "Step: 1137 of 5001.\n",
      "Step: 1138 of 5001.\n",
      "Step: 1139 of 5001.\n",
      "Step: 1140 of 5001.\n",
      "Generator model loss: 1.2317711234092712.\n",
      "Discriminator model loss real: 0.6750000774860382.\n",
      "Discriminator model loss generated: 0.6257615208625793.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1141 of 5001.\n",
      "Step: 1142 of 5001.\n",
      "Step: 1143 of 5001.\n",
      "Step: 1144 of 5001.\n",
      "Step: 1145 of 5001.\n",
      "Step: 1146 of 5001.\n",
      "Step: 1147 of 5001.\n",
      "Step: 1148 of 5001.\n",
      "Step: 1149 of 5001.\n",
      "Step: 1150 of 5001.\n",
      "Generator model loss: 1.2666779160499573.\n",
      "Discriminator model loss real: 0.6887540072202682.\n",
      "Discriminator model loss generated: 0.5325775146484375.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1151 of 5001.\n",
      "Step: 1152 of 5001.\n",
      "Step: 1153 of 5001.\n",
      "Step: 1154 of 5001.\n",
      "Step: 1155 of 5001.\n",
      "Step: 1156 of 5001.\n",
      "Step: 1157 of 5001.\n",
      "Step: 1158 of 5001.\n",
      "Step: 1159 of 5001.\n",
      "Step: 1160 of 5001.\n",
      "Generator model loss: 1.2088937640190125.\n",
      "Discriminator model loss real: 0.7531301736831665.\n",
      "Discriminator model loss generated: 0.5404070496559144.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1161 of 5001.\n",
      "Step: 1162 of 5001.\n",
      "Step: 1163 of 5001.\n",
      "Step: 1164 of 5001.\n",
      "Step: 1165 of 5001.\n",
      "Step: 1166 of 5001.\n",
      "Step: 1167 of 5001.\n",
      "Step: 1168 of 5001.\n",
      "Step: 1169 of 5001.\n",
      "Step: 1170 of 5001.\n",
      "Generator model loss: 1.2450058460235596.\n",
      "Discriminator model loss real: 0.6864369928836822.\n",
      "Discriminator model loss generated: 0.5671655595302582.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1171 of 5001.\n",
      "Step: 1172 of 5001.\n",
      "Step: 1173 of 5001.\n",
      "Step: 1174 of 5001.\n",
      "Step: 1175 of 5001.\n",
      "Step: 1176 of 5001.\n",
      "Step: 1177 of 5001.\n",
      "Step: 1178 of 5001.\n",
      "Step: 1179 of 5001.\n",
      "Step: 1180 of 5001.\n",
      "Generator model loss: 1.2231300115585326.\n",
      "Discriminator model loss real: 0.6751094311475754.\n",
      "Discriminator model loss generated: 0.556090384721756.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1181 of 5001.\n",
      "Step: 1182 of 5001.\n",
      "Step: 1183 of 5001.\n",
      "Step: 1184 of 5001.\n",
      "Step: 1185 of 5001.\n",
      "Step: 1186 of 5001.\n",
      "Step: 1187 of 5001.\n",
      "Step: 1188 of 5001.\n",
      "Step: 1189 of 5001.\n",
      "Step: 1190 of 5001.\n",
      "Generator model loss: 1.2358219146728515.\n",
      "Discriminator model loss real: 0.6944375663995743.\n",
      "Discriminator model loss generated: 0.5980712234973907.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1191 of 5001.\n",
      "Step: 1192 of 5001.\n",
      "Step: 1193 of 5001.\n",
      "Step: 1194 of 5001.\n",
      "Step: 1195 of 5001.\n",
      "Step: 1196 of 5001.\n",
      "Step: 1197 of 5001.\n",
      "Step: 1198 of 5001.\n",
      "Step: 1199 of 5001.\n",
      "Step: 1200 of 5001.\n",
      "Generator model loss: 1.1940686106681824.\n",
      "Discriminator model loss real: 0.6794110983610153.\n",
      "Discriminator model loss generated: 0.5871162384748458.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1201 of 5001.\n",
      "Step: 1202 of 5001.\n",
      "Step: 1203 of 5001.\n",
      "Step: 1204 of 5001.\n",
      "Step: 1205 of 5001.\n",
      "Step: 1206 of 5001.\n",
      "Step: 1207 of 5001.\n",
      "Step: 1208 of 5001.\n",
      "Step: 1209 of 5001.\n",
      "Step: 1210 of 5001.\n",
      "Generator model loss: 1.2280558466911315.\n",
      "Discriminator model loss real: 0.7566398650407791.\n",
      "Discriminator model loss generated: 0.5751704454421998.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1211 of 5001.\n",
      "Step: 1212 of 5001.\n",
      "Step: 1213 of 5001.\n",
      "Step: 1214 of 5001.\n",
      "Step: 1215 of 5001.\n",
      "Step: 1216 of 5001.\n",
      "Step: 1217 of 5001.\n",
      "Step: 1218 of 5001.\n",
      "Step: 1219 of 5001.\n",
      "Step: 1220 of 5001.\n",
      "Generator model loss: 1.2097107529640199.\n",
      "Discriminator model loss real: 0.7239256024360656.\n",
      "Discriminator model loss generated: 0.5768635988235473.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1221 of 5001.\n",
      "Step: 1222 of 5001.\n",
      "Step: 1223 of 5001.\n",
      "Step: 1224 of 5001.\n",
      "Step: 1225 of 5001.\n",
      "Step: 1226 of 5001.\n",
      "Step: 1227 of 5001.\n",
      "Step: 1228 of 5001.\n",
      "Step: 1229 of 5001.\n",
      "Step: 1230 of 5001.\n",
      "Generator model loss: 1.1972428798675536.\n",
      "Discriminator model loss real: 0.6879956632852554.\n",
      "Discriminator model loss generated: 0.5391131341457367.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1231 of 5001.\n",
      "Step: 1232 of 5001.\n",
      "Step: 1233 of 5001.\n",
      "Step: 1234 of 5001.\n",
      "Step: 1235 of 5001.\n",
      "Step: 1236 of 5001.\n",
      "Step: 1237 of 5001.\n",
      "Step: 1238 of 5001.\n",
      "Step: 1239 of 5001.\n",
      "Step: 1240 of 5001.\n",
      "Generator model loss: 1.233573055267334.\n",
      "Discriminator model loss real: 0.7741441875696182.\n",
      "Discriminator model loss generated: 0.5563242256641387.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1241 of 5001.\n",
      "Step: 1242 of 5001.\n",
      "Step: 1243 of 5001.\n",
      "Step: 1244 of 5001.\n",
      "Step: 1245 of 5001.\n",
      "Step: 1246 of 5001.\n",
      "Step: 1247 of 5001.\n",
      "Step: 1248 of 5001.\n",
      "Step: 1249 of 5001.\n",
      "Step: 1250 of 5001.\n",
      "Generator model loss: 1.208497941493988.\n",
      "Discriminator model loss real: 0.7391070902347565.\n",
      "Discriminator model loss generated: 0.5878816843032837.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1251 of 5001.\n",
      "Step: 1252 of 5001.\n",
      "Step: 1253 of 5001.\n",
      "Step: 1254 of 5001.\n",
      "Step: 1255 of 5001.\n",
      "Step: 1256 of 5001.\n",
      "Step: 1257 of 5001.\n",
      "Step: 1258 of 5001.\n",
      "Step: 1259 of 5001.\n",
      "Step: 1260 of 5001.\n",
      "Generator model loss: 1.2647141456604003.\n",
      "Discriminator model loss real: 0.7140522718429565.\n",
      "Discriminator model loss generated: 0.5789841830730438.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1261 of 5001.\n",
      "Step: 1262 of 5001.\n",
      "Step: 1263 of 5001.\n",
      "Step: 1264 of 5001.\n",
      "Step: 1265 of 5001.\n",
      "Step: 1266 of 5001.\n",
      "Step: 1267 of 5001.\n",
      "Step: 1268 of 5001.\n",
      "Step: 1269 of 5001.\n",
      "Step: 1270 of 5001.\n",
      "Generator model loss: 1.1948313593864441.\n",
      "Discriminator model loss real: 0.6933365613222122.\n",
      "Discriminator model loss generated: 0.614285945892334.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1271 of 5001.\n",
      "Step: 1272 of 5001.\n",
      "Step: 1273 of 5001.\n",
      "Step: 1274 of 5001.\n",
      "Step: 1275 of 5001.\n",
      "Step: 1276 of 5001.\n",
      "Step: 1277 of 5001.\n",
      "Step: 1278 of 5001.\n",
      "Step: 1279 of 5001.\n",
      "Step: 1280 of 5001.\n",
      "Generator model loss: 1.2537243962287903.\n",
      "Discriminator model loss real: 0.7305476039648056.\n",
      "Discriminator model loss generated: 0.6067914724349975.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1281 of 5001.\n",
      "Step: 1282 of 5001.\n",
      "Step: 1283 of 5001.\n",
      "Step: 1284 of 5001.\n",
      "Step: 1285 of 5001.\n",
      "Step: 1286 of 5001.\n",
      "Step: 1287 of 5001.\n",
      "Step: 1288 of 5001.\n",
      "Step: 1289 of 5001.\n",
      "Step: 1290 of 5001.\n",
      "Generator model loss: 1.2247217655181886.\n",
      "Discriminator model loss real: 0.7210937410593032.\n",
      "Discriminator model loss generated: 0.6147426486015319.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1291 of 5001.\n",
      "Step: 1292 of 5001.\n",
      "Step: 1293 of 5001.\n",
      "Step: 1294 of 5001.\n",
      "Step: 1295 of 5001.\n",
      "Step: 1296 of 5001.\n",
      "Step: 1297 of 5001.\n",
      "Step: 1298 of 5001.\n",
      "Step: 1299 of 5001.\n",
      "Step: 1300 of 5001.\n",
      "Generator model loss: 1.2116244196891786.\n",
      "Discriminator model loss real: 0.7175053581595421.\n",
      "Discriminator model loss generated: 0.5374958872795105.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1301 of 5001.\n",
      "Step: 1302 of 5001.\n",
      "Step: 1303 of 5001.\n",
      "Step: 1304 of 5001.\n",
      "Step: 1305 of 5001.\n",
      "Step: 1306 of 5001.\n",
      "Step: 1307 of 5001.\n",
      "Step: 1308 of 5001.\n",
      "Step: 1309 of 5001.\n",
      "Step: 1310 of 5001.\n",
      "Generator model loss: 1.278391706943512.\n",
      "Discriminator model loss real: 0.692907352745533.\n",
      "Discriminator model loss generated: 0.6229660212993622.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1311 of 5001.\n",
      "Step: 1312 of 5001.\n",
      "Step: 1313 of 5001.\n",
      "Step: 1314 of 5001.\n",
      "Step: 1315 of 5001.\n",
      "Step: 1316 of 5001.\n",
      "Step: 1317 of 5001.\n",
      "Step: 1318 of 5001.\n",
      "Step: 1319 of 5001.\n",
      "Step: 1320 of 5001.\n",
      "Generator model loss: 1.2198494791984558.\n",
      "Discriminator model loss real: 0.7862374484539032.\n",
      "Discriminator model loss generated: 0.6269652009010315.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1321 of 5001.\n",
      "Step: 1322 of 5001.\n",
      "Step: 1323 of 5001.\n",
      "Step: 1324 of 5001.\n",
      "Step: 1325 of 5001.\n",
      "Step: 1326 of 5001.\n",
      "Step: 1327 of 5001.\n",
      "Step: 1328 of 5001.\n",
      "Step: 1329 of 5001.\n",
      "Step: 1330 of 5001.\n",
      "Generator model loss: 1.2304182648658752.\n",
      "Discriminator model loss real: 0.7406315565109253.\n",
      "Discriminator model loss generated: 0.5782089054584503.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1331 of 5001.\n",
      "Step: 1332 of 5001.\n",
      "Step: 1333 of 5001.\n",
      "Step: 1334 of 5001.\n",
      "Step: 1335 of 5001.\n",
      "Step: 1336 of 5001.\n",
      "Step: 1337 of 5001.\n",
      "Step: 1338 of 5001.\n",
      "Step: 1339 of 5001.\n",
      "Step: 1340 of 5001.\n",
      "Generator model loss: 1.2315175652503967.\n",
      "Discriminator model loss real: 0.7060918211936951.\n",
      "Discriminator model loss generated: 0.5968475908041.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1341 of 5001.\n",
      "Step: 1342 of 5001.\n",
      "Step: 1343 of 5001.\n",
      "Step: 1344 of 5001.\n",
      "Step: 1345 of 5001.\n",
      "Step: 1346 of 5001.\n",
      "Step: 1347 of 5001.\n",
      "Step: 1348 of 5001.\n",
      "Step: 1349 of 5001.\n",
      "Step: 1350 of 5001.\n",
      "Generator model loss: 1.2307523965835572.\n",
      "Discriminator model loss real: 0.7460007816553116.\n",
      "Discriminator model loss generated: 0.6475708544254303.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1351 of 5001.\n",
      "Step: 1352 of 5001.\n",
      "Step: 1353 of 5001.\n",
      "Step: 1354 of 5001.\n",
      "Step: 1355 of 5001.\n",
      "Step: 1356 of 5001.\n",
      "Step: 1357 of 5001.\n",
      "Step: 1358 of 5001.\n",
      "Step: 1359 of 5001.\n",
      "Step: 1360 of 5001.\n",
      "Generator model loss: 1.2285211682319641.\n",
      "Discriminator model loss real: 0.6953136637806893.\n",
      "Discriminator model loss generated: 0.5658588826656341.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1361 of 5001.\n",
      "Step: 1362 of 5001.\n",
      "Step: 1363 of 5001.\n",
      "Step: 1364 of 5001.\n",
      "Step: 1365 of 5001.\n",
      "Step: 1366 of 5001.\n",
      "Step: 1367 of 5001.\n",
      "Step: 1368 of 5001.\n",
      "Step: 1369 of 5001.\n",
      "Step: 1370 of 5001.\n",
      "Generator model loss: 1.2531318068504333.\n",
      "Discriminator model loss real: 0.6768522977828979.\n",
      "Discriminator model loss generated: 0.613735556602478.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1371 of 5001.\n",
      "Step: 1372 of 5001.\n",
      "Step: 1373 of 5001.\n",
      "Step: 1374 of 5001.\n",
      "Step: 1375 of 5001.\n",
      "Step: 1376 of 5001.\n",
      "Step: 1377 of 5001.\n",
      "Step: 1378 of 5001.\n",
      "Step: 1379 of 5001.\n",
      "Step: 1380 of 5001.\n",
      "Generator model loss: 1.2511088013648988.\n",
      "Discriminator model loss real: 0.7365817785263061.\n",
      "Discriminator model loss generated: 0.6035050630569458.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1381 of 5001.\n",
      "Step: 1382 of 5001.\n",
      "Step: 1383 of 5001.\n",
      "Step: 1384 of 5001.\n",
      "Step: 1385 of 5001.\n",
      "Step: 1386 of 5001.\n",
      "Step: 1387 of 5001.\n",
      "Step: 1388 of 5001.\n",
      "Step: 1389 of 5001.\n",
      "Step: 1390 of 5001.\n",
      "Generator model loss: 1.2454929947853088.\n",
      "Discriminator model loss real: 0.7031239762902259.\n",
      "Discriminator model loss generated: 0.6018691748380661.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1391 of 5001.\n",
      "Step: 1392 of 5001.\n",
      "Step: 1393 of 5001.\n",
      "Step: 1394 of 5001.\n",
      "Step: 1395 of 5001.\n",
      "Step: 1396 of 5001.\n",
      "Step: 1397 of 5001.\n",
      "Step: 1398 of 5001.\n",
      "Step: 1399 of 5001.\n",
      "Step: 1400 of 5001.\n",
      "Generator model loss: 1.277572464942932.\n",
      "Discriminator model loss real: 0.7404332548379898.\n",
      "Discriminator model loss generated: 0.5829740345478058.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1401 of 5001.\n",
      "Step: 1402 of 5001.\n",
      "Step: 1403 of 5001.\n",
      "Step: 1404 of 5001.\n",
      "Step: 1405 of 5001.\n",
      "Step: 1406 of 5001.\n",
      "Step: 1407 of 5001.\n",
      "Step: 1408 of 5001.\n",
      "Step: 1409 of 5001.\n",
      "Step: 1410 of 5001.\n",
      "Generator model loss: 1.250034999847412.\n",
      "Discriminator model loss real: 0.7279359117150307.\n",
      "Discriminator model loss generated: 0.6134957998991013.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1411 of 5001.\n",
      "Step: 1412 of 5001.\n",
      "Step: 1413 of 5001.\n",
      "Step: 1414 of 5001.\n",
      "Step: 1415 of 5001.\n",
      "Step: 1416 of 5001.\n",
      "Step: 1417 of 5001.\n",
      "Step: 1418 of 5001.\n",
      "Step: 1419 of 5001.\n",
      "Step: 1420 of 5001.\n",
      "Generator model loss: 1.2329877495765686.\n",
      "Discriminator model loss real: 0.7688072592020034.\n",
      "Discriminator model loss generated: 0.594443964958191.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1421 of 5001.\n",
      "Step: 1422 of 5001.\n",
      "Step: 1423 of 5001.\n",
      "Step: 1424 of 5001.\n",
      "Step: 1425 of 5001.\n",
      "Step: 1426 of 5001.\n",
      "Step: 1427 of 5001.\n",
      "Step: 1428 of 5001.\n",
      "Step: 1429 of 5001.\n",
      "Step: 1430 of 5001.\n",
      "Generator model loss: 1.2082305908203126.\n",
      "Discriminator model loss real: 0.7614386975765228.\n",
      "Discriminator model loss generated: 0.677132761478424.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1431 of 5001.\n",
      "Step: 1432 of 5001.\n",
      "Step: 1433 of 5001.\n",
      "Step: 1434 of 5001.\n",
      "Step: 1435 of 5001.\n",
      "Step: 1436 of 5001.\n",
      "Step: 1437 of 5001.\n",
      "Step: 1438 of 5001.\n",
      "Step: 1439 of 5001.\n",
      "Step: 1440 of 5001.\n",
      "Generator model loss: 1.234313464164734.\n",
      "Discriminator model loss real: 0.6997342854738235.\n",
      "Discriminator model loss generated: 0.6447097837924958.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1441 of 5001.\n",
      "Step: 1442 of 5001.\n",
      "Step: 1443 of 5001.\n",
      "Step: 1444 of 5001.\n",
      "Step: 1445 of 5001.\n",
      "Step: 1446 of 5001.\n",
      "Step: 1447 of 5001.\n",
      "Step: 1448 of 5001.\n",
      "Step: 1449 of 5001.\n",
      "Step: 1450 of 5001.\n",
      "Generator model loss: 1.2309486031532288.\n",
      "Discriminator model loss real: 0.7044113874435425.\n",
      "Discriminator model loss generated: 0.6382252097129821.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1451 of 5001.\n",
      "Step: 1452 of 5001.\n",
      "Step: 1453 of 5001.\n",
      "Step: 1454 of 5001.\n",
      "Step: 1455 of 5001.\n",
      "Step: 1456 of 5001.\n",
      "Step: 1457 of 5001.\n",
      "Step: 1458 of 5001.\n",
      "Step: 1459 of 5001.\n",
      "Step: 1460 of 5001.\n",
      "Generator model loss: 1.210041606426239.\n",
      "Discriminator model loss real: 0.7366574913263321.\n",
      "Discriminator model loss generated: 0.6241061449050903.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1461 of 5001.\n",
      "Step: 1462 of 5001.\n",
      "Step: 1463 of 5001.\n",
      "Step: 1464 of 5001.\n",
      "Step: 1465 of 5001.\n",
      "Step: 1466 of 5001.\n",
      "Step: 1467 of 5001.\n",
      "Step: 1468 of 5001.\n",
      "Step: 1469 of 5001.\n",
      "Step: 1470 of 5001.\n",
      "Generator model loss: 1.2455928206443787.\n",
      "Discriminator model loss real: 0.7004663437604904.\n",
      "Discriminator model loss generated: 0.6058921694755555.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1471 of 5001.\n",
      "Step: 1472 of 5001.\n",
      "Step: 1473 of 5001.\n",
      "Step: 1474 of 5001.\n",
      "Step: 1475 of 5001.\n",
      "Step: 1476 of 5001.\n",
      "Step: 1477 of 5001.\n",
      "Step: 1478 of 5001.\n",
      "Step: 1479 of 5001.\n",
      "Step: 1480 of 5001.\n",
      "Generator model loss: 1.255669391155243.\n",
      "Discriminator model loss real: 0.7409505397081375.\n",
      "Discriminator model loss generated: 0.6851554870605469.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1481 of 5001.\n",
      "Step: 1482 of 5001.\n",
      "Step: 1483 of 5001.\n",
      "Step: 1484 of 5001.\n",
      "Step: 1485 of 5001.\n",
      "Step: 1486 of 5001.\n",
      "Step: 1487 of 5001.\n",
      "Step: 1488 of 5001.\n",
      "Step: 1489 of 5001.\n",
      "Step: 1490 of 5001.\n",
      "Generator model loss: 1.2224910378456115.\n",
      "Discriminator model loss real: 0.7617387354373932.\n",
      "Discriminator model loss generated: 0.6348838627338409.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1491 of 5001.\n",
      "Step: 1492 of 5001.\n",
      "Step: 1493 of 5001.\n",
      "Step: 1494 of 5001.\n",
      "Step: 1495 of 5001.\n",
      "Step: 1496 of 5001.\n",
      "Step: 1497 of 5001.\n",
      "Step: 1498 of 5001.\n",
      "Step: 1499 of 5001.\n",
      "Step: 1500 of 5001.\n",
      "Generator model loss: 1.2755685210227967.\n",
      "Discriminator model loss real: 0.7284927755594254.\n",
      "Discriminator model loss generated: 0.6151148498058319.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1501 of 5001.\n",
      "Step: 1502 of 5001.\n",
      "Step: 1503 of 5001.\n",
      "Step: 1504 of 5001.\n",
      "Step: 1505 of 5001.\n",
      "Step: 1506 of 5001.\n",
      "Step: 1507 of 5001.\n",
      "Step: 1508 of 5001.\n",
      "Step: 1509 of 5001.\n",
      "Step: 1510 of 5001.\n",
      "Generator model loss: 1.2411255717277527.\n",
      "Discriminator model loss real: 0.8198842227458953.\n",
      "Discriminator model loss generated: 0.6080701589584351.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1511 of 5001.\n",
      "Step: 1512 of 5001.\n",
      "Step: 1513 of 5001.\n",
      "Step: 1514 of 5001.\n",
      "Step: 1515 of 5001.\n",
      "Step: 1516 of 5001.\n",
      "Step: 1517 of 5001.\n",
      "Step: 1518 of 5001.\n",
      "Step: 1519 of 5001.\n",
      "Step: 1520 of 5001.\n",
      "Generator model loss: 1.2397146344184875.\n",
      "Discriminator model loss real: 0.76158706843853.\n",
      "Discriminator model loss generated: 0.6196459710597992.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1521 of 5001.\n",
      "Step: 1522 of 5001.\n",
      "Step: 1523 of 5001.\n",
      "Step: 1524 of 5001.\n",
      "Step: 1525 of 5001.\n",
      "Step: 1526 of 5001.\n",
      "Step: 1527 of 5001.\n",
      "Step: 1528 of 5001.\n",
      "Step: 1529 of 5001.\n",
      "Step: 1530 of 5001.\n",
      "Generator model loss: 1.228987717628479.\n",
      "Discriminator model loss real: 0.7550577789545059.\n",
      "Discriminator model loss generated: 0.5937544405460358.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1531 of 5001.\n",
      "Step: 1532 of 5001.\n",
      "Step: 1533 of 5001.\n",
      "Step: 1534 of 5001.\n",
      "Step: 1535 of 5001.\n",
      "Step: 1536 of 5001.\n",
      "Step: 1537 of 5001.\n",
      "Step: 1538 of 5001.\n",
      "Step: 1539 of 5001.\n",
      "Step: 1540 of 5001.\n",
      "Generator model loss: 1.2217001557350158.\n",
      "Discriminator model loss real: 0.7030923396348954.\n",
      "Discriminator model loss generated: 0.5861090451478959.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1541 of 5001.\n",
      "Step: 1542 of 5001.\n",
      "Step: 1543 of 5001.\n",
      "Step: 1544 of 5001.\n",
      "Step: 1545 of 5001.\n",
      "Step: 1546 of 5001.\n",
      "Step: 1547 of 5001.\n",
      "Step: 1548 of 5001.\n",
      "Step: 1549 of 5001.\n",
      "Step: 1550 of 5001.\n",
      "Generator model loss: 1.2163768649101256.\n",
      "Discriminator model loss real: 0.7766042351722717.\n",
      "Discriminator model loss generated: 0.6052365064620971.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1551 of 5001.\n",
      "Step: 1552 of 5001.\n",
      "Step: 1553 of 5001.\n",
      "Step: 1554 of 5001.\n",
      "Step: 1555 of 5001.\n",
      "Step: 1556 of 5001.\n",
      "Step: 1557 of 5001.\n",
      "Step: 1558 of 5001.\n",
      "Step: 1559 of 5001.\n",
      "Step: 1560 of 5001.\n",
      "Generator model loss: 1.2282392263412476.\n",
      "Discriminator model loss real: 0.7250477015972138.\n",
      "Discriminator model loss generated: 0.6749412000179291.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1561 of 5001.\n",
      "Step: 1562 of 5001.\n",
      "Step: 1563 of 5001.\n",
      "Step: 1564 of 5001.\n",
      "Step: 1565 of 5001.\n",
      "Step: 1566 of 5001.\n",
      "Step: 1567 of 5001.\n",
      "Step: 1568 of 5001.\n",
      "Step: 1569 of 5001.\n",
      "Step: 1570 of 5001.\n",
      "Generator model loss: 1.2259069442749024.\n",
      "Discriminator model loss real: 0.7967637002468109.\n",
      "Discriminator model loss generated: 0.6043187022209168.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1571 of 5001.\n",
      "Step: 1572 of 5001.\n",
      "Step: 1573 of 5001.\n",
      "Step: 1574 of 5001.\n",
      "Step: 1575 of 5001.\n",
      "Step: 1576 of 5001.\n",
      "Step: 1577 of 5001.\n",
      "Step: 1578 of 5001.\n",
      "Step: 1579 of 5001.\n",
      "Step: 1580 of 5001.\n",
      "Generator model loss: 1.249699020385742.\n",
      "Discriminator model loss real: 0.7413362443447113.\n",
      "Discriminator model loss generated: 0.6984651267528534.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1581 of 5001.\n",
      "Step: 1582 of 5001.\n",
      "Step: 1583 of 5001.\n",
      "Step: 1584 of 5001.\n",
      "Step: 1585 of 5001.\n",
      "Step: 1586 of 5001.\n",
      "Step: 1587 of 5001.\n",
      "Step: 1588 of 5001.\n",
      "Step: 1589 of 5001.\n",
      "Step: 1590 of 5001.\n",
      "Generator model loss: 1.2471652150154113.\n",
      "Discriminator model loss real: 0.7449224889278412.\n",
      "Discriminator model loss generated: 0.6715123534202576.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1591 of 5001.\n",
      "Step: 1592 of 5001.\n",
      "Step: 1593 of 5001.\n",
      "Step: 1594 of 5001.\n",
      "Step: 1595 of 5001.\n",
      "Step: 1596 of 5001.\n",
      "Step: 1597 of 5001.\n",
      "Step: 1598 of 5001.\n",
      "Step: 1599 of 5001.\n",
      "Step: 1600 of 5001.\n",
      "Generator model loss: 1.2381475687026977.\n",
      "Discriminator model loss real: 0.7518954634666443.\n",
      "Discriminator model loss generated: 0.6408589720726013.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1601 of 5001.\n",
      "Step: 1602 of 5001.\n",
      "Step: 1603 of 5001.\n",
      "Step: 1604 of 5001.\n",
      "Step: 1605 of 5001.\n",
      "Step: 1606 of 5001.\n",
      "Step: 1607 of 5001.\n",
      "Step: 1608 of 5001.\n",
      "Step: 1609 of 5001.\n",
      "Step: 1610 of 5001.\n",
      "Generator model loss: 1.2444262146949767.\n",
      "Discriminator model loss real: 0.6975537091493607.\n",
      "Discriminator model loss generated: 0.6561549574136734.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1611 of 5001.\n",
      "Step: 1612 of 5001.\n",
      "Step: 1613 of 5001.\n",
      "Step: 1614 of 5001.\n",
      "Step: 1615 of 5001.\n",
      "Step: 1616 of 5001.\n",
      "Step: 1617 of 5001.\n",
      "Step: 1618 of 5001.\n",
      "Step: 1619 of 5001.\n",
      "Step: 1620 of 5001.\n",
      "Generator model loss: 1.248047947883606.\n",
      "Discriminator model loss real: 0.7875723987817764.\n",
      "Discriminator model loss generated: 0.6915124595165253.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1621 of 5001.\n",
      "Step: 1622 of 5001.\n",
      "Step: 1623 of 5001.\n",
      "Step: 1624 of 5001.\n",
      "Step: 1625 of 5001.\n",
      "Step: 1626 of 5001.\n",
      "Step: 1627 of 5001.\n",
      "Step: 1628 of 5001.\n",
      "Step: 1629 of 5001.\n",
      "Step: 1630 of 5001.\n",
      "Generator model loss: 1.1954794049263.\n",
      "Discriminator model loss real: 0.7255655288696289.\n",
      "Discriminator model loss generated: 0.6707858204841614.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1631 of 5001.\n",
      "Step: 1632 of 5001.\n",
      "Step: 1633 of 5001.\n",
      "Step: 1634 of 5001.\n",
      "Step: 1635 of 5001.\n",
      "Step: 1636 of 5001.\n",
      "Step: 1637 of 5001.\n",
      "Step: 1638 of 5001.\n",
      "Step: 1639 of 5001.\n",
      "Step: 1640 of 5001.\n",
      "Generator model loss: 1.2249799728393556.\n",
      "Discriminator model loss real: 0.7476543396711349.\n",
      "Discriminator model loss generated: 0.5748226702213287.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1641 of 5001.\n",
      "Step: 1642 of 5001.\n",
      "Step: 1643 of 5001.\n",
      "Step: 1644 of 5001.\n",
      "Step: 1645 of 5001.\n",
      "Step: 1646 of 5001.\n",
      "Step: 1647 of 5001.\n",
      "Step: 1648 of 5001.\n",
      "Step: 1649 of 5001.\n",
      "Step: 1650 of 5001.\n",
      "Generator model loss: 1.1993562579154968.\n",
      "Discriminator model loss real: 0.7294158101081848.\n",
      "Discriminator model loss generated: 0.6282234728336334.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1651 of 5001.\n",
      "Step: 1652 of 5001.\n",
      "Step: 1653 of 5001.\n",
      "Step: 1654 of 5001.\n",
      "Step: 1655 of 5001.\n",
      "Step: 1656 of 5001.\n",
      "Step: 1657 of 5001.\n",
      "Step: 1658 of 5001.\n",
      "Step: 1659 of 5001.\n",
      "Step: 1660 of 5001.\n",
      "Generator model loss: 1.1954602241516112.\n",
      "Discriminator model loss real: 0.7064258188009263.\n",
      "Discriminator model loss generated: 0.6204129755496979.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1661 of 5001.\n",
      "Step: 1662 of 5001.\n",
      "Step: 1663 of 5001.\n",
      "Step: 1664 of 5001.\n",
      "Step: 1665 of 5001.\n",
      "Step: 1666 of 5001.\n",
      "Step: 1667 of 5001.\n",
      "Step: 1668 of 5001.\n",
      "Step: 1669 of 5001.\n",
      "Step: 1670 of 5001.\n",
      "Generator model loss: 1.1951243877410889.\n",
      "Discriminator model loss real: 0.6891103208065033.\n",
      "Discriminator model loss generated: 0.7272532880306244.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1671 of 5001.\n",
      "Step: 1672 of 5001.\n",
      "Step: 1673 of 5001.\n",
      "Step: 1674 of 5001.\n",
      "Step: 1675 of 5001.\n",
      "Step: 1676 of 5001.\n",
      "Step: 1677 of 5001.\n",
      "Step: 1678 of 5001.\n",
      "Step: 1679 of 5001.\n",
      "Step: 1680 of 5001.\n",
      "Generator model loss: 1.1622955560684205.\n",
      "Discriminator model loss real: 0.8008375614881516.\n",
      "Discriminator model loss generated: 0.6976348400115967.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1681 of 5001.\n",
      "Step: 1682 of 5001.\n",
      "Step: 1683 of 5001.\n",
      "Step: 1684 of 5001.\n",
      "Step: 1685 of 5001.\n",
      "Step: 1686 of 5001.\n",
      "Step: 1687 of 5001.\n",
      "Step: 1688 of 5001.\n",
      "Step: 1689 of 5001.\n",
      "Step: 1690 of 5001.\n",
      "Generator model loss: 1.1776888132095338.\n",
      "Discriminator model loss real: 0.7422423958778381.\n",
      "Discriminator model loss generated: 0.6711664766073226.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1691 of 5001.\n",
      "Step: 1692 of 5001.\n",
      "Step: 1693 of 5001.\n",
      "Step: 1694 of 5001.\n",
      "Step: 1695 of 5001.\n",
      "Step: 1696 of 5001.\n",
      "Step: 1697 of 5001.\n",
      "Step: 1698 of 5001.\n",
      "Step: 1699 of 5001.\n",
      "Step: 1700 of 5001.\n",
      "Generator model loss: 1.224550712108612.\n",
      "Discriminator model loss real: 0.7138081341981888.\n",
      "Discriminator model loss generated: 0.6653123021125793.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1701 of 5001.\n",
      "Step: 1702 of 5001.\n",
      "Step: 1703 of 5001.\n",
      "Step: 1704 of 5001.\n",
      "Step: 1705 of 5001.\n",
      "Step: 1706 of 5001.\n",
      "Step: 1707 of 5001.\n",
      "Step: 1708 of 5001.\n",
      "Step: 1709 of 5001.\n",
      "Step: 1710 of 5001.\n",
      "Generator model loss: 1.2271175026893615.\n",
      "Discriminator model loss real: 0.719780969619751.\n",
      "Discriminator model loss generated: 0.6344725251197815.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1711 of 5001.\n",
      "Step: 1712 of 5001.\n",
      "Step: 1713 of 5001.\n",
      "Step: 1714 of 5001.\n",
      "Step: 1715 of 5001.\n",
      "Step: 1716 of 5001.\n",
      "Step: 1717 of 5001.\n",
      "Step: 1718 of 5001.\n",
      "Step: 1719 of 5001.\n",
      "Step: 1720 of 5001.\n",
      "Generator model loss: 1.1619428873062134.\n",
      "Discriminator model loss real: 0.7514103472232818.\n",
      "Discriminator model loss generated: 0.5963241398334503.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1721 of 5001.\n",
      "Step: 1722 of 5001.\n",
      "Step: 1723 of 5001.\n",
      "Step: 1724 of 5001.\n",
      "Step: 1725 of 5001.\n",
      "Step: 1726 of 5001.\n",
      "Step: 1727 of 5001.\n",
      "Step: 1728 of 5001.\n",
      "Step: 1729 of 5001.\n",
      "Step: 1730 of 5001.\n",
      "Generator model loss: 1.177448332309723.\n",
      "Discriminator model loss real: 0.7509263962507248.\n",
      "Discriminator model loss generated: 0.587029093503952.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1731 of 5001.\n",
      "Step: 1732 of 5001.\n",
      "Step: 1733 of 5001.\n",
      "Step: 1734 of 5001.\n",
      "Step: 1735 of 5001.\n",
      "Step: 1736 of 5001.\n",
      "Step: 1737 of 5001.\n",
      "Step: 1738 of 5001.\n",
      "Step: 1739 of 5001.\n",
      "Step: 1740 of 5001.\n",
      "Generator model loss: 1.1674606800079346.\n",
      "Discriminator model loss real: 0.7777840673923493.\n",
      "Discriminator model loss generated: 0.599174851179123.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1741 of 5001.\n",
      "Step: 1742 of 5001.\n",
      "Step: 1743 of 5001.\n",
      "Step: 1744 of 5001.\n",
      "Step: 1745 of 5001.\n",
      "Step: 1746 of 5001.\n",
      "Step: 1747 of 5001.\n",
      "Step: 1748 of 5001.\n",
      "Step: 1749 of 5001.\n",
      "Step: 1750 of 5001.\n",
      "Generator model loss: 1.1705988764762878.\n",
      "Discriminator model loss real: 0.7496793925762176.\n",
      "Discriminator model loss generated: 0.6242520451545716.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1751 of 5001.\n",
      "Step: 1752 of 5001.\n",
      "Step: 1753 of 5001.\n",
      "Step: 1754 of 5001.\n",
      "Step: 1755 of 5001.\n",
      "Step: 1756 of 5001.\n",
      "Step: 1757 of 5001.\n",
      "Step: 1758 of 5001.\n",
      "Step: 1759 of 5001.\n",
      "Step: 1760 of 5001.\n",
      "Generator model loss: 1.2133734107017518.\n",
      "Discriminator model loss real: 0.7597093284130096.\n",
      "Discriminator model loss generated: 0.6191280007362365.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1761 of 5001.\n",
      "Step: 1762 of 5001.\n",
      "Step: 1763 of 5001.\n",
      "Step: 1764 of 5001.\n",
      "Step: 1765 of 5001.\n",
      "Step: 1766 of 5001.\n",
      "Step: 1767 of 5001.\n",
      "Step: 1768 of 5001.\n",
      "Step: 1769 of 5001.\n",
      "Step: 1770 of 5001.\n",
      "Generator model loss: 1.2006441593170165.\n",
      "Discriminator model loss real: 0.7383070260286331.\n",
      "Discriminator model loss generated: 0.6563723683357239.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1771 of 5001.\n",
      "Step: 1772 of 5001.\n",
      "Step: 1773 of 5001.\n",
      "Step: 1774 of 5001.\n",
      "Step: 1775 of 5001.\n",
      "Step: 1776 of 5001.\n",
      "Step: 1777 of 5001.\n",
      "Step: 1778 of 5001.\n",
      "Step: 1779 of 5001.\n",
      "Step: 1780 of 5001.\n",
      "Generator model loss: 1.189479446411133.\n",
      "Discriminator model loss real: 0.7620055377483368.\n",
      "Discriminator model loss generated: 0.6000691890716553.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1781 of 5001.\n",
      "Step: 1782 of 5001.\n",
      "Step: 1783 of 5001.\n",
      "Step: 1784 of 5001.\n",
      "Step: 1785 of 5001.\n",
      "Step: 1786 of 5001.\n",
      "Step: 1787 of 5001.\n",
      "Step: 1788 of 5001.\n",
      "Step: 1789 of 5001.\n",
      "Step: 1790 of 5001.\n",
      "Generator model loss: 1.1638588905334473.\n",
      "Discriminator model loss real: 0.7594734787940979.\n",
      "Discriminator model loss generated: 0.6576638042926788.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1791 of 5001.\n",
      "Step: 1792 of 5001.\n",
      "Step: 1793 of 5001.\n",
      "Step: 1794 of 5001.\n",
      "Step: 1795 of 5001.\n",
      "Step: 1796 of 5001.\n",
      "Step: 1797 of 5001.\n",
      "Step: 1798 of 5001.\n",
      "Step: 1799 of 5001.\n",
      "Step: 1800 of 5001.\n",
      "Generator model loss: 1.1570641160011292.\n",
      "Discriminator model loss real: 0.7412856310606003.\n",
      "Discriminator model loss generated: 0.6360841274261475.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1801 of 5001.\n",
      "Step: 1802 of 5001.\n",
      "Step: 1803 of 5001.\n",
      "Step: 1804 of 5001.\n",
      "Step: 1805 of 5001.\n",
      "Step: 1806 of 5001.\n",
      "Step: 1807 of 5001.\n",
      "Step: 1808 of 5001.\n",
      "Step: 1809 of 5001.\n",
      "Step: 1810 of 5001.\n",
      "Generator model loss: 1.172312045097351.\n",
      "Discriminator model loss real: 0.7623951137065887.\n",
      "Discriminator model loss generated: 0.6527955889701843.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1811 of 5001.\n",
      "Step: 1812 of 5001.\n",
      "Step: 1813 of 5001.\n",
      "Step: 1814 of 5001.\n",
      "Step: 1815 of 5001.\n",
      "Step: 1816 of 5001.\n",
      "Step: 1817 of 5001.\n",
      "Step: 1818 of 5001.\n",
      "Step: 1819 of 5001.\n",
      "Step: 1820 of 5001.\n",
      "Generator model loss: 1.1467918515205384.\n",
      "Discriminator model loss real: 0.735930222272873.\n",
      "Discriminator model loss generated: 0.7153809309005738.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1821 of 5001.\n",
      "Step: 1822 of 5001.\n",
      "Step: 1823 of 5001.\n",
      "Step: 1824 of 5001.\n",
      "Step: 1825 of 5001.\n",
      "Step: 1826 of 5001.\n",
      "Step: 1827 of 5001.\n",
      "Step: 1828 of 5001.\n",
      "Step: 1829 of 5001.\n",
      "Step: 1830 of 5001.\n",
      "Generator model loss: 1.200965690612793.\n",
      "Discriminator model loss real: 0.7633353739976882.\n",
      "Discriminator model loss generated: 0.6229097008705139.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1831 of 5001.\n",
      "Step: 1832 of 5001.\n",
      "Step: 1833 of 5001.\n",
      "Step: 1834 of 5001.\n",
      "Step: 1835 of 5001.\n",
      "Step: 1836 of 5001.\n",
      "Step: 1837 of 5001.\n",
      "Step: 1838 of 5001.\n",
      "Step: 1839 of 5001.\n",
      "Step: 1840 of 5001.\n",
      "Generator model loss: 1.1568767309188843.\n",
      "Discriminator model loss real: 0.6821867614984513.\n",
      "Discriminator model loss generated: 0.6856485843658447.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1841 of 5001.\n",
      "Step: 1842 of 5001.\n",
      "Step: 1843 of 5001.\n",
      "Step: 1844 of 5001.\n",
      "Step: 1845 of 5001.\n",
      "Step: 1846 of 5001.\n",
      "Step: 1847 of 5001.\n",
      "Step: 1848 of 5001.\n",
      "Step: 1849 of 5001.\n",
      "Step: 1850 of 5001.\n",
      "Generator model loss: 1.1423391222953796.\n",
      "Discriminator model loss real: 0.751266461610794.\n",
      "Discriminator model loss generated: 0.6729901194572449.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1851 of 5001.\n",
      "Step: 1852 of 5001.\n",
      "Step: 1853 of 5001.\n",
      "Step: 1854 of 5001.\n",
      "Step: 1855 of 5001.\n",
      "Step: 1856 of 5001.\n",
      "Step: 1857 of 5001.\n",
      "Step: 1858 of 5001.\n",
      "Step: 1859 of 5001.\n",
      "Step: 1860 of 5001.\n",
      "Generator model loss: 1.1387245535850525.\n",
      "Discriminator model loss real: 0.7675779581069946.\n",
      "Discriminator model loss generated: 0.623492032289505.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1861 of 5001.\n",
      "Step: 1862 of 5001.\n",
      "Step: 1863 of 5001.\n",
      "Step: 1864 of 5001.\n",
      "Step: 1865 of 5001.\n",
      "Step: 1866 of 5001.\n",
      "Step: 1867 of 5001.\n",
      "Step: 1868 of 5001.\n",
      "Step: 1869 of 5001.\n",
      "Step: 1870 of 5001.\n",
      "Generator model loss: 1.115649366378784.\n",
      "Discriminator model loss real: 0.7763258725404739.\n",
      "Discriminator model loss generated: 0.6846338212490082.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1871 of 5001.\n",
      "Step: 1872 of 5001.\n",
      "Step: 1873 of 5001.\n",
      "Step: 1874 of 5001.\n",
      "Step: 1875 of 5001.\n",
      "Step: 1876 of 5001.\n",
      "Step: 1877 of 5001.\n",
      "Step: 1878 of 5001.\n",
      "Step: 1879 of 5001.\n",
      "Step: 1880 of 5001.\n",
      "Generator model loss: 1.1973968148231506.\n",
      "Discriminator model loss real: 0.767319256067276.\n",
      "Discriminator model loss generated: 0.6892388820648193.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1881 of 5001.\n",
      "Step: 1882 of 5001.\n",
      "Step: 1883 of 5001.\n",
      "Step: 1884 of 5001.\n",
      "Step: 1885 of 5001.\n",
      "Step: 1886 of 5001.\n",
      "Step: 1887 of 5001.\n",
      "Step: 1888 of 5001.\n",
      "Step: 1889 of 5001.\n",
      "Step: 1890 of 5001.\n",
      "Generator model loss: 1.1146222472190856.\n",
      "Discriminator model loss real: 0.7930493175983429.\n",
      "Discriminator model loss generated: 0.6310745894908905.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1891 of 5001.\n",
      "Step: 1892 of 5001.\n",
      "Step: 1893 of 5001.\n",
      "Step: 1894 of 5001.\n",
      "Step: 1895 of 5001.\n",
      "Step: 1896 of 5001.\n",
      "Step: 1897 of 5001.\n",
      "Step: 1898 of 5001.\n",
      "Step: 1899 of 5001.\n",
      "Step: 1900 of 5001.\n",
      "Generator model loss: 1.0933254599571227.\n",
      "Discriminator model loss real: 0.7622797369956971.\n",
      "Discriminator model loss generated: 0.7136836409568786.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1901 of 5001.\n",
      "Step: 1902 of 5001.\n",
      "Step: 1903 of 5001.\n",
      "Step: 1904 of 5001.\n",
      "Step: 1905 of 5001.\n",
      "Step: 1906 of 5001.\n",
      "Step: 1907 of 5001.\n",
      "Step: 1908 of 5001.\n",
      "Step: 1909 of 5001.\n",
      "Step: 1910 of 5001.\n",
      "Generator model loss: 1.1385281026363372.\n",
      "Discriminator model loss real: 0.7923894464969635.\n",
      "Discriminator model loss generated: 0.5994019746780396.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1911 of 5001.\n",
      "Step: 1912 of 5001.\n",
      "Step: 1913 of 5001.\n",
      "Step: 1914 of 5001.\n",
      "Step: 1915 of 5001.\n",
      "Step: 1916 of 5001.\n",
      "Step: 1917 of 5001.\n",
      "Step: 1918 of 5001.\n",
      "Step: 1919 of 5001.\n",
      "Step: 1920 of 5001.\n",
      "Generator model loss: 1.1228284239768982.\n",
      "Discriminator model loss real: 0.7586245208978653.\n",
      "Discriminator model loss generated: 0.674950897693634.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1921 of 5001.\n",
      "Step: 1922 of 5001.\n",
      "Step: 1923 of 5001.\n",
      "Step: 1924 of 5001.\n",
      "Step: 1925 of 5001.\n",
      "Step: 1926 of 5001.\n",
      "Step: 1927 of 5001.\n",
      "Step: 1928 of 5001.\n",
      "Step: 1929 of 5001.\n",
      "Step: 1930 of 5001.\n",
      "Generator model loss: 1.1232629418373108.\n",
      "Discriminator model loss real: 0.7187942743301392.\n",
      "Discriminator model loss generated: 0.6949044942855835.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1931 of 5001.\n",
      "Step: 1932 of 5001.\n",
      "Step: 1933 of 5001.\n",
      "Step: 1934 of 5001.\n",
      "Step: 1935 of 5001.\n",
      "Step: 1936 of 5001.\n",
      "Step: 1937 of 5001.\n",
      "Step: 1938 of 5001.\n",
      "Step: 1939 of 5001.\n",
      "Step: 1940 of 5001.\n",
      "Generator model loss: 1.09675931930542.\n",
      "Discriminator model loss real: 0.7012017577886581.\n",
      "Discriminator model loss generated: 0.6776555120944977.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1941 of 5001.\n",
      "Step: 1942 of 5001.\n",
      "Step: 1943 of 5001.\n",
      "Step: 1944 of 5001.\n",
      "Step: 1945 of 5001.\n",
      "Step: 1946 of 5001.\n",
      "Step: 1947 of 5001.\n",
      "Step: 1948 of 5001.\n",
      "Step: 1949 of 5001.\n",
      "Step: 1950 of 5001.\n",
      "Generator model loss: 1.1024967551231384.\n",
      "Discriminator model loss real: 0.8140114128589631.\n",
      "Discriminator model loss generated: 0.6371257841587067.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1951 of 5001.\n",
      "Step: 1952 of 5001.\n",
      "Step: 1953 of 5001.\n",
      "Step: 1954 of 5001.\n",
      "Step: 1955 of 5001.\n",
      "Step: 1956 of 5001.\n",
      "Step: 1957 of 5001.\n",
      "Step: 1958 of 5001.\n",
      "Step: 1959 of 5001.\n",
      "Step: 1960 of 5001.\n",
      "Generator model loss: 1.1123765230178833.\n",
      "Discriminator model loss real: 0.7448398321866989.\n",
      "Discriminator model loss generated: 0.5867010831832886.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1961 of 5001.\n",
      "Step: 1962 of 5001.\n",
      "Step: 1963 of 5001.\n",
      "Step: 1964 of 5001.\n",
      "Step: 1965 of 5001.\n",
      "Step: 1966 of 5001.\n",
      "Step: 1967 of 5001.\n",
      "Step: 1968 of 5001.\n",
      "Step: 1969 of 5001.\n",
      "Step: 1970 of 5001.\n",
      "Generator model loss: 1.1140912413597106.\n",
      "Discriminator model loss real: 0.7344078481197357.\n",
      "Discriminator model loss generated: 0.60189129114151.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1971 of 5001.\n",
      "Step: 1972 of 5001.\n",
      "Step: 1973 of 5001.\n",
      "Step: 1974 of 5001.\n",
      "Step: 1975 of 5001.\n",
      "Step: 1976 of 5001.\n",
      "Step: 1977 of 5001.\n",
      "Step: 1978 of 5001.\n",
      "Step: 1979 of 5001.\n",
      "Step: 1980 of 5001.\n",
      "Generator model loss: 1.0924103498458861.\n",
      "Discriminator model loss real: 0.702366727590561.\n",
      "Discriminator model loss generated: 0.6283035457134247.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1981 of 5001.\n",
      "Step: 1982 of 5001.\n",
      "Step: 1983 of 5001.\n",
      "Step: 1984 of 5001.\n",
      "Step: 1985 of 5001.\n",
      "Step: 1986 of 5001.\n",
      "Step: 1987 of 5001.\n",
      "Step: 1988 of 5001.\n",
      "Step: 1989 of 5001.\n",
      "Step: 1990 of 5001.\n",
      "Generator model loss: 1.0699429214000702.\n",
      "Discriminator model loss real: 0.7376348912715912.\n",
      "Discriminator model loss generated: 0.6765010118484497.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1991 of 5001.\n",
      "Step: 1992 of 5001.\n",
      "Step: 1993 of 5001.\n",
      "Step: 1994 of 5001.\n",
      "Step: 1995 of 5001.\n",
      "Step: 1996 of 5001.\n",
      "Step: 1997 of 5001.\n",
      "Step: 1998 of 5001.\n",
      "Step: 1999 of 5001.\n",
      "Step: 2000 of 5001.\n",
      "Generator model loss: 1.0955572247505188.\n",
      "Discriminator model loss real: 0.7153151273727417.\n",
      "Discriminator model loss generated: 0.6454349875450134.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2001 of 5001.\n",
      "Step: 2002 of 5001.\n",
      "Step: 2003 of 5001.\n",
      "Step: 2004 of 5001.\n",
      "Step: 2005 of 5001.\n",
      "Step: 2006 of 5001.\n",
      "Step: 2007 of 5001.\n",
      "Step: 2008 of 5001.\n",
      "Step: 2009 of 5001.\n",
      "Step: 2010 of 5001.\n",
      "Generator model loss: 1.0818632006645204.\n",
      "Discriminator model loss real: 0.7652354300022125.\n",
      "Discriminator model loss generated: 0.6508048295974731.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2011 of 5001.\n",
      "Step: 2012 of 5001.\n",
      "Step: 2013 of 5001.\n",
      "Step: 2014 of 5001.\n",
      "Step: 2015 of 5001.\n",
      "Step: 2016 of 5001.\n",
      "Step: 2017 of 5001.\n",
      "Step: 2018 of 5001.\n",
      "Step: 2019 of 5001.\n",
      "Step: 2020 of 5001.\n",
      "Generator model loss: 1.1016131341457367.\n",
      "Discriminator model loss real: 0.8014043807983399.\n",
      "Discriminator model loss generated: 0.6782564163208008.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2021 of 5001.\n",
      "Step: 2022 of 5001.\n",
      "Step: 2023 of 5001.\n",
      "Step: 2024 of 5001.\n",
      "Step: 2025 of 5001.\n",
      "Step: 2026 of 5001.\n",
      "Step: 2027 of 5001.\n",
      "Step: 2028 of 5001.\n",
      "Step: 2029 of 5001.\n",
      "Step: 2030 of 5001.\n",
      "Generator model loss: 1.1024832844734191.\n",
      "Discriminator model loss real: 0.7612598776817322.\n",
      "Discriminator model loss generated: 0.625373762845993.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2031 of 5001.\n",
      "Step: 2032 of 5001.\n",
      "Step: 2033 of 5001.\n",
      "Step: 2034 of 5001.\n",
      "Step: 2035 of 5001.\n",
      "Step: 2036 of 5001.\n",
      "Step: 2037 of 5001.\n",
      "Step: 2038 of 5001.\n",
      "Step: 2039 of 5001.\n",
      "Step: 2040 of 5001.\n",
      "Generator model loss: 1.0594094514846801.\n",
      "Discriminator model loss real: 0.7320826292037964.\n",
      "Discriminator model loss generated: 0.5828498065471649.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2041 of 5001.\n",
      "Step: 2042 of 5001.\n",
      "Step: 2043 of 5001.\n",
      "Step: 2044 of 5001.\n",
      "Step: 2045 of 5001.\n",
      "Step: 2046 of 5001.\n",
      "Step: 2047 of 5001.\n",
      "Step: 2048 of 5001.\n",
      "Step: 2049 of 5001.\n",
      "Step: 2050 of 5001.\n",
      "Generator model loss: 1.0577165186405182.\n",
      "Discriminator model loss real: 0.7708681583404541.\n",
      "Discriminator model loss generated: 0.651670640707016.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2051 of 5001.\n",
      "Step: 2052 of 5001.\n",
      "Step: 2053 of 5001.\n",
      "Step: 2054 of 5001.\n",
      "Step: 2055 of 5001.\n",
      "Step: 2056 of 5001.\n",
      "Step: 2057 of 5001.\n",
      "Step: 2058 of 5001.\n",
      "Step: 2059 of 5001.\n",
      "Step: 2060 of 5001.\n",
      "Generator model loss: 1.0749083518981934.\n",
      "Discriminator model loss real: 0.7288723587989807.\n",
      "Discriminator model loss generated: 0.6596275448799134.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2061 of 5001.\n",
      "Step: 2062 of 5001.\n",
      "Step: 2063 of 5001.\n",
      "Step: 2064 of 5001.\n",
      "Step: 2065 of 5001.\n",
      "Step: 2066 of 5001.\n",
      "Step: 2067 of 5001.\n",
      "Step: 2068 of 5001.\n",
      "Step: 2069 of 5001.\n",
      "Step: 2070 of 5001.\n",
      "Generator model loss: 1.076936012506485.\n",
      "Discriminator model loss real: 0.7146819174289704.\n",
      "Discriminator model loss generated: 0.6130490720272064.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2071 of 5001.\n",
      "Step: 2072 of 5001.\n",
      "Step: 2073 of 5001.\n",
      "Step: 2074 of 5001.\n",
      "Step: 2075 of 5001.\n",
      "Step: 2076 of 5001.\n",
      "Step: 2077 of 5001.\n",
      "Step: 2078 of 5001.\n",
      "Step: 2079 of 5001.\n",
      "Step: 2080 of 5001.\n",
      "Generator model loss: 1.0372438251972198.\n",
      "Discriminator model loss real: 0.704490813612938.\n",
      "Discriminator model loss generated: 0.6582474291324616.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2081 of 5001.\n",
      "Step: 2082 of 5001.\n",
      "Step: 2083 of 5001.\n",
      "Step: 2084 of 5001.\n",
      "Step: 2085 of 5001.\n",
      "Step: 2086 of 5001.\n",
      "Step: 2087 of 5001.\n",
      "Step: 2088 of 5001.\n",
      "Step: 2089 of 5001.\n",
      "Step: 2090 of 5001.\n",
      "Generator model loss: 1.069316601753235.\n",
      "Discriminator model loss real: 0.7877741783857346.\n",
      "Discriminator model loss generated: 0.6254412591457367.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2091 of 5001.\n",
      "Step: 2092 of 5001.\n",
      "Step: 2093 of 5001.\n",
      "Step: 2094 of 5001.\n",
      "Step: 2095 of 5001.\n",
      "Step: 2096 of 5001.\n",
      "Step: 2097 of 5001.\n",
      "Step: 2098 of 5001.\n",
      "Step: 2099 of 5001.\n",
      "Step: 2100 of 5001.\n",
      "Generator model loss: 1.076783335208893.\n",
      "Discriminator model loss real: 0.795150238275528.\n",
      "Discriminator model loss generated: 0.6977570056915283.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2101 of 5001.\n",
      "Step: 2102 of 5001.\n",
      "Step: 2103 of 5001.\n",
      "Step: 2104 of 5001.\n",
      "Step: 2105 of 5001.\n",
      "Step: 2106 of 5001.\n",
      "Step: 2107 of 5001.\n",
      "Step: 2108 of 5001.\n",
      "Step: 2109 of 5001.\n",
      "Step: 2110 of 5001.\n",
      "Generator model loss: 1.0748091340065002.\n",
      "Discriminator model loss real: 0.7135291039943695.\n",
      "Discriminator model loss generated: 0.623257714509964.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2111 of 5001.\n",
      "Step: 2112 of 5001.\n",
      "Step: 2113 of 5001.\n",
      "Step: 2114 of 5001.\n",
      "Step: 2115 of 5001.\n",
      "Step: 2116 of 5001.\n",
      "Step: 2117 of 5001.\n",
      "Step: 2118 of 5001.\n",
      "Step: 2119 of 5001.\n",
      "Step: 2120 of 5001.\n",
      "Generator model loss: 1.0534189462661743.\n",
      "Discriminator model loss real: 0.725400972366333.\n",
      "Discriminator model loss generated: 0.6296007215976716.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2121 of 5001.\n",
      "Step: 2122 of 5001.\n",
      "Step: 2123 of 5001.\n",
      "Step: 2124 of 5001.\n",
      "Step: 2125 of 5001.\n",
      "Step: 2126 of 5001.\n",
      "Step: 2127 of 5001.\n",
      "Step: 2128 of 5001.\n",
      "Step: 2129 of 5001.\n",
      "Step: 2130 of 5001.\n",
      "Generator model loss: 1.0589475512504578.\n",
      "Discriminator model loss real: 0.7515018701553344.\n",
      "Discriminator model loss generated: 0.6174829304218292.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2131 of 5001.\n",
      "Step: 2132 of 5001.\n",
      "Step: 2133 of 5001.\n",
      "Step: 2134 of 5001.\n",
      "Step: 2135 of 5001.\n",
      "Step: 2136 of 5001.\n",
      "Step: 2137 of 5001.\n",
      "Step: 2138 of 5001.\n",
      "Step: 2139 of 5001.\n",
      "Step: 2140 of 5001.\n",
      "Generator model loss: 1.0474888741970063.\n",
      "Discriminator model loss real: 0.7954009085893631.\n",
      "Discriminator model loss generated: 0.6481894433498383.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2141 of 5001.\n",
      "Step: 2142 of 5001.\n",
      "Step: 2143 of 5001.\n",
      "Step: 2144 of 5001.\n",
      "Step: 2145 of 5001.\n",
      "Step: 2146 of 5001.\n",
      "Step: 2147 of 5001.\n",
      "Step: 2148 of 5001.\n",
      "Step: 2149 of 5001.\n",
      "Step: 2150 of 5001.\n",
      "Generator model loss: 1.065122938156128.\n",
      "Discriminator model loss real: 0.8047922730445862.\n",
      "Discriminator model loss generated: 0.6010131716728211.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2151 of 5001.\n",
      "Step: 2152 of 5001.\n",
      "Step: 2153 of 5001.\n",
      "Step: 2154 of 5001.\n",
      "Step: 2155 of 5001.\n",
      "Step: 2156 of 5001.\n",
      "Step: 2157 of 5001.\n",
      "Step: 2158 of 5001.\n",
      "Step: 2159 of 5001.\n",
      "Step: 2160 of 5001.\n",
      "Generator model loss: 1.0525878727436067.\n",
      "Discriminator model loss real: 0.7886053413152695.\n",
      "Discriminator model loss generated: 0.6475446403026581.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2161 of 5001.\n",
      "Step: 2162 of 5001.\n",
      "Step: 2163 of 5001.\n",
      "Step: 2164 of 5001.\n",
      "Step: 2165 of 5001.\n",
      "Step: 2166 of 5001.\n",
      "Step: 2167 of 5001.\n",
      "Step: 2168 of 5001.\n",
      "Step: 2169 of 5001.\n",
      "Step: 2170 of 5001.\n",
      "Generator model loss: 1.0476945519447327.\n",
      "Discriminator model loss real: 0.7222303360700607.\n",
      "Discriminator model loss generated: 0.7290137529373169.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2171 of 5001.\n",
      "Step: 2172 of 5001.\n",
      "Step: 2173 of 5001.\n",
      "Step: 2174 of 5001.\n",
      "Step: 2175 of 5001.\n",
      "Step: 2176 of 5001.\n",
      "Step: 2177 of 5001.\n",
      "Step: 2178 of 5001.\n",
      "Step: 2179 of 5001.\n",
      "Step: 2180 of 5001.\n",
      "Generator model loss: 1.0478807926177978.\n",
      "Discriminator model loss real: 0.7615929692983627.\n",
      "Discriminator model loss generated: 0.6684125542640686.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2181 of 5001.\n",
      "Step: 2182 of 5001.\n",
      "Step: 2183 of 5001.\n",
      "Step: 2184 of 5001.\n",
      "Step: 2185 of 5001.\n",
      "Step: 2186 of 5001.\n",
      "Step: 2187 of 5001.\n",
      "Step: 2188 of 5001.\n",
      "Step: 2189 of 5001.\n",
      "Step: 2190 of 5001.\n",
      "Generator model loss: 1.0823161959648133.\n",
      "Discriminator model loss real: 0.7792797237634659.\n",
      "Discriminator model loss generated: 0.6127685010433197.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2191 of 5001.\n",
      "Step: 2192 of 5001.\n",
      "Step: 2193 of 5001.\n",
      "Step: 2194 of 5001.\n",
      "Step: 2195 of 5001.\n",
      "Step: 2196 of 5001.\n",
      "Step: 2197 of 5001.\n",
      "Step: 2198 of 5001.\n",
      "Step: 2199 of 5001.\n",
      "Step: 2200 of 5001.\n",
      "Generator model loss: 1.040001517534256.\n",
      "Discriminator model loss real: 0.711896413564682.\n",
      "Discriminator model loss generated: 0.5865800976753235.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2201 of 5001.\n",
      "Step: 2202 of 5001.\n",
      "Step: 2203 of 5001.\n",
      "Step: 2204 of 5001.\n",
      "Step: 2205 of 5001.\n",
      "Step: 2206 of 5001.\n",
      "Step: 2207 of 5001.\n",
      "Step: 2208 of 5001.\n",
      "Step: 2209 of 5001.\n",
      "Step: 2210 of 5001.\n",
      "Generator model loss: 0.9983801305294037.\n",
      "Discriminator model loss real: 0.8012289851903915.\n",
      "Discriminator model loss generated: 0.6548084259033203.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2211 of 5001.\n",
      "Step: 2212 of 5001.\n",
      "Step: 2213 of 5001.\n",
      "Step: 2214 of 5001.\n",
      "Step: 2215 of 5001.\n",
      "Step: 2216 of 5001.\n",
      "Step: 2217 of 5001.\n",
      "Step: 2218 of 5001.\n",
      "Step: 2219 of 5001.\n",
      "Step: 2220 of 5001.\n",
      "Generator model loss: 1.023546314239502.\n",
      "Discriminator model loss real: 0.7715230107307434.\n",
      "Discriminator model loss generated: 0.5885863661766052.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2221 of 5001.\n",
      "Step: 2222 of 5001.\n",
      "Step: 2223 of 5001.\n",
      "Step: 2224 of 5001.\n",
      "Step: 2225 of 5001.\n",
      "Step: 2226 of 5001.\n",
      "Step: 2227 of 5001.\n",
      "Step: 2228 of 5001.\n",
      "Step: 2229 of 5001.\n",
      "Step: 2230 of 5001.\n",
      "Generator model loss: 1.0073730885982513.\n",
      "Discriminator model loss real: 0.7436725258827209.\n",
      "Discriminator model loss generated: 0.5949139297008514.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2231 of 5001.\n",
      "Step: 2232 of 5001.\n",
      "Step: 2233 of 5001.\n",
      "Step: 2234 of 5001.\n",
      "Step: 2235 of 5001.\n",
      "Step: 2236 of 5001.\n",
      "Step: 2237 of 5001.\n",
      "Step: 2238 of 5001.\n",
      "Step: 2239 of 5001.\n",
      "Step: 2240 of 5001.\n",
      "Generator model loss: 1.0246849238872529.\n",
      "Discriminator model loss real: 0.708979994058609.\n",
      "Discriminator model loss generated: 0.6639737725257874.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2241 of 5001.\n",
      "Step: 2242 of 5001.\n",
      "Step: 2243 of 5001.\n",
      "Step: 2244 of 5001.\n",
      "Step: 2245 of 5001.\n",
      "Step: 2246 of 5001.\n",
      "Step: 2247 of 5001.\n",
      "Step: 2248 of 5001.\n",
      "Step: 2249 of 5001.\n",
      "Step: 2250 of 5001.\n",
      "Generator model loss: 1.016078132390976.\n",
      "Discriminator model loss real: 0.7205660760402679.\n",
      "Discriminator model loss generated: 0.6570274591445923.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2251 of 5001.\n",
      "Step: 2252 of 5001.\n",
      "Step: 2253 of 5001.\n",
      "Step: 2254 of 5001.\n",
      "Step: 2255 of 5001.\n",
      "Step: 2256 of 5001.\n",
      "Step: 2257 of 5001.\n",
      "Step: 2258 of 5001.\n",
      "Step: 2259 of 5001.\n",
      "Step: 2260 of 5001.\n",
      "Generator model loss: 1.0135393977165221.\n",
      "Discriminator model loss real: 0.7565511465072632.\n",
      "Discriminator model loss generated: 0.5832959175109863.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2261 of 5001.\n",
      "Step: 2262 of 5001.\n",
      "Step: 2263 of 5001.\n",
      "Step: 2264 of 5001.\n",
      "Step: 2265 of 5001.\n",
      "Step: 2266 of 5001.\n",
      "Step: 2267 of 5001.\n",
      "Step: 2268 of 5001.\n",
      "Step: 2269 of 5001.\n",
      "Step: 2270 of 5001.\n",
      "Generator model loss: 1.0146710932254792.\n",
      "Discriminator model loss real: 0.7662095308303833.\n",
      "Discriminator model loss generated: 0.6053287208080291.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2271 of 5001.\n",
      "Step: 2272 of 5001.\n",
      "Step: 2273 of 5001.\n",
      "Step: 2274 of 5001.\n",
      "Step: 2275 of 5001.\n",
      "Step: 2276 of 5001.\n",
      "Step: 2277 of 5001.\n",
      "Step: 2278 of 5001.\n",
      "Step: 2279 of 5001.\n",
      "Step: 2280 of 5001.\n",
      "Generator model loss: 1.0196961164474487.\n",
      "Discriminator model loss real: 0.7627725273370742.\n",
      "Discriminator model loss generated: 0.6493391752243042.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2281 of 5001.\n",
      "Step: 2282 of 5001.\n",
      "Step: 2283 of 5001.\n",
      "Step: 2284 of 5001.\n",
      "Step: 2285 of 5001.\n",
      "Step: 2286 of 5001.\n",
      "Step: 2287 of 5001.\n",
      "Step: 2288 of 5001.\n",
      "Step: 2289 of 5001.\n",
      "Step: 2290 of 5001.\n",
      "Generator model loss: 0.9999258160591126.\n",
      "Discriminator model loss real: 0.7341974765062332.\n",
      "Discriminator model loss generated: 0.6297561228275299.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2291 of 5001.\n",
      "Step: 2292 of 5001.\n",
      "Step: 2293 of 5001.\n",
      "Step: 2294 of 5001.\n",
      "Step: 2295 of 5001.\n",
      "Step: 2296 of 5001.\n",
      "Step: 2297 of 5001.\n",
      "Step: 2298 of 5001.\n",
      "Step: 2299 of 5001.\n",
      "Step: 2300 of 5001.\n",
      "Generator model loss: 0.9669769048690796.\n",
      "Discriminator model loss real: 0.7448775231838226.\n",
      "Discriminator model loss generated: 0.6711834013462067.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2301 of 5001.\n",
      "Step: 2302 of 5001.\n",
      "Step: 2303 of 5001.\n",
      "Step: 2304 of 5001.\n",
      "Step: 2305 of 5001.\n",
      "Step: 2306 of 5001.\n",
      "Step: 2307 of 5001.\n",
      "Step: 2308 of 5001.\n",
      "Step: 2309 of 5001.\n",
      "Step: 2310 of 5001.\n",
      "Generator model loss: 1.0174050152301788.\n",
      "Discriminator model loss real: 0.747171825170517.\n",
      "Discriminator model loss generated: 0.6349184811115265.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2311 of 5001.\n",
      "Step: 2312 of 5001.\n",
      "Step: 2313 of 5001.\n",
      "Step: 2314 of 5001.\n",
      "Step: 2315 of 5001.\n",
      "Step: 2316 of 5001.\n",
      "Step: 2317 of 5001.\n",
      "Step: 2318 of 5001.\n",
      "Step: 2319 of 5001.\n",
      "Step: 2320 of 5001.\n",
      "Generator model loss: 1.0106084525585175.\n",
      "Discriminator model loss real: 0.7163666725158692.\n",
      "Discriminator model loss generated: 0.5886896014213562.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2321 of 5001.\n",
      "Step: 2322 of 5001.\n",
      "Step: 2323 of 5001.\n",
      "Step: 2324 of 5001.\n",
      "Step: 2325 of 5001.\n",
      "Step: 2326 of 5001.\n",
      "Step: 2327 of 5001.\n",
      "Step: 2328 of 5001.\n",
      "Step: 2329 of 5001.\n",
      "Step: 2330 of 5001.\n",
      "Generator model loss: 1.0227618634700775.\n",
      "Discriminator model loss real: 0.7533257961273193.\n",
      "Discriminator model loss generated: 0.6618548095226288.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2331 of 5001.\n",
      "Step: 2332 of 5001.\n",
      "Step: 2333 of 5001.\n",
      "Step: 2334 of 5001.\n",
      "Step: 2335 of 5001.\n",
      "Step: 2336 of 5001.\n",
      "Step: 2337 of 5001.\n",
      "Step: 2338 of 5001.\n",
      "Step: 2339 of 5001.\n",
      "Step: 2340 of 5001.\n",
      "Generator model loss: 1.0094344735145568.\n",
      "Discriminator model loss real: 0.722503525018692.\n",
      "Discriminator model loss generated: 0.6211804330348969.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2341 of 5001.\n",
      "Step: 2342 of 5001.\n",
      "Step: 2343 of 5001.\n",
      "Step: 2344 of 5001.\n",
      "Step: 2345 of 5001.\n",
      "Step: 2346 of 5001.\n",
      "Step: 2347 of 5001.\n",
      "Step: 2348 of 5001.\n",
      "Step: 2349 of 5001.\n",
      "Step: 2350 of 5001.\n",
      "Generator model loss: 0.9976943731307983.\n",
      "Discriminator model loss real: 0.7578755378723144.\n",
      "Discriminator model loss generated: 0.629173070192337.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2351 of 5001.\n",
      "Step: 2352 of 5001.\n",
      "Step: 2353 of 5001.\n",
      "Step: 2354 of 5001.\n",
      "Step: 2355 of 5001.\n",
      "Step: 2356 of 5001.\n",
      "Step: 2357 of 5001.\n",
      "Step: 2358 of 5001.\n",
      "Step: 2359 of 5001.\n",
      "Step: 2360 of 5001.\n",
      "Generator model loss: 0.9972362816333771.\n",
      "Discriminator model loss real: 0.7671513557434082.\n",
      "Discriminator model loss generated: 0.5906075835227966.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2361 of 5001.\n",
      "Step: 2362 of 5001.\n",
      "Step: 2363 of 5001.\n",
      "Step: 2364 of 5001.\n",
      "Step: 2365 of 5001.\n",
      "Step: 2366 of 5001.\n",
      "Step: 2367 of 5001.\n",
      "Step: 2368 of 5001.\n",
      "Step: 2369 of 5001.\n",
      "Step: 2370 of 5001.\n",
      "Generator model loss: 0.986528503894806.\n",
      "Discriminator model loss real: 0.7339333057403564.\n",
      "Discriminator model loss generated: 0.6287322342395782.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2371 of 5001.\n",
      "Step: 2372 of 5001.\n",
      "Step: 2373 of 5001.\n",
      "Step: 2374 of 5001.\n",
      "Step: 2375 of 5001.\n",
      "Step: 2376 of 5001.\n",
      "Step: 2377 of 5001.\n",
      "Step: 2378 of 5001.\n",
      "Step: 2379 of 5001.\n",
      "Step: 2380 of 5001.\n",
      "Generator model loss: 1.0068924129009247.\n",
      "Discriminator model loss real: 0.7120776742696762.\n",
      "Discriminator model loss generated: 0.5930969476699829.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2381 of 5001.\n",
      "Step: 2382 of 5001.\n",
      "Step: 2383 of 5001.\n",
      "Step: 2384 of 5001.\n",
      "Step: 2385 of 5001.\n",
      "Step: 2386 of 5001.\n",
      "Step: 2387 of 5001.\n",
      "Step: 2388 of 5001.\n",
      "Step: 2389 of 5001.\n",
      "Step: 2390 of 5001.\n",
      "Generator model loss: 1.0049126327037812.\n",
      "Discriminator model loss real: 0.7146601855754853.\n",
      "Discriminator model loss generated: 0.5942309379577637.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2391 of 5001.\n",
      "Step: 2392 of 5001.\n",
      "Step: 2393 of 5001.\n",
      "Step: 2394 of 5001.\n",
      "Step: 2395 of 5001.\n",
      "Step: 2396 of 5001.\n",
      "Step: 2397 of 5001.\n",
      "Step: 2398 of 5001.\n",
      "Step: 2399 of 5001.\n",
      "Step: 2400 of 5001.\n",
      "Generator model loss: 0.9734345257282258.\n",
      "Discriminator model loss real: 0.7915273606777191.\n",
      "Discriminator model loss generated: 0.5897523581981658.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2401 of 5001.\n",
      "Step: 2402 of 5001.\n",
      "Step: 2403 of 5001.\n",
      "Step: 2404 of 5001.\n",
      "Step: 2405 of 5001.\n",
      "Step: 2406 of 5001.\n",
      "Step: 2407 of 5001.\n",
      "Step: 2408 of 5001.\n",
      "Step: 2409 of 5001.\n",
      "Step: 2410 of 5001.\n",
      "Generator model loss: 0.9857249081134796.\n",
      "Discriminator model loss real: 0.7644412368535995.\n",
      "Discriminator model loss generated: 0.6473931729793548.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2411 of 5001.\n",
      "Step: 2412 of 5001.\n",
      "Step: 2413 of 5001.\n",
      "Step: 2414 of 5001.\n",
      "Step: 2415 of 5001.\n",
      "Step: 2416 of 5001.\n",
      "Step: 2417 of 5001.\n",
      "Step: 2418 of 5001.\n",
      "Step: 2419 of 5001.\n",
      "Step: 2420 of 5001.\n",
      "Generator model loss: 0.9856118857860565.\n",
      "Discriminator model loss real: 0.7159860014915467.\n",
      "Discriminator model loss generated: 0.5943704962730407.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2421 of 5001.\n",
      "Step: 2422 of 5001.\n",
      "Step: 2423 of 5001.\n",
      "Step: 2424 of 5001.\n",
      "Step: 2425 of 5001.\n",
      "Step: 2426 of 5001.\n",
      "Step: 2427 of 5001.\n",
      "Step: 2428 of 5001.\n",
      "Step: 2429 of 5001.\n",
      "Step: 2430 of 5001.\n",
      "Generator model loss: 0.9661787927150727.\n",
      "Discriminator model loss real: 0.6869016051292419.\n",
      "Discriminator model loss generated: 0.5903742671012878.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2431 of 5001.\n",
      "Step: 2432 of 5001.\n",
      "Step: 2433 of 5001.\n",
      "Step: 2434 of 5001.\n",
      "Step: 2435 of 5001.\n",
      "Step: 2436 of 5001.\n",
      "Step: 2437 of 5001.\n",
      "Step: 2438 of 5001.\n",
      "Step: 2439 of 5001.\n",
      "Step: 2440 of 5001.\n",
      "Generator model loss: 0.9887797594070434.\n",
      "Discriminator model loss real: 0.760200959444046.\n",
      "Discriminator model loss generated: 0.6144523441791534.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2441 of 5001.\n",
      "Step: 2442 of 5001.\n",
      "Step: 2443 of 5001.\n",
      "Step: 2444 of 5001.\n",
      "Step: 2445 of 5001.\n",
      "Step: 2446 of 5001.\n",
      "Step: 2447 of 5001.\n",
      "Step: 2448 of 5001.\n",
      "Step: 2449 of 5001.\n",
      "Step: 2450 of 5001.\n",
      "Generator model loss: 0.9947239339351654.\n",
      "Discriminator model loss real: 0.7749056428670883.\n",
      "Discriminator model loss generated: 0.5977428376674652.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 2451 of 5001.\n",
      "Step: 2452 of 5001.\n",
      "Step: 2453 of 5001.\n",
      "Step: 2454 of 5001.\n",
      "Step: 2455 of 5001.\n",
      "Step: 2456 of 5001.\n",
      "Step: 2457 of 5001.\n",
      "Step: 2458 of 5001.\n",
      "Step: 2459 of 5001.\n",
      "Step: 2460 of 5001.\n",
      "Generator model loss: 0.9636151194572449.\n",
      "Discriminator model loss real: 0.7297221899032593.\n",
      "Discriminator model loss generated: 0.6012269914150238.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2461 of 5001.\n",
      "Step: 2462 of 5001.\n",
      "Step: 2463 of 5001.\n",
      "Step: 2464 of 5001.\n",
      "Step: 2465 of 5001.\n",
      "Step: 2466 of 5001.\n",
      "Step: 2467 of 5001.\n",
      "Step: 2468 of 5001.\n",
      "Step: 2469 of 5001.\n",
      "Step: 2470 of 5001.\n",
      "Generator model loss: 0.964861923456192.\n",
      "Discriminator model loss real: 0.7703504264354706.\n",
      "Discriminator model loss generated: 0.6040903985500335.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2471 of 5001.\n",
      "Step: 2472 of 5001.\n",
      "Step: 2473 of 5001.\n",
      "Step: 2474 of 5001.\n",
      "Step: 2475 of 5001.\n",
      "Step: 2476 of 5001.\n",
      "Step: 2477 of 5001.\n",
      "Step: 2478 of 5001.\n",
      "Step: 2479 of 5001.\n",
      "Step: 2480 of 5001.\n",
      "Generator model loss: 0.9857414960861206.\n",
      "Discriminator model loss real: 0.673169219493866.\n",
      "Discriminator model loss generated: 0.6060090780258178.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2481 of 5001.\n",
      "Step: 2482 of 5001.\n",
      "Step: 2483 of 5001.\n",
      "Step: 2484 of 5001.\n",
      "Step: 2485 of 5001.\n",
      "Step: 2486 of 5001.\n",
      "Step: 2487 of 5001.\n",
      "Step: 2488 of 5001.\n",
      "Step: 2489 of 5001.\n",
      "Step: 2490 of 5001.\n",
      "Generator model loss: 0.9944669663906097.\n",
      "Discriminator model loss real: 0.7188221693038941.\n",
      "Discriminator model loss generated: 0.6003228664398194.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2491 of 5001.\n",
      "Step: 2492 of 5001.\n",
      "Step: 2493 of 5001.\n",
      "Step: 2494 of 5001.\n",
      "Step: 2495 of 5001.\n",
      "Step: 2496 of 5001.\n",
      "Step: 2497 of 5001.\n",
      "Step: 2498 of 5001.\n",
      "Step: 2499 of 5001.\n",
      "Step: 2500 of 5001.\n",
      "Generator model loss: 0.9742176175117493.\n",
      "Discriminator model loss real: 0.6997463703155518.\n",
      "Discriminator model loss generated: 0.5778065621852875.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2501 of 5001.\n",
      "Step: 2502 of 5001.\n",
      "Step: 2503 of 5001.\n",
      "Step: 2504 of 5001.\n",
      "Step: 2505 of 5001.\n",
      "Step: 2506 of 5001.\n",
      "Step: 2507 of 5001.\n",
      "Step: 2508 of 5001.\n",
      "Step: 2509 of 5001.\n",
      "Step: 2510 of 5001.\n",
      "Generator model loss: 1.0026506245136262.\n",
      "Discriminator model loss real: 0.7230598598718643.\n",
      "Discriminator model loss generated: 0.5847901225090026.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2511 of 5001.\n",
      "Step: 2512 of 5001.\n",
      "Step: 2513 of 5001.\n",
      "Step: 2514 of 5001.\n",
      "Step: 2515 of 5001.\n",
      "Step: 2516 of 5001.\n",
      "Step: 2517 of 5001.\n",
      "Step: 2518 of 5001.\n",
      "Step: 2519 of 5001.\n",
      "Step: 2520 of 5001.\n",
      "Generator model loss: 0.9987592339515686.\n",
      "Discriminator model loss real: 0.7738983511924744.\n",
      "Discriminator model loss generated: 0.5949222385883332.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2521 of 5001.\n",
      "Step: 2522 of 5001.\n",
      "Step: 2523 of 5001.\n",
      "Step: 2524 of 5001.\n",
      "Step: 2525 of 5001.\n",
      "Step: 2526 of 5001.\n",
      "Step: 2527 of 5001.\n",
      "Step: 2528 of 5001.\n",
      "Step: 2529 of 5001.\n",
      "Step: 2530 of 5001.\n",
      "Generator model loss: 0.9852377414703369.\n",
      "Discriminator model loss real: 0.7442494451999664.\n",
      "Discriminator model loss generated: 0.6096814751625061.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2531 of 5001.\n",
      "Step: 2532 of 5001.\n",
      "Step: 2533 of 5001.\n",
      "Step: 2534 of 5001.\n",
      "Step: 2535 of 5001.\n",
      "Step: 2536 of 5001.\n",
      "Step: 2537 of 5001.\n",
      "Step: 2538 of 5001.\n",
      "Step: 2539 of 5001.\n",
      "Step: 2540 of 5001.\n",
      "Generator model loss: 0.969528341293335.\n",
      "Discriminator model loss real: 0.7699954509735107.\n",
      "Discriminator model loss generated: 0.5934639990329742.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2541 of 5001.\n",
      "Step: 2542 of 5001.\n",
      "Step: 2543 of 5001.\n",
      "Step: 2544 of 5001.\n",
      "Step: 2545 of 5001.\n",
      "Step: 2546 of 5001.\n",
      "Step: 2547 of 5001.\n",
      "Step: 2548 of 5001.\n",
      "Step: 2549 of 5001.\n",
      "Step: 2550 of 5001.\n",
      "Generator model loss: 0.9795464694499969.\n",
      "Discriminator model loss real: 0.7019951403141022.\n",
      "Discriminator model loss generated: 0.5829581439495086.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2551 of 5001.\n",
      "Step: 2552 of 5001.\n",
      "Step: 2553 of 5001.\n",
      "Step: 2554 of 5001.\n",
      "Step: 2555 of 5001.\n",
      "Step: 2556 of 5001.\n",
      "Step: 2557 of 5001.\n",
      "Step: 2558 of 5001.\n",
      "Step: 2559 of 5001.\n",
      "Step: 2560 of 5001.\n",
      "Generator model loss: 0.98506019115448.\n",
      "Discriminator model loss real: 0.7430100768804551.\n",
      "Discriminator model loss generated: 0.6458603918552399.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 2561 of 5001.\n",
      "Step: 2562 of 5001.\n",
      "Step: 2563 of 5001.\n",
      "Step: 2564 of 5001.\n",
      "Step: 2565 of 5001.\n",
      "Step: 2566 of 5001.\n",
      "Step: 2567 of 5001.\n",
      "Step: 2568 of 5001.\n",
      "Step: 2569 of 5001.\n",
      "Step: 2570 of 5001.\n",
      "Generator model loss: 0.9768481135368348.\n",
      "Discriminator model loss real: 0.7096797347068786.\n",
      "Discriminator model loss generated: 0.5988907396793366.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2571 of 5001.\n",
      "Step: 2572 of 5001.\n",
      "Step: 2573 of 5001.\n",
      "Step: 2574 of 5001.\n",
      "Step: 2575 of 5001.\n",
      "Step: 2576 of 5001.\n",
      "Step: 2577 of 5001.\n",
      "Step: 2578 of 5001.\n",
      "Step: 2579 of 5001.\n",
      "Step: 2580 of 5001.\n",
      "Generator model loss: 0.9656428039073944.\n",
      "Discriminator model loss real: 0.7101260751485825.\n",
      "Discriminator model loss generated: 0.625542813539505.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2581 of 5001.\n",
      "Step: 2582 of 5001.\n",
      "Step: 2583 of 5001.\n",
      "Step: 2584 of 5001.\n",
      "Step: 2585 of 5001.\n",
      "Step: 2586 of 5001.\n",
      "Step: 2587 of 5001.\n",
      "Step: 2588 of 5001.\n",
      "Step: 2589 of 5001.\n",
      "Step: 2590 of 5001.\n",
      "Generator model loss: 0.9747167587280273.\n",
      "Discriminator model loss real: 0.7477702260017395.\n",
      "Discriminator model loss generated: 0.5868783533573151.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2591 of 5001.\n",
      "Step: 2592 of 5001.\n",
      "Step: 2593 of 5001.\n",
      "Step: 2594 of 5001.\n",
      "Step: 2595 of 5001.\n",
      "Step: 2596 of 5001.\n",
      "Step: 2597 of 5001.\n",
      "Step: 2598 of 5001.\n",
      "Step: 2599 of 5001.\n",
      "Step: 2600 of 5001.\n",
      "Generator model loss: 0.9821396350860596.\n",
      "Discriminator model loss real: 0.6741262882947922.\n",
      "Discriminator model loss generated: 0.5928993403911591.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2601 of 5001.\n",
      "Step: 2602 of 5001.\n",
      "Step: 2603 of 5001.\n",
      "Step: 2604 of 5001.\n",
      "Step: 2605 of 5001.\n",
      "Step: 2606 of 5001.\n",
      "Step: 2607 of 5001.\n",
      "Step: 2608 of 5001.\n",
      "Step: 2609 of 5001.\n",
      "Step: 2610 of 5001.\n",
      "Generator model loss: 1.0109144270420074.\n",
      "Discriminator model loss real: 0.7296587407588959.\n",
      "Discriminator model loss generated: 0.5874010324478149.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2611 of 5001.\n",
      "Step: 2612 of 5001.\n",
      "Step: 2613 of 5001.\n",
      "Step: 2614 of 5001.\n",
      "Step: 2615 of 5001.\n",
      "Step: 2616 of 5001.\n",
      "Step: 2617 of 5001.\n",
      "Step: 2618 of 5001.\n",
      "Step: 2619 of 5001.\n",
      "Step: 2620 of 5001.\n",
      "Generator model loss: 0.9655499041080475.\n",
      "Discriminator model loss real: 0.7095352590084076.\n",
      "Discriminator model loss generated: 0.5784849345684051.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2621 of 5001.\n",
      "Step: 2622 of 5001.\n",
      "Step: 2623 of 5001.\n",
      "Step: 2624 of 5001.\n",
      "Step: 2625 of 5001.\n",
      "Step: 2626 of 5001.\n",
      "Step: 2627 of 5001.\n",
      "Step: 2628 of 5001.\n",
      "Step: 2629 of 5001.\n",
      "Step: 2630 of 5001.\n",
      "Generator model loss: 0.9947654187679291.\n",
      "Discriminator model loss real: 0.7784622341394425.\n",
      "Discriminator model loss generated: 0.6176502764225006.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2631 of 5001.\n",
      "Step: 2632 of 5001.\n",
      "Step: 2633 of 5001.\n",
      "Step: 2634 of 5001.\n",
      "Step: 2635 of 5001.\n",
      "Step: 2636 of 5001.\n",
      "Step: 2637 of 5001.\n",
      "Step: 2638 of 5001.\n",
      "Step: 2639 of 5001.\n",
      "Step: 2640 of 5001.\n",
      "Generator model loss: 0.9743932783603668.\n",
      "Discriminator model loss real: 0.7731828600168228.\n",
      "Discriminator model loss generated: 0.6220879256725311.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2641 of 5001.\n",
      "Step: 2642 of 5001.\n",
      "Step: 2643 of 5001.\n",
      "Step: 2644 of 5001.\n",
      "Step: 2645 of 5001.\n",
      "Step: 2646 of 5001.\n",
      "Step: 2647 of 5001.\n",
      "Step: 2648 of 5001.\n",
      "Step: 2649 of 5001.\n",
      "Step: 2650 of 5001.\n",
      "Generator model loss: 0.9882934629917145.\n",
      "Discriminator model loss real: 0.7219098567962646.\n",
      "Discriminator model loss generated: 0.6294846832752228.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2651 of 5001.\n",
      "Step: 2652 of 5001.\n",
      "Step: 2653 of 5001.\n",
      "Step: 2654 of 5001.\n",
      "Step: 2655 of 5001.\n",
      "Step: 2656 of 5001.\n",
      "Step: 2657 of 5001.\n",
      "Step: 2658 of 5001.\n",
      "Step: 2659 of 5001.\n",
      "Step: 2660 of 5001.\n",
      "Generator model loss: 0.9717976748943329.\n",
      "Discriminator model loss real: 0.7152682602405548.\n",
      "Discriminator model loss generated: 0.6243185579776764.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2661 of 5001.\n",
      "Step: 2662 of 5001.\n",
      "Step: 2663 of 5001.\n",
      "Step: 2664 of 5001.\n",
      "Step: 2665 of 5001.\n",
      "Step: 2666 of 5001.\n",
      "Step: 2667 of 5001.\n",
      "Step: 2668 of 5001.\n",
      "Step: 2669 of 5001.\n",
      "Step: 2670 of 5001.\n",
      "Generator model loss: 0.9910784900188446.\n",
      "Discriminator model loss real: 0.7099514991044998.\n",
      "Discriminator model loss generated: 0.6333603143692017.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2671 of 5001.\n",
      "Step: 2672 of 5001.\n",
      "Step: 2673 of 5001.\n",
      "Step: 2674 of 5001.\n",
      "Step: 2675 of 5001.\n",
      "Step: 2676 of 5001.\n",
      "Step: 2677 of 5001.\n",
      "Step: 2678 of 5001.\n",
      "Step: 2679 of 5001.\n",
      "Step: 2680 of 5001.\n",
      "Generator model loss: 1.008865374326706.\n",
      "Discriminator model loss real: 0.7224991470575333.\n",
      "Discriminator model loss generated: 0.6425128877162933.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2681 of 5001.\n",
      "Step: 2682 of 5001.\n",
      "Step: 2683 of 5001.\n",
      "Step: 2684 of 5001.\n",
      "Step: 2685 of 5001.\n",
      "Step: 2686 of 5001.\n",
      "Step: 2687 of 5001.\n",
      "Step: 2688 of 5001.\n",
      "Step: 2689 of 5001.\n",
      "Step: 2690 of 5001.\n",
      "Generator model loss: 0.9766368627548218.\n",
      "Discriminator model loss real: 0.6794540405273437.\n",
      "Discriminator model loss generated: 0.6326902866363525.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2691 of 5001.\n",
      "Step: 2692 of 5001.\n",
      "Step: 2693 of 5001.\n",
      "Step: 2694 of 5001.\n",
      "Step: 2695 of 5001.\n",
      "Step: 2696 of 5001.\n",
      "Step: 2697 of 5001.\n",
      "Step: 2698 of 5001.\n",
      "Step: 2699 of 5001.\n",
      "Step: 2700 of 5001.\n",
      "Generator model loss: 0.9574013769626617.\n",
      "Discriminator model loss real: 0.7499357521533966.\n",
      "Discriminator model loss generated: 0.6674126505851745.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2701 of 5001.\n",
      "Step: 2702 of 5001.\n",
      "Step: 2703 of 5001.\n",
      "Step: 2704 of 5001.\n",
      "Step: 2705 of 5001.\n",
      "Step: 2706 of 5001.\n",
      "Step: 2707 of 5001.\n",
      "Step: 2708 of 5001.\n",
      "Step: 2709 of 5001.\n",
      "Step: 2710 of 5001.\n",
      "Generator model loss: 1.0005977749824524.\n",
      "Discriminator model loss real: 0.7290616273880005.\n",
      "Discriminator model loss generated: 0.6321844339370728.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2711 of 5001.\n",
      "Step: 2712 of 5001.\n",
      "Step: 2713 of 5001.\n",
      "Step: 2714 of 5001.\n",
      "Step: 2715 of 5001.\n",
      "Step: 2716 of 5001.\n",
      "Step: 2717 of 5001.\n",
      "Step: 2718 of 5001.\n",
      "Step: 2719 of 5001.\n",
      "Step: 2720 of 5001.\n",
      "Generator model loss: 0.9686041831970215.\n",
      "Discriminator model loss real: 0.7311487197875977.\n",
      "Discriminator model loss generated: 0.6181345343589782.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2721 of 5001.\n",
      "Step: 2722 of 5001.\n",
      "Step: 2723 of 5001.\n",
      "Step: 2724 of 5001.\n",
      "Step: 2725 of 5001.\n",
      "Step: 2726 of 5001.\n",
      "Step: 2727 of 5001.\n",
      "Step: 2728 of 5001.\n",
      "Step: 2729 of 5001.\n",
      "Step: 2730 of 5001.\n",
      "Generator model loss: 0.9954488933086395.\n",
      "Discriminator model loss real: 0.7081807434558869.\n",
      "Discriminator model loss generated: 0.6248969793319702.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2731 of 5001.\n",
      "Step: 2732 of 5001.\n",
      "Step: 2733 of 5001.\n",
      "Step: 2734 of 5001.\n",
      "Step: 2735 of 5001.\n",
      "Step: 2736 of 5001.\n",
      "Step: 2737 of 5001.\n",
      "Step: 2738 of 5001.\n",
      "Step: 2739 of 5001.\n",
      "Step: 2740 of 5001.\n",
      "Generator model loss: 0.9850968837738037.\n",
      "Discriminator model loss real: 0.69975266456604.\n",
      "Discriminator model loss generated: 0.6155915439128876.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2741 of 5001.\n",
      "Step: 2742 of 5001.\n",
      "Step: 2743 of 5001.\n",
      "Step: 2744 of 5001.\n",
      "Step: 2745 of 5001.\n",
      "Step: 2746 of 5001.\n",
      "Step: 2747 of 5001.\n",
      "Step: 2748 of 5001.\n",
      "Step: 2749 of 5001.\n",
      "Step: 2750 of 5001.\n",
      "Generator model loss: 1.0149704813957214.\n",
      "Discriminator model loss real: 0.6927219420671463.\n",
      "Discriminator model loss generated: 0.6109720289707183.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2751 of 5001.\n",
      "Step: 2752 of 5001.\n",
      "Step: 2753 of 5001.\n",
      "Step: 2754 of 5001.\n",
      "Step: 2755 of 5001.\n",
      "Step: 2756 of 5001.\n",
      "Step: 2757 of 5001.\n",
      "Step: 2758 of 5001.\n",
      "Step: 2759 of 5001.\n",
      "Step: 2760 of 5001.\n",
      "Generator model loss: 0.9638565123081207.\n",
      "Discriminator model loss real: 0.7148740470409394.\n",
      "Discriminator model loss generated: 0.6189844310283661.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2761 of 5001.\n",
      "Step: 2762 of 5001.\n",
      "Step: 2763 of 5001.\n",
      "Step: 2764 of 5001.\n",
      "Step: 2765 of 5001.\n",
      "Step: 2766 of 5001.\n",
      "Step: 2767 of 5001.\n",
      "Step: 2768 of 5001.\n",
      "Step: 2769 of 5001.\n",
      "Step: 2770 of 5001.\n",
      "Generator model loss: 0.9879186034202576.\n",
      "Discriminator model loss real: 0.7140145659446716.\n",
      "Discriminator model loss generated: 0.6487357974052429.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2771 of 5001.\n",
      "Step: 2772 of 5001.\n",
      "Step: 2773 of 5001.\n",
      "Step: 2774 of 5001.\n",
      "Step: 2775 of 5001.\n",
      "Step: 2776 of 5001.\n",
      "Step: 2777 of 5001.\n",
      "Step: 2778 of 5001.\n",
      "Step: 2779 of 5001.\n",
      "Step: 2780 of 5001.\n",
      "Generator model loss: 0.9880147635936737.\n",
      "Discriminator model loss real: 0.7086848348379136.\n",
      "Discriminator model loss generated: 0.6004330515861511.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2781 of 5001.\n",
      "Step: 2782 of 5001.\n",
      "Step: 2783 of 5001.\n",
      "Step: 2784 of 5001.\n",
      "Step: 2785 of 5001.\n",
      "Step: 2786 of 5001.\n",
      "Step: 2787 of 5001.\n",
      "Step: 2788 of 5001.\n",
      "Step: 2789 of 5001.\n",
      "Step: 2790 of 5001.\n",
      "Generator model loss: 0.9633692383766175.\n",
      "Discriminator model loss real: 0.7832246541976928.\n",
      "Discriminator model loss generated: 0.6106220424175263.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2791 of 5001.\n",
      "Step: 2792 of 5001.\n",
      "Step: 2793 of 5001.\n",
      "Step: 2794 of 5001.\n",
      "Step: 2795 of 5001.\n",
      "Step: 2796 of 5001.\n",
      "Step: 2797 of 5001.\n",
      "Step: 2798 of 5001.\n",
      "Step: 2799 of 5001.\n",
      "Step: 2800 of 5001.\n",
      "Generator model loss: 0.9849595844745636.\n",
      "Discriminator model loss real: 0.6856302201747895.\n",
      "Discriminator model loss generated: 0.6037692129611969.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2801 of 5001.\n",
      "Step: 2802 of 5001.\n",
      "Step: 2803 of 5001.\n",
      "Step: 2804 of 5001.\n",
      "Step: 2805 of 5001.\n",
      "Step: 2806 of 5001.\n",
      "Step: 2807 of 5001.\n",
      "Step: 2808 of 5001.\n",
      "Step: 2809 of 5001.\n",
      "Step: 2810 of 5001.\n",
      "Generator model loss: 1.0039569854736328.\n",
      "Discriminator model loss real: 0.655563873052597.\n",
      "Discriminator model loss generated: 0.6358910739421845.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2811 of 5001.\n",
      "Step: 2812 of 5001.\n",
      "Step: 2813 of 5001.\n",
      "Step: 2814 of 5001.\n",
      "Step: 2815 of 5001.\n",
      "Step: 2816 of 5001.\n",
      "Step: 2817 of 5001.\n",
      "Step: 2818 of 5001.\n",
      "Step: 2819 of 5001.\n",
      "Step: 2820 of 5001.\n",
      "Generator model loss: 0.9834304273128509.\n",
      "Discriminator model loss real: 0.6898139178752899.\n",
      "Discriminator model loss generated: 0.605435311794281.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2821 of 5001.\n",
      "Step: 2822 of 5001.\n",
      "Step: 2823 of 5001.\n",
      "Step: 2824 of 5001.\n",
      "Step: 2825 of 5001.\n",
      "Step: 2826 of 5001.\n",
      "Step: 2827 of 5001.\n",
      "Step: 2828 of 5001.\n",
      "Step: 2829 of 5001.\n",
      "Step: 2830 of 5001.\n",
      "Generator model loss: 1.015335476398468.\n",
      "Discriminator model loss real: 0.7436176508665084.\n",
      "Discriminator model loss generated: 0.5897220492362976.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2831 of 5001.\n",
      "Step: 2832 of 5001.\n",
      "Step: 2833 of 5001.\n",
      "Step: 2834 of 5001.\n",
      "Step: 2835 of 5001.\n",
      "Step: 2836 of 5001.\n",
      "Step: 2837 of 5001.\n",
      "Step: 2838 of 5001.\n",
      "Step: 2839 of 5001.\n",
      "Step: 2840 of 5001.\n",
      "Generator model loss: 1.035740029811859.\n",
      "Discriminator model loss real: 0.7050548523664475.\n",
      "Discriminator model loss generated: 0.5740572810173035.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2841 of 5001.\n",
      "Step: 2842 of 5001.\n",
      "Step: 2843 of 5001.\n",
      "Step: 2844 of 5001.\n",
      "Step: 2845 of 5001.\n",
      "Step: 2846 of 5001.\n",
      "Step: 2847 of 5001.\n",
      "Step: 2848 of 5001.\n",
      "Step: 2849 of 5001.\n",
      "Step: 2850 of 5001.\n",
      "Generator model loss: 0.98622367978096.\n",
      "Discriminator model loss real: 0.7055919647216797.\n",
      "Discriminator model loss generated: 0.6019006550312043.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 2851 of 5001.\n",
      "Step: 2852 of 5001.\n",
      "Step: 2853 of 5001.\n",
      "Step: 2854 of 5001.\n",
      "Step: 2855 of 5001.\n",
      "Step: 2856 of 5001.\n",
      "Step: 2857 of 5001.\n",
      "Step: 2858 of 5001.\n",
      "Step: 2859 of 5001.\n",
      "Step: 2860 of 5001.\n",
      "Generator model loss: 0.993503886461258.\n",
      "Discriminator model loss real: 0.7109064370393753.\n",
      "Discriminator model loss generated: 0.6137766361236572.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2861 of 5001.\n",
      "Step: 2862 of 5001.\n",
      "Step: 2863 of 5001.\n",
      "Step: 2864 of 5001.\n",
      "Step: 2865 of 5001.\n",
      "Step: 2866 of 5001.\n",
      "Step: 2867 of 5001.\n",
      "Step: 2868 of 5001.\n",
      "Step: 2869 of 5001.\n",
      "Step: 2870 of 5001.\n",
      "Generator model loss: 1.0176738560199738.\n",
      "Discriminator model loss real: 0.755221563577652.\n",
      "Discriminator model loss generated: 0.577269047498703.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2871 of 5001.\n",
      "Step: 2872 of 5001.\n",
      "Step: 2873 of 5001.\n",
      "Step: 2874 of 5001.\n",
      "Step: 2875 of 5001.\n",
      "Step: 2876 of 5001.\n",
      "Step: 2877 of 5001.\n",
      "Step: 2878 of 5001.\n",
      "Step: 2879 of 5001.\n",
      "Step: 2880 of 5001.\n",
      "Generator model loss: 1.0025221347808837.\n",
      "Discriminator model loss real: 0.7047715038061142.\n",
      "Discriminator model loss generated: 0.5884113669395447.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2881 of 5001.\n",
      "Step: 2882 of 5001.\n",
      "Step: 2883 of 5001.\n",
      "Step: 2884 of 5001.\n",
      "Step: 2885 of 5001.\n",
      "Step: 2886 of 5001.\n",
      "Step: 2887 of 5001.\n",
      "Step: 2888 of 5001.\n",
      "Step: 2889 of 5001.\n",
      "Step: 2890 of 5001.\n",
      "Generator model loss: 0.9933288037776947.\n",
      "Discriminator model loss real: 0.7184110373258591.\n",
      "Discriminator model loss generated: 0.5719165861606598.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2891 of 5001.\n",
      "Step: 2892 of 5001.\n",
      "Step: 2893 of 5001.\n",
      "Step: 2894 of 5001.\n",
      "Step: 2895 of 5001.\n",
      "Step: 2896 of 5001.\n",
      "Step: 2897 of 5001.\n",
      "Step: 2898 of 5001.\n",
      "Step: 2899 of 5001.\n",
      "Step: 2900 of 5001.\n",
      "Generator model loss: 1.0096017956733703.\n",
      "Discriminator model loss real: 0.7533240199089051.\n",
      "Discriminator model loss generated: 0.6013550877571106.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2901 of 5001.\n",
      "Step: 2902 of 5001.\n",
      "Step: 2903 of 5001.\n",
      "Step: 2904 of 5001.\n",
      "Step: 2905 of 5001.\n",
      "Step: 2906 of 5001.\n",
      "Step: 2907 of 5001.\n",
      "Step: 2908 of 5001.\n",
      "Step: 2909 of 5001.\n",
      "Step: 2910 of 5001.\n",
      "Generator model loss: 1.0055326759815215.\n",
      "Discriminator model loss real: 0.7072762757539749.\n",
      "Discriminator model loss generated: 0.642891275882721.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2911 of 5001.\n",
      "Step: 2912 of 5001.\n",
      "Step: 2913 of 5001.\n",
      "Step: 2914 of 5001.\n",
      "Step: 2915 of 5001.\n",
      "Step: 2916 of 5001.\n",
      "Step: 2917 of 5001.\n",
      "Step: 2918 of 5001.\n",
      "Step: 2919 of 5001.\n",
      "Step: 2920 of 5001.\n",
      "Generator model loss: 0.989794272184372.\n",
      "Discriminator model loss real: 0.6678891748189926.\n",
      "Discriminator model loss generated: 0.655511474609375.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2921 of 5001.\n",
      "Step: 2922 of 5001.\n",
      "Step: 2923 of 5001.\n",
      "Step: 2924 of 5001.\n",
      "Step: 2925 of 5001.\n",
      "Step: 2926 of 5001.\n",
      "Step: 2927 of 5001.\n",
      "Step: 2928 of 5001.\n",
      "Step: 2929 of 5001.\n",
      "Step: 2930 of 5001.\n",
      "Generator model loss: 0.977321881055832.\n",
      "Discriminator model loss real: 0.7526335805654526.\n",
      "Discriminator model loss generated: 0.57878378033638.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2931 of 5001.\n",
      "Step: 2932 of 5001.\n",
      "Step: 2933 of 5001.\n",
      "Step: 2934 of 5001.\n",
      "Step: 2935 of 5001.\n",
      "Step: 2936 of 5001.\n",
      "Step: 2937 of 5001.\n",
      "Step: 2938 of 5001.\n",
      "Step: 2939 of 5001.\n",
      "Step: 2940 of 5001.\n",
      "Generator model loss: 0.9946162939071655.\n",
      "Discriminator model loss real: 0.6937021672725677.\n",
      "Discriminator model loss generated: 0.5830485880374908.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2941 of 5001.\n",
      "Step: 2942 of 5001.\n",
      "Step: 2943 of 5001.\n",
      "Step: 2944 of 5001.\n",
      "Step: 2945 of 5001.\n",
      "Step: 2946 of 5001.\n",
      "Step: 2947 of 5001.\n",
      "Step: 2948 of 5001.\n",
      "Step: 2949 of 5001.\n",
      "Step: 2950 of 5001.\n",
      "Generator model loss: 1.0340324938297272.\n",
      "Discriminator model loss real: 0.7578286617994309.\n",
      "Discriminator model loss generated: 0.6081965506076813.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2951 of 5001.\n",
      "Step: 2952 of 5001.\n",
      "Step: 2953 of 5001.\n",
      "Step: 2954 of 5001.\n",
      "Step: 2955 of 5001.\n",
      "Step: 2956 of 5001.\n",
      "Step: 2957 of 5001.\n",
      "Step: 2958 of 5001.\n",
      "Step: 2959 of 5001.\n",
      "Step: 2960 of 5001.\n",
      "Generator model loss: 1.0250368595123291.\n",
      "Discriminator model loss real: 0.674885305762291.\n",
      "Discriminator model loss generated: 0.6039705872535706.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2961 of 5001.\n",
      "Step: 2962 of 5001.\n",
      "Step: 2963 of 5001.\n",
      "Step: 2964 of 5001.\n",
      "Step: 2965 of 5001.\n",
      "Step: 2966 of 5001.\n",
      "Step: 2967 of 5001.\n",
      "Step: 2968 of 5001.\n",
      "Step: 2969 of 5001.\n",
      "Step: 2970 of 5001.\n",
      "Generator model loss: 1.005704826116562.\n",
      "Discriminator model loss real: 0.7537017822265625.\n",
      "Discriminator model loss generated: 0.6164993405342102.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 2971 of 5001.\n",
      "Step: 2972 of 5001.\n",
      "Step: 2973 of 5001.\n",
      "Step: 2974 of 5001.\n",
      "Step: 2975 of 5001.\n",
      "Step: 2976 of 5001.\n",
      "Step: 2977 of 5001.\n",
      "Step: 2978 of 5001.\n",
      "Step: 2979 of 5001.\n",
      "Step: 2980 of 5001.\n",
      "Generator model loss: 0.966213446855545.\n",
      "Discriminator model loss real: 0.7046064674854279.\n",
      "Discriminator model loss generated: 0.5891000688076019.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2981 of 5001.\n",
      "Step: 2982 of 5001.\n",
      "Step: 2983 of 5001.\n",
      "Step: 2984 of 5001.\n",
      "Step: 2985 of 5001.\n",
      "Step: 2986 of 5001.\n",
      "Step: 2987 of 5001.\n",
      "Step: 2988 of 5001.\n",
      "Step: 2989 of 5001.\n",
      "Step: 2990 of 5001.\n",
      "Generator model loss: 1.0152215361595154.\n",
      "Discriminator model loss real: 0.75287224650383.\n",
      "Discriminator model loss generated: 0.6051531136035919.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2991 of 5001.\n",
      "Step: 2992 of 5001.\n",
      "Step: 2993 of 5001.\n",
      "Step: 2994 of 5001.\n",
      "Step: 2995 of 5001.\n",
      "Step: 2996 of 5001.\n",
      "Step: 2997 of 5001.\n",
      "Step: 2998 of 5001.\n",
      "Step: 2999 of 5001.\n",
      "Step: 3000 of 5001.\n",
      "Generator model loss: 1.0682683527469634.\n",
      "Discriminator model loss real: 0.6906683802604675.\n",
      "Discriminator model loss generated: 0.6419729113578796.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3001 of 5001.\n",
      "Step: 3002 of 5001.\n",
      "Step: 3003 of 5001.\n",
      "Step: 3004 of 5001.\n",
      "Step: 3005 of 5001.\n",
      "Step: 3006 of 5001.\n",
      "Step: 3007 of 5001.\n",
      "Step: 3008 of 5001.\n",
      "Step: 3009 of 5001.\n",
      "Step: 3010 of 5001.\n",
      "Generator model loss: 1.0294493019580842.\n",
      "Discriminator model loss real: 0.7094888389110565.\n",
      "Discriminator model loss generated: 0.6370162844657898.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3011 of 5001.\n",
      "Step: 3012 of 5001.\n",
      "Step: 3013 of 5001.\n",
      "Step: 3014 of 5001.\n",
      "Step: 3015 of 5001.\n",
      "Step: 3016 of 5001.\n",
      "Step: 3017 of 5001.\n",
      "Step: 3018 of 5001.\n",
      "Step: 3019 of 5001.\n",
      "Step: 3020 of 5001.\n",
      "Generator model loss: 1.0071870267391205.\n",
      "Discriminator model loss real: 0.7092817783355713.\n",
      "Discriminator model loss generated: 0.6407606899738312.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3021 of 5001.\n",
      "Step: 3022 of 5001.\n",
      "Step: 3023 of 5001.\n",
      "Step: 3024 of 5001.\n",
      "Step: 3025 of 5001.\n",
      "Step: 3026 of 5001.\n",
      "Step: 3027 of 5001.\n",
      "Step: 3028 of 5001.\n",
      "Step: 3029 of 5001.\n",
      "Step: 3030 of 5001.\n",
      "Generator model loss: 0.9947782099246979.\n",
      "Discriminator model loss real: 0.6682646125555038.\n",
      "Discriminator model loss generated: 0.6190751016139984.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3031 of 5001.\n",
      "Step: 3032 of 5001.\n",
      "Step: 3033 of 5001.\n",
      "Step: 3034 of 5001.\n",
      "Step: 3035 of 5001.\n",
      "Step: 3036 of 5001.\n",
      "Step: 3037 of 5001.\n",
      "Step: 3038 of 5001.\n",
      "Step: 3039 of 5001.\n",
      "Step: 3040 of 5001.\n",
      "Generator model loss: 1.0344092965126037.\n",
      "Discriminator model loss real: 0.6942546248435975.\n",
      "Discriminator model loss generated: 0.6197505414485931.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3041 of 5001.\n",
      "Step: 3042 of 5001.\n",
      "Step: 3043 of 5001.\n",
      "Step: 3044 of 5001.\n",
      "Step: 3045 of 5001.\n",
      "Step: 3046 of 5001.\n",
      "Step: 3047 of 5001.\n",
      "Step: 3048 of 5001.\n",
      "Step: 3049 of 5001.\n",
      "Step: 3050 of 5001.\n",
      "Generator model loss: 0.9865882515907287.\n",
      "Discriminator model loss real: 0.7334038704633713.\n",
      "Discriminator model loss generated: 0.6021479547023774.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3051 of 5001.\n",
      "Step: 3052 of 5001.\n",
      "Step: 3053 of 5001.\n",
      "Step: 3054 of 5001.\n",
      "Step: 3055 of 5001.\n",
      "Step: 3056 of 5001.\n",
      "Step: 3057 of 5001.\n",
      "Step: 3058 of 5001.\n",
      "Step: 3059 of 5001.\n",
      "Step: 3060 of 5001.\n",
      "Generator model loss: 0.9711138963699341.\n",
      "Discriminator model loss real: 0.7086503684520722.\n",
      "Discriminator model loss generated: 0.6443222343921662.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3061 of 5001.\n",
      "Step: 3062 of 5001.\n",
      "Step: 3063 of 5001.\n",
      "Step: 3064 of 5001.\n",
      "Step: 3065 of 5001.\n",
      "Step: 3066 of 5001.\n",
      "Step: 3067 of 5001.\n",
      "Step: 3068 of 5001.\n",
      "Step: 3069 of 5001.\n",
      "Step: 3070 of 5001.\n",
      "Generator model loss: 0.9899441421031951.\n",
      "Discriminator model loss real: 0.7050363272428513.\n",
      "Discriminator model loss generated: 0.6596282422542572.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3071 of 5001.\n",
      "Step: 3072 of 5001.\n",
      "Step: 3073 of 5001.\n",
      "Step: 3074 of 5001.\n",
      "Step: 3075 of 5001.\n",
      "Step: 3076 of 5001.\n",
      "Step: 3077 of 5001.\n",
      "Step: 3078 of 5001.\n",
      "Step: 3079 of 5001.\n",
      "Step: 3080 of 5001.\n",
      "Generator model loss: 1.049418604373932.\n",
      "Discriminator model loss real: 0.7305889189243316.\n",
      "Discriminator model loss generated: 0.6233566224575042.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3081 of 5001.\n",
      "Step: 3082 of 5001.\n",
      "Step: 3083 of 5001.\n",
      "Step: 3084 of 5001.\n",
      "Step: 3085 of 5001.\n",
      "Step: 3086 of 5001.\n",
      "Step: 3087 of 5001.\n",
      "Step: 3088 of 5001.\n",
      "Step: 3089 of 5001.\n",
      "Step: 3090 of 5001.\n",
      "Generator model loss: 0.9951200664043427.\n",
      "Discriminator model loss real: 0.7348969936370849.\n",
      "Discriminator model loss generated: 0.6291844308376312.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3091 of 5001.\n",
      "Step: 3092 of 5001.\n",
      "Step: 3093 of 5001.\n",
      "Step: 3094 of 5001.\n",
      "Step: 3095 of 5001.\n",
      "Step: 3096 of 5001.\n",
      "Step: 3097 of 5001.\n",
      "Step: 3098 of 5001.\n",
      "Step: 3099 of 5001.\n",
      "Step: 3100 of 5001.\n",
      "Generator model loss: 1.0062804579734803.\n",
      "Discriminator model loss real: 0.6819411784410476.\n",
      "Discriminator model loss generated: 0.613290935754776.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3101 of 5001.\n",
      "Step: 3102 of 5001.\n",
      "Step: 3103 of 5001.\n",
      "Step: 3104 of 5001.\n",
      "Step: 3105 of 5001.\n",
      "Step: 3106 of 5001.\n",
      "Step: 3107 of 5001.\n",
      "Step: 3108 of 5001.\n",
      "Step: 3109 of 5001.\n",
      "Step: 3110 of 5001.\n",
      "Generator model loss: 0.9920706033706665.\n",
      "Discriminator model loss real: 0.7315869688987732.\n",
      "Discriminator model loss generated: 0.6058907330036163.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3111 of 5001.\n",
      "Step: 3112 of 5001.\n",
      "Step: 3113 of 5001.\n",
      "Step: 3114 of 5001.\n",
      "Step: 3115 of 5001.\n",
      "Step: 3116 of 5001.\n",
      "Step: 3117 of 5001.\n",
      "Step: 3118 of 5001.\n",
      "Step: 3119 of 5001.\n",
      "Step: 3120 of 5001.\n",
      "Generator model loss: 1.0313544869422913.\n",
      "Discriminator model loss real: 0.7194697678089141.\n",
      "Discriminator model loss generated: 0.611445939540863.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3121 of 5001.\n",
      "Step: 3122 of 5001.\n",
      "Step: 3123 of 5001.\n",
      "Step: 3124 of 5001.\n",
      "Step: 3125 of 5001.\n",
      "Step: 3126 of 5001.\n",
      "Step: 3127 of 5001.\n",
      "Step: 3128 of 5001.\n",
      "Step: 3129 of 5001.\n",
      "Step: 3130 of 5001.\n",
      "Generator model loss: 1.049387401342392.\n",
      "Discriminator model loss real: 0.6947867006063462.\n",
      "Discriminator model loss generated: 0.6279518663883209.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3131 of 5001.\n",
      "Step: 3132 of 5001.\n",
      "Step: 3133 of 5001.\n",
      "Step: 3134 of 5001.\n",
      "Step: 3135 of 5001.\n",
      "Step: 3136 of 5001.\n",
      "Step: 3137 of 5001.\n",
      "Step: 3138 of 5001.\n",
      "Step: 3139 of 5001.\n",
      "Step: 3140 of 5001.\n",
      "Generator model loss: 1.0458854496479035.\n",
      "Discriminator model loss real: 0.6965654611587524.\n",
      "Discriminator model loss generated: 0.6295786559581756.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3141 of 5001.\n",
      "Step: 3142 of 5001.\n",
      "Step: 3143 of 5001.\n",
      "Step: 3144 of 5001.\n",
      "Step: 3145 of 5001.\n",
      "Step: 3146 of 5001.\n",
      "Step: 3147 of 5001.\n",
      "Step: 3148 of 5001.\n",
      "Step: 3149 of 5001.\n",
      "Step: 3150 of 5001.\n",
      "Generator model loss: 1.0103572249412536.\n",
      "Discriminator model loss real: 0.7130458861589432.\n",
      "Discriminator model loss generated: 0.6200182437896729.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3151 of 5001.\n",
      "Step: 3152 of 5001.\n",
      "Step: 3153 of 5001.\n",
      "Step: 3154 of 5001.\n",
      "Step: 3155 of 5001.\n",
      "Step: 3156 of 5001.\n",
      "Step: 3157 of 5001.\n",
      "Step: 3158 of 5001.\n",
      "Step: 3159 of 5001.\n",
      "Step: 3160 of 5001.\n",
      "Generator model loss: 1.0212301790714264.\n",
      "Discriminator model loss real: 0.7018563926219941.\n",
      "Discriminator model loss generated: 0.6527942180633545.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3161 of 5001.\n",
      "Step: 3162 of 5001.\n",
      "Step: 3163 of 5001.\n",
      "Step: 3164 of 5001.\n",
      "Step: 3165 of 5001.\n",
      "Step: 3166 of 5001.\n",
      "Step: 3167 of 5001.\n",
      "Step: 3168 of 5001.\n",
      "Step: 3169 of 5001.\n",
      "Step: 3170 of 5001.\n",
      "Generator model loss: 1.048667997121811.\n",
      "Discriminator model loss real: 0.6820421785116195.\n",
      "Discriminator model loss generated: 0.5959898412227631.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3171 of 5001.\n",
      "Step: 3172 of 5001.\n",
      "Step: 3173 of 5001.\n",
      "Step: 3174 of 5001.\n",
      "Step: 3175 of 5001.\n",
      "Step: 3176 of 5001.\n",
      "Step: 3177 of 5001.\n",
      "Step: 3178 of 5001.\n",
      "Step: 3179 of 5001.\n",
      "Step: 3180 of 5001.\n",
      "Generator model loss: 1.081066220998764.\n",
      "Discriminator model loss real: 0.703645920753479.\n",
      "Discriminator model loss generated: 0.57441446185112.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3181 of 5001.\n",
      "Step: 3182 of 5001.\n",
      "Step: 3183 of 5001.\n",
      "Step: 3184 of 5001.\n",
      "Step: 3185 of 5001.\n",
      "Step: 3186 of 5001.\n",
      "Step: 3187 of 5001.\n",
      "Step: 3188 of 5001.\n",
      "Step: 3189 of 5001.\n",
      "Step: 3190 of 5001.\n",
      "Generator model loss: 1.0544374287128448.\n",
      "Discriminator model loss real: 0.6705947309732437.\n",
      "Discriminator model loss generated: 0.5941478192806244.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3191 of 5001.\n",
      "Step: 3192 of 5001.\n",
      "Step: 3193 of 5001.\n",
      "Step: 3194 of 5001.\n",
      "Step: 3195 of 5001.\n",
      "Step: 3196 of 5001.\n",
      "Step: 3197 of 5001.\n",
      "Step: 3198 of 5001.\n",
      "Step: 3199 of 5001.\n",
      "Step: 3200 of 5001.\n",
      "Generator model loss: 1.0505635857582092.\n",
      "Discriminator model loss real: 0.7376759886741638.\n",
      "Discriminator model loss generated: 0.6383359253406524.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3201 of 5001.\n",
      "Step: 3202 of 5001.\n",
      "Step: 3203 of 5001.\n",
      "Step: 3204 of 5001.\n",
      "Step: 3205 of 5001.\n",
      "Step: 3206 of 5001.\n",
      "Step: 3207 of 5001.\n",
      "Step: 3208 of 5001.\n",
      "Step: 3209 of 5001.\n",
      "Step: 3210 of 5001.\n",
      "Generator model loss: 1.0592974364757537.\n",
      "Discriminator model loss real: 0.6864872217178345.\n",
      "Discriminator model loss generated: 0.6308870553970337.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3211 of 5001.\n",
      "Step: 3212 of 5001.\n",
      "Step: 3213 of 5001.\n",
      "Step: 3214 of 5001.\n",
      "Step: 3215 of 5001.\n",
      "Step: 3216 of 5001.\n",
      "Step: 3217 of 5001.\n",
      "Step: 3218 of 5001.\n",
      "Step: 3219 of 5001.\n",
      "Step: 3220 of 5001.\n",
      "Generator model loss: 1.0036888599395752.\n",
      "Discriminator model loss real: 0.6624405741691589.\n",
      "Discriminator model loss generated: 0.6955392181873321.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3221 of 5001.\n",
      "Step: 3222 of 5001.\n",
      "Step: 3223 of 5001.\n",
      "Step: 3224 of 5001.\n",
      "Step: 3225 of 5001.\n",
      "Step: 3226 of 5001.\n",
      "Step: 3227 of 5001.\n",
      "Step: 3228 of 5001.\n",
      "Step: 3229 of 5001.\n",
      "Step: 3230 of 5001.\n",
      "Generator model loss: 1.0547627747058868.\n",
      "Discriminator model loss real: 0.7360801696777344.\n",
      "Discriminator model loss generated: 0.5910890161991119.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3231 of 5001.\n",
      "Step: 3232 of 5001.\n",
      "Step: 3233 of 5001.\n",
      "Step: 3234 of 5001.\n",
      "Step: 3235 of 5001.\n",
      "Step: 3236 of 5001.\n",
      "Step: 3237 of 5001.\n",
      "Step: 3238 of 5001.\n",
      "Step: 3239 of 5001.\n",
      "Step: 3240 of 5001.\n",
      "Generator model loss: 1.043426549434662.\n",
      "Discriminator model loss real: 0.7160254031419754.\n",
      "Discriminator model loss generated: 0.6232020318508148.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3241 of 5001.\n",
      "Step: 3242 of 5001.\n",
      "Step: 3243 of 5001.\n",
      "Step: 3244 of 5001.\n",
      "Step: 3245 of 5001.\n",
      "Step: 3246 of 5001.\n",
      "Step: 3247 of 5001.\n",
      "Step: 3248 of 5001.\n",
      "Step: 3249 of 5001.\n",
      "Step: 3250 of 5001.\n",
      "Generator model loss: 1.0389716506004334.\n",
      "Discriminator model loss real: 0.7017705082893372.\n",
      "Discriminator model loss generated: 0.6876538872718811.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3251 of 5001.\n",
      "Step: 3252 of 5001.\n",
      "Step: 3253 of 5001.\n",
      "Step: 3254 of 5001.\n",
      "Step: 3255 of 5001.\n",
      "Step: 3256 of 5001.\n",
      "Step: 3257 of 5001.\n",
      "Step: 3258 of 5001.\n",
      "Step: 3259 of 5001.\n",
      "Step: 3260 of 5001.\n",
      "Generator model loss: 1.0148625195026397.\n",
      "Discriminator model loss real: 0.7048255145549774.\n",
      "Discriminator model loss generated: 0.5912041127681732.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3261 of 5001.\n",
      "Step: 3262 of 5001.\n",
      "Step: 3263 of 5001.\n",
      "Step: 3264 of 5001.\n",
      "Step: 3265 of 5001.\n",
      "Step: 3266 of 5001.\n",
      "Step: 3267 of 5001.\n",
      "Step: 3268 of 5001.\n",
      "Step: 3269 of 5001.\n",
      "Step: 3270 of 5001.\n",
      "Generator model loss: 1.0754372000694274.\n",
      "Discriminator model loss real: 0.6976794362068176.\n",
      "Discriminator model loss generated: 0.6012073218822479.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3271 of 5001.\n",
      "Step: 3272 of 5001.\n",
      "Step: 3273 of 5001.\n",
      "Step: 3274 of 5001.\n",
      "Step: 3275 of 5001.\n",
      "Step: 3276 of 5001.\n",
      "Step: 3277 of 5001.\n",
      "Step: 3278 of 5001.\n",
      "Step: 3279 of 5001.\n",
      "Step: 3280 of 5001.\n",
      "Generator model loss: 1.0924691438674927.\n",
      "Discriminator model loss real: 0.7839813530445099.\n",
      "Discriminator model loss generated: 0.5871037721633912.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3281 of 5001.\n",
      "Step: 3282 of 5001.\n",
      "Step: 3283 of 5001.\n",
      "Step: 3284 of 5001.\n",
      "Step: 3285 of 5001.\n",
      "Step: 3286 of 5001.\n",
      "Step: 3287 of 5001.\n",
      "Step: 3288 of 5001.\n",
      "Step: 3289 of 5001.\n",
      "Step: 3290 of 5001.\n",
      "Generator model loss: 1.106131649017334.\n",
      "Discriminator model loss real: 0.7202873528003693.\n",
      "Discriminator model loss generated: 0.6531690955162048.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3291 of 5001.\n",
      "Step: 3292 of 5001.\n",
      "Step: 3293 of 5001.\n",
      "Step: 3294 of 5001.\n",
      "Step: 3295 of 5001.\n",
      "Step: 3296 of 5001.\n",
      "Step: 3297 of 5001.\n",
      "Step: 3298 of 5001.\n",
      "Step: 3299 of 5001.\n",
      "Step: 3300 of 5001.\n",
      "Generator model loss: 1.0312732815742494.\n",
      "Discriminator model loss real: 0.6933819115161896.\n",
      "Discriminator model loss generated: 0.60358966588974.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3301 of 5001.\n",
      "Step: 3302 of 5001.\n",
      "Step: 3303 of 5001.\n",
      "Step: 3304 of 5001.\n",
      "Step: 3305 of 5001.\n",
      "Step: 3306 of 5001.\n",
      "Step: 3307 of 5001.\n",
      "Step: 3308 of 5001.\n",
      "Step: 3309 of 5001.\n",
      "Step: 3310 of 5001.\n",
      "Generator model loss: 1.0929473876953124.\n",
      "Discriminator model loss real: 0.7325716614723206.\n",
      "Discriminator model loss generated: 0.6132302343845367.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3311 of 5001.\n",
      "Step: 3312 of 5001.\n",
      "Step: 3313 of 5001.\n",
      "Step: 3314 of 5001.\n",
      "Step: 3315 of 5001.\n",
      "Step: 3316 of 5001.\n",
      "Step: 3317 of 5001.\n",
      "Step: 3318 of 5001.\n",
      "Step: 3319 of 5001.\n",
      "Step: 3320 of 5001.\n",
      "Generator model loss: 1.0450263619422913.\n",
      "Discriminator model loss real: 0.7170606404542923.\n",
      "Discriminator model loss generated: 0.590433394908905.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3321 of 5001.\n",
      "Step: 3322 of 5001.\n",
      "Step: 3323 of 5001.\n",
      "Step: 3324 of 5001.\n",
      "Step: 3325 of 5001.\n",
      "Step: 3326 of 5001.\n",
      "Step: 3327 of 5001.\n",
      "Step: 3328 of 5001.\n",
      "Step: 3329 of 5001.\n",
      "Step: 3330 of 5001.\n",
      "Generator model loss: 1.0656426906585694.\n",
      "Discriminator model loss real: 0.7104080736637115.\n",
      "Discriminator model loss generated: 0.6215113520622253.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3331 of 5001.\n",
      "Step: 3332 of 5001.\n",
      "Step: 3333 of 5001.\n",
      "Step: 3334 of 5001.\n",
      "Step: 3335 of 5001.\n",
      "Step: 3336 of 5001.\n",
      "Step: 3337 of 5001.\n",
      "Step: 3338 of 5001.\n",
      "Step: 3339 of 5001.\n",
      "Step: 3340 of 5001.\n",
      "Generator model loss: 1.1269182443618775.\n",
      "Discriminator model loss real: 0.7057116895914077.\n",
      "Discriminator model loss generated: 0.5939023077487946.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3341 of 5001.\n",
      "Step: 3342 of 5001.\n",
      "Step: 3343 of 5001.\n",
      "Step: 3344 of 5001.\n",
      "Step: 3345 of 5001.\n",
      "Step: 3346 of 5001.\n",
      "Step: 3347 of 5001.\n",
      "Step: 3348 of 5001.\n",
      "Step: 3349 of 5001.\n",
      "Step: 3350 of 5001.\n",
      "Generator model loss: 1.117196923494339.\n",
      "Discriminator model loss real: 0.7365943849086761.\n",
      "Discriminator model loss generated: 0.622405743598938.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3351 of 5001.\n",
      "Step: 3352 of 5001.\n",
      "Step: 3353 of 5001.\n",
      "Step: 3354 of 5001.\n",
      "Step: 3355 of 5001.\n",
      "Step: 3356 of 5001.\n",
      "Step: 3357 of 5001.\n",
      "Step: 3358 of 5001.\n",
      "Step: 3359 of 5001.\n",
      "Step: 3360 of 5001.\n",
      "Generator model loss: 1.0454720854759216.\n",
      "Discriminator model loss real: 0.6783876329660415.\n",
      "Discriminator model loss generated: 0.6405735611915588.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3361 of 5001.\n",
      "Step: 3362 of 5001.\n",
      "Step: 3363 of 5001.\n",
      "Step: 3364 of 5001.\n",
      "Step: 3365 of 5001.\n",
      "Step: 3366 of 5001.\n",
      "Step: 3367 of 5001.\n",
      "Step: 3368 of 5001.\n",
      "Step: 3369 of 5001.\n",
      "Step: 3370 of 5001.\n",
      "Generator model loss: 1.0377673089504242.\n",
      "Discriminator model loss real: 0.6953171819448472.\n",
      "Discriminator model loss generated: 0.6263910591602325.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3371 of 5001.\n",
      "Step: 3372 of 5001.\n",
      "Step: 3373 of 5001.\n",
      "Step: 3374 of 5001.\n",
      "Step: 3375 of 5001.\n",
      "Step: 3376 of 5001.\n",
      "Step: 3377 of 5001.\n",
      "Step: 3378 of 5001.\n",
      "Step: 3379 of 5001.\n",
      "Step: 3380 of 5001.\n",
      "Generator model loss: 1.1527027785778046.\n",
      "Discriminator model loss real: 0.7018254399299622.\n",
      "Discriminator model loss generated: 0.6412464380264282.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3381 of 5001.\n",
      "Step: 3382 of 5001.\n",
      "Step: 3383 of 5001.\n",
      "Step: 3384 of 5001.\n",
      "Step: 3385 of 5001.\n",
      "Step: 3386 of 5001.\n",
      "Step: 3387 of 5001.\n",
      "Step: 3388 of 5001.\n",
      "Step: 3389 of 5001.\n",
      "Step: 3390 of 5001.\n",
      "Generator model loss: 1.0862291932106019.\n",
      "Discriminator model loss real: 0.6946973919868469.\n",
      "Discriminator model loss generated: 0.6284256517887116.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3391 of 5001.\n",
      "Step: 3392 of 5001.\n",
      "Step: 3393 of 5001.\n",
      "Step: 3394 of 5001.\n",
      "Step: 3395 of 5001.\n",
      "Step: 3396 of 5001.\n",
      "Step: 3397 of 5001.\n",
      "Step: 3398 of 5001.\n",
      "Step: 3399 of 5001.\n",
      "Step: 3400 of 5001.\n",
      "Generator model loss: 1.0806726276874543.\n",
      "Discriminator model loss real: 0.70029037296772.\n",
      "Discriminator model loss generated: 0.6264832258224488.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3401 of 5001.\n",
      "Step: 3402 of 5001.\n",
      "Step: 3403 of 5001.\n",
      "Step: 3404 of 5001.\n",
      "Step: 3405 of 5001.\n",
      "Step: 3406 of 5001.\n",
      "Step: 3407 of 5001.\n",
      "Step: 3408 of 5001.\n",
      "Step: 3409 of 5001.\n",
      "Step: 3410 of 5001.\n",
      "Generator model loss: 1.1567674040794373.\n",
      "Discriminator model loss real: 0.6915872812271118.\n",
      "Discriminator model loss generated: 0.6492650926113128.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3411 of 5001.\n",
      "Step: 3412 of 5001.\n",
      "Step: 3413 of 5001.\n",
      "Step: 3414 of 5001.\n",
      "Step: 3415 of 5001.\n",
      "Step: 3416 of 5001.\n",
      "Step: 3417 of 5001.\n",
      "Step: 3418 of 5001.\n",
      "Step: 3419 of 5001.\n",
      "Step: 3420 of 5001.\n",
      "Generator model loss: 1.0453504741191864.\n",
      "Discriminator model loss real: 0.6479787647724151.\n",
      "Discriminator model loss generated: 0.6848929047584533.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3421 of 5001.\n",
      "Step: 3422 of 5001.\n",
      "Step: 3423 of 5001.\n",
      "Step: 3424 of 5001.\n",
      "Step: 3425 of 5001.\n",
      "Step: 3426 of 5001.\n",
      "Step: 3427 of 5001.\n",
      "Step: 3428 of 5001.\n",
      "Step: 3429 of 5001.\n",
      "Step: 3430 of 5001.\n",
      "Generator model loss: 1.0667546212673187.\n",
      "Discriminator model loss real: 0.7016390919685364.\n",
      "Discriminator model loss generated: 0.5897168159484864.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3431 of 5001.\n",
      "Step: 3432 of 5001.\n",
      "Step: 3433 of 5001.\n",
      "Step: 3434 of 5001.\n",
      "Step: 3435 of 5001.\n",
      "Step: 3436 of 5001.\n",
      "Step: 3437 of 5001.\n",
      "Step: 3438 of 5001.\n",
      "Step: 3439 of 5001.\n",
      "Step: 3440 of 5001.\n",
      "Generator model loss: 1.2269973397254943.\n",
      "Discriminator model loss real: 0.6807023048400879.\n",
      "Discriminator model loss generated: 0.6097866654396057.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3441 of 5001.\n",
      "Step: 3442 of 5001.\n",
      "Step: 3443 of 5001.\n",
      "Step: 3444 of 5001.\n",
      "Step: 3445 of 5001.\n",
      "Step: 3446 of 5001.\n",
      "Step: 3447 of 5001.\n",
      "Step: 3448 of 5001.\n",
      "Step: 3449 of 5001.\n",
      "Step: 3450 of 5001.\n",
      "Generator model loss: 1.0844620406627654.\n",
      "Discriminator model loss real: 0.6672170490026474.\n",
      "Discriminator model loss generated: 0.6261128425598145.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3451 of 5001.\n",
      "Step: 3452 of 5001.\n",
      "Step: 3453 of 5001.\n",
      "Step: 3454 of 5001.\n",
      "Step: 3455 of 5001.\n",
      "Step: 3456 of 5001.\n",
      "Step: 3457 of 5001.\n",
      "Step: 3458 of 5001.\n",
      "Step: 3459 of 5001.\n",
      "Step: 3460 of 5001.\n",
      "Generator model loss: 1.121058213710785.\n",
      "Discriminator model loss real: 0.7425496280193329.\n",
      "Discriminator model loss generated: 0.682370126247406.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3461 of 5001.\n",
      "Step: 3462 of 5001.\n",
      "Step: 3463 of 5001.\n",
      "Step: 3464 of 5001.\n",
      "Step: 3465 of 5001.\n",
      "Step: 3466 of 5001.\n",
      "Step: 3467 of 5001.\n",
      "Step: 3468 of 5001.\n",
      "Step: 3469 of 5001.\n",
      "Step: 3470 of 5001.\n",
      "Generator model loss: 1.0866360306739806.\n",
      "Discriminator model loss real: 0.693221652507782.\n",
      "Discriminator model loss generated: 0.6673896193504334.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3471 of 5001.\n",
      "Step: 3472 of 5001.\n",
      "Step: 3473 of 5001.\n",
      "Step: 3474 of 5001.\n",
      "Step: 3475 of 5001.\n",
      "Step: 3476 of 5001.\n",
      "Step: 3477 of 5001.\n",
      "Step: 3478 of 5001.\n",
      "Step: 3479 of 5001.\n",
      "Step: 3480 of 5001.\n",
      "Generator model loss: 1.0985917270183563.\n",
      "Discriminator model loss real: 0.669073635339737.\n",
      "Discriminator model loss generated: 0.6294709384441376.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3481 of 5001.\n",
      "Step: 3482 of 5001.\n",
      "Step: 3483 of 5001.\n",
      "Step: 3484 of 5001.\n",
      "Step: 3485 of 5001.\n",
      "Step: 3486 of 5001.\n",
      "Step: 3487 of 5001.\n",
      "Step: 3488 of 5001.\n",
      "Step: 3489 of 5001.\n",
      "Step: 3490 of 5001.\n",
      "Generator model loss: 1.1031028270721435.\n",
      "Discriminator model loss real: 0.6881511032581329.\n",
      "Discriminator model loss generated: 0.6403444230556488.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3491 of 5001.\n",
      "Step: 3492 of 5001.\n",
      "Step: 3493 of 5001.\n",
      "Step: 3494 of 5001.\n",
      "Step: 3495 of 5001.\n",
      "Step: 3496 of 5001.\n",
      "Step: 3497 of 5001.\n",
      "Step: 3498 of 5001.\n",
      "Step: 3499 of 5001.\n",
      "Step: 3500 of 5001.\n",
      "Generator model loss: 1.0578191816806792.\n",
      "Discriminator model loss real: 0.696714773774147.\n",
      "Discriminator model loss generated: 0.5893152713775635.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3501 of 5001.\n",
      "Step: 3502 of 5001.\n",
      "Step: 3503 of 5001.\n",
      "Step: 3504 of 5001.\n",
      "Step: 3505 of 5001.\n",
      "Step: 3506 of 5001.\n",
      "Step: 3507 of 5001.\n",
      "Step: 3508 of 5001.\n",
      "Step: 3509 of 5001.\n",
      "Step: 3510 of 5001.\n",
      "Generator model loss: 1.1146938264369965.\n",
      "Discriminator model loss real: 0.7338549077510834.\n",
      "Discriminator model loss generated: 0.6637673735618591.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3511 of 5001.\n",
      "Step: 3512 of 5001.\n",
      "Step: 3513 of 5001.\n",
      "Step: 3514 of 5001.\n",
      "Step: 3515 of 5001.\n",
      "Step: 3516 of 5001.\n",
      "Step: 3517 of 5001.\n",
      "Step: 3518 of 5001.\n",
      "Step: 3519 of 5001.\n",
      "Step: 3520 of 5001.\n",
      "Generator model loss: 1.0312683522701263.\n",
      "Discriminator model loss real: 0.6718732267618179.\n",
      "Discriminator model loss generated: 0.5974982440471649.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3521 of 5001.\n",
      "Step: 3522 of 5001.\n",
      "Step: 3523 of 5001.\n",
      "Step: 3524 of 5001.\n",
      "Step: 3525 of 5001.\n",
      "Step: 3526 of 5001.\n",
      "Step: 3527 of 5001.\n",
      "Step: 3528 of 5001.\n",
      "Step: 3529 of 5001.\n",
      "Step: 3530 of 5001.\n",
      "Generator model loss: 1.0772545874118804.\n",
      "Discriminator model loss real: 0.7329481482505799.\n",
      "Discriminator model loss generated: 0.6052744269371033.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3531 of 5001.\n",
      "Step: 3532 of 5001.\n",
      "Step: 3533 of 5001.\n",
      "Step: 3534 of 5001.\n",
      "Step: 3535 of 5001.\n",
      "Step: 3536 of 5001.\n",
      "Step: 3537 of 5001.\n",
      "Step: 3538 of 5001.\n",
      "Step: 3539 of 5001.\n",
      "Step: 3540 of 5001.\n",
      "Generator model loss: 1.0692564070224762.\n",
      "Discriminator model loss real: 0.7151512384414673.\n",
      "Discriminator model loss generated: 0.6758620619773865.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3541 of 5001.\n",
      "Step: 3542 of 5001.\n",
      "Step: 3543 of 5001.\n",
      "Step: 3544 of 5001.\n",
      "Step: 3545 of 5001.\n",
      "Step: 3546 of 5001.\n",
      "Step: 3547 of 5001.\n",
      "Step: 3548 of 5001.\n",
      "Step: 3549 of 5001.\n",
      "Step: 3550 of 5001.\n",
      "Generator model loss: 1.0605186820030212.\n",
      "Discriminator model loss real: 0.7111478924751282.\n",
      "Discriminator model loss generated: 0.6448308825492859.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3551 of 5001.\n",
      "Step: 3552 of 5001.\n",
      "Step: 3553 of 5001.\n",
      "Step: 3554 of 5001.\n",
      "Step: 3555 of 5001.\n",
      "Step: 3556 of 5001.\n",
      "Step: 3557 of 5001.\n",
      "Step: 3558 of 5001.\n",
      "Step: 3559 of 5001.\n",
      "Step: 3560 of 5001.\n",
      "Generator model loss: 1.1003332793712617.\n",
      "Discriminator model loss real: 0.679591315984726.\n",
      "Discriminator model loss generated: 0.5973956823348999.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3561 of 5001.\n",
      "Step: 3562 of 5001.\n",
      "Step: 3563 of 5001.\n",
      "Step: 3564 of 5001.\n",
      "Step: 3565 of 5001.\n",
      "Step: 3566 of 5001.\n",
      "Step: 3567 of 5001.\n",
      "Step: 3568 of 5001.\n",
      "Step: 3569 of 5001.\n",
      "Step: 3570 of 5001.\n",
      "Generator model loss: 1.0714453041553498.\n",
      "Discriminator model loss real: 0.7321567952632904.\n",
      "Discriminator model loss generated: 0.6662177324295044.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3571 of 5001.\n",
      "Step: 3572 of 5001.\n",
      "Step: 3573 of 5001.\n",
      "Step: 3574 of 5001.\n",
      "Step: 3575 of 5001.\n",
      "Step: 3576 of 5001.\n",
      "Step: 3577 of 5001.\n",
      "Step: 3578 of 5001.\n",
      "Step: 3579 of 5001.\n",
      "Step: 3580 of 5001.\n",
      "Generator model loss: 1.0402695953845977.\n",
      "Discriminator model loss real: 0.6762036621570587.\n",
      "Discriminator model loss generated: 0.6409224092960357.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3581 of 5001.\n",
      "Step: 3582 of 5001.\n",
      "Step: 3583 of 5001.\n",
      "Step: 3584 of 5001.\n",
      "Step: 3585 of 5001.\n",
      "Step: 3586 of 5001.\n",
      "Step: 3587 of 5001.\n",
      "Step: 3588 of 5001.\n",
      "Step: 3589 of 5001.\n",
      "Step: 3590 of 5001.\n",
      "Generator model loss: 1.0524387657642365.\n",
      "Discriminator model loss real: 0.6694152474403381.\n",
      "Discriminator model loss generated: 0.6634624600410461.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3591 of 5001.\n",
      "Step: 3592 of 5001.\n",
      "Step: 3593 of 5001.\n",
      "Step: 3594 of 5001.\n",
      "Step: 3595 of 5001.\n",
      "Step: 3596 of 5001.\n",
      "Step: 3597 of 5001.\n",
      "Step: 3598 of 5001.\n",
      "Step: 3599 of 5001.\n",
      "Step: 3600 of 5001.\n",
      "Generator model loss: 1.0520961165428162.\n",
      "Discriminator model loss real: 0.687419855594635.\n",
      "Discriminator model loss generated: 0.6127289831638336.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3601 of 5001.\n",
      "Step: 3602 of 5001.\n",
      "Step: 3603 of 5001.\n",
      "Step: 3604 of 5001.\n",
      "Step: 3605 of 5001.\n",
      "Step: 3606 of 5001.\n",
      "Step: 3607 of 5001.\n",
      "Step: 3608 of 5001.\n",
      "Step: 3609 of 5001.\n",
      "Step: 3610 of 5001.\n",
      "Generator model loss: 1.1005683183670043.\n",
      "Discriminator model loss real: 0.7476416051387786.\n",
      "Discriminator model loss generated: 0.6516557037830353.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3611 of 5001.\n",
      "Step: 3612 of 5001.\n",
      "Step: 3613 of 5001.\n",
      "Step: 3614 of 5001.\n",
      "Step: 3615 of 5001.\n",
      "Step: 3616 of 5001.\n",
      "Step: 3617 of 5001.\n",
      "Step: 3618 of 5001.\n",
      "Step: 3619 of 5001.\n",
      "Step: 3620 of 5001.\n",
      "Generator model loss: 1.048584097623825.\n",
      "Discriminator model loss real: 0.6826253145933151.\n",
      "Discriminator model loss generated: 0.5979626178741455.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3621 of 5001.\n",
      "Step: 3622 of 5001.\n",
      "Step: 3623 of 5001.\n",
      "Step: 3624 of 5001.\n",
      "Step: 3625 of 5001.\n",
      "Step: 3626 of 5001.\n",
      "Step: 3627 of 5001.\n",
      "Step: 3628 of 5001.\n",
      "Step: 3629 of 5001.\n",
      "Step: 3630 of 5001.\n",
      "Generator model loss: 1.0784980535507203.\n",
      "Discriminator model loss real: 0.6728777825832367.\n",
      "Discriminator model loss generated: 0.5939927756786346.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3631 of 5001.\n",
      "Step: 3632 of 5001.\n",
      "Step: 3633 of 5001.\n",
      "Step: 3634 of 5001.\n",
      "Step: 3635 of 5001.\n",
      "Step: 3636 of 5001.\n",
      "Step: 3637 of 5001.\n",
      "Step: 3638 of 5001.\n",
      "Step: 3639 of 5001.\n",
      "Step: 3640 of 5001.\n",
      "Generator model loss: 1.1301194310188294.\n",
      "Discriminator model loss real: 0.7495088160037995.\n",
      "Discriminator model loss generated: 0.6495864629745484.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3641 of 5001.\n",
      "Step: 3642 of 5001.\n",
      "Step: 3643 of 5001.\n",
      "Step: 3644 of 5001.\n",
      "Step: 3645 of 5001.\n",
      "Step: 3646 of 5001.\n",
      "Step: 3647 of 5001.\n",
      "Step: 3648 of 5001.\n",
      "Step: 3649 of 5001.\n",
      "Step: 3650 of 5001.\n",
      "Generator model loss: 1.0778205752372743.\n",
      "Discriminator model loss real: 0.6911471664905549.\n",
      "Discriminator model loss generated: 0.6364917159080505.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3651 of 5001.\n",
      "Step: 3652 of 5001.\n",
      "Step: 3653 of 5001.\n",
      "Step: 3654 of 5001.\n",
      "Step: 3655 of 5001.\n",
      "Step: 3656 of 5001.\n",
      "Step: 3657 of 5001.\n",
      "Step: 3658 of 5001.\n",
      "Step: 3659 of 5001.\n",
      "Step: 3660 of 5001.\n",
      "Generator model loss: 1.056045228242874.\n",
      "Discriminator model loss real: 0.6206220865249634.\n",
      "Discriminator model loss generated: 0.6155686438083648.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3661 of 5001.\n",
      "Step: 3662 of 5001.\n",
      "Step: 3663 of 5001.\n",
      "Step: 3664 of 5001.\n",
      "Step: 3665 of 5001.\n",
      "Step: 3666 of 5001.\n",
      "Step: 3667 of 5001.\n",
      "Step: 3668 of 5001.\n",
      "Step: 3669 of 5001.\n",
      "Step: 3670 of 5001.\n",
      "Generator model loss: 1.0475658893585205.\n",
      "Discriminator model loss real: 0.6578756123781204.\n",
      "Discriminator model loss generated: 0.6478176295757294.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3671 of 5001.\n",
      "Step: 3672 of 5001.\n",
      "Step: 3673 of 5001.\n",
      "Step: 3674 of 5001.\n",
      "Step: 3675 of 5001.\n",
      "Step: 3676 of 5001.\n",
      "Step: 3677 of 5001.\n",
      "Step: 3678 of 5001.\n",
      "Step: 3679 of 5001.\n",
      "Step: 3680 of 5001.\n",
      "Generator model loss: 1.0997306942939757.\n",
      "Discriminator model loss real: 0.7107139348983764.\n",
      "Discriminator model loss generated: 0.6256923854351044.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3681 of 5001.\n",
      "Step: 3682 of 5001.\n",
      "Step: 3683 of 5001.\n",
      "Step: 3684 of 5001.\n",
      "Step: 3685 of 5001.\n",
      "Step: 3686 of 5001.\n",
      "Step: 3687 of 5001.\n",
      "Step: 3688 of 5001.\n",
      "Step: 3689 of 5001.\n",
      "Step: 3690 of 5001.\n",
      "Generator model loss: 1.0826228976249694.\n",
      "Discriminator model loss real: 0.7276841044425965.\n",
      "Discriminator model loss generated: 0.6235058605670929.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3691 of 5001.\n",
      "Step: 3692 of 5001.\n",
      "Step: 3693 of 5001.\n",
      "Step: 3694 of 5001.\n",
      "Step: 3695 of 5001.\n",
      "Step: 3696 of 5001.\n",
      "Step: 3697 of 5001.\n",
      "Step: 3698 of 5001.\n",
      "Step: 3699 of 5001.\n",
      "Step: 3700 of 5001.\n",
      "Generator model loss: 1.0985494256019592.\n",
      "Discriminator model loss real: 0.7031273305416107.\n",
      "Discriminator model loss generated: 0.5841176629066467.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3701 of 5001.\n",
      "Step: 3702 of 5001.\n",
      "Step: 3703 of 5001.\n",
      "Step: 3704 of 5001.\n",
      "Step: 3705 of 5001.\n",
      "Step: 3706 of 5001.\n",
      "Step: 3707 of 5001.\n",
      "Step: 3708 of 5001.\n",
      "Step: 3709 of 5001.\n",
      "Step: 3710 of 5001.\n",
      "Generator model loss: 1.0675292134284973.\n",
      "Discriminator model loss real: 0.7169072270393372.\n",
      "Discriminator model loss generated: 0.6354388952255249.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3711 of 5001.\n",
      "Step: 3712 of 5001.\n",
      "Step: 3713 of 5001.\n",
      "Step: 3714 of 5001.\n",
      "Step: 3715 of 5001.\n",
      "Step: 3716 of 5001.\n",
      "Step: 3717 of 5001.\n",
      "Step: 3718 of 5001.\n",
      "Step: 3719 of 5001.\n",
      "Step: 3720 of 5001.\n",
      "Generator model loss: 1.0733651757240295.\n",
      "Discriminator model loss real: 0.7030740350484848.\n",
      "Discriminator model loss generated: 0.6181801438331604.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3721 of 5001.\n",
      "Step: 3722 of 5001.\n",
      "Step: 3723 of 5001.\n",
      "Step: 3724 of 5001.\n",
      "Step: 3725 of 5001.\n",
      "Step: 3726 of 5001.\n",
      "Step: 3727 of 5001.\n",
      "Step: 3728 of 5001.\n",
      "Step: 3729 of 5001.\n",
      "Step: 3730 of 5001.\n",
      "Generator model loss: 1.1619983077049256.\n",
      "Discriminator model loss real: 0.7788023829460144.\n",
      "Discriminator model loss generated: 0.6063194632530212.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3731 of 5001.\n",
      "Step: 3732 of 5001.\n",
      "Step: 3733 of 5001.\n",
      "Step: 3734 of 5001.\n",
      "Step: 3735 of 5001.\n",
      "Step: 3736 of 5001.\n",
      "Step: 3737 of 5001.\n",
      "Step: 3738 of 5001.\n",
      "Step: 3739 of 5001.\n",
      "Step: 3740 of 5001.\n",
      "Generator model loss: 1.0692847549915314.\n",
      "Discriminator model loss real: 0.6970838397741318.\n",
      "Discriminator model loss generated: 0.5831107199192047.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3741 of 5001.\n",
      "Step: 3742 of 5001.\n",
      "Step: 3743 of 5001.\n",
      "Step: 3744 of 5001.\n",
      "Step: 3745 of 5001.\n",
      "Step: 3746 of 5001.\n",
      "Step: 3747 of 5001.\n",
      "Step: 3748 of 5001.\n",
      "Step: 3749 of 5001.\n",
      "Step: 3750 of 5001.\n",
      "Generator model loss: 1.0912840723991395.\n",
      "Discriminator model loss real: 0.6877367526292801.\n",
      "Discriminator model loss generated: 0.606881844997406.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3751 of 5001.\n",
      "Step: 3752 of 5001.\n",
      "Step: 3753 of 5001.\n",
      "Step: 3754 of 5001.\n",
      "Step: 3755 of 5001.\n",
      "Step: 3756 of 5001.\n",
      "Step: 3757 of 5001.\n",
      "Step: 3758 of 5001.\n",
      "Step: 3759 of 5001.\n",
      "Step: 3760 of 5001.\n",
      "Generator model loss: 1.0893083035945892.\n",
      "Discriminator model loss real: 0.7291826575994491.\n",
      "Discriminator model loss generated: 0.6108081936836243.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3761 of 5001.\n",
      "Step: 3762 of 5001.\n",
      "Step: 3763 of 5001.\n",
      "Step: 3764 of 5001.\n",
      "Step: 3765 of 5001.\n",
      "Step: 3766 of 5001.\n",
      "Step: 3767 of 5001.\n",
      "Step: 3768 of 5001.\n",
      "Step: 3769 of 5001.\n",
      "Step: 3770 of 5001.\n",
      "Generator model loss: 1.0817135572433472.\n",
      "Discriminator model loss real: 0.6957714557647705.\n",
      "Discriminator model loss generated: 0.6237954437732697.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3771 of 5001.\n",
      "Step: 3772 of 5001.\n",
      "Step: 3773 of 5001.\n",
      "Step: 3774 of 5001.\n",
      "Step: 3775 of 5001.\n",
      "Step: 3776 of 5001.\n",
      "Step: 3777 of 5001.\n",
      "Step: 3778 of 5001.\n",
      "Step: 3779 of 5001.\n",
      "Step: 3780 of 5001.\n",
      "Generator model loss: 1.080635130405426.\n",
      "Discriminator model loss real: 0.7476206660270691.\n",
      "Discriminator model loss generated: 0.5906329154968262.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3781 of 5001.\n",
      "Step: 3782 of 5001.\n",
      "Step: 3783 of 5001.\n",
      "Step: 3784 of 5001.\n",
      "Step: 3785 of 5001.\n",
      "Step: 3786 of 5001.\n",
      "Step: 3787 of 5001.\n",
      "Step: 3788 of 5001.\n",
      "Step: 3789 of 5001.\n",
      "Step: 3790 of 5001.\n",
      "Generator model loss: 1.0417966187000274.\n",
      "Discriminator model loss real: 0.6860545068979264.\n",
      "Discriminator model loss generated: 0.6325308084487915.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3791 of 5001.\n",
      "Step: 3792 of 5001.\n",
      "Step: 3793 of 5001.\n",
      "Step: 3794 of 5001.\n",
      "Step: 3795 of 5001.\n",
      "Step: 3796 of 5001.\n",
      "Step: 3797 of 5001.\n",
      "Step: 3798 of 5001.\n",
      "Step: 3799 of 5001.\n",
      "Step: 3800 of 5001.\n",
      "Generator model loss: 1.0704032480716705.\n",
      "Discriminator model loss real: 0.6930830925703049.\n",
      "Discriminator model loss generated: 0.6426132142543792.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3801 of 5001.\n",
      "Step: 3802 of 5001.\n",
      "Step: 3803 of 5001.\n",
      "Step: 3804 of 5001.\n",
      "Step: 3805 of 5001.\n",
      "Step: 3806 of 5001.\n",
      "Step: 3807 of 5001.\n",
      "Step: 3808 of 5001.\n",
      "Step: 3809 of 5001.\n",
      "Step: 3810 of 5001.\n",
      "Generator model loss: 1.0660694658756256.\n",
      "Discriminator model loss real: 0.6508313596248627.\n",
      "Discriminator model loss generated: 0.6596546411514282.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3811 of 5001.\n",
      "Step: 3812 of 5001.\n",
      "Step: 3813 of 5001.\n",
      "Step: 3814 of 5001.\n",
      "Step: 3815 of 5001.\n",
      "Step: 3816 of 5001.\n",
      "Step: 3817 of 5001.\n",
      "Step: 3818 of 5001.\n",
      "Step: 3819 of 5001.\n",
      "Step: 3820 of 5001.\n",
      "Generator model loss: 1.062606281042099.\n",
      "Discriminator model loss real: 0.6987123608589172.\n",
      "Discriminator model loss generated: 0.604238873720169.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3821 of 5001.\n",
      "Step: 3822 of 5001.\n",
      "Step: 3823 of 5001.\n",
      "Step: 3824 of 5001.\n",
      "Step: 3825 of 5001.\n",
      "Step: 3826 of 5001.\n",
      "Step: 3827 of 5001.\n",
      "Step: 3828 of 5001.\n",
      "Step: 3829 of 5001.\n",
      "Step: 3830 of 5001.\n",
      "Generator model loss: 1.1041015028953551.\n",
      "Discriminator model loss real: 0.6666580021381379.\n",
      "Discriminator model loss generated: 0.6130822658538818.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3831 of 5001.\n",
      "Step: 3832 of 5001.\n",
      "Step: 3833 of 5001.\n",
      "Step: 3834 of 5001.\n",
      "Step: 3835 of 5001.\n",
      "Step: 3836 of 5001.\n",
      "Step: 3837 of 5001.\n",
      "Step: 3838 of 5001.\n",
      "Step: 3839 of 5001.\n",
      "Step: 3840 of 5001.\n",
      "Generator model loss: 1.0314130306243896.\n",
      "Discriminator model loss real: 0.6770295321941375.\n",
      "Discriminator model loss generated: 0.634776359796524.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3841 of 5001.\n",
      "Step: 3842 of 5001.\n",
      "Step: 3843 of 5001.\n",
      "Step: 3844 of 5001.\n",
      "Step: 3845 of 5001.\n",
      "Step: 3846 of 5001.\n",
      "Step: 3847 of 5001.\n",
      "Step: 3848 of 5001.\n",
      "Step: 3849 of 5001.\n",
      "Step: 3850 of 5001.\n",
      "Generator model loss: 1.0192854583263398.\n",
      "Discriminator model loss real: 0.6399400353431701.\n",
      "Discriminator model loss generated: 0.6165226757526397.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3851 of 5001.\n",
      "Step: 3852 of 5001.\n",
      "Step: 3853 of 5001.\n",
      "Step: 3854 of 5001.\n",
      "Step: 3855 of 5001.\n",
      "Step: 3856 of 5001.\n",
      "Step: 3857 of 5001.\n",
      "Step: 3858 of 5001.\n",
      "Step: 3859 of 5001.\n",
      "Step: 3860 of 5001.\n",
      "Generator model loss: 1.0532459795475007.\n",
      "Discriminator model loss real: 0.7251208543777465.\n",
      "Discriminator model loss generated: 0.6637214004993439.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3861 of 5001.\n",
      "Step: 3862 of 5001.\n",
      "Step: 3863 of 5001.\n",
      "Step: 3864 of 5001.\n",
      "Step: 3865 of 5001.\n",
      "Step: 3866 of 5001.\n",
      "Step: 3867 of 5001.\n",
      "Step: 3868 of 5001.\n",
      "Step: 3869 of 5001.\n",
      "Step: 3870 of 5001.\n",
      "Generator model loss: 1.0695889830589294.\n",
      "Discriminator model loss real: 0.6850906312465668.\n",
      "Discriminator model loss generated: 0.6613653421401977.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3871 of 5001.\n",
      "Step: 3872 of 5001.\n",
      "Step: 3873 of 5001.\n",
      "Step: 3874 of 5001.\n",
      "Step: 3875 of 5001.\n",
      "Step: 3876 of 5001.\n",
      "Step: 3877 of 5001.\n",
      "Step: 3878 of 5001.\n",
      "Step: 3879 of 5001.\n",
      "Step: 3880 of 5001.\n",
      "Generator model loss: 1.0685524702072144.\n",
      "Discriminator model loss real: 0.6838063418865203.\n",
      "Discriminator model loss generated: 0.6055220603942871.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3881 of 5001.\n",
      "Step: 3882 of 5001.\n",
      "Step: 3883 of 5001.\n",
      "Step: 3884 of 5001.\n",
      "Step: 3885 of 5001.\n",
      "Step: 3886 of 5001.\n",
      "Step: 3887 of 5001.\n",
      "Step: 3888 of 5001.\n",
      "Step: 3889 of 5001.\n",
      "Step: 3890 of 5001.\n",
      "Generator model loss: 1.088586002588272.\n",
      "Discriminator model loss real: 0.6814543396234513.\n",
      "Discriminator model loss generated: 0.6112295687198639.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3891 of 5001.\n",
      "Step: 3892 of 5001.\n",
      "Step: 3893 of 5001.\n",
      "Step: 3894 of 5001.\n",
      "Step: 3895 of 5001.\n",
      "Step: 3896 of 5001.\n",
      "Step: 3897 of 5001.\n",
      "Step: 3898 of 5001.\n",
      "Step: 3899 of 5001.\n",
      "Step: 3900 of 5001.\n",
      "Generator model loss: 1.07207892537117.\n",
      "Discriminator model loss real: 0.7043440937995911.\n",
      "Discriminator model loss generated: 0.6235505938529968.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3901 of 5001.\n",
      "Step: 3902 of 5001.\n",
      "Step: 3903 of 5001.\n",
      "Step: 3904 of 5001.\n",
      "Step: 3905 of 5001.\n",
      "Step: 3906 of 5001.\n",
      "Step: 3907 of 5001.\n",
      "Step: 3908 of 5001.\n",
      "Step: 3909 of 5001.\n",
      "Step: 3910 of 5001.\n",
      "Generator model loss: 1.0947115004062653.\n",
      "Discriminator model loss real: 0.6793779999017715.\n",
      "Discriminator model loss generated: 0.6104035139083862.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3911 of 5001.\n",
      "Step: 3912 of 5001.\n",
      "Step: 3913 of 5001.\n",
      "Step: 3914 of 5001.\n",
      "Step: 3915 of 5001.\n",
      "Step: 3916 of 5001.\n",
      "Step: 3917 of 5001.\n",
      "Step: 3918 of 5001.\n",
      "Step: 3919 of 5001.\n",
      "Step: 3920 of 5001.\n",
      "Generator model loss: 1.046848601102829.\n",
      "Discriminator model loss real: 0.6454040884971619.\n",
      "Discriminator model loss generated: 0.646356201171875.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3921 of 5001.\n",
      "Step: 3922 of 5001.\n",
      "Step: 3923 of 5001.\n",
      "Step: 3924 of 5001.\n",
      "Step: 3925 of 5001.\n",
      "Step: 3926 of 5001.\n",
      "Step: 3927 of 5001.\n",
      "Step: 3928 of 5001.\n",
      "Step: 3929 of 5001.\n",
      "Step: 3930 of 5001.\n",
      "Generator model loss: 1.0851962089538574.\n",
      "Discriminator model loss real: 0.7221752583980561.\n",
      "Discriminator model loss generated: 0.7123595714569092.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3931 of 5001.\n",
      "Step: 3932 of 5001.\n",
      "Step: 3933 of 5001.\n",
      "Step: 3934 of 5001.\n",
      "Step: 3935 of 5001.\n",
      "Step: 3936 of 5001.\n",
      "Step: 3937 of 5001.\n",
      "Step: 3938 of 5001.\n",
      "Step: 3939 of 5001.\n",
      "Step: 3940 of 5001.\n",
      "Generator model loss: 1.0337141811847688.\n",
      "Discriminator model loss real: 0.693579837679863.\n",
      "Discriminator model loss generated: 0.6005472421646119.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3941 of 5001.\n",
      "Step: 3942 of 5001.\n",
      "Step: 3943 of 5001.\n",
      "Step: 3944 of 5001.\n",
      "Step: 3945 of 5001.\n",
      "Step: 3946 of 5001.\n",
      "Step: 3947 of 5001.\n",
      "Step: 3948 of 5001.\n",
      "Step: 3949 of 5001.\n",
      "Step: 3950 of 5001.\n",
      "Generator model loss: 1.1157068848609923.\n",
      "Discriminator model loss real: 0.7311622262001037.\n",
      "Discriminator model loss generated: 0.6074368238449097.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3951 of 5001.\n",
      "Step: 3952 of 5001.\n",
      "Step: 3953 of 5001.\n",
      "Step: 3954 of 5001.\n",
      "Step: 3955 of 5001.\n",
      "Step: 3956 of 5001.\n",
      "Step: 3957 of 5001.\n",
      "Step: 3958 of 5001.\n",
      "Step: 3959 of 5001.\n",
      "Step: 3960 of 5001.\n",
      "Generator model loss: 1.0300715029239655.\n",
      "Discriminator model loss real: 0.7101167351007461.\n",
      "Discriminator model loss generated: 0.6515162527561188.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3961 of 5001.\n",
      "Step: 3962 of 5001.\n",
      "Step: 3963 of 5001.\n",
      "Step: 3964 of 5001.\n",
      "Step: 3965 of 5001.\n",
      "Step: 3966 of 5001.\n",
      "Step: 3967 of 5001.\n",
      "Step: 3968 of 5001.\n",
      "Step: 3969 of 5001.\n",
      "Step: 3970 of 5001.\n",
      "Generator model loss: 1.0453369200229645.\n",
      "Discriminator model loss real: 0.6416013330221176.\n",
      "Discriminator model loss generated: 0.6230700731277465.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 3971 of 5001.\n",
      "Step: 3972 of 5001.\n",
      "Step: 3973 of 5001.\n",
      "Step: 3974 of 5001.\n",
      "Step: 3975 of 5001.\n",
      "Step: 3976 of 5001.\n",
      "Step: 3977 of 5001.\n",
      "Step: 3978 of 5001.\n",
      "Step: 3979 of 5001.\n",
      "Step: 3980 of 5001.\n",
      "Generator model loss: 1.0629498958587646.\n",
      "Discriminator model loss real: 0.6886291623115539.\n",
      "Discriminator model loss generated: 0.6814434587955475.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3981 of 5001.\n",
      "Step: 3982 of 5001.\n",
      "Step: 3983 of 5001.\n",
      "Step: 3984 of 5001.\n",
      "Step: 3985 of 5001.\n",
      "Step: 3986 of 5001.\n",
      "Step: 3987 of 5001.\n",
      "Step: 3988 of 5001.\n",
      "Step: 3989 of 5001.\n",
      "Step: 3990 of 5001.\n",
      "Generator model loss: 1.0624300956726074.\n",
      "Discriminator model loss real: 0.6663424521684647.\n",
      "Discriminator model loss generated: 0.6787882566452026.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3991 of 5001.\n",
      "Step: 3992 of 5001.\n",
      "Step: 3993 of 5001.\n",
      "Step: 3994 of 5001.\n",
      "Step: 3995 of 5001.\n",
      "Step: 3996 of 5001.\n",
      "Step: 3997 of 5001.\n",
      "Step: 3998 of 5001.\n",
      "Step: 3999 of 5001.\n",
      "Step: 4000 of 5001.\n",
      "Generator model loss: 1.0142277479171753.\n",
      "Discriminator model loss real: 0.690429738163948.\n",
      "Discriminator model loss generated: 0.602600634098053.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4001 of 5001.\n",
      "Step: 4002 of 5001.\n",
      "Step: 4003 of 5001.\n",
      "Step: 4004 of 5001.\n",
      "Step: 4005 of 5001.\n",
      "Step: 4006 of 5001.\n",
      "Step: 4007 of 5001.\n",
      "Step: 4008 of 5001.\n",
      "Step: 4009 of 5001.\n",
      "Step: 4010 of 5001.\n",
      "Generator model loss: 1.109533929824829.\n",
      "Discriminator model loss real: 0.6969321668148041.\n",
      "Discriminator model loss generated: 0.6704159319400788.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4011 of 5001.\n",
      "Step: 4012 of 5001.\n",
      "Step: 4013 of 5001.\n",
      "Step: 4014 of 5001.\n",
      "Step: 4015 of 5001.\n",
      "Step: 4016 of 5001.\n",
      "Step: 4017 of 5001.\n",
      "Step: 4018 of 5001.\n",
      "Step: 4019 of 5001.\n",
      "Step: 4020 of 5001.\n",
      "Generator model loss: 1.055148285627365.\n",
      "Discriminator model loss real: 0.6816438406705856.\n",
      "Discriminator model loss generated: 0.6837718784809113.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4021 of 5001.\n",
      "Step: 4022 of 5001.\n",
      "Step: 4023 of 5001.\n",
      "Step: 4024 of 5001.\n",
      "Step: 4025 of 5001.\n",
      "Step: 4026 of 5001.\n",
      "Step: 4027 of 5001.\n",
      "Step: 4028 of 5001.\n",
      "Step: 4029 of 5001.\n",
      "Step: 4030 of 5001.\n",
      "Generator model loss: 1.050149142742157.\n",
      "Discriminator model loss real: 0.6885404318571091.\n",
      "Discriminator model loss generated: 0.6025156021118164.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4031 of 5001.\n",
      "Step: 4032 of 5001.\n",
      "Step: 4033 of 5001.\n",
      "Step: 4034 of 5001.\n",
      "Step: 4035 of 5001.\n",
      "Step: 4036 of 5001.\n",
      "Step: 4037 of 5001.\n",
      "Step: 4038 of 5001.\n",
      "Step: 4039 of 5001.\n",
      "Step: 4040 of 5001.\n",
      "Generator model loss: 1.0670037508010863.\n",
      "Discriminator model loss real: 0.6781127035617829.\n",
      "Discriminator model loss generated: 0.6194222271442413.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4041 of 5001.\n",
      "Step: 4042 of 5001.\n",
      "Step: 4043 of 5001.\n",
      "Step: 4044 of 5001.\n",
      "Step: 4045 of 5001.\n",
      "Step: 4046 of 5001.\n",
      "Step: 4047 of 5001.\n",
      "Step: 4048 of 5001.\n",
      "Step: 4049 of 5001.\n",
      "Step: 4050 of 5001.\n",
      "Generator model loss: 1.0417636632919312.\n",
      "Discriminator model loss real: 0.6949234545230866.\n",
      "Discriminator model loss generated: 0.6407524824142456.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4051 of 5001.\n",
      "Step: 4052 of 5001.\n",
      "Step: 4053 of 5001.\n",
      "Step: 4054 of 5001.\n",
      "Step: 4055 of 5001.\n",
      "Step: 4056 of 5001.\n",
      "Step: 4057 of 5001.\n",
      "Step: 4058 of 5001.\n",
      "Step: 4059 of 5001.\n",
      "Step: 4060 of 5001.\n",
      "Generator model loss: 1.1532825231552124.\n",
      "Discriminator model loss real: 0.7183380514383316.\n",
      "Discriminator model loss generated: 0.6777334451675415.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4061 of 5001.\n",
      "Step: 4062 of 5001.\n",
      "Step: 4063 of 5001.\n",
      "Step: 4064 of 5001.\n",
      "Step: 4065 of 5001.\n",
      "Step: 4066 of 5001.\n",
      "Step: 4067 of 5001.\n",
      "Step: 4068 of 5001.\n",
      "Step: 4069 of 5001.\n",
      "Step: 4070 of 5001.\n",
      "Generator model loss: 1.0676958441734314.\n",
      "Discriminator model loss real: 0.6941411942243576.\n",
      "Discriminator model loss generated: 0.6119200229644776.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4071 of 5001.\n",
      "Step: 4072 of 5001.\n",
      "Step: 4073 of 5001.\n",
      "Step: 4074 of 5001.\n",
      "Step: 4075 of 5001.\n",
      "Step: 4076 of 5001.\n",
      "Step: 4077 of 5001.\n",
      "Step: 4078 of 5001.\n",
      "Step: 4079 of 5001.\n",
      "Step: 4080 of 5001.\n",
      "Generator model loss: 1.1138917207717896.\n",
      "Discriminator model loss real: 0.7174017518758774.\n",
      "Discriminator model loss generated: 0.5793823957443237.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4081 of 5001.\n",
      "Step: 4082 of 5001.\n",
      "Step: 4083 of 5001.\n",
      "Step: 4084 of 5001.\n",
      "Step: 4085 of 5001.\n",
      "Step: 4086 of 5001.\n",
      "Step: 4087 of 5001.\n",
      "Step: 4088 of 5001.\n",
      "Step: 4089 of 5001.\n",
      "Step: 4090 of 5001.\n",
      "Generator model loss: 1.049043023586273.\n",
      "Discriminator model loss real: 0.684305214881897.\n",
      "Discriminator model loss generated: 0.616100651025772.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4091 of 5001.\n",
      "Step: 4092 of 5001.\n",
      "Step: 4093 of 5001.\n",
      "Step: 4094 of 5001.\n",
      "Step: 4095 of 5001.\n",
      "Step: 4096 of 5001.\n",
      "Step: 4097 of 5001.\n",
      "Step: 4098 of 5001.\n",
      "Step: 4099 of 5001.\n",
      "Step: 4100 of 5001.\n",
      "Generator model loss: 1.0542885780334472.\n",
      "Discriminator model loss real: 0.6547618240118027.\n",
      "Discriminator model loss generated: 0.5982309341430664.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4101 of 5001.\n",
      "Step: 4102 of 5001.\n",
      "Step: 4103 of 5001.\n",
      "Step: 4104 of 5001.\n",
      "Step: 4105 of 5001.\n",
      "Step: 4106 of 5001.\n",
      "Step: 4107 of 5001.\n",
      "Step: 4108 of 5001.\n",
      "Step: 4109 of 5001.\n",
      "Step: 4110 of 5001.\n",
      "Generator model loss: 1.041011506319046.\n",
      "Discriminator model loss real: 0.7040140986442566.\n",
      "Discriminator model loss generated: 0.6182600080966949.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4111 of 5001.\n",
      "Step: 4112 of 5001.\n",
      "Step: 4113 of 5001.\n",
      "Step: 4114 of 5001.\n",
      "Step: 4115 of 5001.\n",
      "Step: 4116 of 5001.\n",
      "Step: 4117 of 5001.\n",
      "Step: 4118 of 5001.\n",
      "Step: 4119 of 5001.\n",
      "Step: 4120 of 5001.\n",
      "Generator model loss: 1.0663919150829315.\n",
      "Discriminator model loss real: 0.6558283001184464.\n",
      "Discriminator model loss generated: 0.7068852007389068.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4121 of 5001.\n",
      "Step: 4122 of 5001.\n",
      "Step: 4123 of 5001.\n",
      "Step: 4124 of 5001.\n",
      "Step: 4125 of 5001.\n",
      "Step: 4126 of 5001.\n",
      "Step: 4127 of 5001.\n",
      "Step: 4128 of 5001.\n",
      "Step: 4129 of 5001.\n",
      "Step: 4130 of 5001.\n",
      "Generator model loss: 1.0690141439437866.\n",
      "Discriminator model loss real: 0.6704282701015473.\n",
      "Discriminator model loss generated: 0.6369811177253724.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4131 of 5001.\n",
      "Step: 4132 of 5001.\n",
      "Step: 4133 of 5001.\n",
      "Step: 4134 of 5001.\n",
      "Step: 4135 of 5001.\n",
      "Step: 4136 of 5001.\n",
      "Step: 4137 of 5001.\n",
      "Step: 4138 of 5001.\n",
      "Step: 4139 of 5001.\n",
      "Step: 4140 of 5001.\n",
      "Generator model loss: 1.079619860649109.\n",
      "Discriminator model loss real: 0.7614349305629731.\n",
      "Discriminator model loss generated: 0.6028543889522553.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4141 of 5001.\n",
      "Step: 4142 of 5001.\n",
      "Step: 4143 of 5001.\n",
      "Step: 4144 of 5001.\n",
      "Step: 4145 of 5001.\n",
      "Step: 4146 of 5001.\n",
      "Step: 4147 of 5001.\n",
      "Step: 4148 of 5001.\n",
      "Step: 4149 of 5001.\n",
      "Step: 4150 of 5001.\n",
      "Generator model loss: 1.064349538087845.\n",
      "Discriminator model loss real: 0.7102698564529419.\n",
      "Discriminator model loss generated: 0.6598049700260162.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4151 of 5001.\n",
      "Step: 4152 of 5001.\n",
      "Step: 4153 of 5001.\n",
      "Step: 4154 of 5001.\n",
      "Step: 4155 of 5001.\n",
      "Step: 4156 of 5001.\n",
      "Step: 4157 of 5001.\n",
      "Step: 4158 of 5001.\n",
      "Step: 4159 of 5001.\n",
      "Step: 4160 of 5001.\n",
      "Generator model loss: 1.0199111640453338.\n",
      "Discriminator model loss real: 0.6776341795921326.\n",
      "Discriminator model loss generated: 0.6951148033142089.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4161 of 5001.\n",
      "Step: 4162 of 5001.\n",
      "Step: 4163 of 5001.\n",
      "Step: 4164 of 5001.\n",
      "Step: 4165 of 5001.\n",
      "Step: 4166 of 5001.\n",
      "Step: 4167 of 5001.\n",
      "Step: 4168 of 5001.\n",
      "Step: 4169 of 5001.\n",
      "Step: 4170 of 5001.\n",
      "Generator model loss: 1.0724277317523956.\n",
      "Discriminator model loss real: 0.6810784459114074.\n",
      "Discriminator model loss generated: 0.6673233032226562.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4171 of 5001.\n",
      "Step: 4172 of 5001.\n",
      "Step: 4173 of 5001.\n",
      "Step: 4174 of 5001.\n",
      "Step: 4175 of 5001.\n",
      "Step: 4176 of 5001.\n",
      "Step: 4177 of 5001.\n",
      "Step: 4178 of 5001.\n",
      "Step: 4179 of 5001.\n",
      "Step: 4180 of 5001.\n",
      "Generator model loss: 1.0773751974105834.\n",
      "Discriminator model loss real: 0.705358237028122.\n",
      "Discriminator model loss generated: 0.6475607037544251.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4181 of 5001.\n",
      "Step: 4182 of 5001.\n",
      "Step: 4183 of 5001.\n",
      "Step: 4184 of 5001.\n",
      "Step: 4185 of 5001.\n",
      "Step: 4186 of 5001.\n",
      "Step: 4187 of 5001.\n",
      "Step: 4188 of 5001.\n",
      "Step: 4189 of 5001.\n",
      "Step: 4190 of 5001.\n",
      "Generator model loss: 1.0626881659030913.\n",
      "Discriminator model loss real: 0.6744256019592285.\n",
      "Discriminator model loss generated: 0.6165609300136566.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4191 of 5001.\n",
      "Step: 4192 of 5001.\n",
      "Step: 4193 of 5001.\n",
      "Step: 4194 of 5001.\n",
      "Step: 4195 of 5001.\n",
      "Step: 4196 of 5001.\n",
      "Step: 4197 of 5001.\n",
      "Step: 4198 of 5001.\n",
      "Step: 4199 of 5001.\n",
      "Step: 4200 of 5001.\n",
      "Generator model loss: 1.000736129283905.\n",
      "Discriminator model loss real: 0.6477183341979981.\n",
      "Discriminator model loss generated: 0.5994698286056519.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4201 of 5001.\n",
      "Step: 4202 of 5001.\n",
      "Step: 4203 of 5001.\n",
      "Step: 4204 of 5001.\n",
      "Step: 4205 of 5001.\n",
      "Step: 4206 of 5001.\n",
      "Step: 4207 of 5001.\n",
      "Step: 4208 of 5001.\n",
      "Step: 4209 of 5001.\n",
      "Step: 4210 of 5001.\n",
      "Generator model loss: 1.0281183421611786.\n",
      "Discriminator model loss real: 0.7124451160430908.\n",
      "Discriminator model loss generated: 0.654330825805664.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4211 of 5001.\n",
      "Step: 4212 of 5001.\n",
      "Step: 4213 of 5001.\n",
      "Step: 4214 of 5001.\n",
      "Step: 4215 of 5001.\n",
      "Step: 4216 of 5001.\n",
      "Step: 4217 of 5001.\n",
      "Step: 4218 of 5001.\n",
      "Step: 4219 of 5001.\n",
      "Step: 4220 of 5001.\n",
      "Generator model loss: 1.0565668165683746.\n",
      "Discriminator model loss real: 0.6680289804935455.\n",
      "Discriminator model loss generated: 0.6787994265556335.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4221 of 5001.\n",
      "Step: 4222 of 5001.\n",
      "Step: 4223 of 5001.\n",
      "Step: 4224 of 5001.\n",
      "Step: 4225 of 5001.\n",
      "Step: 4226 of 5001.\n",
      "Step: 4227 of 5001.\n",
      "Step: 4228 of 5001.\n",
      "Step: 4229 of 5001.\n",
      "Step: 4230 of 5001.\n",
      "Generator model loss: 1.018879348039627.\n",
      "Discriminator model loss real: 0.706001278758049.\n",
      "Discriminator model loss generated: 0.6443516969680786.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4231 of 5001.\n",
      "Step: 4232 of 5001.\n",
      "Step: 4233 of 5001.\n",
      "Step: 4234 of 5001.\n",
      "Step: 4235 of 5001.\n",
      "Step: 4236 of 5001.\n",
      "Step: 4237 of 5001.\n",
      "Step: 4238 of 5001.\n",
      "Step: 4239 of 5001.\n",
      "Step: 4240 of 5001.\n",
      "Generator model loss: 1.0242563486099243.\n",
      "Discriminator model loss real: 0.6809322029352188.\n",
      "Discriminator model loss generated: 0.6101389825344086.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4241 of 5001.\n",
      "Step: 4242 of 5001.\n",
      "Step: 4243 of 5001.\n",
      "Step: 4244 of 5001.\n",
      "Step: 4245 of 5001.\n",
      "Step: 4246 of 5001.\n",
      "Step: 4247 of 5001.\n",
      "Step: 4248 of 5001.\n",
      "Step: 4249 of 5001.\n",
      "Step: 4250 of 5001.\n",
      "Generator model loss: 1.063153737783432.\n",
      "Discriminator model loss real: 0.6650465071201325.\n",
      "Discriminator model loss generated: 0.6732931494712829.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4251 of 5001.\n",
      "Step: 4252 of 5001.\n",
      "Step: 4253 of 5001.\n",
      "Step: 4254 of 5001.\n",
      "Step: 4255 of 5001.\n",
      "Step: 4256 of 5001.\n",
      "Step: 4257 of 5001.\n",
      "Step: 4258 of 5001.\n",
      "Step: 4259 of 5001.\n",
      "Step: 4260 of 5001.\n",
      "Generator model loss: 1.0340011954307555.\n",
      "Discriminator model loss real: 0.6838915586471558.\n",
      "Discriminator model loss generated: 0.6964356124401092.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4261 of 5001.\n",
      "Step: 4262 of 5001.\n",
      "Step: 4263 of 5001.\n",
      "Step: 4264 of 5001.\n",
      "Step: 4265 of 5001.\n",
      "Step: 4266 of 5001.\n",
      "Step: 4267 of 5001.\n",
      "Step: 4268 of 5001.\n",
      "Step: 4269 of 5001.\n",
      "Step: 4270 of 5001.\n",
      "Generator model loss: 1.0157107055187224.\n",
      "Discriminator model loss real: 0.675658518075943.\n",
      "Discriminator model loss generated: 0.6283706188201904.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4271 of 5001.\n",
      "Step: 4272 of 5001.\n",
      "Step: 4273 of 5001.\n",
      "Step: 4274 of 5001.\n",
      "Step: 4275 of 5001.\n",
      "Step: 4276 of 5001.\n",
      "Step: 4277 of 5001.\n",
      "Step: 4278 of 5001.\n",
      "Step: 4279 of 5001.\n",
      "Step: 4280 of 5001.\n",
      "Generator model loss: 1.0317942917346954.\n",
      "Discriminator model loss real: 0.6441491365432739.\n",
      "Discriminator model loss generated: 0.627684873342514.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4281 of 5001.\n",
      "Step: 4282 of 5001.\n",
      "Step: 4283 of 5001.\n",
      "Step: 4284 of 5001.\n",
      "Step: 4285 of 5001.\n",
      "Step: 4286 of 5001.\n",
      "Step: 4287 of 5001.\n",
      "Step: 4288 of 5001.\n",
      "Step: 4289 of 5001.\n",
      "Step: 4290 of 5001.\n",
      "Generator model loss: 1.0312571585178376.\n",
      "Discriminator model loss real: 0.7393054753541947.\n",
      "Discriminator model loss generated: 0.6567689120769501.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4291 of 5001.\n",
      "Step: 4292 of 5001.\n",
      "Step: 4293 of 5001.\n",
      "Step: 4294 of 5001.\n",
      "Step: 4295 of 5001.\n",
      "Step: 4296 of 5001.\n",
      "Step: 4297 of 5001.\n",
      "Step: 4298 of 5001.\n",
      "Step: 4299 of 5001.\n",
      "Step: 4300 of 5001.\n",
      "Generator model loss: 1.0760643839836121.\n",
      "Discriminator model loss real: 0.6818752110004425.\n",
      "Discriminator model loss generated: 0.6498409926891326.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4301 of 5001.\n",
      "Step: 4302 of 5001.\n",
      "Step: 4303 of 5001.\n",
      "Step: 4304 of 5001.\n",
      "Step: 4305 of 5001.\n",
      "Step: 4306 of 5001.\n",
      "Step: 4307 of 5001.\n",
      "Step: 4308 of 5001.\n",
      "Step: 4309 of 5001.\n",
      "Step: 4310 of 5001.\n",
      "Generator model loss: 1.0359743237495422.\n",
      "Discriminator model loss real: 0.7413749426603318.\n",
      "Discriminator model loss generated: 0.634503972530365.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4311 of 5001.\n",
      "Step: 4312 of 5001.\n",
      "Step: 4313 of 5001.\n",
      "Step: 4314 of 5001.\n",
      "Step: 4315 of 5001.\n",
      "Step: 4316 of 5001.\n",
      "Step: 4317 of 5001.\n",
      "Step: 4318 of 5001.\n",
      "Step: 4319 of 5001.\n",
      "Step: 4320 of 5001.\n",
      "Generator model loss: 1.0649454236030578.\n",
      "Discriminator model loss real: 0.7283174335956574.\n",
      "Discriminator model loss generated: 0.6314062178134918.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4321 of 5001.\n",
      "Step: 4322 of 5001.\n",
      "Step: 4323 of 5001.\n",
      "Step: 4324 of 5001.\n",
      "Step: 4325 of 5001.\n",
      "Step: 4326 of 5001.\n",
      "Step: 4327 of 5001.\n",
      "Step: 4328 of 5001.\n",
      "Step: 4329 of 5001.\n",
      "Step: 4330 of 5001.\n",
      "Generator model loss: 1.043519389629364.\n",
      "Discriminator model loss real: 0.6857339382171631.\n",
      "Discriminator model loss generated: 0.6321467757225037.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4331 of 5001.\n",
      "Step: 4332 of 5001.\n",
      "Step: 4333 of 5001.\n",
      "Step: 4334 of 5001.\n",
      "Step: 4335 of 5001.\n",
      "Step: 4336 of 5001.\n",
      "Step: 4337 of 5001.\n",
      "Step: 4338 of 5001.\n",
      "Step: 4339 of 5001.\n",
      "Step: 4340 of 5001.\n",
      "Generator model loss: 0.9991703629493713.\n",
      "Discriminator model loss real: 0.6868833094835282.\n",
      "Discriminator model loss generated: 0.6471363186836243.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 4341 of 5001.\n",
      "Step: 4342 of 5001.\n",
      "Step: 4343 of 5001.\n",
      "Step: 4344 of 5001.\n",
      "Step: 4345 of 5001.\n",
      "Step: 4346 of 5001.\n",
      "Step: 4347 of 5001.\n",
      "Step: 4348 of 5001.\n",
      "Step: 4349 of 5001.\n",
      "Step: 4350 of 5001.\n",
      "Generator model loss: 1.0822469174861908.\n",
      "Discriminator model loss real: 0.6616844058036804.\n",
      "Discriminator model loss generated: 0.6292302429676055.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4351 of 5001.\n",
      "Step: 4352 of 5001.\n",
      "Step: 4353 of 5001.\n",
      "Step: 4354 of 5001.\n",
      "Step: 4355 of 5001.\n",
      "Step: 4356 of 5001.\n",
      "Step: 4357 of 5001.\n",
      "Step: 4358 of 5001.\n",
      "Step: 4359 of 5001.\n",
      "Step: 4360 of 5001.\n",
      "Generator model loss: 1.068616557121277.\n",
      "Discriminator model loss real: 0.6416928052902222.\n",
      "Discriminator model loss generated: 0.6262686371803283.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4361 of 5001.\n",
      "Step: 4362 of 5001.\n",
      "Step: 4363 of 5001.\n",
      "Step: 4364 of 5001.\n",
      "Step: 4365 of 5001.\n",
      "Step: 4366 of 5001.\n",
      "Step: 4367 of 5001.\n",
      "Step: 4368 of 5001.\n",
      "Step: 4369 of 5001.\n",
      "Step: 4370 of 5001.\n",
      "Generator model loss: 1.092391127347946.\n",
      "Discriminator model loss real: 0.7156869381666183.\n",
      "Discriminator model loss generated: 0.6246410608291626.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4371 of 5001.\n",
      "Step: 4372 of 5001.\n",
      "Step: 4373 of 5001.\n",
      "Step: 4374 of 5001.\n",
      "Step: 4375 of 5001.\n",
      "Step: 4376 of 5001.\n",
      "Step: 4377 of 5001.\n",
      "Step: 4378 of 5001.\n",
      "Step: 4379 of 5001.\n",
      "Step: 4380 of 5001.\n",
      "Generator model loss: 1.010017704963684.\n",
      "Discriminator model loss real: 0.6577213555574417.\n",
      "Discriminator model loss generated: 0.6395941913127899.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4381 of 5001.\n",
      "Step: 4382 of 5001.\n",
      "Step: 4383 of 5001.\n",
      "Step: 4384 of 5001.\n",
      "Step: 4385 of 5001.\n",
      "Step: 4386 of 5001.\n",
      "Step: 4387 of 5001.\n",
      "Step: 4388 of 5001.\n",
      "Step: 4389 of 5001.\n",
      "Step: 4390 of 5001.\n",
      "Generator model loss: 1.0381070494651794.\n",
      "Discriminator model loss real: 0.6421077698469162.\n",
      "Discriminator model loss generated: 0.6236941576004028.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4391 of 5001.\n",
      "Step: 4392 of 5001.\n",
      "Step: 4393 of 5001.\n",
      "Step: 4394 of 5001.\n",
      "Step: 4395 of 5001.\n",
      "Step: 4396 of 5001.\n",
      "Step: 4397 of 5001.\n",
      "Step: 4398 of 5001.\n",
      "Step: 4399 of 5001.\n",
      "Step: 4400 of 5001.\n",
      "Generator model loss: 1.0800577580928803.\n",
      "Discriminator model loss real: 0.681432631611824.\n",
      "Discriminator model loss generated: 0.5969232201576233.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4401 of 5001.\n",
      "Step: 4402 of 5001.\n",
      "Step: 4403 of 5001.\n",
      "Step: 4404 of 5001.\n",
      "Step: 4405 of 5001.\n",
      "Step: 4406 of 5001.\n",
      "Step: 4407 of 5001.\n",
      "Step: 4408 of 5001.\n",
      "Step: 4409 of 5001.\n",
      "Step: 4410 of 5001.\n",
      "Generator model loss: 1.0663681864738463.\n",
      "Discriminator model loss real: 0.6691411852836608.\n",
      "Discriminator model loss generated: 0.6346269369125366.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4411 of 5001.\n",
      "Step: 4412 of 5001.\n",
      "Step: 4413 of 5001.\n",
      "Step: 4414 of 5001.\n",
      "Step: 4415 of 5001.\n",
      "Step: 4416 of 5001.\n",
      "Step: 4417 of 5001.\n",
      "Step: 4418 of 5001.\n",
      "Step: 4419 of 5001.\n",
      "Step: 4420 of 5001.\n",
      "Generator model loss: 1.0288462877273559.\n",
      "Discriminator model loss real: 0.6816518694162369.\n",
      "Discriminator model loss generated: 0.6401158213615418.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4421 of 5001.\n",
      "Step: 4422 of 5001.\n",
      "Step: 4423 of 5001.\n",
      "Step: 4424 of 5001.\n",
      "Step: 4425 of 5001.\n",
      "Step: 4426 of 5001.\n",
      "Step: 4427 of 5001.\n",
      "Step: 4428 of 5001.\n",
      "Step: 4429 of 5001.\n",
      "Step: 4430 of 5001.\n",
      "Generator model loss: 1.0013563454151153.\n",
      "Discriminator model loss real: 0.636517459154129.\n",
      "Discriminator model loss generated: 0.6997334063053131.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4431 of 5001.\n",
      "Step: 4432 of 5001.\n",
      "Step: 4433 of 5001.\n",
      "Step: 4434 of 5001.\n",
      "Step: 4435 of 5001.\n",
      "Step: 4436 of 5001.\n",
      "Step: 4437 of 5001.\n",
      "Step: 4438 of 5001.\n",
      "Step: 4439 of 5001.\n",
      "Step: 4440 of 5001.\n",
      "Generator model loss: 0.9911258697509766.\n",
      "Discriminator model loss real: 0.651768046617508.\n",
      "Discriminator model loss generated: 0.6346375703811645.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4441 of 5001.\n",
      "Step: 4442 of 5001.\n",
      "Step: 4443 of 5001.\n",
      "Step: 4444 of 5001.\n",
      "Step: 4445 of 5001.\n",
      "Step: 4446 of 5001.\n",
      "Step: 4447 of 5001.\n",
      "Step: 4448 of 5001.\n",
      "Step: 4449 of 5001.\n",
      "Step: 4450 of 5001.\n",
      "Generator model loss: 1.1625453174114226.\n",
      "Discriminator model loss real: 0.6934355914592742.\n",
      "Discriminator model loss generated: 0.6521462380886078.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4451 of 5001.\n",
      "Step: 4452 of 5001.\n",
      "Step: 4453 of 5001.\n",
      "Step: 4454 of 5001.\n",
      "Step: 4455 of 5001.\n",
      "Step: 4456 of 5001.\n",
      "Step: 4457 of 5001.\n",
      "Step: 4458 of 5001.\n",
      "Step: 4459 of 5001.\n",
      "Step: 4460 of 5001.\n",
      "Generator model loss: 1.0735962629318236.\n",
      "Discriminator model loss real: 0.6600760281085968.\n",
      "Discriminator model loss generated: 0.6576072096824646.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4461 of 5001.\n",
      "Step: 4462 of 5001.\n",
      "Step: 4463 of 5001.\n",
      "Step: 4464 of 5001.\n",
      "Step: 4465 of 5001.\n",
      "Step: 4466 of 5001.\n",
      "Step: 4467 of 5001.\n",
      "Step: 4468 of 5001.\n",
      "Step: 4469 of 5001.\n",
      "Step: 4470 of 5001.\n",
      "Generator model loss: 1.0786515772342682.\n",
      "Discriminator model loss real: 0.6501544535160064.\n",
      "Discriminator model loss generated: 0.6634297013282776.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4471 of 5001.\n",
      "Step: 4472 of 5001.\n",
      "Step: 4473 of 5001.\n",
      "Step: 4474 of 5001.\n",
      "Step: 4475 of 5001.\n",
      "Step: 4476 of 5001.\n",
      "Step: 4477 of 5001.\n",
      "Step: 4478 of 5001.\n",
      "Step: 4479 of 5001.\n",
      "Step: 4480 of 5001.\n",
      "Generator model loss: 1.0318925201892852.\n",
      "Discriminator model loss real: 0.6371633321046829.\n",
      "Discriminator model loss generated: 0.6121208846569062.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4481 of 5001.\n",
      "Step: 4482 of 5001.\n",
      "Step: 4483 of 5001.\n",
      "Step: 4484 of 5001.\n",
      "Step: 4485 of 5001.\n",
      "Step: 4486 of 5001.\n",
      "Step: 4487 of 5001.\n",
      "Step: 4488 of 5001.\n",
      "Step: 4489 of 5001.\n",
      "Step: 4490 of 5001.\n",
      "Generator model loss: 1.0413459837436676.\n",
      "Discriminator model loss real: 0.6599943399429321.\n",
      "Discriminator model loss generated: 0.6685845017433166.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4491 of 5001.\n",
      "Step: 4492 of 5001.\n",
      "Step: 4493 of 5001.\n",
      "Step: 4494 of 5001.\n",
      "Step: 4495 of 5001.\n",
      "Step: 4496 of 5001.\n",
      "Step: 4497 of 5001.\n",
      "Step: 4498 of 5001.\n",
      "Step: 4499 of 5001.\n",
      "Step: 4500 of 5001.\n",
      "Generator model loss: 0.9954910337924957.\n",
      "Discriminator model loss real: 0.6309306561946869.\n",
      "Discriminator model loss generated: 0.6783984303474426.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4501 of 5001.\n",
      "Step: 4502 of 5001.\n",
      "Step: 4503 of 5001.\n",
      "Step: 4504 of 5001.\n",
      "Step: 4505 of 5001.\n",
      "Step: 4506 of 5001.\n",
      "Step: 4507 of 5001.\n",
      "Step: 4508 of 5001.\n",
      "Step: 4509 of 5001.\n",
      "Step: 4510 of 5001.\n",
      "Generator model loss: 1.0810672461986541.\n",
      "Discriminator model loss real: 0.696149542927742.\n",
      "Discriminator model loss generated: 0.5869128108024597.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4511 of 5001.\n",
      "Step: 4512 of 5001.\n",
      "Step: 4513 of 5001.\n",
      "Step: 4514 of 5001.\n",
      "Step: 4515 of 5001.\n",
      "Step: 4516 of 5001.\n",
      "Step: 4517 of 5001.\n",
      "Step: 4518 of 5001.\n",
      "Step: 4519 of 5001.\n",
      "Step: 4520 of 5001.\n",
      "Generator model loss: 1.1266357600688934.\n",
      "Discriminator model loss real: 0.6655012845993042.\n",
      "Discriminator model loss generated: 0.6231131553649902.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4521 of 5001.\n",
      "Step: 4522 of 5001.\n",
      "Step: 4523 of 5001.\n",
      "Step: 4524 of 5001.\n",
      "Step: 4525 of 5001.\n",
      "Step: 4526 of 5001.\n",
      "Step: 4527 of 5001.\n",
      "Step: 4528 of 5001.\n",
      "Step: 4529 of 5001.\n",
      "Step: 4530 of 5001.\n",
      "Generator model loss: 1.0632169008255006.\n",
      "Discriminator model loss real: 0.689687168598175.\n",
      "Discriminator model loss generated: 0.6819407224655152.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4531 of 5001.\n",
      "Step: 4532 of 5001.\n",
      "Step: 4533 of 5001.\n",
      "Step: 4534 of 5001.\n",
      "Step: 4535 of 5001.\n",
      "Step: 4536 of 5001.\n",
      "Step: 4537 of 5001.\n",
      "Step: 4538 of 5001.\n",
      "Step: 4539 of 5001.\n",
      "Step: 4540 of 5001.\n",
      "Generator model loss: 1.0321274995803833.\n",
      "Discriminator model loss real: 0.6488738685846329.\n",
      "Discriminator model loss generated: 0.6595015347003936.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4541 of 5001.\n",
      "Step: 4542 of 5001.\n",
      "Step: 4543 of 5001.\n",
      "Step: 4544 of 5001.\n",
      "Step: 4545 of 5001.\n",
      "Step: 4546 of 5001.\n",
      "Step: 4547 of 5001.\n",
      "Step: 4548 of 5001.\n",
      "Step: 4549 of 5001.\n",
      "Step: 4550 of 5001.\n",
      "Generator model loss: 1.110504400730133.\n",
      "Discriminator model loss real: 0.6604411333799363.\n",
      "Discriminator model loss generated: 0.6569340825080872.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 4551 of 5001.\n",
      "Step: 4552 of 5001.\n",
      "Step: 4553 of 5001.\n",
      "Step: 4554 of 5001.\n",
      "Step: 4555 of 5001.\n",
      "Step: 4556 of 5001.\n",
      "Step: 4557 of 5001.\n",
      "Step: 4558 of 5001.\n",
      "Step: 4559 of 5001.\n",
      "Step: 4560 of 5001.\n",
      "Generator model loss: 1.0744101047515868.\n",
      "Discriminator model loss real: 0.6418765366077424.\n",
      "Discriminator model loss generated: 0.6588010013103485.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4561 of 5001.\n",
      "Step: 4562 of 5001.\n",
      "Step: 4563 of 5001.\n",
      "Step: 4564 of 5001.\n",
      "Step: 4565 of 5001.\n",
      "Step: 4566 of 5001.\n",
      "Step: 4567 of 5001.\n",
      "Step: 4568 of 5001.\n",
      "Step: 4569 of 5001.\n",
      "Step: 4570 of 5001.\n",
      "Generator model loss: 1.0497724175453187.\n",
      "Discriminator model loss real: 0.7588815212249755.\n",
      "Discriminator model loss generated: 0.5997481942176819.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4571 of 5001.\n",
      "Step: 4572 of 5001.\n",
      "Step: 4573 of 5001.\n",
      "Step: 4574 of 5001.\n",
      "Step: 4575 of 5001.\n",
      "Step: 4576 of 5001.\n",
      "Step: 4577 of 5001.\n",
      "Step: 4578 of 5001.\n",
      "Step: 4579 of 5001.\n",
      "Step: 4580 of 5001.\n",
      "Generator model loss: 1.0561994731426239.\n",
      "Discriminator model loss real: 0.6764317214488983.\n",
      "Discriminator model loss generated: 0.6059677481651307.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4581 of 5001.\n",
      "Step: 4582 of 5001.\n",
      "Step: 4583 of 5001.\n",
      "Step: 4584 of 5001.\n",
      "Step: 4585 of 5001.\n",
      "Step: 4586 of 5001.\n",
      "Step: 4587 of 5001.\n",
      "Step: 4588 of 5001.\n",
      "Step: 4589 of 5001.\n",
      "Step: 4590 of 5001.\n",
      "Generator model loss: 1.0632525086402893.\n",
      "Discriminator model loss real: 0.6687390267848968.\n",
      "Discriminator model loss generated: 0.6195232272148132.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4591 of 5001.\n",
      "Step: 4592 of 5001.\n",
      "Step: 4593 of 5001.\n",
      "Step: 4594 of 5001.\n",
      "Step: 4595 of 5001.\n",
      "Step: 4596 of 5001.\n",
      "Step: 4597 of 5001.\n",
      "Step: 4598 of 5001.\n",
      "Step: 4599 of 5001.\n",
      "Step: 4600 of 5001.\n",
      "Generator model loss: 0.9972098052501679.\n",
      "Discriminator model loss real: 0.6351972669363022.\n",
      "Discriminator model loss generated: 0.6078752994537353.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4601 of 5001.\n",
      "Step: 4602 of 5001.\n",
      "Step: 4603 of 5001.\n",
      "Step: 4604 of 5001.\n",
      "Step: 4605 of 5001.\n",
      "Step: 4606 of 5001.\n",
      "Step: 4607 of 5001.\n",
      "Step: 4608 of 5001.\n",
      "Step: 4609 of 5001.\n",
      "Step: 4610 of 5001.\n",
      "Generator model loss: 1.0435663282871246.\n",
      "Discriminator model loss real: 0.6264858186244965.\n",
      "Discriminator model loss generated: 0.6394375205039978.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4611 of 5001.\n",
      "Step: 4612 of 5001.\n",
      "Step: 4613 of 5001.\n",
      "Step: 4614 of 5001.\n",
      "Step: 4615 of 5001.\n",
      "Step: 4616 of 5001.\n",
      "Step: 4617 of 5001.\n",
      "Step: 4618 of 5001.\n",
      "Step: 4619 of 5001.\n",
      "Step: 4620 of 5001.\n",
      "Generator model loss: 1.0163703978061676.\n",
      "Discriminator model loss real: 0.6793220996856689.\n",
      "Discriminator model loss generated: 0.6025338649749756.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4621 of 5001.\n",
      "Step: 4622 of 5001.\n",
      "Step: 4623 of 5001.\n",
      "Step: 4624 of 5001.\n",
      "Step: 4625 of 5001.\n",
      "Step: 4626 of 5001.\n",
      "Step: 4627 of 5001.\n",
      "Step: 4628 of 5001.\n",
      "Step: 4629 of 5001.\n",
      "Step: 4630 of 5001.\n",
      "Generator model loss: 1.0570882439613343.\n",
      "Discriminator model loss real: 0.6451882719993591.\n",
      "Discriminator model loss generated: 0.6051872372627258.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4631 of 5001.\n",
      "Step: 4632 of 5001.\n",
      "Step: 4633 of 5001.\n",
      "Step: 4634 of 5001.\n",
      "Step: 4635 of 5001.\n",
      "Step: 4636 of 5001.\n",
      "Step: 4637 of 5001.\n",
      "Step: 4638 of 5001.\n",
      "Step: 4639 of 5001.\n",
      "Step: 4640 of 5001.\n",
      "Generator model loss: 1.0435440301895142.\n",
      "Discriminator model loss real: 0.6180136889219284.\n",
      "Discriminator model loss generated: 0.6344384253025055.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4641 of 5001.\n",
      "Step: 4642 of 5001.\n",
      "Step: 4643 of 5001.\n",
      "Step: 4644 of 5001.\n",
      "Step: 4645 of 5001.\n",
      "Step: 4646 of 5001.\n",
      "Step: 4647 of 5001.\n",
      "Step: 4648 of 5001.\n",
      "Step: 4649 of 5001.\n",
      "Step: 4650 of 5001.\n",
      "Generator model loss: 1.09998921751976.\n",
      "Discriminator model loss real: 0.6674397617578507.\n",
      "Discriminator model loss generated: 0.6679539740085602.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4651 of 5001.\n",
      "Step: 4652 of 5001.\n",
      "Step: 4653 of 5001.\n",
      "Step: 4654 of 5001.\n",
      "Step: 4655 of 5001.\n",
      "Step: 4656 of 5001.\n",
      "Step: 4657 of 5001.\n",
      "Step: 4658 of 5001.\n",
      "Step: 4659 of 5001.\n",
      "Step: 4660 of 5001.\n",
      "Generator model loss: 1.076236742734909.\n",
      "Discriminator model loss real: 0.6539190620183944.\n",
      "Discriminator model loss generated: 0.6240892469882965.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4661 of 5001.\n",
      "Step: 4662 of 5001.\n",
      "Step: 4663 of 5001.\n",
      "Step: 4664 of 5001.\n",
      "Step: 4665 of 5001.\n",
      "Step: 4666 of 5001.\n",
      "Step: 4667 of 5001.\n",
      "Step: 4668 of 5001.\n",
      "Step: 4669 of 5001.\n",
      "Step: 4670 of 5001.\n",
      "Generator model loss: 1.055577176809311.\n",
      "Discriminator model loss real: 0.6395406186580658.\n",
      "Discriminator model loss generated: 0.6845534801483154.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4671 of 5001.\n",
      "Step: 4672 of 5001.\n",
      "Step: 4673 of 5001.\n",
      "Step: 4674 of 5001.\n",
      "Step: 4675 of 5001.\n",
      "Step: 4676 of 5001.\n",
      "Step: 4677 of 5001.\n",
      "Step: 4678 of 5001.\n",
      "Step: 4679 of 5001.\n",
      "Step: 4680 of 5001.\n",
      "Generator model loss: 1.037059623003006.\n",
      "Discriminator model loss real: 0.683062669634819.\n",
      "Discriminator model loss generated: 0.7054882407188415.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4681 of 5001.\n",
      "Step: 4682 of 5001.\n",
      "Step: 4683 of 5001.\n",
      "Step: 4684 of 5001.\n",
      "Step: 4685 of 5001.\n",
      "Step: 4686 of 5001.\n",
      "Step: 4687 of 5001.\n",
      "Step: 4688 of 5001.\n",
      "Step: 4689 of 5001.\n",
      "Step: 4690 of 5001.\n",
      "Generator model loss: 1.111643099784851.\n",
      "Discriminator model loss real: 0.6742360055446625.\n",
      "Discriminator model loss generated: 0.5881248950958252.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4691 of 5001.\n",
      "Step: 4692 of 5001.\n",
      "Step: 4693 of 5001.\n",
      "Step: 4694 of 5001.\n",
      "Step: 4695 of 5001.\n",
      "Step: 4696 of 5001.\n",
      "Step: 4697 of 5001.\n",
      "Step: 4698 of 5001.\n",
      "Step: 4699 of 5001.\n",
      "Step: 4700 of 5001.\n",
      "Generator model loss: 1.0911332368850708.\n",
      "Discriminator model loss real: 0.633787852525711.\n",
      "Discriminator model loss generated: 0.6887488961219788.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4701 of 5001.\n",
      "Step: 4702 of 5001.\n",
      "Step: 4703 of 5001.\n",
      "Step: 4704 of 5001.\n",
      "Step: 4705 of 5001.\n",
      "Step: 4706 of 5001.\n",
      "Step: 4707 of 5001.\n",
      "Step: 4708 of 5001.\n",
      "Step: 4709 of 5001.\n",
      "Step: 4710 of 5001.\n",
      "Generator model loss: 1.0315404951572418.\n",
      "Discriminator model loss real: 0.6385791033506394.\n",
      "Discriminator model loss generated: 0.6772421896457672.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4711 of 5001.\n",
      "Step: 4712 of 5001.\n",
      "Step: 4713 of 5001.\n",
      "Step: 4714 of 5001.\n",
      "Step: 4715 of 5001.\n",
      "Step: 4716 of 5001.\n",
      "Step: 4717 of 5001.\n",
      "Step: 4718 of 5001.\n",
      "Step: 4719 of 5001.\n",
      "Step: 4720 of 5001.\n",
      "Generator model loss: 1.0916445791721343.\n",
      "Discriminator model loss real: 0.6256905376911164.\n",
      "Discriminator model loss generated: 0.6956194281578064.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4721 of 5001.\n",
      "Step: 4722 of 5001.\n",
      "Step: 4723 of 5001.\n",
      "Step: 4724 of 5001.\n",
      "Step: 4725 of 5001.\n",
      "Step: 4726 of 5001.\n",
      "Step: 4727 of 5001.\n",
      "Step: 4728 of 5001.\n",
      "Step: 4729 of 5001.\n",
      "Step: 4730 of 5001.\n",
      "Generator model loss: 1.0380422949790955.\n",
      "Discriminator model loss real: 0.5975898265838623.\n",
      "Discriminator model loss generated: 0.6324406564235687.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4731 of 5001.\n",
      "Step: 4732 of 5001.\n",
      "Step: 4733 of 5001.\n",
      "Step: 4734 of 5001.\n",
      "Step: 4735 of 5001.\n",
      "Step: 4736 of 5001.\n",
      "Step: 4737 of 5001.\n",
      "Step: 4738 of 5001.\n",
      "Step: 4739 of 5001.\n",
      "Step: 4740 of 5001.\n",
      "Generator model loss: 1.0564717292785644.\n",
      "Discriminator model loss real: 0.6933332264423371.\n",
      "Discriminator model loss generated: 0.6340425729751586.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4741 of 5001.\n",
      "Step: 4742 of 5001.\n",
      "Step: 4743 of 5001.\n",
      "Step: 4744 of 5001.\n",
      "Step: 4745 of 5001.\n",
      "Step: 4746 of 5001.\n",
      "Step: 4747 of 5001.\n",
      "Step: 4748 of 5001.\n",
      "Step: 4749 of 5001.\n",
      "Step: 4750 of 5001.\n",
      "Generator model loss: 1.1811484694480896.\n",
      "Discriminator model loss real: 0.6653104484081268.\n",
      "Discriminator model loss generated: 0.5992836833000184.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4751 of 5001.\n",
      "Step: 4752 of 5001.\n",
      "Step: 4753 of 5001.\n",
      "Step: 4754 of 5001.\n",
      "Step: 4755 of 5001.\n",
      "Step: 4756 of 5001.\n",
      "Step: 4757 of 5001.\n",
      "Step: 4758 of 5001.\n",
      "Step: 4759 of 5001.\n",
      "Step: 4760 of 5001.\n",
      "Generator model loss: 1.0612078547477721.\n",
      "Discriminator model loss real: 0.6610294222831726.\n",
      "Discriminator model loss generated: 0.5975886940956116.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4761 of 5001.\n",
      "Step: 4762 of 5001.\n",
      "Step: 4763 of 5001.\n",
      "Step: 4764 of 5001.\n",
      "Step: 4765 of 5001.\n",
      "Step: 4766 of 5001.\n",
      "Step: 4767 of 5001.\n",
      "Step: 4768 of 5001.\n",
      "Step: 4769 of 5001.\n",
      "Step: 4770 of 5001.\n",
      "Generator model loss: 1.0634305357933045.\n",
      "Discriminator model loss real: 0.6591716319322586.\n",
      "Discriminator model loss generated: 0.6403205931186676.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4771 of 5001.\n",
      "Step: 4772 of 5001.\n",
      "Step: 4773 of 5001.\n",
      "Step: 4774 of 5001.\n",
      "Step: 4775 of 5001.\n",
      "Step: 4776 of 5001.\n",
      "Step: 4777 of 5001.\n",
      "Step: 4778 of 5001.\n",
      "Step: 4779 of 5001.\n",
      "Step: 4780 of 5001.\n",
      "Generator model loss: 1.0767125606536865.\n",
      "Discriminator model loss real: 0.6714201271533966.\n",
      "Discriminator model loss generated: 0.6415550291538239.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4781 of 5001.\n",
      "Step: 4782 of 5001.\n",
      "Step: 4783 of 5001.\n",
      "Step: 4784 of 5001.\n",
      "Step: 4785 of 5001.\n",
      "Step: 4786 of 5001.\n",
      "Step: 4787 of 5001.\n",
      "Step: 4788 of 5001.\n",
      "Step: 4789 of 5001.\n",
      "Step: 4790 of 5001.\n",
      "Generator model loss: 1.0572391092777251.\n",
      "Discriminator model loss real: 0.6855813533067703.\n",
      "Discriminator model loss generated: 0.6103269875049591.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4791 of 5001.\n",
      "Step: 4792 of 5001.\n",
      "Step: 4793 of 5001.\n",
      "Step: 4794 of 5001.\n",
      "Step: 4795 of 5001.\n",
      "Step: 4796 of 5001.\n",
      "Step: 4797 of 5001.\n",
      "Step: 4798 of 5001.\n",
      "Step: 4799 of 5001.\n",
      "Step: 4800 of 5001.\n",
      "Generator model loss: 1.1000830769538879.\n",
      "Discriminator model loss real: 0.6335003644227981.\n",
      "Discriminator model loss generated: 0.6535063326358795.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4801 of 5001.\n",
      "Step: 4802 of 5001.\n",
      "Step: 4803 of 5001.\n",
      "Step: 4804 of 5001.\n",
      "Step: 4805 of 5001.\n",
      "Step: 4806 of 5001.\n",
      "Step: 4807 of 5001.\n",
      "Step: 4808 of 5001.\n",
      "Step: 4809 of 5001.\n",
      "Step: 4810 of 5001.\n",
      "Generator model loss: 1.0914491534233093.\n",
      "Discriminator model loss real: 0.673565861582756.\n",
      "Discriminator model loss generated: 0.6871963083744049.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4811 of 5001.\n",
      "Step: 4812 of 5001.\n",
      "Step: 4813 of 5001.\n",
      "Step: 4814 of 5001.\n",
      "Step: 4815 of 5001.\n",
      "Step: 4816 of 5001.\n",
      "Step: 4817 of 5001.\n",
      "Step: 4818 of 5001.\n",
      "Step: 4819 of 5001.\n",
      "Step: 4820 of 5001.\n",
      "Generator model loss: 1.0646036624908448.\n",
      "Discriminator model loss real: 0.6658161401748657.\n",
      "Discriminator model loss generated: 0.6110210299491883.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4821 of 5001.\n",
      "Step: 4822 of 5001.\n",
      "Step: 4823 of 5001.\n",
      "Step: 4824 of 5001.\n",
      "Step: 4825 of 5001.\n",
      "Step: 4826 of 5001.\n",
      "Step: 4827 of 5001.\n",
      "Step: 4828 of 5001.\n",
      "Step: 4829 of 5001.\n",
      "Step: 4830 of 5001.\n",
      "Generator model loss: 1.0712969422340393.\n",
      "Discriminator model loss real: 0.6832755118608475.\n",
      "Discriminator model loss generated: 0.7518560469150544.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4831 of 5001.\n",
      "Step: 4832 of 5001.\n",
      "Step: 4833 of 5001.\n",
      "Step: 4834 of 5001.\n",
      "Step: 4835 of 5001.\n",
      "Step: 4836 of 5001.\n",
      "Step: 4837 of 5001.\n",
      "Step: 4838 of 5001.\n",
      "Step: 4839 of 5001.\n",
      "Step: 4840 of 5001.\n",
      "Generator model loss: 1.0925699293613433.\n",
      "Discriminator model loss real: 0.6598303914070129.\n",
      "Discriminator model loss generated: 0.6254219174385071.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4841 of 5001.\n",
      "Step: 4842 of 5001.\n",
      "Step: 4843 of 5001.\n",
      "Step: 4844 of 5001.\n",
      "Step: 4845 of 5001.\n",
      "Step: 4846 of 5001.\n",
      "Step: 4847 of 5001.\n",
      "Step: 4848 of 5001.\n",
      "Step: 4849 of 5001.\n",
      "Step: 4850 of 5001.\n",
      "Generator model loss: 1.0777527213096618.\n",
      "Discriminator model loss real: 0.7338810712099075.\n",
      "Discriminator model loss generated: 0.616789698600769.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4851 of 5001.\n",
      "Step: 4852 of 5001.\n",
      "Step: 4853 of 5001.\n",
      "Step: 4854 of 5001.\n",
      "Step: 4855 of 5001.\n",
      "Step: 4856 of 5001.\n",
      "Step: 4857 of 5001.\n",
      "Step: 4858 of 5001.\n",
      "Step: 4859 of 5001.\n",
      "Step: 4860 of 5001.\n",
      "Generator model loss: 1.0247918903827666.\n",
      "Discriminator model loss real: 0.6824724018573761.\n",
      "Discriminator model loss generated: 0.6537991881370544.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4861 of 5001.\n",
      "Step: 4862 of 5001.\n",
      "Step: 4863 of 5001.\n",
      "Step: 4864 of 5001.\n",
      "Step: 4865 of 5001.\n",
      "Step: 4866 of 5001.\n",
      "Step: 4867 of 5001.\n",
      "Step: 4868 of 5001.\n",
      "Step: 4869 of 5001.\n",
      "Step: 4870 of 5001.\n",
      "Generator model loss: 1.0579236626625061.\n",
      "Discriminator model loss real: 0.6327886044979095.\n",
      "Discriminator model loss generated: 0.6308421611785888.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4871 of 5001.\n",
      "Step: 4872 of 5001.\n",
      "Step: 4873 of 5001.\n",
      "Step: 4874 of 5001.\n",
      "Step: 4875 of 5001.\n",
      "Step: 4876 of 5001.\n",
      "Step: 4877 of 5001.\n",
      "Step: 4878 of 5001.\n",
      "Step: 4879 of 5001.\n",
      "Step: 4880 of 5001.\n",
      "Generator model loss: 1.0688271224498749.\n",
      "Discriminator model loss real: 0.6014551907777786.\n",
      "Discriminator model loss generated: 0.6216818630695343.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4881 of 5001.\n",
      "Step: 4882 of 5001.\n",
      "Step: 4883 of 5001.\n",
      "Step: 4884 of 5001.\n",
      "Step: 4885 of 5001.\n",
      "Step: 4886 of 5001.\n",
      "Step: 4887 of 5001.\n",
      "Step: 4888 of 5001.\n",
      "Step: 4889 of 5001.\n",
      "Step: 4890 of 5001.\n",
      "Generator model loss: 1.0552249729633332.\n",
      "Discriminator model loss real: 0.6374756157398224.\n",
      "Discriminator model loss generated: 0.6192575454711914.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4891 of 5001.\n",
      "Step: 4892 of 5001.\n",
      "Step: 4893 of 5001.\n",
      "Step: 4894 of 5001.\n",
      "Step: 4895 of 5001.\n",
      "Step: 4896 of 5001.\n",
      "Step: 4897 of 5001.\n",
      "Step: 4898 of 5001.\n",
      "Step: 4899 of 5001.\n",
      "Step: 4900 of 5001.\n",
      "Generator model loss: 1.0677852928638458.\n",
      "Discriminator model loss real: 0.6262461364269256.\n",
      "Discriminator model loss generated: 0.6562639653682709.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4901 of 5001.\n",
      "Step: 4902 of 5001.\n",
      "Step: 4903 of 5001.\n",
      "Step: 4904 of 5001.\n",
      "Step: 4905 of 5001.\n",
      "Step: 4906 of 5001.\n",
      "Step: 4907 of 5001.\n",
      "Step: 4908 of 5001.\n",
      "Step: 4909 of 5001.\n",
      "Step: 4910 of 5001.\n",
      "Generator model loss: 1.0114816784858705.\n",
      "Discriminator model loss real: 0.6965327143669129.\n",
      "Discriminator model loss generated: 0.6628438293933868.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4911 of 5001.\n",
      "Step: 4912 of 5001.\n",
      "Step: 4913 of 5001.\n",
      "Step: 4914 of 5001.\n",
      "Step: 4915 of 5001.\n",
      "Step: 4916 of 5001.\n",
      "Step: 4917 of 5001.\n",
      "Step: 4918 of 5001.\n",
      "Step: 4919 of 5001.\n",
      "Step: 4920 of 5001.\n",
      "Generator model loss: 1.1007262229919434.\n",
      "Discriminator model loss real: 0.6340449899435043.\n",
      "Discriminator model loss generated: 0.6160704851150512.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4921 of 5001.\n",
      "Step: 4922 of 5001.\n",
      "Step: 4923 of 5001.\n",
      "Step: 4924 of 5001.\n",
      "Step: 4925 of 5001.\n",
      "Step: 4926 of 5001.\n",
      "Step: 4927 of 5001.\n",
      "Step: 4928 of 5001.\n",
      "Step: 4929 of 5001.\n",
      "Step: 4930 of 5001.\n",
      "Generator model loss: 1.1064679026603699.\n",
      "Discriminator model loss real: 0.6767516106367111.\n",
      "Discriminator model loss generated: 0.6890028119087219.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4931 of 5001.\n",
      "Step: 4932 of 5001.\n",
      "Step: 4933 of 5001.\n",
      "Step: 4934 of 5001.\n",
      "Step: 4935 of 5001.\n",
      "Step: 4936 of 5001.\n",
      "Step: 4937 of 5001.\n",
      "Step: 4938 of 5001.\n",
      "Step: 4939 of 5001.\n",
      "Step: 4940 of 5001.\n",
      "Generator model loss: 1.0748297929763795.\n",
      "Discriminator model loss real: 0.6564058780670166.\n",
      "Discriminator model loss generated: 0.6306459903717041.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4941 of 5001.\n",
      "Step: 4942 of 5001.\n",
      "Step: 4943 of 5001.\n",
      "Step: 4944 of 5001.\n",
      "Step: 4945 of 5001.\n",
      "Step: 4946 of 5001.\n",
      "Step: 4947 of 5001.\n",
      "Step: 4948 of 5001.\n",
      "Step: 4949 of 5001.\n",
      "Step: 4950 of 5001.\n",
      "Generator model loss: 1.0441229104995728.\n",
      "Discriminator model loss real: 0.6398996621370315.\n",
      "Discriminator model loss generated: 0.6487124681472778.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4951 of 5001.\n",
      "Step: 4952 of 5001.\n",
      "Step: 4953 of 5001.\n",
      "Step: 4954 of 5001.\n",
      "Step: 4955 of 5001.\n",
      "Step: 4956 of 5001.\n",
      "Step: 4957 of 5001.\n",
      "Step: 4958 of 5001.\n",
      "Step: 4959 of 5001.\n",
      "Step: 4960 of 5001.\n",
      "Generator model loss: 1.1502585530281066.\n",
      "Discriminator model loss real: 0.6753020465373993.\n",
      "Discriminator model loss generated: 0.6327462077140809.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4961 of 5001.\n",
      "Step: 4962 of 5001.\n",
      "Step: 4963 of 5001.\n",
      "Step: 4964 of 5001.\n",
      "Step: 4965 of 5001.\n",
      "Step: 4966 of 5001.\n",
      "Step: 4967 of 5001.\n",
      "Step: 4968 of 5001.\n",
      "Step: 4969 of 5001.\n",
      "Step: 4970 of 5001.\n",
      "Generator model loss: 1.0744226276874542.\n",
      "Discriminator model loss real: 0.6885615587234497.\n",
      "Discriminator model loss generated: 0.6791091680526733.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4971 of 5001.\n",
      "Step: 4972 of 5001.\n",
      "Step: 4973 of 5001.\n",
      "Step: 4974 of 5001.\n",
      "Step: 4975 of 5001.\n",
      "Step: 4976 of 5001.\n",
      "Step: 4977 of 5001.\n",
      "Step: 4978 of 5001.\n",
      "Step: 4979 of 5001.\n",
      "Step: 4980 of 5001.\n",
      "Generator model loss: 1.0973525583744048.\n",
      "Discriminator model loss real: 0.6378693550825119.\n",
      "Discriminator model loss generated: 0.6023927390575409.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4981 of 5001.\n",
      "Step: 4982 of 5001.\n",
      "Step: 4983 of 5001.\n",
      "Step: 4984 of 5001.\n",
      "Step: 4985 of 5001.\n",
      "Step: 4986 of 5001.\n",
      "Step: 4987 of 5001.\n",
      "Step: 4988 of 5001.\n",
      "Step: 4989 of 5001.\n",
      "Step: 4990 of 5001.\n",
      "Generator model loss: 1.090342116355896.\n",
      "Discriminator model loss real: 0.6611052304506302.\n",
      "Discriminator model loss generated: 0.7176002025604248.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4991 of 5001.\n",
      "Step: 4992 of 5001.\n",
      "Step: 4993 of 5001.\n",
      "Step: 4994 of 5001.\n",
      "Step: 4995 of 5001.\n",
      "Step: 4996 of 5001.\n",
      "Step: 4997 of 5001.\n",
      "Step: 4998 of 5001.\n",
      "Step: 4999 of 5001.\n",
      "Step: 5000 of 5001.\n",
      "Generator model loss: 1.1256563365459442.\n",
      "Discriminator model loss real: 0.6341014832258225.\n",
      "Discriminator model loss generated: 0.679579246044159.\n",
      "xgboost accuracy: 0.83\n",
      "CPU times: user 10min 12s, sys: 48.1 s, total: 11min\n",
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K.set_learning_phase(1) # 1 = train\n",
    "adversarial_training('', None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for continued training\n",
    "# adversarial_training('', 'cache/GAN_generator_model_weights_step_100.h5', 'cache/GAN_discriminator_model_weights_step_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[combined_loss, disc_loss_real, disc_loss_generated, xgb_losses] = pickle.load(open(os.path.join(cache_dir, 'GAN_losses.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8JuZFeYfi3zAkzP2k+cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc9902e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( xgb_losses[1:] ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0ImIDIKBTkRkEAx0IiKDYKATERnE/wPPuQGRyfXECAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc990073c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngVsIIQKMBG4hhAgw/w9iO7S7yTgRvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc46dda20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( combined_loss[1:], label='combined_loss' ) ; plt.show()\n",
    "\n",
    "plt.plot( disc_loss_real[1:], label='disc_loss_real' )\n",
    "plt.plot( disc_loss_generated[1:], label='disc_loss_generated' )\n",
    "plt.legend() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.4-py3.6.egg/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "    \n",
    "generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "generated_image_tensor = generator_network(generator_input_tensor)\n",
    "generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "\n",
    "generator_model.load_weights('cache/GAN_generator_model_weights_step_5000.h5')\n",
    "\n",
    "temp_noise = np.random.normal(size=(batch_size, rand_dim))  # fixed noise to generate batches of generated images\n",
    "\n",
    "g_z = generator_model.predict(temp_noise)\n",
    "\n",
    "# g_z[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "print( CheckAccuracy( generator_model, 100, train ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.89'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 100\n",
    "\n",
    "np.random.seed(0)\n",
    "temp_noise = np.random.normal(size=(n_samples*2, rand_dim))  # fixed noise to generate batches of generated images\n",
    "test_samples = generator_model.predict(temp_noise)\n",
    "test_samples = np.reshape(test_samples, (n_samples*2, data_dim))\n",
    "test_samples = pd.DataFrame(test_samples,columns=train.columns)\n",
    "test_samples['syn_label'] = 1\n",
    "\n",
    "# real_samples = test.sample(n_samples*2,replace=False)\n",
    "real_samples = train.sample(n_samples*2,replace=False)\n",
    "real_samples['syn_label'] = 0\n",
    "\n",
    "train_df = pd.concat([real_samples[:n_samples],test_samples[:n_samples]],axis=0)\n",
    "test_df = pd.concat([real_samples[n_samples:],test_samples[n_samples:]],axis=0)\n",
    "\n",
    "X_col = test_df.columns[:-1]\n",
    "y_col = test_df.columns[-1]\n",
    "dtrain = xgb.DMatrix(train_df[X_col], train_df[y_col], feature_names=X_col)\n",
    "dtest = xgb.DMatrix(test_df[X_col], feature_names=X_col)\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 0 }\n",
    "xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "y_pred = np.round(xgb_test.predict(dtest))\n",
    "y_true = test_df['syn_label']\n",
    "'{:.2f}'.format(SimpleAccuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True 0</th>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 1</th>\n",
       "      <td>14</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pred 0  Pred 1\n",
       "True 0      92       8\n",
       "True 1      14      86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.89\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on validation set\n",
    "SimpleMetrics(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAHwCAYAAAAl/FzOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noHTkmpYdQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc2bd4400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importances\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "xgb.plot_importance(xgb_test, max_num_features=20, height=0.5, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value\n",
    "# import operator\n",
    "# x = xgb_test.get_fscore()\n",
    "# sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# # sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for col, imp in sorted_x:\n",
    "# # for col in xgb_model_DCGAN.get_fscore().keys():\n",
    "# # for col in ['V1','V14','V3']:\n",
    "#     plt.hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "# #     plt.title( '{}: {}'.format(col, xgb_model_DCGAN.get_fscore()[col]) )\n",
    "#     plt.title( '{}: {}'.format(col, imp) )\n",
    "#     plt.legend() ; plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/figure.py:1742: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+8AAALICAYAAAAOpMEfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc44ec978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for col in train.columns:\n",
    "#     plt.hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "#     plt.title( '{}'.format(col) )\n",
    "#     plt.legend() ; plt.show()\n",
    "    \n",
    "# plt.figure(figsize=(14,5))    \n",
    "f, axarr = plt.subplots(7, 4, figsize=(14,10) )\n",
    "for i in range(28):\n",
    "    col = train_df.columns[i]\n",
    "    axarr[i//4, i%4].hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "    axarr[i//4, i%4].set_title( '{}'.format(col) )\n",
    "    if i == 0: axarr[i//4, i%4].legend()\n",
    "#     axarr[i//4, i%4].set_xlim([-0.1,1.1])\n",
    "#     axarr[i//4, i%4].set_ylim([0,40])\n",
    "f.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Waya.ai CGAN dense\"><h1>Waya.ai CGAN dense</h1></a>\n",
    "\n",
    "<a href='#TOC'>Table of contents</a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Standard GAN implemented on top of keras/tensorflow.\n",
    "\n",
    "With conditional labels added\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adversarial_training(data_dir, generator_model_path, discriminator_model_path, evaluate=False):\n",
    "    \"\"\"\n",
    "    Adversarial training of the generator network Gθ and discriminator network Dφ.\n",
    "\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(5)\n",
    "    \n",
    "    #\n",
    "    # define model input and output tensors\n",
    "    #\n",
    "\n",
    "    generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "    generated_image_tensor = generator_network(generator_input_tensor)\n",
    "\n",
    "    generated_or_real_image_tensor = layers.Input(shape=(data_dim,))\n",
    "    discriminator_output = discriminator_network(generated_or_real_image_tensor)\n",
    "\n",
    "    #\n",
    "    # define models\n",
    "    #\n",
    "\n",
    "    generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "    discriminator_model = models.Model(inputs=[generated_or_real_image_tensor],\n",
    "                                       outputs=[discriminator_output],\n",
    "                                       name='discriminator')\n",
    "\n",
    "    combined_output = discriminator_model(generator_model(generator_input_tensor))\n",
    "    combined_model = models.Model(inputs=[generator_input_tensor], outputs=[combined_output], name='combined')\n",
    "\n",
    "    #\n",
    "    # compile models\n",
    "    #\n",
    "\n",
    "    adam = optimizers.Adam(lr=.0001, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "    generator_model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    discriminator_model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    \n",
    "    discriminator_model.trainable = False\n",
    "#     combined_model.compile(optimizer=adam, loss=[em_loss])\n",
    "    combined_model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    \n",
    "    print(generator_model.summary())\n",
    "    print(discriminator_model.summary())\n",
    "    print(combined_model.summary())\n",
    "\n",
    "\n",
    "#     disc_loss = []\n",
    "#     combined_loss = []\n",
    "    combined_loss = np.empty(shape=1)\n",
    "    disc_loss_real = np.empty(shape=1)\n",
    "    disc_loss_generated = np.empty(shape=1)\n",
    "    xgb_losses = np.empty(shape=1)\n",
    "    \n",
    "    if generator_model_path:\n",
    "        generator_model.load_weights(generator_model_path, by_name=True)\n",
    "    if discriminator_model_path:\n",
    "        discriminator_model.load_weights(discriminator_model_path, by_name=True)\n",
    "    \n",
    "    for i in range(nb_steps):\n",
    "        print('Step: {} of {}.'.format(i, nb_steps))\n",
    "        K.set_learning_phase(1) # 1 = train\n",
    "\n",
    "        # train the discriminator\n",
    "        for _ in range(k_d):\n",
    "            # sample a mini-batch of noise (generator input)\n",
    "            z = np.random.normal(size=(batch_size, rand_dim))\n",
    "\n",
    "            # sample a mini-batch of real images\n",
    "            x = get_data_batch(train_w_class, batch_size, data_dim)\n",
    "\n",
    "            # generate a batch of images with the current generator\n",
    "            g_z = generator_model.predict(z)\n",
    "\n",
    "            # update φ by taking an SGD step on mini-batch loss LD(φ)\n",
    "            disc_loss_real = np.append(disc_loss_real, discriminator_model.train_on_batch(x, np.random.uniform(\n",
    "                low=0.7, high=1.2, size=batch_size)))\n",
    "            disc_loss_generated = np.append(disc_loss_generated, discriminator_model.train_on_batch(g_z,\n",
    "                np.random.uniform(low=0.0, high=0.3, size=batch_size)))\n",
    "\n",
    "\n",
    "        # train the generator\n",
    "        for _ in range(k_g):\n",
    "            z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, rand_dim))\n",
    "            # update θ by taking an SGD step on mini-batch loss LR(θ)\n",
    "            combined_loss = np.append(combined_loss, combined_model.train_on_batch(z, np.random.uniform(\n",
    "                low=0.7, high=1.2, size=batch_size)))\n",
    "\n",
    "        if not i % log_interval and i != 0:\n",
    "            K.set_learning_phase(0) # 0 = test\n",
    "\n",
    "            # log loss summary\n",
    "            print('Generator model loss: {}.'.format(np.mean(combined_loss[-log_interval:], axis=0)))\n",
    "            print('Discriminator model loss real: {}.'.format(np.mean(disc_loss_real[-log_interval:], axis=0)))\n",
    "            print('Discriminator model loss generated: {}.'.format(np.mean(disc_loss_generated[-log_interval:], axis=0)))\n",
    "            \n",
    "            \n",
    "            xgb_loss = CheckAccuracy( generator_model, 400, train_w_class )\n",
    "#             xgb_loss = CheckAccuracy( generator_model, 100, test )\n",
    "            xgb_losses = np.append(xgb_losses, xgb_loss)\n",
    "            print('xgboost accuracy: {}'.format(xgb_loss) )\n",
    "\n",
    "            # save model checkpoints\n",
    "            model_checkpoint_base_name = os.path.join(cache_dir, 'CGAN_{}_model_weights_step_{}.h5')\n",
    "            generator_model.save_weights(model_checkpoint_base_name.format('generator', i))\n",
    "            discriminator_model.save_weights(model_checkpoint_base_name.format('discriminator', i))\n",
    "    \n",
    "    pickle.dump([combined_loss, disc_loss_real, disc_loss_generated, xgb_losses], \n",
    "                open(os.path.join(cache_dir, 'CGAN_losses.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 29)                957       \n",
      "=================================================================\n",
      "Total params: 3,069\n",
      "Trainable params: 3,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                960       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,919\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,919\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            (None, 29)                3069      \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 2919      \n",
      "=================================================================\n",
      "Total params: 5,988\n",
      "Trainable params: 3,069\n",
      "Non-trainable params: 2,919\n",
      "_________________________________________________________________\n",
      "None\n",
      "Step: 0 of 5001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.4-py3.6.egg/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 of 5001.\n",
      "Step: 2 of 5001.\n",
      "Step: 3 of 5001.\n",
      "Step: 4 of 5001.\n",
      "Step: 5 of 5001.\n",
      "Step: 6 of 5001.\n",
      "Step: 7 of 5001.\n",
      "Step: 8 of 5001.\n",
      "Step: 9 of 5001.\n",
      "Step: 10 of 5001.\n",
      "Generator model loss: 5.978703880310059.\n",
      "Discriminator model loss real: 7.393591451644897.\n",
      "Discriminator model loss generated: 2.143365812301636.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 11 of 5001.\n",
      "Step: 12 of 5001.\n",
      "Step: 13 of 5001.\n",
      "Step: 14 of 5001.\n",
      "Step: 15 of 5001.\n",
      "Step: 16 of 5001.\n",
      "Step: 17 of 5001.\n",
      "Step: 18 of 5001.\n",
      "Step: 19 of 5001.\n",
      "Step: 20 of 5001.\n",
      "Generator model loss: 4.808601236343383.\n",
      "Discriminator model loss real: 5.247726774215698.\n",
      "Discriminator model loss generated: 1.9485689282417298.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 21 of 5001.\n",
      "Step: 22 of 5001.\n",
      "Step: 23 of 5001.\n",
      "Step: 24 of 5001.\n",
      "Step: 25 of 5001.\n",
      "Step: 26 of 5001.\n",
      "Step: 27 of 5001.\n",
      "Step: 28 of 5001.\n",
      "Step: 29 of 5001.\n",
      "Step: 30 of 5001.\n",
      "Generator model loss: 4.994474029541015.\n",
      "Discriminator model loss real: 4.5369186162948605.\n",
      "Discriminator model loss generated: 2.1932241916656494.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 31 of 5001.\n",
      "Step: 32 of 5001.\n",
      "Step: 33 of 5001.\n",
      "Step: 34 of 5001.\n",
      "Step: 35 of 5001.\n",
      "Step: 36 of 5001.\n",
      "Step: 37 of 5001.\n",
      "Step: 38 of 5001.\n",
      "Step: 39 of 5001.\n",
      "Step: 40 of 5001.\n",
      "Generator model loss: 4.411012315750122.\n",
      "Discriminator model loss real: 3.7232166051864626.\n",
      "Discriminator model loss generated: 2.2539599776268004.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 41 of 5001.\n",
      "Step: 42 of 5001.\n",
      "Step: 43 of 5001.\n",
      "Step: 44 of 5001.\n",
      "Step: 45 of 5001.\n",
      "Step: 46 of 5001.\n",
      "Step: 47 of 5001.\n",
      "Step: 48 of 5001.\n",
      "Step: 49 of 5001.\n",
      "Step: 50 of 5001.\n",
      "Generator model loss: 4.289163303375244.\n",
      "Discriminator model loss real: 3.8639313697814943.\n",
      "Discriminator model loss generated: 2.2508181810379027.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 51 of 5001.\n",
      "Step: 52 of 5001.\n",
      "Step: 53 of 5001.\n",
      "Step: 54 of 5001.\n",
      "Step: 55 of 5001.\n",
      "Step: 56 of 5001.\n",
      "Step: 57 of 5001.\n",
      "Step: 58 of 5001.\n",
      "Step: 59 of 5001.\n",
      "Step: 60 of 5001.\n",
      "Generator model loss: 4.2344016313552855.\n",
      "Discriminator model loss real: 3.441194772720337.\n",
      "Discriminator model loss generated: 2.2740479588508604.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 61 of 5001.\n",
      "Step: 62 of 5001.\n",
      "Step: 63 of 5001.\n",
      "Step: 64 of 5001.\n",
      "Step: 65 of 5001.\n",
      "Step: 66 of 5001.\n",
      "Step: 67 of 5001.\n",
      "Step: 68 of 5001.\n",
      "Step: 69 of 5001.\n",
      "Step: 70 of 5001.\n",
      "Generator model loss: 3.9086368560791014.\n",
      "Discriminator model loss real: 2.512012779712677.\n",
      "Discriminator model loss generated: 2.1557286620140075.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 71 of 5001.\n",
      "Step: 72 of 5001.\n",
      "Step: 73 of 5001.\n",
      "Step: 74 of 5001.\n",
      "Step: 75 of 5001.\n",
      "Step: 76 of 5001.\n",
      "Step: 77 of 5001.\n",
      "Step: 78 of 5001.\n",
      "Step: 79 of 5001.\n",
      "Step: 80 of 5001.\n",
      "Generator model loss: 3.838645005226135.\n",
      "Discriminator model loss real: 2.5629924178123473.\n",
      "Discriminator model loss generated: 2.302002024650574.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 81 of 5001.\n",
      "Step: 82 of 5001.\n",
      "Step: 83 of 5001.\n",
      "Step: 84 of 5001.\n",
      "Step: 85 of 5001.\n",
      "Step: 86 of 5001.\n",
      "Step: 87 of 5001.\n",
      "Step: 88 of 5001.\n",
      "Step: 89 of 5001.\n",
      "Step: 90 of 5001.\n",
      "Generator model loss: 3.652479553222656.\n",
      "Discriminator model loss real: 2.496863293647766.\n",
      "Discriminator model loss generated: 2.19183429479599.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 91 of 5001.\n",
      "Step: 92 of 5001.\n",
      "Step: 93 of 5001.\n",
      "Step: 94 of 5001.\n",
      "Step: 95 of 5001.\n",
      "Step: 96 of 5001.\n",
      "Step: 97 of 5001.\n",
      "Step: 98 of 5001.\n",
      "Step: 99 of 5001.\n",
      "Step: 100 of 5001.\n",
      "Generator model loss: 3.3961506605148317.\n",
      "Discriminator model loss real: 2.224412226676941.\n",
      "Discriminator model loss generated: 2.156525731086731.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 101 of 5001.\n",
      "Step: 102 of 5001.\n",
      "Step: 103 of 5001.\n",
      "Step: 104 of 5001.\n",
      "Step: 105 of 5001.\n",
      "Step: 106 of 5001.\n",
      "Step: 107 of 5001.\n",
      "Step: 108 of 5001.\n",
      "Step: 109 of 5001.\n",
      "Step: 110 of 5001.\n",
      "Generator model loss: 3.431326389312744.\n",
      "Discriminator model loss real: 2.1443997740745546.\n",
      "Discriminator model loss generated: 1.8494473099708557.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 111 of 5001.\n",
      "Step: 112 of 5001.\n",
      "Step: 113 of 5001.\n",
      "Step: 114 of 5001.\n",
      "Step: 115 of 5001.\n",
      "Step: 116 of 5001.\n",
      "Step: 117 of 5001.\n",
      "Step: 118 of 5001.\n",
      "Step: 119 of 5001.\n",
      "Step: 120 of 5001.\n",
      "Generator model loss: 3.1304786086082457.\n",
      "Discriminator model loss real: 1.8901672959327698.\n",
      "Discriminator model loss generated: 1.8900201976299287.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 121 of 5001.\n",
      "Step: 122 of 5001.\n",
      "Step: 123 of 5001.\n",
      "Step: 124 of 5001.\n",
      "Step: 125 of 5001.\n",
      "Step: 126 of 5001.\n",
      "Step: 127 of 5001.\n",
      "Step: 128 of 5001.\n",
      "Step: 129 of 5001.\n",
      "Step: 130 of 5001.\n",
      "Generator model loss: 3.235852861404419.\n",
      "Discriminator model loss real: 1.7381998777389527.\n",
      "Discriminator model loss generated: 1.8226911067962646.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 131 of 5001.\n",
      "Step: 132 of 5001.\n",
      "Step: 133 of 5001.\n",
      "Step: 134 of 5001.\n",
      "Step: 135 of 5001.\n",
      "Step: 136 of 5001.\n",
      "Step: 137 of 5001.\n",
      "Step: 138 of 5001.\n",
      "Step: 139 of 5001.\n",
      "Step: 140 of 5001.\n",
      "Generator model loss: 3.1696660995483397.\n",
      "Discriminator model loss real: 1.7255576729774476.\n",
      "Discriminator model loss generated: 1.5056079745292663.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 141 of 5001.\n",
      "Step: 142 of 5001.\n",
      "Step: 143 of 5001.\n",
      "Step: 144 of 5001.\n",
      "Step: 145 of 5001.\n",
      "Step: 146 of 5001.\n",
      "Step: 147 of 5001.\n",
      "Step: 148 of 5001.\n",
      "Step: 149 of 5001.\n",
      "Step: 150 of 5001.\n",
      "Generator model loss: 2.84651038646698.\n",
      "Discriminator model loss real: 1.6300734400749206.\n",
      "Discriminator model loss generated: 1.4821126818656922.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 151 of 5001.\n",
      "Step: 152 of 5001.\n",
      "Step: 153 of 5001.\n",
      "Step: 154 of 5001.\n",
      "Step: 155 of 5001.\n",
      "Step: 156 of 5001.\n",
      "Step: 157 of 5001.\n",
      "Step: 158 of 5001.\n",
      "Step: 159 of 5001.\n",
      "Step: 160 of 5001.\n",
      "Generator model loss: 2.8912293195724486.\n",
      "Discriminator model loss real: 1.6216120839118957.\n",
      "Discriminator model loss generated: 1.671588408946991.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 161 of 5001.\n",
      "Step: 162 of 5001.\n",
      "Step: 163 of 5001.\n",
      "Step: 164 of 5001.\n",
      "Step: 165 of 5001.\n",
      "Step: 166 of 5001.\n",
      "Step: 167 of 5001.\n",
      "Step: 168 of 5001.\n",
      "Step: 169 of 5001.\n",
      "Step: 170 of 5001.\n",
      "Generator model loss: 2.71256445646286.\n",
      "Discriminator model loss real: 1.3809150993824004.\n",
      "Discriminator model loss generated: 1.366056787967682.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 171 of 5001.\n",
      "Step: 172 of 5001.\n",
      "Step: 173 of 5001.\n",
      "Step: 174 of 5001.\n",
      "Step: 175 of 5001.\n",
      "Step: 176 of 5001.\n",
      "Step: 177 of 5001.\n",
      "Step: 178 of 5001.\n",
      "Step: 179 of 5001.\n",
      "Step: 180 of 5001.\n",
      "Generator model loss: 2.8920387029647827.\n",
      "Discriminator model loss real: 1.6953962683677672.\n",
      "Discriminator model loss generated: 1.4049173712730407.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 181 of 5001.\n",
      "Step: 182 of 5001.\n",
      "Step: 183 of 5001.\n",
      "Step: 184 of 5001.\n",
      "Step: 185 of 5001.\n",
      "Step: 186 of 5001.\n",
      "Step: 187 of 5001.\n",
      "Step: 188 of 5001.\n",
      "Step: 189 of 5001.\n",
      "Step: 190 of 5001.\n",
      "Generator model loss: 2.987394595146179.\n",
      "Discriminator model loss real: 1.3937883913516997.\n",
      "Discriminator model loss generated: 1.4151595830917358.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 191 of 5001.\n",
      "Step: 192 of 5001.\n",
      "Step: 193 of 5001.\n",
      "Step: 194 of 5001.\n",
      "Step: 195 of 5001.\n",
      "Step: 196 of 5001.\n",
      "Step: 197 of 5001.\n",
      "Step: 198 of 5001.\n",
      "Step: 199 of 5001.\n",
      "Step: 200 of 5001.\n",
      "Generator model loss: 3.079768514633179.\n",
      "Discriminator model loss real: 1.3496299088001251.\n",
      "Discriminator model loss generated: 1.408328902721405.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 201 of 5001.\n",
      "Step: 202 of 5001.\n",
      "Step: 203 of 5001.\n",
      "Step: 204 of 5001.\n",
      "Step: 205 of 5001.\n",
      "Step: 206 of 5001.\n",
      "Step: 207 of 5001.\n",
      "Step: 208 of 5001.\n",
      "Step: 209 of 5001.\n",
      "Step: 210 of 5001.\n",
      "Generator model loss: 2.63904527425766.\n",
      "Discriminator model loss real: 1.2426051497459412.\n",
      "Discriminator model loss generated: 1.1971348166465758.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 211 of 5001.\n",
      "Step: 212 of 5001.\n",
      "Step: 213 of 5001.\n",
      "Step: 214 of 5001.\n",
      "Step: 215 of 5001.\n",
      "Step: 216 of 5001.\n",
      "Step: 217 of 5001.\n",
      "Step: 218 of 5001.\n",
      "Step: 219 of 5001.\n",
      "Step: 220 of 5001.\n",
      "Generator model loss: 2.9068603515625.\n",
      "Discriminator model loss real: 1.4125860214233399.\n",
      "Discriminator model loss generated: 1.2580104291439056.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 221 of 5001.\n",
      "Step: 222 of 5001.\n",
      "Step: 223 of 5001.\n",
      "Step: 224 of 5001.\n",
      "Step: 225 of 5001.\n",
      "Step: 226 of 5001.\n",
      "Step: 227 of 5001.\n",
      "Step: 228 of 5001.\n",
      "Step: 229 of 5001.\n",
      "Step: 230 of 5001.\n",
      "Generator model loss: 2.6339491844177245.\n",
      "Discriminator model loss real: 1.2675484001636506.\n",
      "Discriminator model loss generated: 1.1365120112895966.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 231 of 5001.\n",
      "Step: 232 of 5001.\n",
      "Step: 233 of 5001.\n",
      "Step: 234 of 5001.\n",
      "Step: 235 of 5001.\n",
      "Step: 236 of 5001.\n",
      "Step: 237 of 5001.\n",
      "Step: 238 of 5001.\n",
      "Step: 239 of 5001.\n",
      "Step: 240 of 5001.\n",
      "Generator model loss: 2.544608807563782.\n",
      "Discriminator model loss real: 1.3911243736743928.\n",
      "Discriminator model loss generated: 1.1686092495918274.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 241 of 5001.\n",
      "Step: 242 of 5001.\n",
      "Step: 243 of 5001.\n",
      "Step: 244 of 5001.\n",
      "Step: 245 of 5001.\n",
      "Step: 246 of 5001.\n",
      "Step: 247 of 5001.\n",
      "Step: 248 of 5001.\n",
      "Step: 249 of 5001.\n",
      "Step: 250 of 5001.\n",
      "Generator model loss: 2.412243437767029.\n",
      "Discriminator model loss real: 1.353210872411728.\n",
      "Discriminator model loss generated: 1.1690642595291139.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 251 of 5001.\n",
      "Step: 252 of 5001.\n",
      "Step: 253 of 5001.\n",
      "Step: 254 of 5001.\n",
      "Step: 255 of 5001.\n",
      "Step: 256 of 5001.\n",
      "Step: 257 of 5001.\n",
      "Step: 258 of 5001.\n",
      "Step: 259 of 5001.\n",
      "Step: 260 of 5001.\n",
      "Generator model loss: 2.052516448497772.\n",
      "Discriminator model loss real: 1.0990265667438508.\n",
      "Discriminator model loss generated: 1.1257951140403748.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 261 of 5001.\n",
      "Step: 262 of 5001.\n",
      "Step: 263 of 5001.\n",
      "Step: 264 of 5001.\n",
      "Step: 265 of 5001.\n",
      "Step: 266 of 5001.\n",
      "Step: 267 of 5001.\n",
      "Step: 268 of 5001.\n",
      "Step: 269 of 5001.\n",
      "Step: 270 of 5001.\n",
      "Generator model loss: 2.4603848099708556.\n",
      "Discriminator model loss real: 1.2449625849723815.\n",
      "Discriminator model loss generated: 1.2966893076896668.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 271 of 5001.\n",
      "Step: 272 of 5001.\n",
      "Step: 273 of 5001.\n",
      "Step: 274 of 5001.\n",
      "Step: 275 of 5001.\n",
      "Step: 276 of 5001.\n",
      "Step: 277 of 5001.\n",
      "Step: 278 of 5001.\n",
      "Step: 279 of 5001.\n",
      "Step: 280 of 5001.\n",
      "Generator model loss: 2.07671000957489.\n",
      "Discriminator model loss real: 1.2924962043762207.\n",
      "Discriminator model loss generated: 0.9652684271335602.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 281 of 5001.\n",
      "Step: 282 of 5001.\n",
      "Step: 283 of 5001.\n",
      "Step: 284 of 5001.\n",
      "Step: 285 of 5001.\n",
      "Step: 286 of 5001.\n",
      "Step: 287 of 5001.\n",
      "Step: 288 of 5001.\n",
      "Step: 289 of 5001.\n",
      "Step: 290 of 5001.\n",
      "Generator model loss: 1.9623592853546143.\n",
      "Discriminator model loss real: 1.0453540906310081.\n",
      "Discriminator model loss generated: 1.066322886943817.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 291 of 5001.\n",
      "Step: 292 of 5001.\n",
      "Step: 293 of 5001.\n",
      "Step: 294 of 5001.\n",
      "Step: 295 of 5001.\n",
      "Step: 296 of 5001.\n",
      "Step: 297 of 5001.\n",
      "Step: 298 of 5001.\n",
      "Step: 299 of 5001.\n",
      "Step: 300 of 5001.\n",
      "Generator model loss: 2.083714759349823.\n",
      "Discriminator model loss real: 1.0195929259061813.\n",
      "Discriminator model loss generated: 0.9287685751914978.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 301 of 5001.\n",
      "Step: 302 of 5001.\n",
      "Step: 303 of 5001.\n",
      "Step: 304 of 5001.\n",
      "Step: 305 of 5001.\n",
      "Step: 306 of 5001.\n",
      "Step: 307 of 5001.\n",
      "Step: 308 of 5001.\n",
      "Step: 309 of 5001.\n",
      "Step: 310 of 5001.\n",
      "Generator model loss: 2.0162699699401854.\n",
      "Discriminator model loss real: 1.1412637293338777.\n",
      "Discriminator model loss generated: 0.9616515100002289.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 311 of 5001.\n",
      "Step: 312 of 5001.\n",
      "Step: 313 of 5001.\n",
      "Step: 314 of 5001.\n",
      "Step: 315 of 5001.\n",
      "Step: 316 of 5001.\n",
      "Step: 317 of 5001.\n",
      "Step: 318 of 5001.\n",
      "Step: 319 of 5001.\n",
      "Step: 320 of 5001.\n",
      "Generator model loss: 2.0982691764831545.\n",
      "Discriminator model loss real: 1.187781536579132.\n",
      "Discriminator model loss generated: 1.0207952439785004.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 321 of 5001.\n",
      "Step: 322 of 5001.\n",
      "Step: 323 of 5001.\n",
      "Step: 324 of 5001.\n",
      "Step: 325 of 5001.\n",
      "Step: 326 of 5001.\n",
      "Step: 327 of 5001.\n",
      "Step: 328 of 5001.\n",
      "Step: 329 of 5001.\n",
      "Step: 330 of 5001.\n",
      "Generator model loss: 1.8908031344413758.\n",
      "Discriminator model loss real: 0.9724097371101379.\n",
      "Discriminator model loss generated: 0.9682386338710784.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 331 of 5001.\n",
      "Step: 332 of 5001.\n",
      "Step: 333 of 5001.\n",
      "Step: 334 of 5001.\n",
      "Step: 335 of 5001.\n",
      "Step: 336 of 5001.\n",
      "Step: 337 of 5001.\n",
      "Step: 338 of 5001.\n",
      "Step: 339 of 5001.\n",
      "Step: 340 of 5001.\n",
      "Generator model loss: 1.8464830040931701.\n",
      "Discriminator model loss real: 1.0636883199214935.\n",
      "Discriminator model loss generated: 0.9853945016860962.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 341 of 5001.\n",
      "Step: 342 of 5001.\n",
      "Step: 343 of 5001.\n",
      "Step: 344 of 5001.\n",
      "Step: 345 of 5001.\n",
      "Step: 346 of 5001.\n",
      "Step: 347 of 5001.\n",
      "Step: 348 of 5001.\n",
      "Step: 349 of 5001.\n",
      "Step: 350 of 5001.\n",
      "Generator model loss: 1.745824670791626.\n",
      "Discriminator model loss real: 1.1354481160640717.\n",
      "Discriminator model loss generated: 0.8159882843494415.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 351 of 5001.\n",
      "Step: 352 of 5001.\n",
      "Step: 353 of 5001.\n",
      "Step: 354 of 5001.\n",
      "Step: 355 of 5001.\n",
      "Step: 356 of 5001.\n",
      "Step: 357 of 5001.\n",
      "Step: 358 of 5001.\n",
      "Step: 359 of 5001.\n",
      "Step: 360 of 5001.\n",
      "Generator model loss: 1.7274704337120057.\n",
      "Discriminator model loss real: 1.1276917219161988.\n",
      "Discriminator model loss generated: 0.8133889138698578.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 361 of 5001.\n",
      "Step: 362 of 5001.\n",
      "Step: 363 of 5001.\n",
      "Step: 364 of 5001.\n",
      "Step: 365 of 5001.\n",
      "Step: 366 of 5001.\n",
      "Step: 367 of 5001.\n",
      "Step: 368 of 5001.\n",
      "Step: 369 of 5001.\n",
      "Step: 370 of 5001.\n",
      "Generator model loss: 1.8134927868843078.\n",
      "Discriminator model loss real: 0.905377984046936.\n",
      "Discriminator model loss generated: 0.8411679446697236.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 371 of 5001.\n",
      "Step: 372 of 5001.\n",
      "Step: 373 of 5001.\n",
      "Step: 374 of 5001.\n",
      "Step: 375 of 5001.\n",
      "Step: 376 of 5001.\n",
      "Step: 377 of 5001.\n",
      "Step: 378 of 5001.\n",
      "Step: 379 of 5001.\n",
      "Step: 380 of 5001.\n",
      "Generator model loss: 1.577440083026886.\n",
      "Discriminator model loss real: 0.9584376633167266.\n",
      "Discriminator model loss generated: 0.822674173116684.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 381 of 5001.\n",
      "Step: 382 of 5001.\n",
      "Step: 383 of 5001.\n",
      "Step: 384 of 5001.\n",
      "Step: 385 of 5001.\n",
      "Step: 386 of 5001.\n",
      "Step: 387 of 5001.\n",
      "Step: 388 of 5001.\n",
      "Step: 389 of 5001.\n",
      "Step: 390 of 5001.\n",
      "Generator model loss: 1.5898250937461853.\n",
      "Discriminator model loss real: 1.0743125587701798.\n",
      "Discriminator model loss generated: 0.7736108601093292.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 391 of 5001.\n",
      "Step: 392 of 5001.\n",
      "Step: 393 of 5001.\n",
      "Step: 394 of 5001.\n",
      "Step: 395 of 5001.\n",
      "Step: 396 of 5001.\n",
      "Step: 397 of 5001.\n",
      "Step: 398 of 5001.\n",
      "Step: 399 of 5001.\n",
      "Step: 400 of 5001.\n",
      "Generator model loss: 1.5365979552268982.\n",
      "Discriminator model loss real: 0.9424027264118194.\n",
      "Discriminator model loss generated: 0.8199660837650299.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 401 of 5001.\n",
      "Step: 402 of 5001.\n",
      "Step: 403 of 5001.\n",
      "Step: 404 of 5001.\n",
      "Step: 405 of 5001.\n",
      "Step: 406 of 5001.\n",
      "Step: 407 of 5001.\n",
      "Step: 408 of 5001.\n",
      "Step: 409 of 5001.\n",
      "Step: 410 of 5001.\n",
      "Generator model loss: 1.6007774949073792.\n",
      "Discriminator model loss real: 0.8575932532548904.\n",
      "Discriminator model loss generated: 0.7391111075878143.\n",
      "xgboost accuracy: 0.98\n",
      "Step: 411 of 5001.\n",
      "Step: 412 of 5001.\n",
      "Step: 413 of 5001.\n",
      "Step: 414 of 5001.\n",
      "Step: 415 of 5001.\n",
      "Step: 416 of 5001.\n",
      "Step: 417 of 5001.\n",
      "Step: 418 of 5001.\n",
      "Step: 419 of 5001.\n",
      "Step: 420 of 5001.\n",
      "Generator model loss: 1.6124235391616821.\n",
      "Discriminator model loss real: 0.947032916545868.\n",
      "Discriminator model loss generated: 0.7083945333957672.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 421 of 5001.\n",
      "Step: 422 of 5001.\n",
      "Step: 423 of 5001.\n",
      "Step: 424 of 5001.\n",
      "Step: 425 of 5001.\n",
      "Step: 426 of 5001.\n",
      "Step: 427 of 5001.\n",
      "Step: 428 of 5001.\n",
      "Step: 429 of 5001.\n",
      "Step: 430 of 5001.\n",
      "Generator model loss: 1.5982779383659362.\n",
      "Discriminator model loss real: 0.9448351413011551.\n",
      "Discriminator model loss generated: 0.7097766101360321.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 431 of 5001.\n",
      "Step: 432 of 5001.\n",
      "Step: 433 of 5001.\n",
      "Step: 434 of 5001.\n",
      "Step: 435 of 5001.\n",
      "Step: 436 of 5001.\n",
      "Step: 437 of 5001.\n",
      "Step: 438 of 5001.\n",
      "Step: 439 of 5001.\n",
      "Step: 440 of 5001.\n",
      "Generator model loss: 1.5264819502830504.\n",
      "Discriminator model loss real: 0.9114419430494308.\n",
      "Discriminator model loss generated: 0.7277799606323242.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 441 of 5001.\n",
      "Step: 442 of 5001.\n",
      "Step: 443 of 5001.\n",
      "Step: 444 of 5001.\n",
      "Step: 445 of 5001.\n",
      "Step: 446 of 5001.\n",
      "Step: 447 of 5001.\n",
      "Step: 448 of 5001.\n",
      "Step: 449 of 5001.\n",
      "Step: 450 of 5001.\n",
      "Generator model loss: 1.467749869823456.\n",
      "Discriminator model loss real: 0.8575692757964134.\n",
      "Discriminator model loss generated: 0.6920411705970764.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 451 of 5001.\n",
      "Step: 452 of 5001.\n",
      "Step: 453 of 5001.\n",
      "Step: 454 of 5001.\n",
      "Step: 455 of 5001.\n",
      "Step: 456 of 5001.\n",
      "Step: 457 of 5001.\n",
      "Step: 458 of 5001.\n",
      "Step: 459 of 5001.\n",
      "Step: 460 of 5001.\n",
      "Generator model loss: 1.476220703125.\n",
      "Discriminator model loss real: 0.8080951273441315.\n",
      "Discriminator model loss generated: 0.6738178253173828.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 461 of 5001.\n",
      "Step: 462 of 5001.\n",
      "Step: 463 of 5001.\n",
      "Step: 464 of 5001.\n",
      "Step: 465 of 5001.\n",
      "Step: 466 of 5001.\n",
      "Step: 467 of 5001.\n",
      "Step: 468 of 5001.\n",
      "Step: 469 of 5001.\n",
      "Step: 470 of 5001.\n",
      "Generator model loss: 1.3701695561408997.\n",
      "Discriminator model loss real: 0.9106668889522552.\n",
      "Discriminator model loss generated: 0.6508298456668854.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 471 of 5001.\n",
      "Step: 472 of 5001.\n",
      "Step: 473 of 5001.\n",
      "Step: 474 of 5001.\n",
      "Step: 475 of 5001.\n",
      "Step: 476 of 5001.\n",
      "Step: 477 of 5001.\n",
      "Step: 478 of 5001.\n",
      "Step: 479 of 5001.\n",
      "Step: 480 of 5001.\n",
      "Generator model loss: 1.4105544209480285.\n",
      "Discriminator model loss real: 0.9711602985858917.\n",
      "Discriminator model loss generated: 0.6681958556175231.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 481 of 5001.\n",
      "Step: 482 of 5001.\n",
      "Step: 483 of 5001.\n",
      "Step: 484 of 5001.\n",
      "Step: 485 of 5001.\n",
      "Step: 486 of 5001.\n",
      "Step: 487 of 5001.\n",
      "Step: 488 of 5001.\n",
      "Step: 489 of 5001.\n",
      "Step: 490 of 5001.\n",
      "Generator model loss: 1.3597277402877808.\n",
      "Discriminator model loss real: 0.8303437441587448.\n",
      "Discriminator model loss generated: 0.6786137461662293.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 491 of 5001.\n",
      "Step: 492 of 5001.\n",
      "Step: 493 of 5001.\n",
      "Step: 494 of 5001.\n",
      "Step: 495 of 5001.\n",
      "Step: 496 of 5001.\n",
      "Step: 497 of 5001.\n",
      "Step: 498 of 5001.\n",
      "Step: 499 of 5001.\n",
      "Step: 500 of 5001.\n",
      "Generator model loss: 1.250760841369629.\n",
      "Discriminator model loss real: 0.8604655504226685.\n",
      "Discriminator model loss generated: 0.6454904317855835.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 501 of 5001.\n",
      "Step: 502 of 5001.\n",
      "Step: 503 of 5001.\n",
      "Step: 504 of 5001.\n",
      "Step: 505 of 5001.\n",
      "Step: 506 of 5001.\n",
      "Step: 507 of 5001.\n",
      "Step: 508 of 5001.\n",
      "Step: 509 of 5001.\n",
      "Step: 510 of 5001.\n",
      "Generator model loss: 1.4265389442443848.\n",
      "Discriminator model loss real: 0.7859864741563797.\n",
      "Discriminator model loss generated: 0.5931390285491943.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 511 of 5001.\n",
      "Step: 512 of 5001.\n",
      "Step: 513 of 5001.\n",
      "Step: 514 of 5001.\n",
      "Step: 515 of 5001.\n",
      "Step: 516 of 5001.\n",
      "Step: 517 of 5001.\n",
      "Step: 518 of 5001.\n",
      "Step: 519 of 5001.\n",
      "Step: 520 of 5001.\n",
      "Generator model loss: 1.3767636656761169.\n",
      "Discriminator model loss real: 0.9094221234321594.\n",
      "Discriminator model loss generated: 0.5904195845127106.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 521 of 5001.\n",
      "Step: 522 of 5001.\n",
      "Step: 523 of 5001.\n",
      "Step: 524 of 5001.\n",
      "Step: 525 of 5001.\n",
      "Step: 526 of 5001.\n",
      "Step: 527 of 5001.\n",
      "Step: 528 of 5001.\n",
      "Step: 529 of 5001.\n",
      "Step: 530 of 5001.\n",
      "Generator model loss: 1.3587223291397095.\n",
      "Discriminator model loss real: 0.8982754290103913.\n",
      "Discriminator model loss generated: 0.5905859231948852.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 531 of 5001.\n",
      "Step: 532 of 5001.\n",
      "Step: 533 of 5001.\n",
      "Step: 534 of 5001.\n",
      "Step: 535 of 5001.\n",
      "Step: 536 of 5001.\n",
      "Step: 537 of 5001.\n",
      "Step: 538 of 5001.\n",
      "Step: 539 of 5001.\n",
      "Step: 540 of 5001.\n",
      "Generator model loss: 1.2570841789245606.\n",
      "Discriminator model loss real: 0.8467593252658844.\n",
      "Discriminator model loss generated: 0.6909706771373749.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 541 of 5001.\n",
      "Step: 542 of 5001.\n",
      "Step: 543 of 5001.\n",
      "Step: 544 of 5001.\n",
      "Step: 545 of 5001.\n",
      "Step: 546 of 5001.\n",
      "Step: 547 of 5001.\n",
      "Step: 548 of 5001.\n",
      "Step: 549 of 5001.\n",
      "Step: 550 of 5001.\n",
      "Generator model loss: 1.317385733127594.\n",
      "Discriminator model loss real: 0.8041846603155136.\n",
      "Discriminator model loss generated: 0.6181805789470672.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 551 of 5001.\n",
      "Step: 552 of 5001.\n",
      "Step: 553 of 5001.\n",
      "Step: 554 of 5001.\n",
      "Step: 555 of 5001.\n",
      "Step: 556 of 5001.\n",
      "Step: 557 of 5001.\n",
      "Step: 558 of 5001.\n",
      "Step: 559 of 5001.\n",
      "Step: 560 of 5001.\n",
      "Generator model loss: 1.3415423393249513.\n",
      "Discriminator model loss real: 0.8293126553297043.\n",
      "Discriminator model loss generated: 0.6019754946231842.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 561 of 5001.\n",
      "Step: 562 of 5001.\n",
      "Step: 563 of 5001.\n",
      "Step: 564 of 5001.\n",
      "Step: 565 of 5001.\n",
      "Step: 566 of 5001.\n",
      "Step: 567 of 5001.\n",
      "Step: 568 of 5001.\n",
      "Step: 569 of 5001.\n",
      "Step: 570 of 5001.\n",
      "Generator model loss: 1.2252089977264404.\n",
      "Discriminator model loss real: 0.9956120312213897.\n",
      "Discriminator model loss generated: 0.616983699798584.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 571 of 5001.\n",
      "Step: 572 of 5001.\n",
      "Step: 573 of 5001.\n",
      "Step: 574 of 5001.\n",
      "Step: 575 of 5001.\n",
      "Step: 576 of 5001.\n",
      "Step: 577 of 5001.\n",
      "Step: 578 of 5001.\n",
      "Step: 579 of 5001.\n",
      "Step: 580 of 5001.\n",
      "Generator model loss: 1.3758810997009276.\n",
      "Discriminator model loss real: 0.8905972301959991.\n",
      "Discriminator model loss generated: 0.5977968335151672.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 581 of 5001.\n",
      "Step: 582 of 5001.\n",
      "Step: 583 of 5001.\n",
      "Step: 584 of 5001.\n",
      "Step: 585 of 5001.\n",
      "Step: 586 of 5001.\n",
      "Step: 587 of 5001.\n",
      "Step: 588 of 5001.\n",
      "Step: 589 of 5001.\n",
      "Step: 590 of 5001.\n",
      "Generator model loss: 1.3296879291534425.\n",
      "Discriminator model loss real: 0.7792217373847962.\n",
      "Discriminator model loss generated: 0.6050453007221221.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 591 of 5001.\n",
      "Step: 592 of 5001.\n",
      "Step: 593 of 5001.\n",
      "Step: 594 of 5001.\n",
      "Step: 595 of 5001.\n",
      "Step: 596 of 5001.\n",
      "Step: 597 of 5001.\n",
      "Step: 598 of 5001.\n",
      "Step: 599 of 5001.\n",
      "Step: 600 of 5001.\n",
      "Generator model loss: 1.2353153705596924.\n",
      "Discriminator model loss real: 0.8621115058660507.\n",
      "Discriminator model loss generated: 0.5795561254024506.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 601 of 5001.\n",
      "Step: 602 of 5001.\n",
      "Step: 603 of 5001.\n",
      "Step: 604 of 5001.\n",
      "Step: 605 of 5001.\n",
      "Step: 606 of 5001.\n",
      "Step: 607 of 5001.\n",
      "Step: 608 of 5001.\n",
      "Step: 609 of 5001.\n",
      "Step: 610 of 5001.\n",
      "Generator model loss: 1.1434629440307618.\n",
      "Discriminator model loss real: 0.8428657352924347.\n",
      "Discriminator model loss generated: 0.6142818868160248.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 611 of 5001.\n",
      "Step: 612 of 5001.\n",
      "Step: 613 of 5001.\n",
      "Step: 614 of 5001.\n",
      "Step: 615 of 5001.\n",
      "Step: 616 of 5001.\n",
      "Step: 617 of 5001.\n",
      "Step: 618 of 5001.\n",
      "Step: 619 of 5001.\n",
      "Step: 620 of 5001.\n",
      "Generator model loss: 1.2040990948677064.\n",
      "Discriminator model loss real: 0.7542449474334717.\n",
      "Discriminator model loss generated: 0.595058274269104.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 621 of 5001.\n",
      "Step: 622 of 5001.\n",
      "Step: 623 of 5001.\n",
      "Step: 624 of 5001.\n",
      "Step: 625 of 5001.\n",
      "Step: 626 of 5001.\n",
      "Step: 627 of 5001.\n",
      "Step: 628 of 5001.\n",
      "Step: 629 of 5001.\n",
      "Step: 630 of 5001.\n",
      "Generator model loss: 1.3109037160873414.\n",
      "Discriminator model loss real: 0.8700114727020264.\n",
      "Discriminator model loss generated: 0.6046301603317261.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 631 of 5001.\n",
      "Step: 632 of 5001.\n",
      "Step: 633 of 5001.\n",
      "Step: 634 of 5001.\n",
      "Step: 635 of 5001.\n",
      "Step: 636 of 5001.\n",
      "Step: 637 of 5001.\n",
      "Step: 638 of 5001.\n",
      "Step: 639 of 5001.\n",
      "Step: 640 of 5001.\n",
      "Generator model loss: 1.242259681224823.\n",
      "Discriminator model loss real: 0.7714314341545105.\n",
      "Discriminator model loss generated: 0.6149040400981903.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 641 of 5001.\n",
      "Step: 642 of 5001.\n",
      "Step: 643 of 5001.\n",
      "Step: 644 of 5001.\n",
      "Step: 645 of 5001.\n",
      "Step: 646 of 5001.\n",
      "Step: 647 of 5001.\n",
      "Step: 648 of 5001.\n",
      "Step: 649 of 5001.\n",
      "Step: 650 of 5001.\n",
      "Generator model loss: 1.1693737268447877.\n",
      "Discriminator model loss real: 0.861379599571228.\n",
      "Discriminator model loss generated: 0.5687549948692322.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 651 of 5001.\n",
      "Step: 652 of 5001.\n",
      "Step: 653 of 5001.\n",
      "Step: 654 of 5001.\n",
      "Step: 655 of 5001.\n",
      "Step: 656 of 5001.\n",
      "Step: 657 of 5001.\n",
      "Step: 658 of 5001.\n",
      "Step: 659 of 5001.\n",
      "Step: 660 of 5001.\n",
      "Generator model loss: 1.1799393892288208.\n",
      "Discriminator model loss real: 0.8042820572853089.\n",
      "Discriminator model loss generated: 0.5862389922142028.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 661 of 5001.\n",
      "Step: 662 of 5001.\n",
      "Step: 663 of 5001.\n",
      "Step: 664 of 5001.\n",
      "Step: 665 of 5001.\n",
      "Step: 666 of 5001.\n",
      "Step: 667 of 5001.\n",
      "Step: 668 of 5001.\n",
      "Step: 669 of 5001.\n",
      "Step: 670 of 5001.\n",
      "Generator model loss: 1.2557868838310242.\n",
      "Discriminator model loss real: 0.7965854376554489.\n",
      "Discriminator model loss generated: 0.595448237657547.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 671 of 5001.\n",
      "Step: 672 of 5001.\n",
      "Step: 673 of 5001.\n",
      "Step: 674 of 5001.\n",
      "Step: 675 of 5001.\n",
      "Step: 676 of 5001.\n",
      "Step: 677 of 5001.\n",
      "Step: 678 of 5001.\n",
      "Step: 679 of 5001.\n",
      "Step: 680 of 5001.\n",
      "Generator model loss: 1.150934648513794.\n",
      "Discriminator model loss real: 0.794937688112259.\n",
      "Discriminator model loss generated: 0.5812336146831513.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 681 of 5001.\n",
      "Step: 682 of 5001.\n",
      "Step: 683 of 5001.\n",
      "Step: 684 of 5001.\n",
      "Step: 685 of 5001.\n",
      "Step: 686 of 5001.\n",
      "Step: 687 of 5001.\n",
      "Step: 688 of 5001.\n",
      "Step: 689 of 5001.\n",
      "Step: 690 of 5001.\n",
      "Generator model loss: 1.1848175644874572.\n",
      "Discriminator model loss real: 0.7756800055503845.\n",
      "Discriminator model loss generated: 0.5736667394638062.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 691 of 5001.\n",
      "Step: 692 of 5001.\n",
      "Step: 693 of 5001.\n",
      "Step: 694 of 5001.\n",
      "Step: 695 of 5001.\n",
      "Step: 696 of 5001.\n",
      "Step: 697 of 5001.\n",
      "Step: 698 of 5001.\n",
      "Step: 699 of 5001.\n",
      "Step: 700 of 5001.\n",
      "Generator model loss: 1.35236257314682.\n",
      "Discriminator model loss real: 0.8779567390680313.\n",
      "Discriminator model loss generated: 0.6147270858287811.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 701 of 5001.\n",
      "Step: 702 of 5001.\n",
      "Step: 703 of 5001.\n",
      "Step: 704 of 5001.\n",
      "Step: 705 of 5001.\n",
      "Step: 706 of 5001.\n",
      "Step: 707 of 5001.\n",
      "Step: 708 of 5001.\n",
      "Step: 709 of 5001.\n",
      "Step: 710 of 5001.\n",
      "Generator model loss: 1.181366240978241.\n",
      "Discriminator model loss real: 0.7713613033294677.\n",
      "Discriminator model loss generated: 0.588370817899704.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 711 of 5001.\n",
      "Step: 712 of 5001.\n",
      "Step: 713 of 5001.\n",
      "Step: 714 of 5001.\n",
      "Step: 715 of 5001.\n",
      "Step: 716 of 5001.\n",
      "Step: 717 of 5001.\n",
      "Step: 718 of 5001.\n",
      "Step: 719 of 5001.\n",
      "Step: 720 of 5001.\n",
      "Generator model loss: 1.275067889690399.\n",
      "Discriminator model loss real: 0.7995781689882279.\n",
      "Discriminator model loss generated: 0.5693888783454895.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 721 of 5001.\n",
      "Step: 722 of 5001.\n",
      "Step: 723 of 5001.\n",
      "Step: 724 of 5001.\n",
      "Step: 725 of 5001.\n",
      "Step: 726 of 5001.\n",
      "Step: 727 of 5001.\n",
      "Step: 728 of 5001.\n",
      "Step: 729 of 5001.\n",
      "Step: 730 of 5001.\n",
      "Generator model loss: 1.2473361015319824.\n",
      "Discriminator model loss real: 0.7841748028993607.\n",
      "Discriminator model loss generated: 0.5869709491729737.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 731 of 5001.\n",
      "Step: 732 of 5001.\n",
      "Step: 733 of 5001.\n",
      "Step: 734 of 5001.\n",
      "Step: 735 of 5001.\n",
      "Step: 736 of 5001.\n",
      "Step: 737 of 5001.\n",
      "Step: 738 of 5001.\n",
      "Step: 739 of 5001.\n",
      "Step: 740 of 5001.\n",
      "Generator model loss: 1.260054874420166.\n",
      "Discriminator model loss real: 0.8396052241325378.\n",
      "Discriminator model loss generated: 0.5621005475521088.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 741 of 5001.\n",
      "Step: 742 of 5001.\n",
      "Step: 743 of 5001.\n",
      "Step: 744 of 5001.\n",
      "Step: 745 of 5001.\n",
      "Step: 746 of 5001.\n",
      "Step: 747 of 5001.\n",
      "Step: 748 of 5001.\n",
      "Step: 749 of 5001.\n",
      "Step: 750 of 5001.\n",
      "Generator model loss: 1.1667416572570801.\n",
      "Discriminator model loss real: 0.7411907643079758.\n",
      "Discriminator model loss generated: 0.5490242958068847.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 751 of 5001.\n",
      "Step: 752 of 5001.\n",
      "Step: 753 of 5001.\n",
      "Step: 754 of 5001.\n",
      "Step: 755 of 5001.\n",
      "Step: 756 of 5001.\n",
      "Step: 757 of 5001.\n",
      "Step: 758 of 5001.\n",
      "Step: 759 of 5001.\n",
      "Step: 760 of 5001.\n",
      "Generator model loss: 1.1997060537338258.\n",
      "Discriminator model loss real: 0.788606783747673.\n",
      "Discriminator model loss generated: 0.570592737197876.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 761 of 5001.\n",
      "Step: 762 of 5001.\n",
      "Step: 763 of 5001.\n",
      "Step: 764 of 5001.\n",
      "Step: 765 of 5001.\n",
      "Step: 766 of 5001.\n",
      "Step: 767 of 5001.\n",
      "Step: 768 of 5001.\n",
      "Step: 769 of 5001.\n",
      "Step: 770 of 5001.\n",
      "Generator model loss: 1.1580541133880615.\n",
      "Discriminator model loss real: 0.7008591368794441.\n",
      "Discriminator model loss generated: 0.5835292637348175.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 771 of 5001.\n",
      "Step: 772 of 5001.\n",
      "Step: 773 of 5001.\n",
      "Step: 774 of 5001.\n",
      "Step: 775 of 5001.\n",
      "Step: 776 of 5001.\n",
      "Step: 777 of 5001.\n",
      "Step: 778 of 5001.\n",
      "Step: 779 of 5001.\n",
      "Step: 780 of 5001.\n",
      "Generator model loss: 1.2280947327613831.\n",
      "Discriminator model loss real: 0.800895094871521.\n",
      "Discriminator model loss generated: 0.5699767172336578.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 781 of 5001.\n",
      "Step: 782 of 5001.\n",
      "Step: 783 of 5001.\n",
      "Step: 784 of 5001.\n",
      "Step: 785 of 5001.\n",
      "Step: 786 of 5001.\n",
      "Step: 787 of 5001.\n",
      "Step: 788 of 5001.\n",
      "Step: 789 of 5001.\n",
      "Step: 790 of 5001.\n",
      "Generator model loss: 1.18171888589859.\n",
      "Discriminator model loss real: 0.7818666309118271.\n",
      "Discriminator model loss generated: 0.5403624773025513.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 791 of 5001.\n",
      "Step: 792 of 5001.\n",
      "Step: 793 of 5001.\n",
      "Step: 794 of 5001.\n",
      "Step: 795 of 5001.\n",
      "Step: 796 of 5001.\n",
      "Step: 797 of 5001.\n",
      "Step: 798 of 5001.\n",
      "Step: 799 of 5001.\n",
      "Step: 800 of 5001.\n",
      "Generator model loss: 1.2310809373855591.\n",
      "Discriminator model loss real: 0.8560153067111969.\n",
      "Discriminator model loss generated: 0.5786212742328644.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 801 of 5001.\n",
      "Step: 802 of 5001.\n",
      "Step: 803 of 5001.\n",
      "Step: 804 of 5001.\n",
      "Step: 805 of 5001.\n",
      "Step: 806 of 5001.\n",
      "Step: 807 of 5001.\n",
      "Step: 808 of 5001.\n",
      "Step: 809 of 5001.\n",
      "Step: 810 of 5001.\n",
      "Generator model loss: 1.2058449387550354.\n",
      "Discriminator model loss real: 0.7623139142990112.\n",
      "Discriminator model loss generated: 0.5845565438270569.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 811 of 5001.\n",
      "Step: 812 of 5001.\n",
      "Step: 813 of 5001.\n",
      "Step: 814 of 5001.\n",
      "Step: 815 of 5001.\n",
      "Step: 816 of 5001.\n",
      "Step: 817 of 5001.\n",
      "Step: 818 of 5001.\n",
      "Step: 819 of 5001.\n",
      "Step: 820 of 5001.\n",
      "Generator model loss: 1.2090954542160035.\n",
      "Discriminator model loss real: 0.784952612221241.\n",
      "Discriminator model loss generated: 0.6256582319736481.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 821 of 5001.\n",
      "Step: 822 of 5001.\n",
      "Step: 823 of 5001.\n",
      "Step: 824 of 5001.\n",
      "Step: 825 of 5001.\n",
      "Step: 826 of 5001.\n",
      "Step: 827 of 5001.\n",
      "Step: 828 of 5001.\n",
      "Step: 829 of 5001.\n",
      "Step: 830 of 5001.\n",
      "Generator model loss: 1.2517743587493897.\n",
      "Discriminator model loss real: 0.7977803230285645.\n",
      "Discriminator model loss generated: 0.5962632238864899.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 831 of 5001.\n",
      "Step: 832 of 5001.\n",
      "Step: 833 of 5001.\n",
      "Step: 834 of 5001.\n",
      "Step: 835 of 5001.\n",
      "Step: 836 of 5001.\n",
      "Step: 837 of 5001.\n",
      "Step: 838 of 5001.\n",
      "Step: 839 of 5001.\n",
      "Step: 840 of 5001.\n",
      "Generator model loss: 1.226382803916931.\n",
      "Discriminator model loss real: 0.7334994733333587.\n",
      "Discriminator model loss generated: 0.5680258989334106.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 841 of 5001.\n",
      "Step: 842 of 5001.\n",
      "Step: 843 of 5001.\n",
      "Step: 844 of 5001.\n",
      "Step: 845 of 5001.\n",
      "Step: 846 of 5001.\n",
      "Step: 847 of 5001.\n",
      "Step: 848 of 5001.\n",
      "Step: 849 of 5001.\n",
      "Step: 850 of 5001.\n",
      "Generator model loss: 1.2162149310112.\n",
      "Discriminator model loss real: 0.7511806517839432.\n",
      "Discriminator model loss generated: 0.6384824931621551.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 851 of 5001.\n",
      "Step: 852 of 5001.\n",
      "Step: 853 of 5001.\n",
      "Step: 854 of 5001.\n",
      "Step: 855 of 5001.\n",
      "Step: 856 of 5001.\n",
      "Step: 857 of 5001.\n",
      "Step: 858 of 5001.\n",
      "Step: 859 of 5001.\n",
      "Step: 860 of 5001.\n",
      "Generator model loss: 1.1965828657150268.\n",
      "Discriminator model loss real: 0.7788806676864624.\n",
      "Discriminator model loss generated: 0.5537431836128235.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 861 of 5001.\n",
      "Step: 862 of 5001.\n",
      "Step: 863 of 5001.\n",
      "Step: 864 of 5001.\n",
      "Step: 865 of 5001.\n",
      "Step: 866 of 5001.\n",
      "Step: 867 of 5001.\n",
      "Step: 868 of 5001.\n",
      "Step: 869 of 5001.\n",
      "Step: 870 of 5001.\n",
      "Generator model loss: 1.2109941124916077.\n",
      "Discriminator model loss real: 0.7660863101482391.\n",
      "Discriminator model loss generated: 0.6121034502983094.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 871 of 5001.\n",
      "Step: 872 of 5001.\n",
      "Step: 873 of 5001.\n",
      "Step: 874 of 5001.\n",
      "Step: 875 of 5001.\n",
      "Step: 876 of 5001.\n",
      "Step: 877 of 5001.\n",
      "Step: 878 of 5001.\n",
      "Step: 879 of 5001.\n",
      "Step: 880 of 5001.\n",
      "Generator model loss: 1.245707392692566.\n",
      "Discriminator model loss real: 0.7829805761575699.\n",
      "Discriminator model loss generated: 0.6156104207038879.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 881 of 5001.\n",
      "Step: 882 of 5001.\n",
      "Step: 883 of 5001.\n",
      "Step: 884 of 5001.\n",
      "Step: 885 of 5001.\n",
      "Step: 886 of 5001.\n",
      "Step: 887 of 5001.\n",
      "Step: 888 of 5001.\n",
      "Step: 889 of 5001.\n",
      "Step: 890 of 5001.\n",
      "Generator model loss: 1.2201187491416932.\n",
      "Discriminator model loss real: 0.8078480035066604.\n",
      "Discriminator model loss generated: 0.5740854322910309.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 891 of 5001.\n",
      "Step: 892 of 5001.\n",
      "Step: 893 of 5001.\n",
      "Step: 894 of 5001.\n",
      "Step: 895 of 5001.\n",
      "Step: 896 of 5001.\n",
      "Step: 897 of 5001.\n",
      "Step: 898 of 5001.\n",
      "Step: 899 of 5001.\n",
      "Step: 900 of 5001.\n",
      "Generator model loss: 1.216250205039978.\n",
      "Discriminator model loss real: 0.7269551023840904.\n",
      "Discriminator model loss generated: 0.5267379611730576.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 901 of 5001.\n",
      "Step: 902 of 5001.\n",
      "Step: 903 of 5001.\n",
      "Step: 904 of 5001.\n",
      "Step: 905 of 5001.\n",
      "Step: 906 of 5001.\n",
      "Step: 907 of 5001.\n",
      "Step: 908 of 5001.\n",
      "Step: 909 of 5001.\n",
      "Step: 910 of 5001.\n",
      "Generator model loss: 1.2373343110084534.\n",
      "Discriminator model loss real: 0.7443519622087479.\n",
      "Discriminator model loss generated: 0.6043630957603454.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 911 of 5001.\n",
      "Step: 912 of 5001.\n",
      "Step: 913 of 5001.\n",
      "Step: 914 of 5001.\n",
      "Step: 915 of 5001.\n",
      "Step: 916 of 5001.\n",
      "Step: 917 of 5001.\n",
      "Step: 918 of 5001.\n",
      "Step: 919 of 5001.\n",
      "Step: 920 of 5001.\n",
      "Generator model loss: 1.1786139249801635.\n",
      "Discriminator model loss real: 0.8004480004310608.\n",
      "Discriminator model loss generated: 0.6159316241741181.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 921 of 5001.\n",
      "Step: 922 of 5001.\n",
      "Step: 923 of 5001.\n",
      "Step: 924 of 5001.\n",
      "Step: 925 of 5001.\n",
      "Step: 926 of 5001.\n",
      "Step: 927 of 5001.\n",
      "Step: 928 of 5001.\n",
      "Step: 929 of 5001.\n",
      "Step: 930 of 5001.\n",
      "Generator model loss: 1.2069759130477906.\n",
      "Discriminator model loss real: 0.7677607968449592.\n",
      "Discriminator model loss generated: 0.5455933511257172.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 931 of 5001.\n",
      "Step: 932 of 5001.\n",
      "Step: 933 of 5001.\n",
      "Step: 934 of 5001.\n",
      "Step: 935 of 5001.\n",
      "Step: 936 of 5001.\n",
      "Step: 937 of 5001.\n",
      "Step: 938 of 5001.\n",
      "Step: 939 of 5001.\n",
      "Step: 940 of 5001.\n",
      "Generator model loss: 1.2271888613700868.\n",
      "Discriminator model loss real: 0.8146661162376404.\n",
      "Discriminator model loss generated: 0.5946956038475036.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 941 of 5001.\n",
      "Step: 942 of 5001.\n",
      "Step: 943 of 5001.\n",
      "Step: 944 of 5001.\n",
      "Step: 945 of 5001.\n",
      "Step: 946 of 5001.\n",
      "Step: 947 of 5001.\n",
      "Step: 948 of 5001.\n",
      "Step: 949 of 5001.\n",
      "Step: 950 of 5001.\n",
      "Generator model loss: 1.2441023468971253.\n",
      "Discriminator model loss real: 0.7051908820867538.\n",
      "Discriminator model loss generated: 0.5856484234333038.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 951 of 5001.\n",
      "Step: 952 of 5001.\n",
      "Step: 953 of 5001.\n",
      "Step: 954 of 5001.\n",
      "Step: 955 of 5001.\n",
      "Step: 956 of 5001.\n",
      "Step: 957 of 5001.\n",
      "Step: 958 of 5001.\n",
      "Step: 959 of 5001.\n",
      "Step: 960 of 5001.\n",
      "Generator model loss: 1.2588655710220338.\n",
      "Discriminator model loss real: 0.7285116329789162.\n",
      "Discriminator model loss generated: 0.543932294845581.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 961 of 5001.\n",
      "Step: 962 of 5001.\n",
      "Step: 963 of 5001.\n",
      "Step: 964 of 5001.\n",
      "Step: 965 of 5001.\n",
      "Step: 966 of 5001.\n",
      "Step: 967 of 5001.\n",
      "Step: 968 of 5001.\n",
      "Step: 969 of 5001.\n",
      "Step: 970 of 5001.\n",
      "Generator model loss: 1.2003085136413574.\n",
      "Discriminator model loss real: 0.7846763610839844.\n",
      "Discriminator model loss generated: 0.5534231543540955.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 971 of 5001.\n",
      "Step: 972 of 5001.\n",
      "Step: 973 of 5001.\n",
      "Step: 974 of 5001.\n",
      "Step: 975 of 5001.\n",
      "Step: 976 of 5001.\n",
      "Step: 977 of 5001.\n",
      "Step: 978 of 5001.\n",
      "Step: 979 of 5001.\n",
      "Step: 980 of 5001.\n",
      "Generator model loss: 1.2339849948883057.\n",
      "Discriminator model loss real: 0.734943588078022.\n",
      "Discriminator model loss generated: 0.5711882382631301.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 981 of 5001.\n",
      "Step: 982 of 5001.\n",
      "Step: 983 of 5001.\n",
      "Step: 984 of 5001.\n",
      "Step: 985 of 5001.\n",
      "Step: 986 of 5001.\n",
      "Step: 987 of 5001.\n",
      "Step: 988 of 5001.\n",
      "Step: 989 of 5001.\n",
      "Step: 990 of 5001.\n",
      "Generator model loss: 1.2114097118377685.\n",
      "Discriminator model loss real: 0.6669351130723953.\n",
      "Discriminator model loss generated: 0.5726750016212463.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 991 of 5001.\n",
      "Step: 992 of 5001.\n",
      "Step: 993 of 5001.\n",
      "Step: 994 of 5001.\n",
      "Step: 995 of 5001.\n",
      "Step: 996 of 5001.\n",
      "Step: 997 of 5001.\n",
      "Step: 998 of 5001.\n",
      "Step: 999 of 5001.\n",
      "Step: 1000 of 5001.\n",
      "Generator model loss: 1.2423123598098755.\n",
      "Discriminator model loss real: 0.8066550970077515.\n",
      "Discriminator model loss generated: 0.5617850840091705.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1001 of 5001.\n",
      "Step: 1002 of 5001.\n",
      "Step: 1003 of 5001.\n",
      "Step: 1004 of 5001.\n",
      "Step: 1005 of 5001.\n",
      "Step: 1006 of 5001.\n",
      "Step: 1007 of 5001.\n",
      "Step: 1008 of 5001.\n",
      "Step: 1009 of 5001.\n",
      "Step: 1010 of 5001.\n",
      "Generator model loss: 1.2306500196456909.\n",
      "Discriminator model loss real: 0.785666087269783.\n",
      "Discriminator model loss generated: 0.5578614354133606.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1011 of 5001.\n",
      "Step: 1012 of 5001.\n",
      "Step: 1013 of 5001.\n",
      "Step: 1014 of 5001.\n",
      "Step: 1015 of 5001.\n",
      "Step: 1016 of 5001.\n",
      "Step: 1017 of 5001.\n",
      "Step: 1018 of 5001.\n",
      "Step: 1019 of 5001.\n",
      "Step: 1020 of 5001.\n",
      "Generator model loss: 1.2129668831825255.\n",
      "Discriminator model loss real: 0.772013321518898.\n",
      "Discriminator model loss generated: 0.5952347874641418.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1021 of 5001.\n",
      "Step: 1022 of 5001.\n",
      "Step: 1023 of 5001.\n",
      "Step: 1024 of 5001.\n",
      "Step: 1025 of 5001.\n",
      "Step: 1026 of 5001.\n",
      "Step: 1027 of 5001.\n",
      "Step: 1028 of 5001.\n",
      "Step: 1029 of 5001.\n",
      "Step: 1030 of 5001.\n",
      "Generator model loss: 1.2122474193572998.\n",
      "Discriminator model loss real: 0.7962068736553192.\n",
      "Discriminator model loss generated: 0.5513025492429733.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1031 of 5001.\n",
      "Step: 1032 of 5001.\n",
      "Step: 1033 of 5001.\n",
      "Step: 1034 of 5001.\n",
      "Step: 1035 of 5001.\n",
      "Step: 1036 of 5001.\n",
      "Step: 1037 of 5001.\n",
      "Step: 1038 of 5001.\n",
      "Step: 1039 of 5001.\n",
      "Step: 1040 of 5001.\n",
      "Generator model loss: 1.2214115858078003.\n",
      "Discriminator model loss real: 0.8236649513244629.\n",
      "Discriminator model loss generated: 0.5818605244159698.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1041 of 5001.\n",
      "Step: 1042 of 5001.\n",
      "Step: 1043 of 5001.\n",
      "Step: 1044 of 5001.\n",
      "Step: 1045 of 5001.\n",
      "Step: 1046 of 5001.\n",
      "Step: 1047 of 5001.\n",
      "Step: 1048 of 5001.\n",
      "Step: 1049 of 5001.\n",
      "Step: 1050 of 5001.\n",
      "Generator model loss: 1.24940584897995.\n",
      "Discriminator model loss real: 0.7129390716552735.\n",
      "Discriminator model loss generated: 0.5558554291725158.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1051 of 5001.\n",
      "Step: 1052 of 5001.\n",
      "Step: 1053 of 5001.\n",
      "Step: 1054 of 5001.\n",
      "Step: 1055 of 5001.\n",
      "Step: 1056 of 5001.\n",
      "Step: 1057 of 5001.\n",
      "Step: 1058 of 5001.\n",
      "Step: 1059 of 5001.\n",
      "Step: 1060 of 5001.\n",
      "Generator model loss: 1.2076027631759643.\n",
      "Discriminator model loss real: 0.7554517835378647.\n",
      "Discriminator model loss generated: 0.6330960512161254.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1061 of 5001.\n",
      "Step: 1062 of 5001.\n",
      "Step: 1063 of 5001.\n",
      "Step: 1064 of 5001.\n",
      "Step: 1065 of 5001.\n",
      "Step: 1066 of 5001.\n",
      "Step: 1067 of 5001.\n",
      "Step: 1068 of 5001.\n",
      "Step: 1069 of 5001.\n",
      "Step: 1070 of 5001.\n",
      "Generator model loss: 1.2576997399330139.\n",
      "Discriminator model loss real: 0.8246168449521065.\n",
      "Discriminator model loss generated: 0.5584624767303467.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1071 of 5001.\n",
      "Step: 1072 of 5001.\n",
      "Step: 1073 of 5001.\n",
      "Step: 1074 of 5001.\n",
      "Step: 1075 of 5001.\n",
      "Step: 1076 of 5001.\n",
      "Step: 1077 of 5001.\n",
      "Step: 1078 of 5001.\n",
      "Step: 1079 of 5001.\n",
      "Step: 1080 of 5001.\n",
      "Generator model loss: 1.2446807384490968.\n",
      "Discriminator model loss real: 0.7263029217720032.\n",
      "Discriminator model loss generated: 0.5688911318778992.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1081 of 5001.\n",
      "Step: 1082 of 5001.\n",
      "Step: 1083 of 5001.\n",
      "Step: 1084 of 5001.\n",
      "Step: 1085 of 5001.\n",
      "Step: 1086 of 5001.\n",
      "Step: 1087 of 5001.\n",
      "Step: 1088 of 5001.\n",
      "Step: 1089 of 5001.\n",
      "Step: 1090 of 5001.\n",
      "Generator model loss: 1.2820711493492127.\n",
      "Discriminator model loss real: 0.7633002281188965.\n",
      "Discriminator model loss generated: 0.5747868627309799.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1091 of 5001.\n",
      "Step: 1092 of 5001.\n",
      "Step: 1093 of 5001.\n",
      "Step: 1094 of 5001.\n",
      "Step: 1095 of 5001.\n",
      "Step: 1096 of 5001.\n",
      "Step: 1097 of 5001.\n",
      "Step: 1098 of 5001.\n",
      "Step: 1099 of 5001.\n",
      "Step: 1100 of 5001.\n",
      "Generator model loss: 1.2548494219779969.\n",
      "Discriminator model loss real: 0.7761189579963684.\n",
      "Discriminator model loss generated: 0.6123612105846405.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1101 of 5001.\n",
      "Step: 1102 of 5001.\n",
      "Step: 1103 of 5001.\n",
      "Step: 1104 of 5001.\n",
      "Step: 1105 of 5001.\n",
      "Step: 1106 of 5001.\n",
      "Step: 1107 of 5001.\n",
      "Step: 1108 of 5001.\n",
      "Step: 1109 of 5001.\n",
      "Step: 1110 of 5001.\n",
      "Generator model loss: 1.227248525619507.\n",
      "Discriminator model loss real: 0.791502732038498.\n",
      "Discriminator model loss generated: 0.6203557550907135.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1111 of 5001.\n",
      "Step: 1112 of 5001.\n",
      "Step: 1113 of 5001.\n",
      "Step: 1114 of 5001.\n",
      "Step: 1115 of 5001.\n",
      "Step: 1116 of 5001.\n",
      "Step: 1117 of 5001.\n",
      "Step: 1118 of 5001.\n",
      "Step: 1119 of 5001.\n",
      "Step: 1120 of 5001.\n",
      "Generator model loss: 1.2431315064430237.\n",
      "Discriminator model loss real: 0.7372148543596267.\n",
      "Discriminator model loss generated: 0.6214570879936219.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1121 of 5001.\n",
      "Step: 1122 of 5001.\n",
      "Step: 1123 of 5001.\n",
      "Step: 1124 of 5001.\n",
      "Step: 1125 of 5001.\n",
      "Step: 1126 of 5001.\n",
      "Step: 1127 of 5001.\n",
      "Step: 1128 of 5001.\n",
      "Step: 1129 of 5001.\n",
      "Step: 1130 of 5001.\n",
      "Generator model loss: 1.2629210114479066.\n",
      "Discriminator model loss real: 0.753848060965538.\n",
      "Discriminator model loss generated: 0.6104235172271728.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1131 of 5001.\n",
      "Step: 1132 of 5001.\n",
      "Step: 1133 of 5001.\n",
      "Step: 1134 of 5001.\n",
      "Step: 1135 of 5001.\n",
      "Step: 1136 of 5001.\n",
      "Step: 1137 of 5001.\n",
      "Step: 1138 of 5001.\n",
      "Step: 1139 of 5001.\n",
      "Step: 1140 of 5001.\n",
      "Generator model loss: 1.2468639135360717.\n",
      "Discriminator model loss real: 0.7722464665770531.\n",
      "Discriminator model loss generated: 0.5913680016994476.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1141 of 5001.\n",
      "Step: 1142 of 5001.\n",
      "Step: 1143 of 5001.\n",
      "Step: 1144 of 5001.\n",
      "Step: 1145 of 5001.\n",
      "Step: 1146 of 5001.\n",
      "Step: 1147 of 5001.\n",
      "Step: 1148 of 5001.\n",
      "Step: 1149 of 5001.\n",
      "Step: 1150 of 5001.\n",
      "Generator model loss: 1.2477843642234803.\n",
      "Discriminator model loss real: 0.7997745111584663.\n",
      "Discriminator model loss generated: 0.6149907588958741.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1151 of 5001.\n",
      "Step: 1152 of 5001.\n",
      "Step: 1153 of 5001.\n",
      "Step: 1154 of 5001.\n",
      "Step: 1155 of 5001.\n",
      "Step: 1156 of 5001.\n",
      "Step: 1157 of 5001.\n",
      "Step: 1158 of 5001.\n",
      "Step: 1159 of 5001.\n",
      "Step: 1160 of 5001.\n",
      "Generator model loss: 1.239306664466858.\n",
      "Discriminator model loss real: 0.7491521596908569.\n",
      "Discriminator model loss generated: 0.5985261738300324.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1161 of 5001.\n",
      "Step: 1162 of 5001.\n",
      "Step: 1163 of 5001.\n",
      "Step: 1164 of 5001.\n",
      "Step: 1165 of 5001.\n",
      "Step: 1166 of 5001.\n",
      "Step: 1167 of 5001.\n",
      "Step: 1168 of 5001.\n",
      "Step: 1169 of 5001.\n",
      "Step: 1170 of 5001.\n",
      "Generator model loss: 1.261784565448761.\n",
      "Discriminator model loss real: 0.7318613097071648.\n",
      "Discriminator model loss generated: 0.6595077037811279.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1171 of 5001.\n",
      "Step: 1172 of 5001.\n",
      "Step: 1173 of 5001.\n",
      "Step: 1174 of 5001.\n",
      "Step: 1175 of 5001.\n",
      "Step: 1176 of 5001.\n",
      "Step: 1177 of 5001.\n",
      "Step: 1178 of 5001.\n",
      "Step: 1179 of 5001.\n",
      "Step: 1180 of 5001.\n",
      "Generator model loss: 1.240651249885559.\n",
      "Discriminator model loss real: 0.7264922946691513.\n",
      "Discriminator model loss generated: 0.6877280056476593.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1181 of 5001.\n",
      "Step: 1182 of 5001.\n",
      "Step: 1183 of 5001.\n",
      "Step: 1184 of 5001.\n",
      "Step: 1185 of 5001.\n",
      "Step: 1186 of 5001.\n",
      "Step: 1187 of 5001.\n",
      "Step: 1188 of 5001.\n",
      "Step: 1189 of 5001.\n",
      "Step: 1190 of 5001.\n",
      "Generator model loss: 1.2624950051307677.\n",
      "Discriminator model loss real: 0.8139522492885589.\n",
      "Discriminator model loss generated: 0.5867141366004944.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1191 of 5001.\n",
      "Step: 1192 of 5001.\n",
      "Step: 1193 of 5001.\n",
      "Step: 1194 of 5001.\n",
      "Step: 1195 of 5001.\n",
      "Step: 1196 of 5001.\n",
      "Step: 1197 of 5001.\n",
      "Step: 1198 of 5001.\n",
      "Step: 1199 of 5001.\n",
      "Step: 1200 of 5001.\n",
      "Generator model loss: 1.2514092445373535.\n",
      "Discriminator model loss real: 0.7674031093716621.\n",
      "Discriminator model loss generated: 0.7118603706359863.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1201 of 5001.\n",
      "Step: 1202 of 5001.\n",
      "Step: 1203 of 5001.\n",
      "Step: 1204 of 5001.\n",
      "Step: 1205 of 5001.\n",
      "Step: 1206 of 5001.\n",
      "Step: 1207 of 5001.\n",
      "Step: 1208 of 5001.\n",
      "Step: 1209 of 5001.\n",
      "Step: 1210 of 5001.\n",
      "Generator model loss: 1.2822860598564148.\n",
      "Discriminator model loss real: 0.7906653940677643.\n",
      "Discriminator model loss generated: 0.6081641376018524.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1211 of 5001.\n",
      "Step: 1212 of 5001.\n",
      "Step: 1213 of 5001.\n",
      "Step: 1214 of 5001.\n",
      "Step: 1215 of 5001.\n",
      "Step: 1216 of 5001.\n",
      "Step: 1217 of 5001.\n",
      "Step: 1218 of 5001.\n",
      "Step: 1219 of 5001.\n",
      "Step: 1220 of 5001.\n",
      "Generator model loss: 1.2531951665878296.\n",
      "Discriminator model loss real: 0.8051935344934463.\n",
      "Discriminator model loss generated: 0.5828785479068757.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1221 of 5001.\n",
      "Step: 1222 of 5001.\n",
      "Step: 1223 of 5001.\n",
      "Step: 1224 of 5001.\n",
      "Step: 1225 of 5001.\n",
      "Step: 1226 of 5001.\n",
      "Step: 1227 of 5001.\n",
      "Step: 1228 of 5001.\n",
      "Step: 1229 of 5001.\n",
      "Step: 1230 of 5001.\n",
      "Generator model loss: 1.217890739440918.\n",
      "Discriminator model loss real: 0.7372498244047165.\n",
      "Discriminator model loss generated: 0.6788099467754364.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1231 of 5001.\n",
      "Step: 1232 of 5001.\n",
      "Step: 1233 of 5001.\n",
      "Step: 1234 of 5001.\n",
      "Step: 1235 of 5001.\n",
      "Step: 1236 of 5001.\n",
      "Step: 1237 of 5001.\n",
      "Step: 1238 of 5001.\n",
      "Step: 1239 of 5001.\n",
      "Step: 1240 of 5001.\n",
      "Generator model loss: 1.28509681224823.\n",
      "Discriminator model loss real: 0.6473916590213775.\n",
      "Discriminator model loss generated: 0.5655897319316864.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1241 of 5001.\n",
      "Step: 1242 of 5001.\n",
      "Step: 1243 of 5001.\n",
      "Step: 1244 of 5001.\n",
      "Step: 1245 of 5001.\n",
      "Step: 1246 of 5001.\n",
      "Step: 1247 of 5001.\n",
      "Step: 1248 of 5001.\n",
      "Step: 1249 of 5001.\n",
      "Step: 1250 of 5001.\n",
      "Generator model loss: 1.2525595903396607.\n",
      "Discriminator model loss real: 0.7345114558935165.\n",
      "Discriminator model loss generated: 0.575889402627945.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1251 of 5001.\n",
      "Step: 1252 of 5001.\n",
      "Step: 1253 of 5001.\n",
      "Step: 1254 of 5001.\n",
      "Step: 1255 of 5001.\n",
      "Step: 1256 of 5001.\n",
      "Step: 1257 of 5001.\n",
      "Step: 1258 of 5001.\n",
      "Step: 1259 of 5001.\n",
      "Step: 1260 of 5001.\n",
      "Generator model loss: 1.2605882287025452.\n",
      "Discriminator model loss real: 0.7666913628578186.\n",
      "Discriminator model loss generated: 0.5900226175785065.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1261 of 5001.\n",
      "Step: 1262 of 5001.\n",
      "Step: 1263 of 5001.\n",
      "Step: 1264 of 5001.\n",
      "Step: 1265 of 5001.\n",
      "Step: 1266 of 5001.\n",
      "Step: 1267 of 5001.\n",
      "Step: 1268 of 5001.\n",
      "Step: 1269 of 5001.\n",
      "Step: 1270 of 5001.\n",
      "Generator model loss: 1.2424269199371338.\n",
      "Discriminator model loss real: 0.7169522285461426.\n",
      "Discriminator model loss generated: 0.6466861724853515.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1271 of 5001.\n",
      "Step: 1272 of 5001.\n",
      "Step: 1273 of 5001.\n",
      "Step: 1274 of 5001.\n",
      "Step: 1275 of 5001.\n",
      "Step: 1276 of 5001.\n",
      "Step: 1277 of 5001.\n",
      "Step: 1278 of 5001.\n",
      "Step: 1279 of 5001.\n",
      "Step: 1280 of 5001.\n",
      "Generator model loss: 1.2827567338943482.\n",
      "Discriminator model loss real: 0.7987571686506272.\n",
      "Discriminator model loss generated: 0.6301704466342926.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1281 of 5001.\n",
      "Step: 1282 of 5001.\n",
      "Step: 1283 of 5001.\n",
      "Step: 1284 of 5001.\n",
      "Step: 1285 of 5001.\n",
      "Step: 1286 of 5001.\n",
      "Step: 1287 of 5001.\n",
      "Step: 1288 of 5001.\n",
      "Step: 1289 of 5001.\n",
      "Step: 1290 of 5001.\n",
      "Generator model loss: 1.2161685466766357.\n",
      "Discriminator model loss real: 0.7861693665385246.\n",
      "Discriminator model loss generated: 0.6611526012420654.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1291 of 5001.\n",
      "Step: 1292 of 5001.\n",
      "Step: 1293 of 5001.\n",
      "Step: 1294 of 5001.\n",
      "Step: 1295 of 5001.\n",
      "Step: 1296 of 5001.\n",
      "Step: 1297 of 5001.\n",
      "Step: 1298 of 5001.\n",
      "Step: 1299 of 5001.\n",
      "Step: 1300 of 5001.\n",
      "Generator model loss: 1.2457934617996216.\n",
      "Discriminator model loss real: 0.720752714574337.\n",
      "Discriminator model loss generated: 0.6127796113491059.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1301 of 5001.\n",
      "Step: 1302 of 5001.\n",
      "Step: 1303 of 5001.\n",
      "Step: 1304 of 5001.\n",
      "Step: 1305 of 5001.\n",
      "Step: 1306 of 5001.\n",
      "Step: 1307 of 5001.\n",
      "Step: 1308 of 5001.\n",
      "Step: 1309 of 5001.\n",
      "Step: 1310 of 5001.\n",
      "Generator model loss: 1.2655485153198243.\n",
      "Discriminator model loss real: 0.8075091660022735.\n",
      "Discriminator model loss generated: 0.5546249508857727.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1311 of 5001.\n",
      "Step: 1312 of 5001.\n",
      "Step: 1313 of 5001.\n",
      "Step: 1314 of 5001.\n",
      "Step: 1315 of 5001.\n",
      "Step: 1316 of 5001.\n",
      "Step: 1317 of 5001.\n",
      "Step: 1318 of 5001.\n",
      "Step: 1319 of 5001.\n",
      "Step: 1320 of 5001.\n",
      "Generator model loss: 1.2606563448905945.\n",
      "Discriminator model loss real: 0.7862697660923004.\n",
      "Discriminator model loss generated: 0.5802899539470673.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1321 of 5001.\n",
      "Step: 1322 of 5001.\n",
      "Step: 1323 of 5001.\n",
      "Step: 1324 of 5001.\n",
      "Step: 1325 of 5001.\n",
      "Step: 1326 of 5001.\n",
      "Step: 1327 of 5001.\n",
      "Step: 1328 of 5001.\n",
      "Step: 1329 of 5001.\n",
      "Step: 1330 of 5001.\n",
      "Generator model loss: 1.2902042269706726.\n",
      "Discriminator model loss real: 0.7410168707370758.\n",
      "Discriminator model loss generated: 0.72766153216362.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1331 of 5001.\n",
      "Step: 1332 of 5001.\n",
      "Step: 1333 of 5001.\n",
      "Step: 1334 of 5001.\n",
      "Step: 1335 of 5001.\n",
      "Step: 1336 of 5001.\n",
      "Step: 1337 of 5001.\n",
      "Step: 1338 of 5001.\n",
      "Step: 1339 of 5001.\n",
      "Step: 1340 of 5001.\n",
      "Generator model loss: 1.234582507610321.\n",
      "Discriminator model loss real: 0.8190670609474182.\n",
      "Discriminator model loss generated: 0.6125074326992035.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1341 of 5001.\n",
      "Step: 1342 of 5001.\n",
      "Step: 1343 of 5001.\n",
      "Step: 1344 of 5001.\n",
      "Step: 1345 of 5001.\n",
      "Step: 1346 of 5001.\n",
      "Step: 1347 of 5001.\n",
      "Step: 1348 of 5001.\n",
      "Step: 1349 of 5001.\n",
      "Step: 1350 of 5001.\n",
      "Generator model loss: 1.2338390827178956.\n",
      "Discriminator model loss real: 0.818454971909523.\n",
      "Discriminator model loss generated: 0.6248828828334808.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1351 of 5001.\n",
      "Step: 1352 of 5001.\n",
      "Step: 1353 of 5001.\n",
      "Step: 1354 of 5001.\n",
      "Step: 1355 of 5001.\n",
      "Step: 1356 of 5001.\n",
      "Step: 1357 of 5001.\n",
      "Step: 1358 of 5001.\n",
      "Step: 1359 of 5001.\n",
      "Step: 1360 of 5001.\n",
      "Generator model loss: 1.2031400561332704.\n",
      "Discriminator model loss real: 0.6904281169176102.\n",
      "Discriminator model loss generated: 0.6766704082489013.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1361 of 5001.\n",
      "Step: 1362 of 5001.\n",
      "Step: 1363 of 5001.\n",
      "Step: 1364 of 5001.\n",
      "Step: 1365 of 5001.\n",
      "Step: 1366 of 5001.\n",
      "Step: 1367 of 5001.\n",
      "Step: 1368 of 5001.\n",
      "Step: 1369 of 5001.\n",
      "Step: 1370 of 5001.\n",
      "Generator model loss: 1.247999918460846.\n",
      "Discriminator model loss real: 0.773691838979721.\n",
      "Discriminator model loss generated: 0.6756870329380036.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1371 of 5001.\n",
      "Step: 1372 of 5001.\n",
      "Step: 1373 of 5001.\n",
      "Step: 1374 of 5001.\n",
      "Step: 1375 of 5001.\n",
      "Step: 1376 of 5001.\n",
      "Step: 1377 of 5001.\n",
      "Step: 1378 of 5001.\n",
      "Step: 1379 of 5001.\n",
      "Step: 1380 of 5001.\n",
      "Generator model loss: 1.2094222784042359.\n",
      "Discriminator model loss real: 0.755834424495697.\n",
      "Discriminator model loss generated: 0.6398491621017456.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1381 of 5001.\n",
      "Step: 1382 of 5001.\n",
      "Step: 1383 of 5001.\n",
      "Step: 1384 of 5001.\n",
      "Step: 1385 of 5001.\n",
      "Step: 1386 of 5001.\n",
      "Step: 1387 of 5001.\n",
      "Step: 1388 of 5001.\n",
      "Step: 1389 of 5001.\n",
      "Step: 1390 of 5001.\n",
      "Generator model loss: 1.208592987060547.\n",
      "Discriminator model loss real: 0.7130944818258286.\n",
      "Discriminator model loss generated: 0.6715920627117157.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1391 of 5001.\n",
      "Step: 1392 of 5001.\n",
      "Step: 1393 of 5001.\n",
      "Step: 1394 of 5001.\n",
      "Step: 1395 of 5001.\n",
      "Step: 1396 of 5001.\n",
      "Step: 1397 of 5001.\n",
      "Step: 1398 of 5001.\n",
      "Step: 1399 of 5001.\n",
      "Step: 1400 of 5001.\n",
      "Generator model loss: 1.2661993980407715.\n",
      "Discriminator model loss real: 0.7774898290634156.\n",
      "Discriminator model loss generated: 0.6379951119422913.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1401 of 5001.\n",
      "Step: 1402 of 5001.\n",
      "Step: 1403 of 5001.\n",
      "Step: 1404 of 5001.\n",
      "Step: 1405 of 5001.\n",
      "Step: 1406 of 5001.\n",
      "Step: 1407 of 5001.\n",
      "Step: 1408 of 5001.\n",
      "Step: 1409 of 5001.\n",
      "Step: 1410 of 5001.\n",
      "Generator model loss: 1.2639458179473877.\n",
      "Discriminator model loss real: 0.7668199449777603.\n",
      "Discriminator model loss generated: 0.612878492474556.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1411 of 5001.\n",
      "Step: 1412 of 5001.\n",
      "Step: 1413 of 5001.\n",
      "Step: 1414 of 5001.\n",
      "Step: 1415 of 5001.\n",
      "Step: 1416 of 5001.\n",
      "Step: 1417 of 5001.\n",
      "Step: 1418 of 5001.\n",
      "Step: 1419 of 5001.\n",
      "Step: 1420 of 5001.\n",
      "Generator model loss: 1.2462071180343628.\n",
      "Discriminator model loss real: 0.7359982281923294.\n",
      "Discriminator model loss generated: 0.628958010673523.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1421 of 5001.\n",
      "Step: 1422 of 5001.\n",
      "Step: 1423 of 5001.\n",
      "Step: 1424 of 5001.\n",
      "Step: 1425 of 5001.\n",
      "Step: 1426 of 5001.\n",
      "Step: 1427 of 5001.\n",
      "Step: 1428 of 5001.\n",
      "Step: 1429 of 5001.\n",
      "Step: 1430 of 5001.\n",
      "Generator model loss: 1.2327590107917785.\n",
      "Discriminator model loss real: 0.7402352184057236.\n",
      "Discriminator model loss generated: 0.6568438112735748.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1431 of 5001.\n",
      "Step: 1432 of 5001.\n",
      "Step: 1433 of 5001.\n",
      "Step: 1434 of 5001.\n",
      "Step: 1435 of 5001.\n",
      "Step: 1436 of 5001.\n",
      "Step: 1437 of 5001.\n",
      "Step: 1438 of 5001.\n",
      "Step: 1439 of 5001.\n",
      "Step: 1440 of 5001.\n",
      "Generator model loss: 1.2315383672714233.\n",
      "Discriminator model loss real: 0.7325225740671157.\n",
      "Discriminator model loss generated: 0.6509686052799225.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1441 of 5001.\n",
      "Step: 1442 of 5001.\n",
      "Step: 1443 of 5001.\n",
      "Step: 1444 of 5001.\n",
      "Step: 1445 of 5001.\n",
      "Step: 1446 of 5001.\n",
      "Step: 1447 of 5001.\n",
      "Step: 1448 of 5001.\n",
      "Step: 1449 of 5001.\n",
      "Step: 1450 of 5001.\n",
      "Generator model loss: 1.224637794494629.\n",
      "Discriminator model loss real: 0.7950239181518555.\n",
      "Discriminator model loss generated: 0.6423728108406067.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1451 of 5001.\n",
      "Step: 1452 of 5001.\n",
      "Step: 1453 of 5001.\n",
      "Step: 1454 of 5001.\n",
      "Step: 1455 of 5001.\n",
      "Step: 1456 of 5001.\n",
      "Step: 1457 of 5001.\n",
      "Step: 1458 of 5001.\n",
      "Step: 1459 of 5001.\n",
      "Step: 1460 of 5001.\n",
      "Generator model loss: 1.2019893407821656.\n",
      "Discriminator model loss real: 0.7503422170877456.\n",
      "Discriminator model loss generated: 0.6062282860279083.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1461 of 5001.\n",
      "Step: 1462 of 5001.\n",
      "Step: 1463 of 5001.\n",
      "Step: 1464 of 5001.\n",
      "Step: 1465 of 5001.\n",
      "Step: 1466 of 5001.\n",
      "Step: 1467 of 5001.\n",
      "Step: 1468 of 5001.\n",
      "Step: 1469 of 5001.\n",
      "Step: 1470 of 5001.\n",
      "Generator model loss: 1.2533260941505433.\n",
      "Discriminator model loss real: 0.8067718535661698.\n",
      "Discriminator model loss generated: 0.5752594828605652.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1471 of 5001.\n",
      "Step: 1472 of 5001.\n",
      "Step: 1473 of 5001.\n",
      "Step: 1474 of 5001.\n",
      "Step: 1475 of 5001.\n",
      "Step: 1476 of 5001.\n",
      "Step: 1477 of 5001.\n",
      "Step: 1478 of 5001.\n",
      "Step: 1479 of 5001.\n",
      "Step: 1480 of 5001.\n",
      "Generator model loss: 1.1817604899406433.\n",
      "Discriminator model loss real: 0.7980314671993256.\n",
      "Discriminator model loss generated: 0.6311362683773041.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1481 of 5001.\n",
      "Step: 1482 of 5001.\n",
      "Step: 1483 of 5001.\n",
      "Step: 1484 of 5001.\n",
      "Step: 1485 of 5001.\n",
      "Step: 1486 of 5001.\n",
      "Step: 1487 of 5001.\n",
      "Step: 1488 of 5001.\n",
      "Step: 1489 of 5001.\n",
      "Step: 1490 of 5001.\n",
      "Generator model loss: 1.190634512901306.\n",
      "Discriminator model loss real: 0.8183359384536744.\n",
      "Discriminator model loss generated: 0.6460969269275665.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1491 of 5001.\n",
      "Step: 1492 of 5001.\n",
      "Step: 1493 of 5001.\n",
      "Step: 1494 of 5001.\n",
      "Step: 1495 of 5001.\n",
      "Step: 1496 of 5001.\n",
      "Step: 1497 of 5001.\n",
      "Step: 1498 of 5001.\n",
      "Step: 1499 of 5001.\n",
      "Step: 1500 of 5001.\n",
      "Generator model loss: 1.1898733496665954.\n",
      "Discriminator model loss real: 0.745824471116066.\n",
      "Discriminator model loss generated: 0.6152980268001557.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1501 of 5001.\n",
      "Step: 1502 of 5001.\n",
      "Step: 1503 of 5001.\n",
      "Step: 1504 of 5001.\n",
      "Step: 1505 of 5001.\n",
      "Step: 1506 of 5001.\n",
      "Step: 1507 of 5001.\n",
      "Step: 1508 of 5001.\n",
      "Step: 1509 of 5001.\n",
      "Step: 1510 of 5001.\n",
      "Generator model loss: 1.2446486949920654.\n",
      "Discriminator model loss real: 0.73639395236969.\n",
      "Discriminator model loss generated: 0.6596561551094056.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1511 of 5001.\n",
      "Step: 1512 of 5001.\n",
      "Step: 1513 of 5001.\n",
      "Step: 1514 of 5001.\n",
      "Step: 1515 of 5001.\n",
      "Step: 1516 of 5001.\n",
      "Step: 1517 of 5001.\n",
      "Step: 1518 of 5001.\n",
      "Step: 1519 of 5001.\n",
      "Step: 1520 of 5001.\n",
      "Generator model loss: 1.1979442834854126.\n",
      "Discriminator model loss real: 0.7756425082683563.\n",
      "Discriminator model loss generated: 0.7250233948230743.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1521 of 5001.\n",
      "Step: 1522 of 5001.\n",
      "Step: 1523 of 5001.\n",
      "Step: 1524 of 5001.\n",
      "Step: 1525 of 5001.\n",
      "Step: 1526 of 5001.\n",
      "Step: 1527 of 5001.\n",
      "Step: 1528 of 5001.\n",
      "Step: 1529 of 5001.\n",
      "Step: 1530 of 5001.\n",
      "Generator model loss: 1.2234219908714294.\n",
      "Discriminator model loss real: 0.6904380172491074.\n",
      "Discriminator model loss generated: 0.7151751399040223.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1531 of 5001.\n",
      "Step: 1532 of 5001.\n",
      "Step: 1533 of 5001.\n",
      "Step: 1534 of 5001.\n",
      "Step: 1535 of 5001.\n",
      "Step: 1536 of 5001.\n",
      "Step: 1537 of 5001.\n",
      "Step: 1538 of 5001.\n",
      "Step: 1539 of 5001.\n",
      "Step: 1540 of 5001.\n",
      "Generator model loss: 1.2035245895385742.\n",
      "Discriminator model loss real: 0.7528097629547119.\n",
      "Discriminator model loss generated: 0.6548046708106995.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1541 of 5001.\n",
      "Step: 1542 of 5001.\n",
      "Step: 1543 of 5001.\n",
      "Step: 1544 of 5001.\n",
      "Step: 1545 of 5001.\n",
      "Step: 1546 of 5001.\n",
      "Step: 1547 of 5001.\n",
      "Step: 1548 of 5001.\n",
      "Step: 1549 of 5001.\n",
      "Step: 1550 of 5001.\n",
      "Generator model loss: 1.2426651954650878.\n",
      "Discriminator model loss real: 0.7342466473579407.\n",
      "Discriminator model loss generated: 0.6604062259197235.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1551 of 5001.\n",
      "Step: 1552 of 5001.\n",
      "Step: 1553 of 5001.\n",
      "Step: 1554 of 5001.\n",
      "Step: 1555 of 5001.\n",
      "Step: 1556 of 5001.\n",
      "Step: 1557 of 5001.\n",
      "Step: 1558 of 5001.\n",
      "Step: 1559 of 5001.\n",
      "Step: 1560 of 5001.\n",
      "Generator model loss: 1.2392099976539612.\n",
      "Discriminator model loss real: 0.7714758157730103.\n",
      "Discriminator model loss generated: 0.576028710603714.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1561 of 5001.\n",
      "Step: 1562 of 5001.\n",
      "Step: 1563 of 5001.\n",
      "Step: 1564 of 5001.\n",
      "Step: 1565 of 5001.\n",
      "Step: 1566 of 5001.\n",
      "Step: 1567 of 5001.\n",
      "Step: 1568 of 5001.\n",
      "Step: 1569 of 5001.\n",
      "Step: 1570 of 5001.\n",
      "Generator model loss: 1.210365641117096.\n",
      "Discriminator model loss real: 0.809376698732376.\n",
      "Discriminator model loss generated: 0.5946841657161712.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1571 of 5001.\n",
      "Step: 1572 of 5001.\n",
      "Step: 1573 of 5001.\n",
      "Step: 1574 of 5001.\n",
      "Step: 1575 of 5001.\n",
      "Step: 1576 of 5001.\n",
      "Step: 1577 of 5001.\n",
      "Step: 1578 of 5001.\n",
      "Step: 1579 of 5001.\n",
      "Step: 1580 of 5001.\n",
      "Generator model loss: 1.2298364400863648.\n",
      "Discriminator model loss real: 0.7839026898145676.\n",
      "Discriminator model loss generated: 0.5817709147930146.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1581 of 5001.\n",
      "Step: 1582 of 5001.\n",
      "Step: 1583 of 5001.\n",
      "Step: 1584 of 5001.\n",
      "Step: 1585 of 5001.\n",
      "Step: 1586 of 5001.\n",
      "Step: 1587 of 5001.\n",
      "Step: 1588 of 5001.\n",
      "Step: 1589 of 5001.\n",
      "Step: 1590 of 5001.\n",
      "Generator model loss: 1.1876824855804444.\n",
      "Discriminator model loss real: 0.7415475696325302.\n",
      "Discriminator model loss generated: 0.6101004302501678.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1591 of 5001.\n",
      "Step: 1592 of 5001.\n",
      "Step: 1593 of 5001.\n",
      "Step: 1594 of 5001.\n",
      "Step: 1595 of 5001.\n",
      "Step: 1596 of 5001.\n",
      "Step: 1597 of 5001.\n",
      "Step: 1598 of 5001.\n",
      "Step: 1599 of 5001.\n",
      "Step: 1600 of 5001.\n",
      "Generator model loss: 1.1878973722457886.\n",
      "Discriminator model loss real: 0.7638213187456131.\n",
      "Discriminator model loss generated: 0.5874767124652862.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1601 of 5001.\n",
      "Step: 1602 of 5001.\n",
      "Step: 1603 of 5001.\n",
      "Step: 1604 of 5001.\n",
      "Step: 1605 of 5001.\n",
      "Step: 1606 of 5001.\n",
      "Step: 1607 of 5001.\n",
      "Step: 1608 of 5001.\n",
      "Step: 1609 of 5001.\n",
      "Step: 1610 of 5001.\n",
      "Generator model loss: 1.2304316997528075.\n",
      "Discriminator model loss real: 0.7600520938634873.\n",
      "Discriminator model loss generated: 0.6153600931167602.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1611 of 5001.\n",
      "Step: 1612 of 5001.\n",
      "Step: 1613 of 5001.\n",
      "Step: 1614 of 5001.\n",
      "Step: 1615 of 5001.\n",
      "Step: 1616 of 5001.\n",
      "Step: 1617 of 5001.\n",
      "Step: 1618 of 5001.\n",
      "Step: 1619 of 5001.\n",
      "Step: 1620 of 5001.\n",
      "Generator model loss: 1.1755898237228393.\n",
      "Discriminator model loss real: 0.7840653538703919.\n",
      "Discriminator model loss generated: 0.5817027866840363.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1621 of 5001.\n",
      "Step: 1622 of 5001.\n",
      "Step: 1623 of 5001.\n",
      "Step: 1624 of 5001.\n",
      "Step: 1625 of 5001.\n",
      "Step: 1626 of 5001.\n",
      "Step: 1627 of 5001.\n",
      "Step: 1628 of 5001.\n",
      "Step: 1629 of 5001.\n",
      "Step: 1630 of 5001.\n",
      "Generator model loss: 1.2240848541259766.\n",
      "Discriminator model loss real: 0.7605757206678391.\n",
      "Discriminator model loss generated: 0.6163156270980835.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1631 of 5001.\n",
      "Step: 1632 of 5001.\n",
      "Step: 1633 of 5001.\n",
      "Step: 1634 of 5001.\n",
      "Step: 1635 of 5001.\n",
      "Step: 1636 of 5001.\n",
      "Step: 1637 of 5001.\n",
      "Step: 1638 of 5001.\n",
      "Step: 1639 of 5001.\n",
      "Step: 1640 of 5001.\n",
      "Generator model loss: 1.18687961101532.\n",
      "Discriminator model loss real: 0.7331537112593651.\n",
      "Discriminator model loss generated: 0.6891004562377929.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1641 of 5001.\n",
      "Step: 1642 of 5001.\n",
      "Step: 1643 of 5001.\n",
      "Step: 1644 of 5001.\n",
      "Step: 1645 of 5001.\n",
      "Step: 1646 of 5001.\n",
      "Step: 1647 of 5001.\n",
      "Step: 1648 of 5001.\n",
      "Step: 1649 of 5001.\n",
      "Step: 1650 of 5001.\n",
      "Generator model loss: 1.196055781841278.\n",
      "Discriminator model loss real: 0.7596377223730088.\n",
      "Discriminator model loss generated: 0.6493308901786804.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1651 of 5001.\n",
      "Step: 1652 of 5001.\n",
      "Step: 1653 of 5001.\n",
      "Step: 1654 of 5001.\n",
      "Step: 1655 of 5001.\n",
      "Step: 1656 of 5001.\n",
      "Step: 1657 of 5001.\n",
      "Step: 1658 of 5001.\n",
      "Step: 1659 of 5001.\n",
      "Step: 1660 of 5001.\n",
      "Generator model loss: 1.17824387550354.\n",
      "Discriminator model loss real: 0.7631369292736053.\n",
      "Discriminator model loss generated: 0.6705016314983367.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1661 of 5001.\n",
      "Step: 1662 of 5001.\n",
      "Step: 1663 of 5001.\n",
      "Step: 1664 of 5001.\n",
      "Step: 1665 of 5001.\n",
      "Step: 1666 of 5001.\n",
      "Step: 1667 of 5001.\n",
      "Step: 1668 of 5001.\n",
      "Step: 1669 of 5001.\n",
      "Step: 1670 of 5001.\n",
      "Generator model loss: 1.1482148885726928.\n",
      "Discriminator model loss real: 0.7714692533016205.\n",
      "Discriminator model loss generated: 0.6029995977878571.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1671 of 5001.\n",
      "Step: 1672 of 5001.\n",
      "Step: 1673 of 5001.\n",
      "Step: 1674 of 5001.\n",
      "Step: 1675 of 5001.\n",
      "Step: 1676 of 5001.\n",
      "Step: 1677 of 5001.\n",
      "Step: 1678 of 5001.\n",
      "Step: 1679 of 5001.\n",
      "Step: 1680 of 5001.\n",
      "Generator model loss: 1.2050233364105225.\n",
      "Discriminator model loss real: 0.7438920736312866.\n",
      "Discriminator model loss generated: 0.5956953823566437.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1681 of 5001.\n",
      "Step: 1682 of 5001.\n",
      "Step: 1683 of 5001.\n",
      "Step: 1684 of 5001.\n",
      "Step: 1685 of 5001.\n",
      "Step: 1686 of 5001.\n",
      "Step: 1687 of 5001.\n",
      "Step: 1688 of 5001.\n",
      "Step: 1689 of 5001.\n",
      "Step: 1690 of 5001.\n",
      "Generator model loss: 1.1565033435821532.\n",
      "Discriminator model loss real: 0.7307522535324097.\n",
      "Discriminator model loss generated: 0.622411060333252.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1691 of 5001.\n",
      "Step: 1692 of 5001.\n",
      "Step: 1693 of 5001.\n",
      "Step: 1694 of 5001.\n",
      "Step: 1695 of 5001.\n",
      "Step: 1696 of 5001.\n",
      "Step: 1697 of 5001.\n",
      "Step: 1698 of 5001.\n",
      "Step: 1699 of 5001.\n",
      "Step: 1700 of 5001.\n",
      "Generator model loss: 1.2075875997543335.\n",
      "Discriminator model loss real: 0.7696158111095428.\n",
      "Discriminator model loss generated: 0.5814199447631836.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1701 of 5001.\n",
      "Step: 1702 of 5001.\n",
      "Step: 1703 of 5001.\n",
      "Step: 1704 of 5001.\n",
      "Step: 1705 of 5001.\n",
      "Step: 1706 of 5001.\n",
      "Step: 1707 of 5001.\n",
      "Step: 1708 of 5001.\n",
      "Step: 1709 of 5001.\n",
      "Step: 1710 of 5001.\n",
      "Generator model loss: 1.1675940036773682.\n",
      "Discriminator model loss real: 0.7780532896518707.\n",
      "Discriminator model loss generated: 0.6655388653278351.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1711 of 5001.\n",
      "Step: 1712 of 5001.\n",
      "Step: 1713 of 5001.\n",
      "Step: 1714 of 5001.\n",
      "Step: 1715 of 5001.\n",
      "Step: 1716 of 5001.\n",
      "Step: 1717 of 5001.\n",
      "Step: 1718 of 5001.\n",
      "Step: 1719 of 5001.\n",
      "Step: 1720 of 5001.\n",
      "Generator model loss: 1.1673904061317444.\n",
      "Discriminator model loss real: 0.782284352183342.\n",
      "Discriminator model loss generated: 0.5762295305728913.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1721 of 5001.\n",
      "Step: 1722 of 5001.\n",
      "Step: 1723 of 5001.\n",
      "Step: 1724 of 5001.\n",
      "Step: 1725 of 5001.\n",
      "Step: 1726 of 5001.\n",
      "Step: 1727 of 5001.\n",
      "Step: 1728 of 5001.\n",
      "Step: 1729 of 5001.\n",
      "Step: 1730 of 5001.\n",
      "Generator model loss: 1.1788074254989624.\n",
      "Discriminator model loss real: 0.783818644285202.\n",
      "Discriminator model loss generated: 0.6237774431705475.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1731 of 5001.\n",
      "Step: 1732 of 5001.\n",
      "Step: 1733 of 5001.\n",
      "Step: 1734 of 5001.\n",
      "Step: 1735 of 5001.\n",
      "Step: 1736 of 5001.\n",
      "Step: 1737 of 5001.\n",
      "Step: 1738 of 5001.\n",
      "Step: 1739 of 5001.\n",
      "Step: 1740 of 5001.\n",
      "Generator model loss: 1.1352259278297425.\n",
      "Discriminator model loss real: 0.762708666920662.\n",
      "Discriminator model loss generated: 0.5752264857292175.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1741 of 5001.\n",
      "Step: 1742 of 5001.\n",
      "Step: 1743 of 5001.\n",
      "Step: 1744 of 5001.\n",
      "Step: 1745 of 5001.\n",
      "Step: 1746 of 5001.\n",
      "Step: 1747 of 5001.\n",
      "Step: 1748 of 5001.\n",
      "Step: 1749 of 5001.\n",
      "Step: 1750 of 5001.\n",
      "Generator model loss: 1.1641765356063842.\n",
      "Discriminator model loss real: 0.7321681588888168.\n",
      "Discriminator model loss generated: 0.6284569144248963.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1751 of 5001.\n",
      "Step: 1752 of 5001.\n",
      "Step: 1753 of 5001.\n",
      "Step: 1754 of 5001.\n",
      "Step: 1755 of 5001.\n",
      "Step: 1756 of 5001.\n",
      "Step: 1757 of 5001.\n",
      "Step: 1758 of 5001.\n",
      "Step: 1759 of 5001.\n",
      "Step: 1760 of 5001.\n",
      "Generator model loss: 1.120873010158539.\n",
      "Discriminator model loss real: 0.729123803973198.\n",
      "Discriminator model loss generated: 0.6894146740436554.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1761 of 5001.\n",
      "Step: 1762 of 5001.\n",
      "Step: 1763 of 5001.\n",
      "Step: 1764 of 5001.\n",
      "Step: 1765 of 5001.\n",
      "Step: 1766 of 5001.\n",
      "Step: 1767 of 5001.\n",
      "Step: 1768 of 5001.\n",
      "Step: 1769 of 5001.\n",
      "Step: 1770 of 5001.\n",
      "Generator model loss: 1.1443458676338196.\n",
      "Discriminator model loss real: 0.7878235071897507.\n",
      "Discriminator model loss generated: 0.6844116568565368.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1771 of 5001.\n",
      "Step: 1772 of 5001.\n",
      "Step: 1773 of 5001.\n",
      "Step: 1774 of 5001.\n",
      "Step: 1775 of 5001.\n",
      "Step: 1776 of 5001.\n",
      "Step: 1777 of 5001.\n",
      "Step: 1778 of 5001.\n",
      "Step: 1779 of 5001.\n",
      "Step: 1780 of 5001.\n",
      "Generator model loss: 1.139307188987732.\n",
      "Discriminator model loss real: 0.7866666555404663.\n",
      "Discriminator model loss generated: 0.6342181086540222.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1781 of 5001.\n",
      "Step: 1782 of 5001.\n",
      "Step: 1783 of 5001.\n",
      "Step: 1784 of 5001.\n",
      "Step: 1785 of 5001.\n",
      "Step: 1786 of 5001.\n",
      "Step: 1787 of 5001.\n",
      "Step: 1788 of 5001.\n",
      "Step: 1789 of 5001.\n",
      "Step: 1790 of 5001.\n",
      "Generator model loss: 1.1254867672920228.\n",
      "Discriminator model loss real: 0.7814280718564988.\n",
      "Discriminator model loss generated: 0.6289677321910858.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1791 of 5001.\n",
      "Step: 1792 of 5001.\n",
      "Step: 1793 of 5001.\n",
      "Step: 1794 of 5001.\n",
      "Step: 1795 of 5001.\n",
      "Step: 1796 of 5001.\n",
      "Step: 1797 of 5001.\n",
      "Step: 1798 of 5001.\n",
      "Step: 1799 of 5001.\n",
      "Step: 1800 of 5001.\n",
      "Generator model loss: 1.1457064032554627.\n",
      "Discriminator model loss real: 0.8033702522516251.\n",
      "Discriminator model loss generated: 0.615435141324997.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1801 of 5001.\n",
      "Step: 1802 of 5001.\n",
      "Step: 1803 of 5001.\n",
      "Step: 1804 of 5001.\n",
      "Step: 1805 of 5001.\n",
      "Step: 1806 of 5001.\n",
      "Step: 1807 of 5001.\n",
      "Step: 1808 of 5001.\n",
      "Step: 1809 of 5001.\n",
      "Step: 1810 of 5001.\n",
      "Generator model loss: 1.1598461031913758.\n",
      "Discriminator model loss real: 0.7518562644720077.\n",
      "Discriminator model loss generated: 0.7262841880321502.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1811 of 5001.\n",
      "Step: 1812 of 5001.\n",
      "Step: 1813 of 5001.\n",
      "Step: 1814 of 5001.\n",
      "Step: 1815 of 5001.\n",
      "Step: 1816 of 5001.\n",
      "Step: 1817 of 5001.\n",
      "Step: 1818 of 5001.\n",
      "Step: 1819 of 5001.\n",
      "Step: 1820 of 5001.\n",
      "Generator model loss: 1.160570454597473.\n",
      "Discriminator model loss real: 0.8520439624786377.\n",
      "Discriminator model loss generated: 0.631296581029892.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1821 of 5001.\n",
      "Step: 1822 of 5001.\n",
      "Step: 1823 of 5001.\n",
      "Step: 1824 of 5001.\n",
      "Step: 1825 of 5001.\n",
      "Step: 1826 of 5001.\n",
      "Step: 1827 of 5001.\n",
      "Step: 1828 of 5001.\n",
      "Step: 1829 of 5001.\n",
      "Step: 1830 of 5001.\n",
      "Generator model loss: 1.1190064907073975.\n",
      "Discriminator model loss real: 0.7994872689247131.\n",
      "Discriminator model loss generated: 0.6104487419128418.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1831 of 5001.\n",
      "Step: 1832 of 5001.\n",
      "Step: 1833 of 5001.\n",
      "Step: 1834 of 5001.\n",
      "Step: 1835 of 5001.\n",
      "Step: 1836 of 5001.\n",
      "Step: 1837 of 5001.\n",
      "Step: 1838 of 5001.\n",
      "Step: 1839 of 5001.\n",
      "Step: 1840 of 5001.\n",
      "Generator model loss: 1.1560583472251893.\n",
      "Discriminator model loss real: 0.7838546246290207.\n",
      "Discriminator model loss generated: 0.626008927822113.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1841 of 5001.\n",
      "Step: 1842 of 5001.\n",
      "Step: 1843 of 5001.\n",
      "Step: 1844 of 5001.\n",
      "Step: 1845 of 5001.\n",
      "Step: 1846 of 5001.\n",
      "Step: 1847 of 5001.\n",
      "Step: 1848 of 5001.\n",
      "Step: 1849 of 5001.\n",
      "Step: 1850 of 5001.\n",
      "Generator model loss: 1.1476458430290222.\n",
      "Discriminator model loss real: 0.8133769303560257.\n",
      "Discriminator model loss generated: 0.6103709101676941.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1851 of 5001.\n",
      "Step: 1852 of 5001.\n",
      "Step: 1853 of 5001.\n",
      "Step: 1854 of 5001.\n",
      "Step: 1855 of 5001.\n",
      "Step: 1856 of 5001.\n",
      "Step: 1857 of 5001.\n",
      "Step: 1858 of 5001.\n",
      "Step: 1859 of 5001.\n",
      "Step: 1860 of 5001.\n",
      "Generator model loss: 1.1320316433906554.\n",
      "Discriminator model loss real: 0.7599584698677063.\n",
      "Discriminator model loss generated: 0.642803406715393.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1861 of 5001.\n",
      "Step: 1862 of 5001.\n",
      "Step: 1863 of 5001.\n",
      "Step: 1864 of 5001.\n",
      "Step: 1865 of 5001.\n",
      "Step: 1866 of 5001.\n",
      "Step: 1867 of 5001.\n",
      "Step: 1868 of 5001.\n",
      "Step: 1869 of 5001.\n",
      "Step: 1870 of 5001.\n",
      "Generator model loss: 1.1519503712654113.\n",
      "Discriminator model loss real: 0.7621534436941146.\n",
      "Discriminator model loss generated: 0.6771626114845276.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1871 of 5001.\n",
      "Step: 1872 of 5001.\n",
      "Step: 1873 of 5001.\n",
      "Step: 1874 of 5001.\n",
      "Step: 1875 of 5001.\n",
      "Step: 1876 of 5001.\n",
      "Step: 1877 of 5001.\n",
      "Step: 1878 of 5001.\n",
      "Step: 1879 of 5001.\n",
      "Step: 1880 of 5001.\n",
      "Generator model loss: 1.115698766708374.\n",
      "Discriminator model loss real: 0.8550519466400146.\n",
      "Discriminator model loss generated: 0.6137652575969696.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1881 of 5001.\n",
      "Step: 1882 of 5001.\n",
      "Step: 1883 of 5001.\n",
      "Step: 1884 of 5001.\n",
      "Step: 1885 of 5001.\n",
      "Step: 1886 of 5001.\n",
      "Step: 1887 of 5001.\n",
      "Step: 1888 of 5001.\n",
      "Step: 1889 of 5001.\n",
      "Step: 1890 of 5001.\n",
      "Generator model loss: 1.1406043767929077.\n",
      "Discriminator model loss real: 0.7707774132490158.\n",
      "Discriminator model loss generated: 0.6269457399845123.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1891 of 5001.\n",
      "Step: 1892 of 5001.\n",
      "Step: 1893 of 5001.\n",
      "Step: 1894 of 5001.\n",
      "Step: 1895 of 5001.\n",
      "Step: 1896 of 5001.\n",
      "Step: 1897 of 5001.\n",
      "Step: 1898 of 5001.\n",
      "Step: 1899 of 5001.\n",
      "Step: 1900 of 5001.\n",
      "Generator model loss: 1.1351125597953797.\n",
      "Discriminator model loss real: 0.8012864321470261.\n",
      "Discriminator model loss generated: 0.5787132024765015.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1901 of 5001.\n",
      "Step: 1902 of 5001.\n",
      "Step: 1903 of 5001.\n",
      "Step: 1904 of 5001.\n",
      "Step: 1905 of 5001.\n",
      "Step: 1906 of 5001.\n",
      "Step: 1907 of 5001.\n",
      "Step: 1908 of 5001.\n",
      "Step: 1909 of 5001.\n",
      "Step: 1910 of 5001.\n",
      "Generator model loss: 1.1489410161972047.\n",
      "Discriminator model loss real: 0.7915697276592255.\n",
      "Discriminator model loss generated: 0.626993077993393.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1911 of 5001.\n",
      "Step: 1912 of 5001.\n",
      "Step: 1913 of 5001.\n",
      "Step: 1914 of 5001.\n",
      "Step: 1915 of 5001.\n",
      "Step: 1916 of 5001.\n",
      "Step: 1917 of 5001.\n",
      "Step: 1918 of 5001.\n",
      "Step: 1919 of 5001.\n",
      "Step: 1920 of 5001.\n",
      "Generator model loss: 1.1319794654846191.\n",
      "Discriminator model loss real: 0.8440828144550323.\n",
      "Discriminator model loss generated: 0.5955296814441681.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1921 of 5001.\n",
      "Step: 1922 of 5001.\n",
      "Step: 1923 of 5001.\n",
      "Step: 1924 of 5001.\n",
      "Step: 1925 of 5001.\n",
      "Step: 1926 of 5001.\n",
      "Step: 1927 of 5001.\n",
      "Step: 1928 of 5001.\n",
      "Step: 1929 of 5001.\n",
      "Step: 1930 of 5001.\n",
      "Generator model loss: 1.1269373774528504.\n",
      "Discriminator model loss real: 0.8079821228981018.\n",
      "Discriminator model loss generated: 0.625601875782013.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1931 of 5001.\n",
      "Step: 1932 of 5001.\n",
      "Step: 1933 of 5001.\n",
      "Step: 1934 of 5001.\n",
      "Step: 1935 of 5001.\n",
      "Step: 1936 of 5001.\n",
      "Step: 1937 of 5001.\n",
      "Step: 1938 of 5001.\n",
      "Step: 1939 of 5001.\n",
      "Step: 1940 of 5001.\n",
      "Generator model loss: 1.106561541557312.\n",
      "Discriminator model loss real: 0.8098610639572144.\n",
      "Discriminator model loss generated: 0.5957881152629853.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1941 of 5001.\n",
      "Step: 1942 of 5001.\n",
      "Step: 1943 of 5001.\n",
      "Step: 1944 of 5001.\n",
      "Step: 1945 of 5001.\n",
      "Step: 1946 of 5001.\n",
      "Step: 1947 of 5001.\n",
      "Step: 1948 of 5001.\n",
      "Step: 1949 of 5001.\n",
      "Step: 1950 of 5001.\n",
      "Generator model loss: 1.0764596164226532.\n",
      "Discriminator model loss real: 0.7490261971950531.\n",
      "Discriminator model loss generated: 0.5672363817691803.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1951 of 5001.\n",
      "Step: 1952 of 5001.\n",
      "Step: 1953 of 5001.\n",
      "Step: 1954 of 5001.\n",
      "Step: 1955 of 5001.\n",
      "Step: 1956 of 5001.\n",
      "Step: 1957 of 5001.\n",
      "Step: 1958 of 5001.\n",
      "Step: 1959 of 5001.\n",
      "Step: 1960 of 5001.\n",
      "Generator model loss: 1.0943753123283386.\n",
      "Discriminator model loss real: 0.8007229208946228.\n",
      "Discriminator model loss generated: 0.6360810279846192.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1961 of 5001.\n",
      "Step: 1962 of 5001.\n",
      "Step: 1963 of 5001.\n",
      "Step: 1964 of 5001.\n",
      "Step: 1965 of 5001.\n",
      "Step: 1966 of 5001.\n",
      "Step: 1967 of 5001.\n",
      "Step: 1968 of 5001.\n",
      "Step: 1969 of 5001.\n",
      "Step: 1970 of 5001.\n",
      "Generator model loss: 1.1040528535842895.\n",
      "Discriminator model loss real: 0.7804667025804519.\n",
      "Discriminator model loss generated: 0.5665941596031189.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1971 of 5001.\n",
      "Step: 1972 of 5001.\n",
      "Step: 1973 of 5001.\n",
      "Step: 1974 of 5001.\n",
      "Step: 1975 of 5001.\n",
      "Step: 1976 of 5001.\n",
      "Step: 1977 of 5001.\n",
      "Step: 1978 of 5001.\n",
      "Step: 1979 of 5001.\n",
      "Step: 1980 of 5001.\n",
      "Generator model loss: 1.1463145017623901.\n",
      "Discriminator model loss real: 0.8155145198106766.\n",
      "Discriminator model loss generated: 0.645525312423706.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1981 of 5001.\n",
      "Step: 1982 of 5001.\n",
      "Step: 1983 of 5001.\n",
      "Step: 1984 of 5001.\n",
      "Step: 1985 of 5001.\n",
      "Step: 1986 of 5001.\n",
      "Step: 1987 of 5001.\n",
      "Step: 1988 of 5001.\n",
      "Step: 1989 of 5001.\n",
      "Step: 1990 of 5001.\n",
      "Generator model loss: 1.1033102869987488.\n",
      "Discriminator model loss real: 0.8117998778820038.\n",
      "Discriminator model loss generated: 0.6187373518943786.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1991 of 5001.\n",
      "Step: 1992 of 5001.\n",
      "Step: 1993 of 5001.\n",
      "Step: 1994 of 5001.\n",
      "Step: 1995 of 5001.\n",
      "Step: 1996 of 5001.\n",
      "Step: 1997 of 5001.\n",
      "Step: 1998 of 5001.\n",
      "Step: 1999 of 5001.\n",
      "Step: 2000 of 5001.\n",
      "Generator model loss: 1.0828640341758728.\n",
      "Discriminator model loss real: 0.8293739229440689.\n",
      "Discriminator model loss generated: 0.6100379288196563.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2001 of 5001.\n",
      "Step: 2002 of 5001.\n",
      "Step: 2003 of 5001.\n",
      "Step: 2004 of 5001.\n",
      "Step: 2005 of 5001.\n",
      "Step: 2006 of 5001.\n",
      "Step: 2007 of 5001.\n",
      "Step: 2008 of 5001.\n",
      "Step: 2009 of 5001.\n",
      "Step: 2010 of 5001.\n",
      "Generator model loss: 1.1008900642395019.\n",
      "Discriminator model loss real: 0.7816815644502639.\n",
      "Discriminator model loss generated: 0.611240440607071.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2011 of 5001.\n",
      "Step: 2012 of 5001.\n",
      "Step: 2013 of 5001.\n",
      "Step: 2014 of 5001.\n",
      "Step: 2015 of 5001.\n",
      "Step: 2016 of 5001.\n",
      "Step: 2017 of 5001.\n",
      "Step: 2018 of 5001.\n",
      "Step: 2019 of 5001.\n",
      "Step: 2020 of 5001.\n",
      "Generator model loss: 1.0971027970314027.\n",
      "Discriminator model loss real: 0.7943192958831787.\n",
      "Discriminator model loss generated: 0.6436871230602265.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2021 of 5001.\n",
      "Step: 2022 of 5001.\n",
      "Step: 2023 of 5001.\n",
      "Step: 2024 of 5001.\n",
      "Step: 2025 of 5001.\n",
      "Step: 2026 of 5001.\n",
      "Step: 2027 of 5001.\n",
      "Step: 2028 of 5001.\n",
      "Step: 2029 of 5001.\n",
      "Step: 2030 of 5001.\n",
      "Generator model loss: 1.1161746859550477.\n",
      "Discriminator model loss real: 0.7816088914871215.\n",
      "Discriminator model loss generated: 0.6409352540969848.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2031 of 5001.\n",
      "Step: 2032 of 5001.\n",
      "Step: 2033 of 5001.\n",
      "Step: 2034 of 5001.\n",
      "Step: 2035 of 5001.\n",
      "Step: 2036 of 5001.\n",
      "Step: 2037 of 5001.\n",
      "Step: 2038 of 5001.\n",
      "Step: 2039 of 5001.\n",
      "Step: 2040 of 5001.\n",
      "Generator model loss: 1.111312460899353.\n",
      "Discriminator model loss real: 0.7608979165554046.\n",
      "Discriminator model loss generated: 0.5689984858036041.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2041 of 5001.\n",
      "Step: 2042 of 5001.\n",
      "Step: 2043 of 5001.\n",
      "Step: 2044 of 5001.\n",
      "Step: 2045 of 5001.\n",
      "Step: 2046 of 5001.\n",
      "Step: 2047 of 5001.\n",
      "Step: 2048 of 5001.\n",
      "Step: 2049 of 5001.\n",
      "Step: 2050 of 5001.\n",
      "Generator model loss: 1.0983568966388702.\n",
      "Discriminator model loss real: 0.7762210488319397.\n",
      "Discriminator model loss generated: 0.588842099905014.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2051 of 5001.\n",
      "Step: 2052 of 5001.\n",
      "Step: 2053 of 5001.\n",
      "Step: 2054 of 5001.\n",
      "Step: 2055 of 5001.\n",
      "Step: 2056 of 5001.\n",
      "Step: 2057 of 5001.\n",
      "Step: 2058 of 5001.\n",
      "Step: 2059 of 5001.\n",
      "Step: 2060 of 5001.\n",
      "Generator model loss: 1.1083680272102356.\n",
      "Discriminator model loss real: 0.8056045055389405.\n",
      "Discriminator model loss generated: 0.6201961517333985.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2061 of 5001.\n",
      "Step: 2062 of 5001.\n",
      "Step: 2063 of 5001.\n",
      "Step: 2064 of 5001.\n",
      "Step: 2065 of 5001.\n",
      "Step: 2066 of 5001.\n",
      "Step: 2067 of 5001.\n",
      "Step: 2068 of 5001.\n",
      "Step: 2069 of 5001.\n",
      "Step: 2070 of 5001.\n",
      "Generator model loss: 1.1149523735046387.\n",
      "Discriminator model loss real: 0.7534485727548599.\n",
      "Discriminator model loss generated: 0.58884237408638.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2071 of 5001.\n",
      "Step: 2072 of 5001.\n",
      "Step: 2073 of 5001.\n",
      "Step: 2074 of 5001.\n",
      "Step: 2075 of 5001.\n",
      "Step: 2076 of 5001.\n",
      "Step: 2077 of 5001.\n",
      "Step: 2078 of 5001.\n",
      "Step: 2079 of 5001.\n",
      "Step: 2080 of 5001.\n",
      "Generator model loss: 1.090129655599594.\n",
      "Discriminator model loss real: 0.774720299243927.\n",
      "Discriminator model loss generated: 0.6607561409473419.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2081 of 5001.\n",
      "Step: 2082 of 5001.\n",
      "Step: 2083 of 5001.\n",
      "Step: 2084 of 5001.\n",
      "Step: 2085 of 5001.\n",
      "Step: 2086 of 5001.\n",
      "Step: 2087 of 5001.\n",
      "Step: 2088 of 5001.\n",
      "Step: 2089 of 5001.\n",
      "Step: 2090 of 5001.\n",
      "Generator model loss: 1.078665053844452.\n",
      "Discriminator model loss real: 0.7655846416950226.\n",
      "Discriminator model loss generated: 0.6549429535865784.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2091 of 5001.\n",
      "Step: 2092 of 5001.\n",
      "Step: 2093 of 5001.\n",
      "Step: 2094 of 5001.\n",
      "Step: 2095 of 5001.\n",
      "Step: 2096 of 5001.\n",
      "Step: 2097 of 5001.\n",
      "Step: 2098 of 5001.\n",
      "Step: 2099 of 5001.\n",
      "Step: 2100 of 5001.\n",
      "Generator model loss: 1.0639883518218993.\n",
      "Discriminator model loss real: 0.809492963552475.\n",
      "Discriminator model loss generated: 0.668065094947815.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2101 of 5001.\n",
      "Step: 2102 of 5001.\n",
      "Step: 2103 of 5001.\n",
      "Step: 2104 of 5001.\n",
      "Step: 2105 of 5001.\n",
      "Step: 2106 of 5001.\n",
      "Step: 2107 of 5001.\n",
      "Step: 2108 of 5001.\n",
      "Step: 2109 of 5001.\n",
      "Step: 2110 of 5001.\n",
      "Generator model loss: 1.093938136100769.\n",
      "Discriminator model loss real: 0.8274509876966476.\n",
      "Discriminator model loss generated: 0.5822547018527985.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2111 of 5001.\n",
      "Step: 2112 of 5001.\n",
      "Step: 2113 of 5001.\n",
      "Step: 2114 of 5001.\n",
      "Step: 2115 of 5001.\n",
      "Step: 2116 of 5001.\n",
      "Step: 2117 of 5001.\n",
      "Step: 2118 of 5001.\n",
      "Step: 2119 of 5001.\n",
      "Step: 2120 of 5001.\n",
      "Generator model loss: 1.1181353688240052.\n",
      "Discriminator model loss real: 0.7985112518072128.\n",
      "Discriminator model loss generated: 0.6367094576358795.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2121 of 5001.\n",
      "Step: 2122 of 5001.\n",
      "Step: 2123 of 5001.\n",
      "Step: 2124 of 5001.\n",
      "Step: 2125 of 5001.\n",
      "Step: 2126 of 5001.\n",
      "Step: 2127 of 5001.\n",
      "Step: 2128 of 5001.\n",
      "Step: 2129 of 5001.\n",
      "Step: 2130 of 5001.\n",
      "Generator model loss: 1.1044276714324952.\n",
      "Discriminator model loss real: 0.8579151690006256.\n",
      "Discriminator model loss generated: 0.6288160145282745.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 2131 of 5001.\n",
      "Step: 2132 of 5001.\n",
      "Step: 2133 of 5001.\n",
      "Step: 2134 of 5001.\n",
      "Step: 2135 of 5001.\n",
      "Step: 2136 of 5001.\n",
      "Step: 2137 of 5001.\n",
      "Step: 2138 of 5001.\n",
      "Step: 2139 of 5001.\n",
      "Step: 2140 of 5001.\n",
      "Generator model loss: 1.0874127507209779.\n",
      "Discriminator model loss real: 0.8310862302780151.\n",
      "Discriminator model loss generated: 0.5748278975486756.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2141 of 5001.\n",
      "Step: 2142 of 5001.\n",
      "Step: 2143 of 5001.\n",
      "Step: 2144 of 5001.\n",
      "Step: 2145 of 5001.\n",
      "Step: 2146 of 5001.\n",
      "Step: 2147 of 5001.\n",
      "Step: 2148 of 5001.\n",
      "Step: 2149 of 5001.\n",
      "Step: 2150 of 5001.\n",
      "Generator model loss: 1.08608375787735.\n",
      "Discriminator model loss real: 0.817106568813324.\n",
      "Discriminator model loss generated: 0.6177547454833985.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2151 of 5001.\n",
      "Step: 2152 of 5001.\n",
      "Step: 2153 of 5001.\n",
      "Step: 2154 of 5001.\n",
      "Step: 2155 of 5001.\n",
      "Step: 2156 of 5001.\n",
      "Step: 2157 of 5001.\n",
      "Step: 2158 of 5001.\n",
      "Step: 2159 of 5001.\n",
      "Step: 2160 of 5001.\n",
      "Generator model loss: 1.0834102749824523.\n",
      "Discriminator model loss real: 0.763467338681221.\n",
      "Discriminator model loss generated: 0.6628402292728424.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2161 of 5001.\n",
      "Step: 2162 of 5001.\n",
      "Step: 2163 of 5001.\n",
      "Step: 2164 of 5001.\n",
      "Step: 2165 of 5001.\n",
      "Step: 2166 of 5001.\n",
      "Step: 2167 of 5001.\n",
      "Step: 2168 of 5001.\n",
      "Step: 2169 of 5001.\n",
      "Step: 2170 of 5001.\n",
      "Generator model loss: 1.0815079748630523.\n",
      "Discriminator model loss real: 0.8024428427219391.\n",
      "Discriminator model loss generated: 0.6004368185997009.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2171 of 5001.\n",
      "Step: 2172 of 5001.\n",
      "Step: 2173 of 5001.\n",
      "Step: 2174 of 5001.\n",
      "Step: 2175 of 5001.\n",
      "Step: 2176 of 5001.\n",
      "Step: 2177 of 5001.\n",
      "Step: 2178 of 5001.\n",
      "Step: 2179 of 5001.\n",
      "Step: 2180 of 5001.\n",
      "Generator model loss: 1.0909766674041748.\n",
      "Discriminator model loss real: 0.8384581238031388.\n",
      "Discriminator model loss generated: 0.583197009563446.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2181 of 5001.\n",
      "Step: 2182 of 5001.\n",
      "Step: 2183 of 5001.\n",
      "Step: 2184 of 5001.\n",
      "Step: 2185 of 5001.\n",
      "Step: 2186 of 5001.\n",
      "Step: 2187 of 5001.\n",
      "Step: 2188 of 5001.\n",
      "Step: 2189 of 5001.\n",
      "Step: 2190 of 5001.\n",
      "Generator model loss: 1.0844327986240387.\n",
      "Discriminator model loss real: 0.7960844010114669.\n",
      "Discriminator model loss generated: 0.6556848168373108.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2191 of 5001.\n",
      "Step: 2192 of 5001.\n",
      "Step: 2193 of 5001.\n",
      "Step: 2194 of 5001.\n",
      "Step: 2195 of 5001.\n",
      "Step: 2196 of 5001.\n",
      "Step: 2197 of 5001.\n",
      "Step: 2198 of 5001.\n",
      "Step: 2199 of 5001.\n",
      "Step: 2200 of 5001.\n",
      "Generator model loss: 1.1021886944770813.\n",
      "Discriminator model loss real: 0.7892654240131378.\n",
      "Discriminator model loss generated: 0.5983890652656555.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2201 of 5001.\n",
      "Step: 2202 of 5001.\n",
      "Step: 2203 of 5001.\n",
      "Step: 2204 of 5001.\n",
      "Step: 2205 of 5001.\n",
      "Step: 2206 of 5001.\n",
      "Step: 2207 of 5001.\n",
      "Step: 2208 of 5001.\n",
      "Step: 2209 of 5001.\n",
      "Step: 2210 of 5001.\n",
      "Generator model loss: 1.0651480317115785.\n",
      "Discriminator model loss real: 0.777810561656952.\n",
      "Discriminator model loss generated: 0.6073405265808105.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2211 of 5001.\n",
      "Step: 2212 of 5001.\n",
      "Step: 2213 of 5001.\n",
      "Step: 2214 of 5001.\n",
      "Step: 2215 of 5001.\n",
      "Step: 2216 of 5001.\n",
      "Step: 2217 of 5001.\n",
      "Step: 2218 of 5001.\n",
      "Step: 2219 of 5001.\n",
      "Step: 2220 of 5001.\n",
      "Generator model loss: 1.0601743102073669.\n",
      "Discriminator model loss real: 0.7890849262475967.\n",
      "Discriminator model loss generated: 0.6178647577762604.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2221 of 5001.\n",
      "Step: 2222 of 5001.\n",
      "Step: 2223 of 5001.\n",
      "Step: 2224 of 5001.\n",
      "Step: 2225 of 5001.\n",
      "Step: 2226 of 5001.\n",
      "Step: 2227 of 5001.\n",
      "Step: 2228 of 5001.\n",
      "Step: 2229 of 5001.\n",
      "Step: 2230 of 5001.\n",
      "Generator model loss: 1.0468352854251861.\n",
      "Discriminator model loss real: 0.7955348402261734.\n",
      "Discriminator model loss generated: 0.7011928558349609.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2231 of 5001.\n",
      "Step: 2232 of 5001.\n",
      "Step: 2233 of 5001.\n",
      "Step: 2234 of 5001.\n",
      "Step: 2235 of 5001.\n",
      "Step: 2236 of 5001.\n",
      "Step: 2237 of 5001.\n",
      "Step: 2238 of 5001.\n",
      "Step: 2239 of 5001.\n",
      "Step: 2240 of 5001.\n",
      "Generator model loss: 1.1012043237686158.\n",
      "Discriminator model loss real: 0.8139274209737778.\n",
      "Discriminator model loss generated: 0.6325998842716217.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2241 of 5001.\n",
      "Step: 2242 of 5001.\n",
      "Step: 2243 of 5001.\n",
      "Step: 2244 of 5001.\n",
      "Step: 2245 of 5001.\n",
      "Step: 2246 of 5001.\n",
      "Step: 2247 of 5001.\n",
      "Step: 2248 of 5001.\n",
      "Step: 2249 of 5001.\n",
      "Step: 2250 of 5001.\n",
      "Generator model loss: 1.0696775197982789.\n",
      "Discriminator model loss real: 0.8059345036745071.\n",
      "Discriminator model loss generated: 0.6390347421169281.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2251 of 5001.\n",
      "Step: 2252 of 5001.\n",
      "Step: 2253 of 5001.\n",
      "Step: 2254 of 5001.\n",
      "Step: 2255 of 5001.\n",
      "Step: 2256 of 5001.\n",
      "Step: 2257 of 5001.\n",
      "Step: 2258 of 5001.\n",
      "Step: 2259 of 5001.\n",
      "Step: 2260 of 5001.\n",
      "Generator model loss: 1.0970151603221894.\n",
      "Discriminator model loss real: 0.8076265275478363.\n",
      "Discriminator model loss generated: 0.6705358684062958.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2261 of 5001.\n",
      "Step: 2262 of 5001.\n",
      "Step: 2263 of 5001.\n",
      "Step: 2264 of 5001.\n",
      "Step: 2265 of 5001.\n",
      "Step: 2266 of 5001.\n",
      "Step: 2267 of 5001.\n",
      "Step: 2268 of 5001.\n",
      "Step: 2269 of 5001.\n",
      "Step: 2270 of 5001.\n",
      "Generator model loss: 1.0719500124454497.\n",
      "Discriminator model loss real: 0.8233159393072128.\n",
      "Discriminator model loss generated: 0.7554686903953552.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2271 of 5001.\n",
      "Step: 2272 of 5001.\n",
      "Step: 2273 of 5001.\n",
      "Step: 2274 of 5001.\n",
      "Step: 2275 of 5001.\n",
      "Step: 2276 of 5001.\n",
      "Step: 2277 of 5001.\n",
      "Step: 2278 of 5001.\n",
      "Step: 2279 of 5001.\n",
      "Step: 2280 of 5001.\n",
      "Generator model loss: 1.05356924533844.\n",
      "Discriminator model loss real: 0.8301366984844207.\n",
      "Discriminator model loss generated: 0.6327953577041626.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2281 of 5001.\n",
      "Step: 2282 of 5001.\n",
      "Step: 2283 of 5001.\n",
      "Step: 2284 of 5001.\n",
      "Step: 2285 of 5001.\n",
      "Step: 2286 of 5001.\n",
      "Step: 2287 of 5001.\n",
      "Step: 2288 of 5001.\n",
      "Step: 2289 of 5001.\n",
      "Step: 2290 of 5001.\n",
      "Generator model loss: 1.0818046927452087.\n",
      "Discriminator model loss real: 0.7566687136888504.\n",
      "Discriminator model loss generated: 0.570074874162674.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2291 of 5001.\n",
      "Step: 2292 of 5001.\n",
      "Step: 2293 of 5001.\n",
      "Step: 2294 of 5001.\n",
      "Step: 2295 of 5001.\n",
      "Step: 2296 of 5001.\n",
      "Step: 2297 of 5001.\n",
      "Step: 2298 of 5001.\n",
      "Step: 2299 of 5001.\n",
      "Step: 2300 of 5001.\n",
      "Generator model loss: 1.0478482961654663.\n",
      "Discriminator model loss real: 0.7795061856508255.\n",
      "Discriminator model loss generated: 0.600034487247467.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2301 of 5001.\n",
      "Step: 2302 of 5001.\n",
      "Step: 2303 of 5001.\n",
      "Step: 2304 of 5001.\n",
      "Step: 2305 of 5001.\n",
      "Step: 2306 of 5001.\n",
      "Step: 2307 of 5001.\n",
      "Step: 2308 of 5001.\n",
      "Step: 2309 of 5001.\n",
      "Step: 2310 of 5001.\n",
      "Generator model loss: 1.0765235543251037.\n",
      "Discriminator model loss real: 0.8188263833522796.\n",
      "Discriminator model loss generated: 0.6207283675670624.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2311 of 5001.\n",
      "Step: 2312 of 5001.\n",
      "Step: 2313 of 5001.\n",
      "Step: 2314 of 5001.\n",
      "Step: 2315 of 5001.\n",
      "Step: 2316 of 5001.\n",
      "Step: 2317 of 5001.\n",
      "Step: 2318 of 5001.\n",
      "Step: 2319 of 5001.\n",
      "Step: 2320 of 5001.\n",
      "Generator model loss: 1.0874119520187377.\n",
      "Discriminator model loss real: 0.7881210505962372.\n",
      "Discriminator model loss generated: 0.5965794324874878.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2321 of 5001.\n",
      "Step: 2322 of 5001.\n",
      "Step: 2323 of 5001.\n",
      "Step: 2324 of 5001.\n",
      "Step: 2325 of 5001.\n",
      "Step: 2326 of 5001.\n",
      "Step: 2327 of 5001.\n",
      "Step: 2328 of 5001.\n",
      "Step: 2329 of 5001.\n",
      "Step: 2330 of 5001.\n",
      "Generator model loss: 1.1025212407112122.\n",
      "Discriminator model loss real: 0.8181569606065751.\n",
      "Discriminator model loss generated: 0.5813846349716186.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2331 of 5001.\n",
      "Step: 2332 of 5001.\n",
      "Step: 2333 of 5001.\n",
      "Step: 2334 of 5001.\n",
      "Step: 2335 of 5001.\n",
      "Step: 2336 of 5001.\n",
      "Step: 2337 of 5001.\n",
      "Step: 2338 of 5001.\n",
      "Step: 2339 of 5001.\n",
      "Step: 2340 of 5001.\n",
      "Generator model loss: 1.0890166521072389.\n",
      "Discriminator model loss real: 0.8142123341560363.\n",
      "Discriminator model loss generated: 0.6368842720985413.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2341 of 5001.\n",
      "Step: 2342 of 5001.\n",
      "Step: 2343 of 5001.\n",
      "Step: 2344 of 5001.\n",
      "Step: 2345 of 5001.\n",
      "Step: 2346 of 5001.\n",
      "Step: 2347 of 5001.\n",
      "Step: 2348 of 5001.\n",
      "Step: 2349 of 5001.\n",
      "Step: 2350 of 5001.\n",
      "Generator model loss: 1.0803130388259887.\n",
      "Discriminator model loss real: 0.8141580432653427.\n",
      "Discriminator model loss generated: 0.6259048044681549.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2351 of 5001.\n",
      "Step: 2352 of 5001.\n",
      "Step: 2353 of 5001.\n",
      "Step: 2354 of 5001.\n",
      "Step: 2355 of 5001.\n",
      "Step: 2356 of 5001.\n",
      "Step: 2357 of 5001.\n",
      "Step: 2358 of 5001.\n",
      "Step: 2359 of 5001.\n",
      "Step: 2360 of 5001.\n",
      "Generator model loss: 1.0501443564891815.\n",
      "Discriminator model loss real: 0.774933859705925.\n",
      "Discriminator model loss generated: 0.588158929347992.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2361 of 5001.\n",
      "Step: 2362 of 5001.\n",
      "Step: 2363 of 5001.\n",
      "Step: 2364 of 5001.\n",
      "Step: 2365 of 5001.\n",
      "Step: 2366 of 5001.\n",
      "Step: 2367 of 5001.\n",
      "Step: 2368 of 5001.\n",
      "Step: 2369 of 5001.\n",
      "Step: 2370 of 5001.\n",
      "Generator model loss: 1.0637255787849427.\n",
      "Discriminator model loss real: 0.8109318107366562.\n",
      "Discriminator model loss generated: 0.6806964814662934.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2371 of 5001.\n",
      "Step: 2372 of 5001.\n",
      "Step: 2373 of 5001.\n",
      "Step: 2374 of 5001.\n",
      "Step: 2375 of 5001.\n",
      "Step: 2376 of 5001.\n",
      "Step: 2377 of 5001.\n",
      "Step: 2378 of 5001.\n",
      "Step: 2379 of 5001.\n",
      "Step: 2380 of 5001.\n",
      "Generator model loss: 1.0472913146018983.\n",
      "Discriminator model loss real: 0.7827378302812577.\n",
      "Discriminator model loss generated: 0.6335891127586365.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2381 of 5001.\n",
      "Step: 2382 of 5001.\n",
      "Step: 2383 of 5001.\n",
      "Step: 2384 of 5001.\n",
      "Step: 2385 of 5001.\n",
      "Step: 2386 of 5001.\n",
      "Step: 2387 of 5001.\n",
      "Step: 2388 of 5001.\n",
      "Step: 2389 of 5001.\n",
      "Step: 2390 of 5001.\n",
      "Generator model loss: 1.1038509488105774.\n",
      "Discriminator model loss real: 0.8171326279640198.\n",
      "Discriminator model loss generated: 0.6575050294399262.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2391 of 5001.\n",
      "Step: 2392 of 5001.\n",
      "Step: 2393 of 5001.\n",
      "Step: 2394 of 5001.\n",
      "Step: 2395 of 5001.\n",
      "Step: 2396 of 5001.\n",
      "Step: 2397 of 5001.\n",
      "Step: 2398 of 5001.\n",
      "Step: 2399 of 5001.\n",
      "Step: 2400 of 5001.\n",
      "Generator model loss: 1.0656216621398926.\n",
      "Discriminator model loss real: 0.7935975670814515.\n",
      "Discriminator model loss generated: 0.587817931175232.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2401 of 5001.\n",
      "Step: 2402 of 5001.\n",
      "Step: 2403 of 5001.\n",
      "Step: 2404 of 5001.\n",
      "Step: 2405 of 5001.\n",
      "Step: 2406 of 5001.\n",
      "Step: 2407 of 5001.\n",
      "Step: 2408 of 5001.\n",
      "Step: 2409 of 5001.\n",
      "Step: 2410 of 5001.\n",
      "Generator model loss: 1.048163366317749.\n",
      "Discriminator model loss real: 0.7958660542964935.\n",
      "Discriminator model loss generated: 0.6423748791217804.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2411 of 5001.\n",
      "Step: 2412 of 5001.\n",
      "Step: 2413 of 5001.\n",
      "Step: 2414 of 5001.\n",
      "Step: 2415 of 5001.\n",
      "Step: 2416 of 5001.\n",
      "Step: 2417 of 5001.\n",
      "Step: 2418 of 5001.\n",
      "Step: 2419 of 5001.\n",
      "Step: 2420 of 5001.\n",
      "Generator model loss: 1.0597204864025116.\n",
      "Discriminator model loss real: 0.7860144317150116.\n",
      "Discriminator model loss generated: 0.6537114918231964.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2421 of 5001.\n",
      "Step: 2422 of 5001.\n",
      "Step: 2423 of 5001.\n",
      "Step: 2424 of 5001.\n",
      "Step: 2425 of 5001.\n",
      "Step: 2426 of 5001.\n",
      "Step: 2427 of 5001.\n",
      "Step: 2428 of 5001.\n",
      "Step: 2429 of 5001.\n",
      "Step: 2430 of 5001.\n",
      "Generator model loss: 1.0667174816131593.\n",
      "Discriminator model loss real: 0.8094814598560334.\n",
      "Discriminator model loss generated: 0.6558170855045319.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2431 of 5001.\n",
      "Step: 2432 of 5001.\n",
      "Step: 2433 of 5001.\n",
      "Step: 2434 of 5001.\n",
      "Step: 2435 of 5001.\n",
      "Step: 2436 of 5001.\n",
      "Step: 2437 of 5001.\n",
      "Step: 2438 of 5001.\n",
      "Step: 2439 of 5001.\n",
      "Step: 2440 of 5001.\n",
      "Generator model loss: 1.0820255279541016.\n",
      "Discriminator model loss real: 0.7952022582292557.\n",
      "Discriminator model loss generated: 0.660645353794098.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2441 of 5001.\n",
      "Step: 2442 of 5001.\n",
      "Step: 2443 of 5001.\n",
      "Step: 2444 of 5001.\n",
      "Step: 2445 of 5001.\n",
      "Step: 2446 of 5001.\n",
      "Step: 2447 of 5001.\n",
      "Step: 2448 of 5001.\n",
      "Step: 2449 of 5001.\n",
      "Step: 2450 of 5001.\n",
      "Generator model loss: 1.0282757759094239.\n",
      "Discriminator model loss real: 0.7977351069450378.\n",
      "Discriminator model loss generated: 0.6723914444446564.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2451 of 5001.\n",
      "Step: 2452 of 5001.\n",
      "Step: 2453 of 5001.\n",
      "Step: 2454 of 5001.\n",
      "Step: 2455 of 5001.\n",
      "Step: 2456 of 5001.\n",
      "Step: 2457 of 5001.\n",
      "Step: 2458 of 5001.\n",
      "Step: 2459 of 5001.\n",
      "Step: 2460 of 5001.\n",
      "Generator model loss: 1.0537159442901611.\n",
      "Discriminator model loss real: 0.7531772702932358.\n",
      "Discriminator model loss generated: 0.6656986892223358.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2461 of 5001.\n",
      "Step: 2462 of 5001.\n",
      "Step: 2463 of 5001.\n",
      "Step: 2464 of 5001.\n",
      "Step: 2465 of 5001.\n",
      "Step: 2466 of 5001.\n",
      "Step: 2467 of 5001.\n",
      "Step: 2468 of 5001.\n",
      "Step: 2469 of 5001.\n",
      "Step: 2470 of 5001.\n",
      "Generator model loss: 1.0960461854934693.\n",
      "Discriminator model loss real: 0.8314330637454986.\n",
      "Discriminator model loss generated: 0.7032466053962707.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2471 of 5001.\n",
      "Step: 2472 of 5001.\n",
      "Step: 2473 of 5001.\n",
      "Step: 2474 of 5001.\n",
      "Step: 2475 of 5001.\n",
      "Step: 2476 of 5001.\n",
      "Step: 2477 of 5001.\n",
      "Step: 2478 of 5001.\n",
      "Step: 2479 of 5001.\n",
      "Step: 2480 of 5001.\n",
      "Generator model loss: 1.0921613037586213.\n",
      "Discriminator model loss real: 0.7574243456125259.\n",
      "Discriminator model loss generated: 0.6499048411846161.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2481 of 5001.\n",
      "Step: 2482 of 5001.\n",
      "Step: 2483 of 5001.\n",
      "Step: 2484 of 5001.\n",
      "Step: 2485 of 5001.\n",
      "Step: 2486 of 5001.\n",
      "Step: 2487 of 5001.\n",
      "Step: 2488 of 5001.\n",
      "Step: 2489 of 5001.\n",
      "Step: 2490 of 5001.\n",
      "Generator model loss: 1.0737958431243897.\n",
      "Discriminator model loss real: 0.8083029210567474.\n",
      "Discriminator model loss generated: 0.5957305252552032.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2491 of 5001.\n",
      "Step: 2492 of 5001.\n",
      "Step: 2493 of 5001.\n",
      "Step: 2494 of 5001.\n",
      "Step: 2495 of 5001.\n",
      "Step: 2496 of 5001.\n",
      "Step: 2497 of 5001.\n",
      "Step: 2498 of 5001.\n",
      "Step: 2499 of 5001.\n",
      "Step: 2500 of 5001.\n",
      "Generator model loss: 1.0760574042797089.\n",
      "Discriminator model loss real: 0.7768992632627487.\n",
      "Discriminator model loss generated: 0.6277638256549836.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2501 of 5001.\n",
      "Step: 2502 of 5001.\n",
      "Step: 2503 of 5001.\n",
      "Step: 2504 of 5001.\n",
      "Step: 2505 of 5001.\n",
      "Step: 2506 of 5001.\n",
      "Step: 2507 of 5001.\n",
      "Step: 2508 of 5001.\n",
      "Step: 2509 of 5001.\n",
      "Step: 2510 of 5001.\n",
      "Generator model loss: 1.0635614037513732.\n",
      "Discriminator model loss real: 0.7975022852420807.\n",
      "Discriminator model loss generated: 0.616821026802063.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2511 of 5001.\n",
      "Step: 2512 of 5001.\n",
      "Step: 2513 of 5001.\n",
      "Step: 2514 of 5001.\n",
      "Step: 2515 of 5001.\n",
      "Step: 2516 of 5001.\n",
      "Step: 2517 of 5001.\n",
      "Step: 2518 of 5001.\n",
      "Step: 2519 of 5001.\n",
      "Step: 2520 of 5001.\n",
      "Generator model loss: 1.06485076546669.\n",
      "Discriminator model loss real: 0.8149713993072509.\n",
      "Discriminator model loss generated: 0.5928995728492736.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2521 of 5001.\n",
      "Step: 2522 of 5001.\n",
      "Step: 2523 of 5001.\n",
      "Step: 2524 of 5001.\n",
      "Step: 2525 of 5001.\n",
      "Step: 2526 of 5001.\n",
      "Step: 2527 of 5001.\n",
      "Step: 2528 of 5001.\n",
      "Step: 2529 of 5001.\n",
      "Step: 2530 of 5001.\n",
      "Generator model loss: 1.0831815898418427.\n",
      "Discriminator model loss real: 0.788945558667183.\n",
      "Discriminator model loss generated: 0.6952416062355041.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2531 of 5001.\n",
      "Step: 2532 of 5001.\n",
      "Step: 2533 of 5001.\n",
      "Step: 2534 of 5001.\n",
      "Step: 2535 of 5001.\n",
      "Step: 2536 of 5001.\n",
      "Step: 2537 of 5001.\n",
      "Step: 2538 of 5001.\n",
      "Step: 2539 of 5001.\n",
      "Step: 2540 of 5001.\n",
      "Generator model loss: 1.069430661201477.\n",
      "Discriminator model loss real: 0.7937903046607971.\n",
      "Discriminator model loss generated: 0.6656783878803253.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2541 of 5001.\n",
      "Step: 2542 of 5001.\n",
      "Step: 2543 of 5001.\n",
      "Step: 2544 of 5001.\n",
      "Step: 2545 of 5001.\n",
      "Step: 2546 of 5001.\n",
      "Step: 2547 of 5001.\n",
      "Step: 2548 of 5001.\n",
      "Step: 2549 of 5001.\n",
      "Step: 2550 of 5001.\n",
      "Generator model loss: 1.0812107980251313.\n",
      "Discriminator model loss real: 0.797451788187027.\n",
      "Discriminator model loss generated: 0.6961030125617981.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2551 of 5001.\n",
      "Step: 2552 of 5001.\n",
      "Step: 2553 of 5001.\n",
      "Step: 2554 of 5001.\n",
      "Step: 2555 of 5001.\n",
      "Step: 2556 of 5001.\n",
      "Step: 2557 of 5001.\n",
      "Step: 2558 of 5001.\n",
      "Step: 2559 of 5001.\n",
      "Step: 2560 of 5001.\n",
      "Generator model loss: 1.0522121727466582.\n",
      "Discriminator model loss real: 0.7792235106229782.\n",
      "Discriminator model loss generated: 0.6209905087947846.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2561 of 5001.\n",
      "Step: 2562 of 5001.\n",
      "Step: 2563 of 5001.\n",
      "Step: 2564 of 5001.\n",
      "Step: 2565 of 5001.\n",
      "Step: 2566 of 5001.\n",
      "Step: 2567 of 5001.\n",
      "Step: 2568 of 5001.\n",
      "Step: 2569 of 5001.\n",
      "Step: 2570 of 5001.\n",
      "Generator model loss: 1.0959041833877563.\n",
      "Discriminator model loss real: 0.7742298901081085.\n",
      "Discriminator model loss generated: 0.6010085582733155.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 2571 of 5001.\n",
      "Step: 2572 of 5001.\n",
      "Step: 2573 of 5001.\n",
      "Step: 2574 of 5001.\n",
      "Step: 2575 of 5001.\n",
      "Step: 2576 of 5001.\n",
      "Step: 2577 of 5001.\n",
      "Step: 2578 of 5001.\n",
      "Step: 2579 of 5001.\n",
      "Step: 2580 of 5001.\n",
      "Generator model loss: 1.0692074775695801.\n",
      "Discriminator model loss real: 0.8156565725803375.\n",
      "Discriminator model loss generated: 0.6566425621509552.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2581 of 5001.\n",
      "Step: 2582 of 5001.\n",
      "Step: 2583 of 5001.\n",
      "Step: 2584 of 5001.\n",
      "Step: 2585 of 5001.\n",
      "Step: 2586 of 5001.\n",
      "Step: 2587 of 5001.\n",
      "Step: 2588 of 5001.\n",
      "Step: 2589 of 5001.\n",
      "Step: 2590 of 5001.\n",
      "Generator model loss: 1.0359568655490876.\n",
      "Discriminator model loss real: 0.7630943864583969.\n",
      "Discriminator model loss generated: 0.6838100910186767.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2591 of 5001.\n",
      "Step: 2592 of 5001.\n",
      "Step: 2593 of 5001.\n",
      "Step: 2594 of 5001.\n",
      "Step: 2595 of 5001.\n",
      "Step: 2596 of 5001.\n",
      "Step: 2597 of 5001.\n",
      "Step: 2598 of 5001.\n",
      "Step: 2599 of 5001.\n",
      "Step: 2600 of 5001.\n",
      "Generator model loss: 1.0722370386123656.\n",
      "Discriminator model loss real: 0.7520139336585998.\n",
      "Discriminator model loss generated: 0.6682696878910065.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2601 of 5001.\n",
      "Step: 2602 of 5001.\n",
      "Step: 2603 of 5001.\n",
      "Step: 2604 of 5001.\n",
      "Step: 2605 of 5001.\n",
      "Step: 2606 of 5001.\n",
      "Step: 2607 of 5001.\n",
      "Step: 2608 of 5001.\n",
      "Step: 2609 of 5001.\n",
      "Step: 2610 of 5001.\n",
      "Generator model loss: 1.0256813943386078.\n",
      "Discriminator model loss real: 0.8339888632297516.\n",
      "Discriminator model loss generated: 0.6445644974708558.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2611 of 5001.\n",
      "Step: 2612 of 5001.\n",
      "Step: 2613 of 5001.\n",
      "Step: 2614 of 5001.\n",
      "Step: 2615 of 5001.\n",
      "Step: 2616 of 5001.\n",
      "Step: 2617 of 5001.\n",
      "Step: 2618 of 5001.\n",
      "Step: 2619 of 5001.\n",
      "Step: 2620 of 5001.\n",
      "Generator model loss: 1.0463713526725769.\n",
      "Discriminator model loss real: 0.8294502556324005.\n",
      "Discriminator model loss generated: 0.6631449639797211.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2621 of 5001.\n",
      "Step: 2622 of 5001.\n",
      "Step: 2623 of 5001.\n",
      "Step: 2624 of 5001.\n",
      "Step: 2625 of 5001.\n",
      "Step: 2626 of 5001.\n",
      "Step: 2627 of 5001.\n",
      "Step: 2628 of 5001.\n",
      "Step: 2629 of 5001.\n",
      "Step: 2630 of 5001.\n",
      "Generator model loss: 1.0374755442142487.\n",
      "Discriminator model loss real: 0.8220362603664398.\n",
      "Discriminator model loss generated: 0.6811395943164825.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2631 of 5001.\n",
      "Step: 2632 of 5001.\n",
      "Step: 2633 of 5001.\n",
      "Step: 2634 of 5001.\n",
      "Step: 2635 of 5001.\n",
      "Step: 2636 of 5001.\n",
      "Step: 2637 of 5001.\n",
      "Step: 2638 of 5001.\n",
      "Step: 2639 of 5001.\n",
      "Step: 2640 of 5001.\n",
      "Generator model loss: 1.04009068608284.\n",
      "Discriminator model loss real: 0.7993882894515991.\n",
      "Discriminator model loss generated: 0.599970144033432.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2641 of 5001.\n",
      "Step: 2642 of 5001.\n",
      "Step: 2643 of 5001.\n",
      "Step: 2644 of 5001.\n",
      "Step: 2645 of 5001.\n",
      "Step: 2646 of 5001.\n",
      "Step: 2647 of 5001.\n",
      "Step: 2648 of 5001.\n",
      "Step: 2649 of 5001.\n",
      "Step: 2650 of 5001.\n",
      "Generator model loss: 1.0205713987350464.\n",
      "Discriminator model loss real: 0.7945306181907654.\n",
      "Discriminator model loss generated: 0.7177985608577728.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2651 of 5001.\n",
      "Step: 2652 of 5001.\n",
      "Step: 2653 of 5001.\n",
      "Step: 2654 of 5001.\n",
      "Step: 2655 of 5001.\n",
      "Step: 2656 of 5001.\n",
      "Step: 2657 of 5001.\n",
      "Step: 2658 of 5001.\n",
      "Step: 2659 of 5001.\n",
      "Step: 2660 of 5001.\n",
      "Generator model loss: 1.0345421850681304.\n",
      "Discriminator model loss real: 0.7426271736621857.\n",
      "Discriminator model loss generated: 0.6835046410560608.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2661 of 5001.\n",
      "Step: 2662 of 5001.\n",
      "Step: 2663 of 5001.\n",
      "Step: 2664 of 5001.\n",
      "Step: 2665 of 5001.\n",
      "Step: 2666 of 5001.\n",
      "Step: 2667 of 5001.\n",
      "Step: 2668 of 5001.\n",
      "Step: 2669 of 5001.\n",
      "Step: 2670 of 5001.\n",
      "Generator model loss: 1.0539595305919647.\n",
      "Discriminator model loss real: 0.779461395740509.\n",
      "Discriminator model loss generated: 0.6628422200679779.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2671 of 5001.\n",
      "Step: 2672 of 5001.\n",
      "Step: 2673 of 5001.\n",
      "Step: 2674 of 5001.\n",
      "Step: 2675 of 5001.\n",
      "Step: 2676 of 5001.\n",
      "Step: 2677 of 5001.\n",
      "Step: 2678 of 5001.\n",
      "Step: 2679 of 5001.\n",
      "Step: 2680 of 5001.\n",
      "Generator model loss: 1.0696599543094636.\n",
      "Discriminator model loss real: 0.7612614661455155.\n",
      "Discriminator model loss generated: 0.667173159122467.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2681 of 5001.\n",
      "Step: 2682 of 5001.\n",
      "Step: 2683 of 5001.\n",
      "Step: 2684 of 5001.\n",
      "Step: 2685 of 5001.\n",
      "Step: 2686 of 5001.\n",
      "Step: 2687 of 5001.\n",
      "Step: 2688 of 5001.\n",
      "Step: 2689 of 5001.\n",
      "Step: 2690 of 5001.\n",
      "Generator model loss: 1.0299248099327087.\n",
      "Discriminator model loss real: 0.7568310528993607.\n",
      "Discriminator model loss generated: 0.6252944946289063.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2691 of 5001.\n",
      "Step: 2692 of 5001.\n",
      "Step: 2693 of 5001.\n",
      "Step: 2694 of 5001.\n",
      "Step: 2695 of 5001.\n",
      "Step: 2696 of 5001.\n",
      "Step: 2697 of 5001.\n",
      "Step: 2698 of 5001.\n",
      "Step: 2699 of 5001.\n",
      "Step: 2700 of 5001.\n",
      "Generator model loss: 1.0389471471309661.\n",
      "Discriminator model loss real: 0.8049695372581482.\n",
      "Discriminator model loss generated: 0.6511011242866516.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 2701 of 5001.\n",
      "Step: 2702 of 5001.\n",
      "Step: 2703 of 5001.\n",
      "Step: 2704 of 5001.\n",
      "Step: 2705 of 5001.\n",
      "Step: 2706 of 5001.\n",
      "Step: 2707 of 5001.\n",
      "Step: 2708 of 5001.\n",
      "Step: 2709 of 5001.\n",
      "Step: 2710 of 5001.\n",
      "Generator model loss: 1.0390882611274719.\n",
      "Discriminator model loss real: 0.747396719455719.\n",
      "Discriminator model loss generated: 0.6457183361053467.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2711 of 5001.\n",
      "Step: 2712 of 5001.\n",
      "Step: 2713 of 5001.\n",
      "Step: 2714 of 5001.\n",
      "Step: 2715 of 5001.\n",
      "Step: 2716 of 5001.\n",
      "Step: 2717 of 5001.\n",
      "Step: 2718 of 5001.\n",
      "Step: 2719 of 5001.\n",
      "Step: 2720 of 5001.\n",
      "Generator model loss: 1.031590211391449.\n",
      "Discriminator model loss real: 0.7378687530755996.\n",
      "Discriminator model loss generated: 0.7344315648078918.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 2721 of 5001.\n",
      "Step: 2722 of 5001.\n",
      "Step: 2723 of 5001.\n",
      "Step: 2724 of 5001.\n",
      "Step: 2725 of 5001.\n",
      "Step: 2726 of 5001.\n",
      "Step: 2727 of 5001.\n",
      "Step: 2728 of 5001.\n",
      "Step: 2729 of 5001.\n",
      "Step: 2730 of 5001.\n",
      "Generator model loss: 1.0378234267234803.\n",
      "Discriminator model loss real: 0.7864932686090469.\n",
      "Discriminator model loss generated: 0.6542977750301361.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2731 of 5001.\n",
      "Step: 2732 of 5001.\n",
      "Step: 2733 of 5001.\n",
      "Step: 2734 of 5001.\n",
      "Step: 2735 of 5001.\n",
      "Step: 2736 of 5001.\n",
      "Step: 2737 of 5001.\n",
      "Step: 2738 of 5001.\n",
      "Step: 2739 of 5001.\n",
      "Step: 2740 of 5001.\n",
      "Generator model loss: 1.0134324789047242.\n",
      "Discriminator model loss real: 0.7762205064296722.\n",
      "Discriminator model loss generated: 0.6762563824653626.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2741 of 5001.\n",
      "Step: 2742 of 5001.\n",
      "Step: 2743 of 5001.\n",
      "Step: 2744 of 5001.\n",
      "Step: 2745 of 5001.\n",
      "Step: 2746 of 5001.\n",
      "Step: 2747 of 5001.\n",
      "Step: 2748 of 5001.\n",
      "Step: 2749 of 5001.\n",
      "Step: 2750 of 5001.\n",
      "Generator model loss: 1.0367960989475251.\n",
      "Discriminator model loss real: 0.7753423392772675.\n",
      "Discriminator model loss generated: 0.6139549672603607.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2751 of 5001.\n",
      "Step: 2752 of 5001.\n",
      "Step: 2753 of 5001.\n",
      "Step: 2754 of 5001.\n",
      "Step: 2755 of 5001.\n",
      "Step: 2756 of 5001.\n",
      "Step: 2757 of 5001.\n",
      "Step: 2758 of 5001.\n",
      "Step: 2759 of 5001.\n",
      "Step: 2760 of 5001.\n",
      "Generator model loss: 1.0274767100811004.\n",
      "Discriminator model loss real: 0.806540846824646.\n",
      "Discriminator model loss generated: 0.663637501001358.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 2761 of 5001.\n",
      "Step: 2762 of 5001.\n",
      "Step: 2763 of 5001.\n",
      "Step: 2764 of 5001.\n",
      "Step: 2765 of 5001.\n",
      "Step: 2766 of 5001.\n",
      "Step: 2767 of 5001.\n",
      "Step: 2768 of 5001.\n",
      "Step: 2769 of 5001.\n",
      "Step: 2770 of 5001.\n",
      "Generator model loss: 1.0305391430854798.\n",
      "Discriminator model loss real: 0.8112647593021393.\n",
      "Discriminator model loss generated: 0.6185056209564209.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2771 of 5001.\n",
      "Step: 2772 of 5001.\n",
      "Step: 2773 of 5001.\n",
      "Step: 2774 of 5001.\n",
      "Step: 2775 of 5001.\n",
      "Step: 2776 of 5001.\n",
      "Step: 2777 of 5001.\n",
      "Step: 2778 of 5001.\n",
      "Step: 2779 of 5001.\n",
      "Step: 2780 of 5001.\n",
      "Generator model loss: 1.0399151563644409.\n",
      "Discriminator model loss real: 0.7369954735040665.\n",
      "Discriminator model loss generated: 0.662822550535202.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2781 of 5001.\n",
      "Step: 2782 of 5001.\n",
      "Step: 2783 of 5001.\n",
      "Step: 2784 of 5001.\n",
      "Step: 2785 of 5001.\n",
      "Step: 2786 of 5001.\n",
      "Step: 2787 of 5001.\n",
      "Step: 2788 of 5001.\n",
      "Step: 2789 of 5001.\n",
      "Step: 2790 of 5001.\n",
      "Generator model loss: 1.0196000576019286.\n",
      "Discriminator model loss real: 0.7432087928056716.\n",
      "Discriminator model loss generated: 0.7333147466182709.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2791 of 5001.\n",
      "Step: 2792 of 5001.\n",
      "Step: 2793 of 5001.\n",
      "Step: 2794 of 5001.\n",
      "Step: 2795 of 5001.\n",
      "Step: 2796 of 5001.\n",
      "Step: 2797 of 5001.\n",
      "Step: 2798 of 5001.\n",
      "Step: 2799 of 5001.\n",
      "Step: 2800 of 5001.\n",
      "Generator model loss: 1.0001157522201538.\n",
      "Discriminator model loss real: 0.7702187061309814.\n",
      "Discriminator model loss generated: 0.6193491637706756.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2801 of 5001.\n",
      "Step: 2802 of 5001.\n",
      "Step: 2803 of 5001.\n",
      "Step: 2804 of 5001.\n",
      "Step: 2805 of 5001.\n",
      "Step: 2806 of 5001.\n",
      "Step: 2807 of 5001.\n",
      "Step: 2808 of 5001.\n",
      "Step: 2809 of 5001.\n",
      "Step: 2810 of 5001.\n",
      "Generator model loss: 1.0205899834632874.\n",
      "Discriminator model loss real: 0.7519178241491318.\n",
      "Discriminator model loss generated: 0.6749850332736969.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2811 of 5001.\n",
      "Step: 2812 of 5001.\n",
      "Step: 2813 of 5001.\n",
      "Step: 2814 of 5001.\n",
      "Step: 2815 of 5001.\n",
      "Step: 2816 of 5001.\n",
      "Step: 2817 of 5001.\n",
      "Step: 2818 of 5001.\n",
      "Step: 2819 of 5001.\n",
      "Step: 2820 of 5001.\n",
      "Generator model loss: 1.0485221862792968.\n",
      "Discriminator model loss real: 0.7988458633422851.\n",
      "Discriminator model loss generated: 0.606347668170929.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2821 of 5001.\n",
      "Step: 2822 of 5001.\n",
      "Step: 2823 of 5001.\n",
      "Step: 2824 of 5001.\n",
      "Step: 2825 of 5001.\n",
      "Step: 2826 of 5001.\n",
      "Step: 2827 of 5001.\n",
      "Step: 2828 of 5001.\n",
      "Step: 2829 of 5001.\n",
      "Step: 2830 of 5001.\n",
      "Generator model loss: 1.00738183259964.\n",
      "Discriminator model loss real: 0.7483623713254929.\n",
      "Discriminator model loss generated: 0.6595583200454712.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2831 of 5001.\n",
      "Step: 2832 of 5001.\n",
      "Step: 2833 of 5001.\n",
      "Step: 2834 of 5001.\n",
      "Step: 2835 of 5001.\n",
      "Step: 2836 of 5001.\n",
      "Step: 2837 of 5001.\n",
      "Step: 2838 of 5001.\n",
      "Step: 2839 of 5001.\n",
      "Step: 2840 of 5001.\n",
      "Generator model loss: 1.019015383720398.\n",
      "Discriminator model loss real: 0.7863856762647629.\n",
      "Discriminator model loss generated: 0.6443441152572632.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2841 of 5001.\n",
      "Step: 2842 of 5001.\n",
      "Step: 2843 of 5001.\n",
      "Step: 2844 of 5001.\n",
      "Step: 2845 of 5001.\n",
      "Step: 2846 of 5001.\n",
      "Step: 2847 of 5001.\n",
      "Step: 2848 of 5001.\n",
      "Step: 2849 of 5001.\n",
      "Step: 2850 of 5001.\n",
      "Generator model loss: 1.0285832703113555.\n",
      "Discriminator model loss real: 0.8024848878383637.\n",
      "Discriminator model loss generated: 0.6635737597942353.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2851 of 5001.\n",
      "Step: 2852 of 5001.\n",
      "Step: 2853 of 5001.\n",
      "Step: 2854 of 5001.\n",
      "Step: 2855 of 5001.\n",
      "Step: 2856 of 5001.\n",
      "Step: 2857 of 5001.\n",
      "Step: 2858 of 5001.\n",
      "Step: 2859 of 5001.\n",
      "Step: 2860 of 5001.\n",
      "Generator model loss: 1.0289533615112305.\n",
      "Discriminator model loss real: 0.7623954206705094.\n",
      "Discriminator model loss generated: 0.595124113559723.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2861 of 5001.\n",
      "Step: 2862 of 5001.\n",
      "Step: 2863 of 5001.\n",
      "Step: 2864 of 5001.\n",
      "Step: 2865 of 5001.\n",
      "Step: 2866 of 5001.\n",
      "Step: 2867 of 5001.\n",
      "Step: 2868 of 5001.\n",
      "Step: 2869 of 5001.\n",
      "Step: 2870 of 5001.\n",
      "Generator model loss: 1.0126112580299378.\n",
      "Discriminator model loss real: 0.7592805743217468.\n",
      "Discriminator model loss generated: 0.6539684712886811.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2871 of 5001.\n",
      "Step: 2872 of 5001.\n",
      "Step: 2873 of 5001.\n",
      "Step: 2874 of 5001.\n",
      "Step: 2875 of 5001.\n",
      "Step: 2876 of 5001.\n",
      "Step: 2877 of 5001.\n",
      "Step: 2878 of 5001.\n",
      "Step: 2879 of 5001.\n",
      "Step: 2880 of 5001.\n",
      "Generator model loss: 1.0043990075588227.\n",
      "Discriminator model loss real: 0.7932231545448303.\n",
      "Discriminator model loss generated: 0.6299280166625977.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2881 of 5001.\n",
      "Step: 2882 of 5001.\n",
      "Step: 2883 of 5001.\n",
      "Step: 2884 of 5001.\n",
      "Step: 2885 of 5001.\n",
      "Step: 2886 of 5001.\n",
      "Step: 2887 of 5001.\n",
      "Step: 2888 of 5001.\n",
      "Step: 2889 of 5001.\n",
      "Step: 2890 of 5001.\n",
      "Generator model loss: 1.0144806921482086.\n",
      "Discriminator model loss real: 0.7623288333415985.\n",
      "Discriminator model loss generated: 0.6646147727966308.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2891 of 5001.\n",
      "Step: 2892 of 5001.\n",
      "Step: 2893 of 5001.\n",
      "Step: 2894 of 5001.\n",
      "Step: 2895 of 5001.\n",
      "Step: 2896 of 5001.\n",
      "Step: 2897 of 5001.\n",
      "Step: 2898 of 5001.\n",
      "Step: 2899 of 5001.\n",
      "Step: 2900 of 5001.\n",
      "Generator model loss: 1.0510737001895905.\n",
      "Discriminator model loss real: 0.8354082196950913.\n",
      "Discriminator model loss generated: 0.6492768466472626.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2901 of 5001.\n",
      "Step: 2902 of 5001.\n",
      "Step: 2903 of 5001.\n",
      "Step: 2904 of 5001.\n",
      "Step: 2905 of 5001.\n",
      "Step: 2906 of 5001.\n",
      "Step: 2907 of 5001.\n",
      "Step: 2908 of 5001.\n",
      "Step: 2909 of 5001.\n",
      "Step: 2910 of 5001.\n",
      "Generator model loss: 1.0169432640075684.\n",
      "Discriminator model loss real: 0.7403637647628785.\n",
      "Discriminator model loss generated: 0.7202087819576264.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2911 of 5001.\n",
      "Step: 2912 of 5001.\n",
      "Step: 2913 of 5001.\n",
      "Step: 2914 of 5001.\n",
      "Step: 2915 of 5001.\n",
      "Step: 2916 of 5001.\n",
      "Step: 2917 of 5001.\n",
      "Step: 2918 of 5001.\n",
      "Step: 2919 of 5001.\n",
      "Step: 2920 of 5001.\n",
      "Generator model loss: 1.1000629127025605.\n",
      "Discriminator model loss real: 0.7696326434612274.\n",
      "Discriminator model loss generated: 0.6226092934608459.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2921 of 5001.\n",
      "Step: 2922 of 5001.\n",
      "Step: 2923 of 5001.\n",
      "Step: 2924 of 5001.\n",
      "Step: 2925 of 5001.\n",
      "Step: 2926 of 5001.\n",
      "Step: 2927 of 5001.\n",
      "Step: 2928 of 5001.\n",
      "Step: 2929 of 5001.\n",
      "Step: 2930 of 5001.\n",
      "Generator model loss: 1.0022175371646882.\n",
      "Discriminator model loss real: 0.7882599353790283.\n",
      "Discriminator model loss generated: 0.6814748406410217.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2931 of 5001.\n",
      "Step: 2932 of 5001.\n",
      "Step: 2933 of 5001.\n",
      "Step: 2934 of 5001.\n",
      "Step: 2935 of 5001.\n",
      "Step: 2936 of 5001.\n",
      "Step: 2937 of 5001.\n",
      "Step: 2938 of 5001.\n",
      "Step: 2939 of 5001.\n",
      "Step: 2940 of 5001.\n",
      "Generator model loss: 0.9968538582324982.\n",
      "Discriminator model loss real: 0.7974483639001846.\n",
      "Discriminator model loss generated: 0.6695384740829468.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2941 of 5001.\n",
      "Step: 2942 of 5001.\n",
      "Step: 2943 of 5001.\n",
      "Step: 2944 of 5001.\n",
      "Step: 2945 of 5001.\n",
      "Step: 2946 of 5001.\n",
      "Step: 2947 of 5001.\n",
      "Step: 2948 of 5001.\n",
      "Step: 2949 of 5001.\n",
      "Step: 2950 of 5001.\n",
      "Generator model loss: 1.0223743140697479.\n",
      "Discriminator model loss real: 0.8066979020833969.\n",
      "Discriminator model loss generated: 0.6864541590213775.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2951 of 5001.\n",
      "Step: 2952 of 5001.\n",
      "Step: 2953 of 5001.\n",
      "Step: 2954 of 5001.\n",
      "Step: 2955 of 5001.\n",
      "Step: 2956 of 5001.\n",
      "Step: 2957 of 5001.\n",
      "Step: 2958 of 5001.\n",
      "Step: 2959 of 5001.\n",
      "Step: 2960 of 5001.\n",
      "Generator model loss: 1.0160885751247406.\n",
      "Discriminator model loss real: 0.7856550246477128.\n",
      "Discriminator model loss generated: 0.6809571146965027.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 2961 of 5001.\n",
      "Step: 2962 of 5001.\n",
      "Step: 2963 of 5001.\n",
      "Step: 2964 of 5001.\n",
      "Step: 2965 of 5001.\n",
      "Step: 2966 of 5001.\n",
      "Step: 2967 of 5001.\n",
      "Step: 2968 of 5001.\n",
      "Step: 2969 of 5001.\n",
      "Step: 2970 of 5001.\n",
      "Generator model loss: 1.0028967201709746.\n",
      "Discriminator model loss real: 0.7855374932289123.\n",
      "Discriminator model loss generated: 0.65440074801445.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 2971 of 5001.\n",
      "Step: 2972 of 5001.\n",
      "Step: 2973 of 5001.\n",
      "Step: 2974 of 5001.\n",
      "Step: 2975 of 5001.\n",
      "Step: 2976 of 5001.\n",
      "Step: 2977 of 5001.\n",
      "Step: 2978 of 5001.\n",
      "Step: 2979 of 5001.\n",
      "Step: 2980 of 5001.\n",
      "Generator model loss: 0.9989883661270141.\n",
      "Discriminator model loss real: 0.7859722942113876.\n",
      "Discriminator model loss generated: 0.7139841973781585.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2981 of 5001.\n",
      "Step: 2982 of 5001.\n",
      "Step: 2983 of 5001.\n",
      "Step: 2984 of 5001.\n",
      "Step: 2985 of 5001.\n",
      "Step: 2986 of 5001.\n",
      "Step: 2987 of 5001.\n",
      "Step: 2988 of 5001.\n",
      "Step: 2989 of 5001.\n",
      "Step: 2990 of 5001.\n",
      "Generator model loss: 0.9976454138755798.\n",
      "Discriminator model loss real: 0.7807832270860672.\n",
      "Discriminator model loss generated: 0.6016034185886383.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 2991 of 5001.\n",
      "Step: 2992 of 5001.\n",
      "Step: 2993 of 5001.\n",
      "Step: 2994 of 5001.\n",
      "Step: 2995 of 5001.\n",
      "Step: 2996 of 5001.\n",
      "Step: 2997 of 5001.\n",
      "Step: 2998 of 5001.\n",
      "Step: 2999 of 5001.\n",
      "Step: 3000 of 5001.\n",
      "Generator model loss: 1.0340635299682617.\n",
      "Discriminator model loss real: 0.7936816334724426.\n",
      "Discriminator model loss generated: 0.6743550181388855.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3001 of 5001.\n",
      "Step: 3002 of 5001.\n",
      "Step: 3003 of 5001.\n",
      "Step: 3004 of 5001.\n",
      "Step: 3005 of 5001.\n",
      "Step: 3006 of 5001.\n",
      "Step: 3007 of 5001.\n",
      "Step: 3008 of 5001.\n",
      "Step: 3009 of 5001.\n",
      "Step: 3010 of 5001.\n",
      "Generator model loss: 1.0090855181217193.\n",
      "Discriminator model loss real: 0.7531979769468308.\n",
      "Discriminator model loss generated: 0.6640628457069397.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3011 of 5001.\n",
      "Step: 3012 of 5001.\n",
      "Step: 3013 of 5001.\n",
      "Step: 3014 of 5001.\n",
      "Step: 3015 of 5001.\n",
      "Step: 3016 of 5001.\n",
      "Step: 3017 of 5001.\n",
      "Step: 3018 of 5001.\n",
      "Step: 3019 of 5001.\n",
      "Step: 3020 of 5001.\n",
      "Generator model loss: 1.0021609485149383.\n",
      "Discriminator model loss real: 0.8038090288639068.\n",
      "Discriminator model loss generated: 0.6740037798881531.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3021 of 5001.\n",
      "Step: 3022 of 5001.\n",
      "Step: 3023 of 5001.\n",
      "Step: 3024 of 5001.\n",
      "Step: 3025 of 5001.\n",
      "Step: 3026 of 5001.\n",
      "Step: 3027 of 5001.\n",
      "Step: 3028 of 5001.\n",
      "Step: 3029 of 5001.\n",
      "Step: 3030 of 5001.\n",
      "Generator model loss: 1.0242284774780273.\n",
      "Discriminator model loss real: 0.746326008439064.\n",
      "Discriminator model loss generated: 0.663434875011444.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3031 of 5001.\n",
      "Step: 3032 of 5001.\n",
      "Step: 3033 of 5001.\n",
      "Step: 3034 of 5001.\n",
      "Step: 3035 of 5001.\n",
      "Step: 3036 of 5001.\n",
      "Step: 3037 of 5001.\n",
      "Step: 3038 of 5001.\n",
      "Step: 3039 of 5001.\n",
      "Step: 3040 of 5001.\n",
      "Generator model loss: 1.0093728065490724.\n",
      "Discriminator model loss real: 0.8127387374639511.\n",
      "Discriminator model loss generated: 0.7224809527397156.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3041 of 5001.\n",
      "Step: 3042 of 5001.\n",
      "Step: 3043 of 5001.\n",
      "Step: 3044 of 5001.\n",
      "Step: 3045 of 5001.\n",
      "Step: 3046 of 5001.\n",
      "Step: 3047 of 5001.\n",
      "Step: 3048 of 5001.\n",
      "Step: 3049 of 5001.\n",
      "Step: 3050 of 5001.\n",
      "Generator model loss: 1.0199385941028596.\n",
      "Discriminator model loss real: 0.7689929813146591.\n",
      "Discriminator model loss generated: 0.6396161198616028.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3051 of 5001.\n",
      "Step: 3052 of 5001.\n",
      "Step: 3053 of 5001.\n",
      "Step: 3054 of 5001.\n",
      "Step: 3055 of 5001.\n",
      "Step: 3056 of 5001.\n",
      "Step: 3057 of 5001.\n",
      "Step: 3058 of 5001.\n",
      "Step: 3059 of 5001.\n",
      "Step: 3060 of 5001.\n",
      "Generator model loss: 1.0114008724689483.\n",
      "Discriminator model loss real: 0.7805567562580109.\n",
      "Discriminator model loss generated: 0.5976586163043975.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3061 of 5001.\n",
      "Step: 3062 of 5001.\n",
      "Step: 3063 of 5001.\n",
      "Step: 3064 of 5001.\n",
      "Step: 3065 of 5001.\n",
      "Step: 3066 of 5001.\n",
      "Step: 3067 of 5001.\n",
      "Step: 3068 of 5001.\n",
      "Step: 3069 of 5001.\n",
      "Step: 3070 of 5001.\n",
      "Generator model loss: 1.0398502588272094.\n",
      "Discriminator model loss real: 0.7860373198986054.\n",
      "Discriminator model loss generated: 0.6988355219364166.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 3071 of 5001.\n",
      "Step: 3072 of 5001.\n",
      "Step: 3073 of 5001.\n",
      "Step: 3074 of 5001.\n",
      "Step: 3075 of 5001.\n",
      "Step: 3076 of 5001.\n",
      "Step: 3077 of 5001.\n",
      "Step: 3078 of 5001.\n",
      "Step: 3079 of 5001.\n",
      "Step: 3080 of 5001.\n",
      "Generator model loss: 1.0215562880039215.\n",
      "Discriminator model loss real: 0.7619986951351165.\n",
      "Discriminator model loss generated: 0.602356231212616.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3081 of 5001.\n",
      "Step: 3082 of 5001.\n",
      "Step: 3083 of 5001.\n",
      "Step: 3084 of 5001.\n",
      "Step: 3085 of 5001.\n",
      "Step: 3086 of 5001.\n",
      "Step: 3087 of 5001.\n",
      "Step: 3088 of 5001.\n",
      "Step: 3089 of 5001.\n",
      "Step: 3090 of 5001.\n",
      "Generator model loss: 0.9927286267280578.\n",
      "Discriminator model loss real: 0.7667195558547973.\n",
      "Discriminator model loss generated: 0.6268303036689759.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3091 of 5001.\n",
      "Step: 3092 of 5001.\n",
      "Step: 3093 of 5001.\n",
      "Step: 3094 of 5001.\n",
      "Step: 3095 of 5001.\n",
      "Step: 3096 of 5001.\n",
      "Step: 3097 of 5001.\n",
      "Step: 3098 of 5001.\n",
      "Step: 3099 of 5001.\n",
      "Step: 3100 of 5001.\n",
      "Generator model loss: 0.9699346780776977.\n",
      "Discriminator model loss real: 0.7746094167232513.\n",
      "Discriminator model loss generated: 0.6836860179901123.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3101 of 5001.\n",
      "Step: 3102 of 5001.\n",
      "Step: 3103 of 5001.\n",
      "Step: 3104 of 5001.\n",
      "Step: 3105 of 5001.\n",
      "Step: 3106 of 5001.\n",
      "Step: 3107 of 5001.\n",
      "Step: 3108 of 5001.\n",
      "Step: 3109 of 5001.\n",
      "Step: 3110 of 5001.\n",
      "Generator model loss: 1.0199656665325165.\n",
      "Discriminator model loss real: 0.7304836392402649.\n",
      "Discriminator model loss generated: 0.6863876461982727.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3111 of 5001.\n",
      "Step: 3112 of 5001.\n",
      "Step: 3113 of 5001.\n",
      "Step: 3114 of 5001.\n",
      "Step: 3115 of 5001.\n",
      "Step: 3116 of 5001.\n",
      "Step: 3117 of 5001.\n",
      "Step: 3118 of 5001.\n",
      "Step: 3119 of 5001.\n",
      "Step: 3120 of 5001.\n",
      "Generator model loss: 0.9879323601722717.\n",
      "Discriminator model loss real: 0.7724143385887146.\n",
      "Discriminator model loss generated: 0.6904900372028351.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3121 of 5001.\n",
      "Step: 3122 of 5001.\n",
      "Step: 3123 of 5001.\n",
      "Step: 3124 of 5001.\n",
      "Step: 3125 of 5001.\n",
      "Step: 3126 of 5001.\n",
      "Step: 3127 of 5001.\n",
      "Step: 3128 of 5001.\n",
      "Step: 3129 of 5001.\n",
      "Step: 3130 of 5001.\n",
      "Generator model loss: 1.0061641037464142.\n",
      "Discriminator model loss real: 0.7850925773382187.\n",
      "Discriminator model loss generated: 0.656347006559372.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3131 of 5001.\n",
      "Step: 3132 of 5001.\n",
      "Step: 3133 of 5001.\n",
      "Step: 3134 of 5001.\n",
      "Step: 3135 of 5001.\n",
      "Step: 3136 of 5001.\n",
      "Step: 3137 of 5001.\n",
      "Step: 3138 of 5001.\n",
      "Step: 3139 of 5001.\n",
      "Step: 3140 of 5001.\n",
      "Generator model loss: 1.005423617362976.\n",
      "Discriminator model loss real: 0.7609411716461182.\n",
      "Discriminator model loss generated: 0.6808825910091401.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3141 of 5001.\n",
      "Step: 3142 of 5001.\n",
      "Step: 3143 of 5001.\n",
      "Step: 3144 of 5001.\n",
      "Step: 3145 of 5001.\n",
      "Step: 3146 of 5001.\n",
      "Step: 3147 of 5001.\n",
      "Step: 3148 of 5001.\n",
      "Step: 3149 of 5001.\n",
      "Step: 3150 of 5001.\n",
      "Generator model loss: 0.9881429672241211.\n",
      "Discriminator model loss real: 0.7431825816631317.\n",
      "Discriminator model loss generated: 0.6707338452339172.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 3151 of 5001.\n",
      "Step: 3152 of 5001.\n",
      "Step: 3153 of 5001.\n",
      "Step: 3154 of 5001.\n",
      "Step: 3155 of 5001.\n",
      "Step: 3156 of 5001.\n",
      "Step: 3157 of 5001.\n",
      "Step: 3158 of 5001.\n",
      "Step: 3159 of 5001.\n",
      "Step: 3160 of 5001.\n",
      "Generator model loss: 1.010289204120636.\n",
      "Discriminator model loss real: 0.7770769387483597.\n",
      "Discriminator model loss generated: 0.6782972395420075.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3161 of 5001.\n",
      "Step: 3162 of 5001.\n",
      "Step: 3163 of 5001.\n",
      "Step: 3164 of 5001.\n",
      "Step: 3165 of 5001.\n",
      "Step: 3166 of 5001.\n",
      "Step: 3167 of 5001.\n",
      "Step: 3168 of 5001.\n",
      "Step: 3169 of 5001.\n",
      "Step: 3170 of 5001.\n",
      "Generator model loss: 1.0423883080482483.\n",
      "Discriminator model loss real: 0.7085896372795105.\n",
      "Discriminator model loss generated: 0.6078786611557007.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3171 of 5001.\n",
      "Step: 3172 of 5001.\n",
      "Step: 3173 of 5001.\n",
      "Step: 3174 of 5001.\n",
      "Step: 3175 of 5001.\n",
      "Step: 3176 of 5001.\n",
      "Step: 3177 of 5001.\n",
      "Step: 3178 of 5001.\n",
      "Step: 3179 of 5001.\n",
      "Step: 3180 of 5001.\n",
      "Generator model loss: 1.046568500995636.\n",
      "Discriminator model loss real: 0.7565813541412354.\n",
      "Discriminator model loss generated: 0.6465285003185273.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3181 of 5001.\n",
      "Step: 3182 of 5001.\n",
      "Step: 3183 of 5001.\n",
      "Step: 3184 of 5001.\n",
      "Step: 3185 of 5001.\n",
      "Step: 3186 of 5001.\n",
      "Step: 3187 of 5001.\n",
      "Step: 3188 of 5001.\n",
      "Step: 3189 of 5001.\n",
      "Step: 3190 of 5001.\n",
      "Generator model loss: 0.9989637017250061.\n",
      "Discriminator model loss real: 0.7319624036550522.\n",
      "Discriminator model loss generated: 0.6902343392372131.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3191 of 5001.\n",
      "Step: 3192 of 5001.\n",
      "Step: 3193 of 5001.\n",
      "Step: 3194 of 5001.\n",
      "Step: 3195 of 5001.\n",
      "Step: 3196 of 5001.\n",
      "Step: 3197 of 5001.\n",
      "Step: 3198 of 5001.\n",
      "Step: 3199 of 5001.\n",
      "Step: 3200 of 5001.\n",
      "Generator model loss: 1.0062523663043976.\n",
      "Discriminator model loss real: 0.7604595720767975.\n",
      "Discriminator model loss generated: 0.5916903555393219.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3201 of 5001.\n",
      "Step: 3202 of 5001.\n",
      "Step: 3203 of 5001.\n",
      "Step: 3204 of 5001.\n",
      "Step: 3205 of 5001.\n",
      "Step: 3206 of 5001.\n",
      "Step: 3207 of 5001.\n",
      "Step: 3208 of 5001.\n",
      "Step: 3209 of 5001.\n",
      "Step: 3210 of 5001.\n",
      "Generator model loss: 1.0248805701732635.\n",
      "Discriminator model loss real: 0.7657187461853028.\n",
      "Discriminator model loss generated: 0.6194078505039216.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3211 of 5001.\n",
      "Step: 3212 of 5001.\n",
      "Step: 3213 of 5001.\n",
      "Step: 3214 of 5001.\n",
      "Step: 3215 of 5001.\n",
      "Step: 3216 of 5001.\n",
      "Step: 3217 of 5001.\n",
      "Step: 3218 of 5001.\n",
      "Step: 3219 of 5001.\n",
      "Step: 3220 of 5001.\n",
      "Generator model loss: 0.9902329266071319.\n",
      "Discriminator model loss real: 0.773035541176796.\n",
      "Discriminator model loss generated: 0.5969387710094451.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3221 of 5001.\n",
      "Step: 3222 of 5001.\n",
      "Step: 3223 of 5001.\n",
      "Step: 3224 of 5001.\n",
      "Step: 3225 of 5001.\n",
      "Step: 3226 of 5001.\n",
      "Step: 3227 of 5001.\n",
      "Step: 3228 of 5001.\n",
      "Step: 3229 of 5001.\n",
      "Step: 3230 of 5001.\n",
      "Generator model loss: 1.0243292212486268.\n",
      "Discriminator model loss real: 0.8058399230241775.\n",
      "Discriminator model loss generated: 0.629223644733429.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3231 of 5001.\n",
      "Step: 3232 of 5001.\n",
      "Step: 3233 of 5001.\n",
      "Step: 3234 of 5001.\n",
      "Step: 3235 of 5001.\n",
      "Step: 3236 of 5001.\n",
      "Step: 3237 of 5001.\n",
      "Step: 3238 of 5001.\n",
      "Step: 3239 of 5001.\n",
      "Step: 3240 of 5001.\n",
      "Generator model loss: 1.052695059776306.\n",
      "Discriminator model loss real: 0.7545982718467712.\n",
      "Discriminator model loss generated: 0.6047636985778808.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 3241 of 5001.\n",
      "Step: 3242 of 5001.\n",
      "Step: 3243 of 5001.\n",
      "Step: 3244 of 5001.\n",
      "Step: 3245 of 5001.\n",
      "Step: 3246 of 5001.\n",
      "Step: 3247 of 5001.\n",
      "Step: 3248 of 5001.\n",
      "Step: 3249 of 5001.\n",
      "Step: 3250 of 5001.\n",
      "Generator model loss: 1.0008052825927733.\n",
      "Discriminator model loss real: 0.7505682438611985.\n",
      "Discriminator model loss generated: 0.5952530980110169.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3251 of 5001.\n",
      "Step: 3252 of 5001.\n",
      "Step: 3253 of 5001.\n",
      "Step: 3254 of 5001.\n",
      "Step: 3255 of 5001.\n",
      "Step: 3256 of 5001.\n",
      "Step: 3257 of 5001.\n",
      "Step: 3258 of 5001.\n",
      "Step: 3259 of 5001.\n",
      "Step: 3260 of 5001.\n",
      "Generator model loss: 0.9946366429328919.\n",
      "Discriminator model loss real: 0.8031278669834137.\n",
      "Discriminator model loss generated: 0.6684978902339935.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3261 of 5001.\n",
      "Step: 3262 of 5001.\n",
      "Step: 3263 of 5001.\n",
      "Step: 3264 of 5001.\n",
      "Step: 3265 of 5001.\n",
      "Step: 3266 of 5001.\n",
      "Step: 3267 of 5001.\n",
      "Step: 3268 of 5001.\n",
      "Step: 3269 of 5001.\n",
      "Step: 3270 of 5001.\n",
      "Generator model loss: 1.0476106405258179.\n",
      "Discriminator model loss real: 0.8005964100360871.\n",
      "Discriminator model loss generated: 0.6625838994979858.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3271 of 5001.\n",
      "Step: 3272 of 5001.\n",
      "Step: 3273 of 5001.\n",
      "Step: 3274 of 5001.\n",
      "Step: 3275 of 5001.\n",
      "Step: 3276 of 5001.\n",
      "Step: 3277 of 5001.\n",
      "Step: 3278 of 5001.\n",
      "Step: 3279 of 5001.\n",
      "Step: 3280 of 5001.\n",
      "Generator model loss: 1.026361608505249.\n",
      "Discriminator model loss real: 0.7414695203304291.\n",
      "Discriminator model loss generated: 0.5946683168411255.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3281 of 5001.\n",
      "Step: 3282 of 5001.\n",
      "Step: 3283 of 5001.\n",
      "Step: 3284 of 5001.\n",
      "Step: 3285 of 5001.\n",
      "Step: 3286 of 5001.\n",
      "Step: 3287 of 5001.\n",
      "Step: 3288 of 5001.\n",
      "Step: 3289 of 5001.\n",
      "Step: 3290 of 5001.\n",
      "Generator model loss: 0.9842663705348969.\n",
      "Discriminator model loss real: 0.784526115655899.\n",
      "Discriminator model loss generated: 0.6222126424312592.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3291 of 5001.\n",
      "Step: 3292 of 5001.\n",
      "Step: 3293 of 5001.\n",
      "Step: 3294 of 5001.\n",
      "Step: 3295 of 5001.\n",
      "Step: 3296 of 5001.\n",
      "Step: 3297 of 5001.\n",
      "Step: 3298 of 5001.\n",
      "Step: 3299 of 5001.\n",
      "Step: 3300 of 5001.\n",
      "Generator model loss: 1.0258533835411072.\n",
      "Discriminator model loss real: 0.7267983347177506.\n",
      "Discriminator model loss generated: 0.6023886740207672.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3301 of 5001.\n",
      "Step: 3302 of 5001.\n",
      "Step: 3303 of 5001.\n",
      "Step: 3304 of 5001.\n",
      "Step: 3305 of 5001.\n",
      "Step: 3306 of 5001.\n",
      "Step: 3307 of 5001.\n",
      "Step: 3308 of 5001.\n",
      "Step: 3309 of 5001.\n",
      "Step: 3310 of 5001.\n",
      "Generator model loss: 1.0257541716098786.\n",
      "Discriminator model loss real: 0.7673359900712967.\n",
      "Discriminator model loss generated: 0.6219491302967072.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3311 of 5001.\n",
      "Step: 3312 of 5001.\n",
      "Step: 3313 of 5001.\n",
      "Step: 3314 of 5001.\n",
      "Step: 3315 of 5001.\n",
      "Step: 3316 of 5001.\n",
      "Step: 3317 of 5001.\n",
      "Step: 3318 of 5001.\n",
      "Step: 3319 of 5001.\n",
      "Step: 3320 of 5001.\n",
      "Generator model loss: 1.0805973291397095.\n",
      "Discriminator model loss real: 0.8204758703708649.\n",
      "Discriminator model loss generated: 0.5838011264801025.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3321 of 5001.\n",
      "Step: 3322 of 5001.\n",
      "Step: 3323 of 5001.\n",
      "Step: 3324 of 5001.\n",
      "Step: 3325 of 5001.\n",
      "Step: 3326 of 5001.\n",
      "Step: 3327 of 5001.\n",
      "Step: 3328 of 5001.\n",
      "Step: 3329 of 5001.\n",
      "Step: 3330 of 5001.\n",
      "Generator model loss: 1.059217494726181.\n",
      "Discriminator model loss real: 0.7192039892077446.\n",
      "Discriminator model loss generated: 0.6200579822063446.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3331 of 5001.\n",
      "Step: 3332 of 5001.\n",
      "Step: 3333 of 5001.\n",
      "Step: 3334 of 5001.\n",
      "Step: 3335 of 5001.\n",
      "Step: 3336 of 5001.\n",
      "Step: 3337 of 5001.\n",
      "Step: 3338 of 5001.\n",
      "Step: 3339 of 5001.\n",
      "Step: 3340 of 5001.\n",
      "Generator model loss: 1.0457485556602477.\n",
      "Discriminator model loss real: 0.7554091215133667.\n",
      "Discriminator model loss generated: 0.6072315454483033.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3341 of 5001.\n",
      "Step: 3342 of 5001.\n",
      "Step: 3343 of 5001.\n",
      "Step: 3344 of 5001.\n",
      "Step: 3345 of 5001.\n",
      "Step: 3346 of 5001.\n",
      "Step: 3347 of 5001.\n",
      "Step: 3348 of 5001.\n",
      "Step: 3349 of 5001.\n",
      "Step: 3350 of 5001.\n",
      "Generator model loss: 1.0454839825630189.\n",
      "Discriminator model loss real: 0.7590057760477066.\n",
      "Discriminator model loss generated: 0.6802306830883026.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3351 of 5001.\n",
      "Step: 3352 of 5001.\n",
      "Step: 3353 of 5001.\n",
      "Step: 3354 of 5001.\n",
      "Step: 3355 of 5001.\n",
      "Step: 3356 of 5001.\n",
      "Step: 3357 of 5001.\n",
      "Step: 3358 of 5001.\n",
      "Step: 3359 of 5001.\n",
      "Step: 3360 of 5001.\n",
      "Generator model loss: 1.0050089955329895.\n",
      "Discriminator model loss real: 0.7984685599803925.\n",
      "Discriminator model loss generated: 0.6009155750274658.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3361 of 5001.\n",
      "Step: 3362 of 5001.\n",
      "Step: 3363 of 5001.\n",
      "Step: 3364 of 5001.\n",
      "Step: 3365 of 5001.\n",
      "Step: 3366 of 5001.\n",
      "Step: 3367 of 5001.\n",
      "Step: 3368 of 5001.\n",
      "Step: 3369 of 5001.\n",
      "Step: 3370 of 5001.\n",
      "Generator model loss: 1.0180282175540925.\n",
      "Discriminator model loss real: 0.7758394360542298.\n",
      "Discriminator model loss generated: 0.6302364766597748.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3371 of 5001.\n",
      "Step: 3372 of 5001.\n",
      "Step: 3373 of 5001.\n",
      "Step: 3374 of 5001.\n",
      "Step: 3375 of 5001.\n",
      "Step: 3376 of 5001.\n",
      "Step: 3377 of 5001.\n",
      "Step: 3378 of 5001.\n",
      "Step: 3379 of 5001.\n",
      "Step: 3380 of 5001.\n",
      "Generator model loss: 1.1163658499717712.\n",
      "Discriminator model loss real: 0.7451807796955109.\n",
      "Discriminator model loss generated: 0.638623321056366.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3381 of 5001.\n",
      "Step: 3382 of 5001.\n",
      "Step: 3383 of 5001.\n",
      "Step: 3384 of 5001.\n",
      "Step: 3385 of 5001.\n",
      "Step: 3386 of 5001.\n",
      "Step: 3387 of 5001.\n",
      "Step: 3388 of 5001.\n",
      "Step: 3389 of 5001.\n",
      "Step: 3390 of 5001.\n",
      "Generator model loss: 1.0617019832134247.\n",
      "Discriminator model loss real: 0.7075008749961853.\n",
      "Discriminator model loss generated: 0.6516960442066193.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3391 of 5001.\n",
      "Step: 3392 of 5001.\n",
      "Step: 3393 of 5001.\n",
      "Step: 3394 of 5001.\n",
      "Step: 3395 of 5001.\n",
      "Step: 3396 of 5001.\n",
      "Step: 3397 of 5001.\n",
      "Step: 3398 of 5001.\n",
      "Step: 3399 of 5001.\n",
      "Step: 3400 of 5001.\n",
      "Generator model loss: 1.0491401135921479.\n",
      "Discriminator model loss real: 0.7671147614717484.\n",
      "Discriminator model loss generated: 0.6140320658683777.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 3401 of 5001.\n",
      "Step: 3402 of 5001.\n",
      "Step: 3403 of 5001.\n",
      "Step: 3404 of 5001.\n",
      "Step: 3405 of 5001.\n",
      "Step: 3406 of 5001.\n",
      "Step: 3407 of 5001.\n",
      "Step: 3408 of 5001.\n",
      "Step: 3409 of 5001.\n",
      "Step: 3410 of 5001.\n",
      "Generator model loss: 1.0417560338974.\n",
      "Discriminator model loss real: 0.7759802758693695.\n",
      "Discriminator model loss generated: 0.6636952877044677.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3411 of 5001.\n",
      "Step: 3412 of 5001.\n",
      "Step: 3413 of 5001.\n",
      "Step: 3414 of 5001.\n",
      "Step: 3415 of 5001.\n",
      "Step: 3416 of 5001.\n",
      "Step: 3417 of 5001.\n",
      "Step: 3418 of 5001.\n",
      "Step: 3419 of 5001.\n",
      "Step: 3420 of 5001.\n",
      "Generator model loss: 1.1225413858890534.\n",
      "Discriminator model loss real: 0.7095287263393402.\n",
      "Discriminator model loss generated: 0.6393779456615448.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3421 of 5001.\n",
      "Step: 3422 of 5001.\n",
      "Step: 3423 of 5001.\n",
      "Step: 3424 of 5001.\n",
      "Step: 3425 of 5001.\n",
      "Step: 3426 of 5001.\n",
      "Step: 3427 of 5001.\n",
      "Step: 3428 of 5001.\n",
      "Step: 3429 of 5001.\n",
      "Step: 3430 of 5001.\n",
      "Generator model loss: 1.0322613954544066.\n",
      "Discriminator model loss real: 0.7416901648044586.\n",
      "Discriminator model loss generated: 0.6167740762233734.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3431 of 5001.\n",
      "Step: 3432 of 5001.\n",
      "Step: 3433 of 5001.\n",
      "Step: 3434 of 5001.\n",
      "Step: 3435 of 5001.\n",
      "Step: 3436 of 5001.\n",
      "Step: 3437 of 5001.\n",
      "Step: 3438 of 5001.\n",
      "Step: 3439 of 5001.\n",
      "Step: 3440 of 5001.\n",
      "Generator model loss: 1.031549447774887.\n",
      "Discriminator model loss real: 0.7798735916614532.\n",
      "Discriminator model loss generated: 0.5852028608322144.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3441 of 5001.\n",
      "Step: 3442 of 5001.\n",
      "Step: 3443 of 5001.\n",
      "Step: 3444 of 5001.\n",
      "Step: 3445 of 5001.\n",
      "Step: 3446 of 5001.\n",
      "Step: 3447 of 5001.\n",
      "Step: 3448 of 5001.\n",
      "Step: 3449 of 5001.\n",
      "Step: 3450 of 5001.\n",
      "Generator model loss: 1.0765581369400024.\n",
      "Discriminator model loss real: 0.738826048374176.\n",
      "Discriminator model loss generated: 0.6150978028774261.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3451 of 5001.\n",
      "Step: 3452 of 5001.\n",
      "Step: 3453 of 5001.\n",
      "Step: 3454 of 5001.\n",
      "Step: 3455 of 5001.\n",
      "Step: 3456 of 5001.\n",
      "Step: 3457 of 5001.\n",
      "Step: 3458 of 5001.\n",
      "Step: 3459 of 5001.\n",
      "Step: 3460 of 5001.\n",
      "Generator model loss: 1.0004130840301513.\n",
      "Discriminator model loss real: 0.7631086468696594.\n",
      "Discriminator model loss generated: 0.6481551945209503.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3461 of 5001.\n",
      "Step: 3462 of 5001.\n",
      "Step: 3463 of 5001.\n",
      "Step: 3464 of 5001.\n",
      "Step: 3465 of 5001.\n",
      "Step: 3466 of 5001.\n",
      "Step: 3467 of 5001.\n",
      "Step: 3468 of 5001.\n",
      "Step: 3469 of 5001.\n",
      "Step: 3470 of 5001.\n",
      "Generator model loss: 1.1512252926826476.\n",
      "Discriminator model loss real: 0.7233678132295609.\n",
      "Discriminator model loss generated: 0.6431870877742767.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3471 of 5001.\n",
      "Step: 3472 of 5001.\n",
      "Step: 3473 of 5001.\n",
      "Step: 3474 of 5001.\n",
      "Step: 3475 of 5001.\n",
      "Step: 3476 of 5001.\n",
      "Step: 3477 of 5001.\n",
      "Step: 3478 of 5001.\n",
      "Step: 3479 of 5001.\n",
      "Step: 3480 of 5001.\n",
      "Generator model loss: 1.0420640468597413.\n",
      "Discriminator model loss real: 0.7167330771684647.\n",
      "Discriminator model loss generated: 0.6104905605316162.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 3481 of 5001.\n",
      "Step: 3482 of 5001.\n",
      "Step: 3483 of 5001.\n",
      "Step: 3484 of 5001.\n",
      "Step: 3485 of 5001.\n",
      "Step: 3486 of 5001.\n",
      "Step: 3487 of 5001.\n",
      "Step: 3488 of 5001.\n",
      "Step: 3489 of 5001.\n",
      "Step: 3490 of 5001.\n",
      "Generator model loss: 1.0017873525619507.\n",
      "Discriminator model loss real: 0.7486887812614441.\n",
      "Discriminator model loss generated: 0.6242247462272644.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3491 of 5001.\n",
      "Step: 3492 of 5001.\n",
      "Step: 3493 of 5001.\n",
      "Step: 3494 of 5001.\n",
      "Step: 3495 of 5001.\n",
      "Step: 3496 of 5001.\n",
      "Step: 3497 of 5001.\n",
      "Step: 3498 of 5001.\n",
      "Step: 3499 of 5001.\n",
      "Step: 3500 of 5001.\n",
      "Generator model loss: 1.0197000205516815.\n",
      "Discriminator model loss real: 0.767614221572876.\n",
      "Discriminator model loss generated: 0.6331401228904724.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3501 of 5001.\n",
      "Step: 3502 of 5001.\n",
      "Step: 3503 of 5001.\n",
      "Step: 3504 of 5001.\n",
      "Step: 3505 of 5001.\n",
      "Step: 3506 of 5001.\n",
      "Step: 3507 of 5001.\n",
      "Step: 3508 of 5001.\n",
      "Step: 3509 of 5001.\n",
      "Step: 3510 of 5001.\n",
      "Generator model loss: 1.092678302526474.\n",
      "Discriminator model loss real: 0.7332657665014267.\n",
      "Discriminator model loss generated: 0.6175037264823914.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3511 of 5001.\n",
      "Step: 3512 of 5001.\n",
      "Step: 3513 of 5001.\n",
      "Step: 3514 of 5001.\n",
      "Step: 3515 of 5001.\n",
      "Step: 3516 of 5001.\n",
      "Step: 3517 of 5001.\n",
      "Step: 3518 of 5001.\n",
      "Step: 3519 of 5001.\n",
      "Step: 3520 of 5001.\n",
      "Generator model loss: 1.0175196528434753.\n",
      "Discriminator model loss real: 0.7410677567124366.\n",
      "Discriminator model loss generated: 0.5993734180927277.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 3521 of 5001.\n",
      "Step: 3522 of 5001.\n",
      "Step: 3523 of 5001.\n",
      "Step: 3524 of 5001.\n",
      "Step: 3525 of 5001.\n",
      "Step: 3526 of 5001.\n",
      "Step: 3527 of 5001.\n",
      "Step: 3528 of 5001.\n",
      "Step: 3529 of 5001.\n",
      "Step: 3530 of 5001.\n",
      "Generator model loss: 1.059093415737152.\n",
      "Discriminator model loss real: 0.7442446812987328.\n",
      "Discriminator model loss generated: 0.5954221248626709.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3531 of 5001.\n",
      "Step: 3532 of 5001.\n",
      "Step: 3533 of 5001.\n",
      "Step: 3534 of 5001.\n",
      "Step: 3535 of 5001.\n",
      "Step: 3536 of 5001.\n",
      "Step: 3537 of 5001.\n",
      "Step: 3538 of 5001.\n",
      "Step: 3539 of 5001.\n",
      "Step: 3540 of 5001.\n",
      "Generator model loss: 0.9960383355617524.\n",
      "Discriminator model loss real: 0.7600309401750565.\n",
      "Discriminator model loss generated: 0.6336013495922088.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3541 of 5001.\n",
      "Step: 3542 of 5001.\n",
      "Step: 3543 of 5001.\n",
      "Step: 3544 of 5001.\n",
      "Step: 3545 of 5001.\n",
      "Step: 3546 of 5001.\n",
      "Step: 3547 of 5001.\n",
      "Step: 3548 of 5001.\n",
      "Step: 3549 of 5001.\n",
      "Step: 3550 of 5001.\n",
      "Generator model loss: 1.0308298885822296.\n",
      "Discriminator model loss real: 0.7990215569734573.\n",
      "Discriminator model loss generated: 0.6344037890434265.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 3551 of 5001.\n",
      "Step: 3552 of 5001.\n",
      "Step: 3553 of 5001.\n",
      "Step: 3554 of 5001.\n",
      "Step: 3555 of 5001.\n",
      "Step: 3556 of 5001.\n",
      "Step: 3557 of 5001.\n",
      "Step: 3558 of 5001.\n",
      "Step: 3559 of 5001.\n",
      "Step: 3560 of 5001.\n",
      "Generator model loss: 1.0646410048007966.\n",
      "Discriminator model loss real: 0.7469541281461716.\n",
      "Discriminator model loss generated: 0.5924362242221832.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3561 of 5001.\n",
      "Step: 3562 of 5001.\n",
      "Step: 3563 of 5001.\n",
      "Step: 3564 of 5001.\n",
      "Step: 3565 of 5001.\n",
      "Step: 3566 of 5001.\n",
      "Step: 3567 of 5001.\n",
      "Step: 3568 of 5001.\n",
      "Step: 3569 of 5001.\n",
      "Step: 3570 of 5001.\n",
      "Generator model loss: 1.1089737176895142.\n",
      "Discriminator model loss real: 0.7778074204921722.\n",
      "Discriminator model loss generated: 0.6166255414485932.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3571 of 5001.\n",
      "Step: 3572 of 5001.\n",
      "Step: 3573 of 5001.\n",
      "Step: 3574 of 5001.\n",
      "Step: 3575 of 5001.\n",
      "Step: 3576 of 5001.\n",
      "Step: 3577 of 5001.\n",
      "Step: 3578 of 5001.\n",
      "Step: 3579 of 5001.\n",
      "Step: 3580 of 5001.\n",
      "Generator model loss: 1.1047124981880188.\n",
      "Discriminator model loss real: 0.7763701409101487.\n",
      "Discriminator model loss generated: 0.6205862760543823.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3581 of 5001.\n",
      "Step: 3582 of 5001.\n",
      "Step: 3583 of 5001.\n",
      "Step: 3584 of 5001.\n",
      "Step: 3585 of 5001.\n",
      "Step: 3586 of 5001.\n",
      "Step: 3587 of 5001.\n",
      "Step: 3588 of 5001.\n",
      "Step: 3589 of 5001.\n",
      "Step: 3590 of 5001.\n",
      "Generator model loss: 1.0592262387275695.\n",
      "Discriminator model loss real: 0.7443794786930085.\n",
      "Discriminator model loss generated: 0.6031042635440826.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3591 of 5001.\n",
      "Step: 3592 of 5001.\n",
      "Step: 3593 of 5001.\n",
      "Step: 3594 of 5001.\n",
      "Step: 3595 of 5001.\n",
      "Step: 3596 of 5001.\n",
      "Step: 3597 of 5001.\n",
      "Step: 3598 of 5001.\n",
      "Step: 3599 of 5001.\n",
      "Step: 3600 of 5001.\n",
      "Generator model loss: 1.065005213022232.\n",
      "Discriminator model loss real: 0.7879880398511887.\n",
      "Discriminator model loss generated: 0.686285650730133.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3601 of 5001.\n",
      "Step: 3602 of 5001.\n",
      "Step: 3603 of 5001.\n",
      "Step: 3604 of 5001.\n",
      "Step: 3605 of 5001.\n",
      "Step: 3606 of 5001.\n",
      "Step: 3607 of 5001.\n",
      "Step: 3608 of 5001.\n",
      "Step: 3609 of 5001.\n",
      "Step: 3610 of 5001.\n",
      "Generator model loss: 1.0727991878986358.\n",
      "Discriminator model loss real: 0.671076101064682.\n",
      "Discriminator model loss generated: 0.634163099527359.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3611 of 5001.\n",
      "Step: 3612 of 5001.\n",
      "Step: 3613 of 5001.\n",
      "Step: 3614 of 5001.\n",
      "Step: 3615 of 5001.\n",
      "Step: 3616 of 5001.\n",
      "Step: 3617 of 5001.\n",
      "Step: 3618 of 5001.\n",
      "Step: 3619 of 5001.\n",
      "Step: 3620 of 5001.\n",
      "Generator model loss: 1.0458106696605682.\n",
      "Discriminator model loss real: 0.6850591391324997.\n",
      "Discriminator model loss generated: 0.6392805576324463.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3621 of 5001.\n",
      "Step: 3622 of 5001.\n",
      "Step: 3623 of 5001.\n",
      "Step: 3624 of 5001.\n",
      "Step: 3625 of 5001.\n",
      "Step: 3626 of 5001.\n",
      "Step: 3627 of 5001.\n",
      "Step: 3628 of 5001.\n",
      "Step: 3629 of 5001.\n",
      "Step: 3630 of 5001.\n",
      "Generator model loss: 1.0394008100032806.\n",
      "Discriminator model loss real: 0.7879922270774842.\n",
      "Discriminator model loss generated: 0.6507645010948181.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3631 of 5001.\n",
      "Step: 3632 of 5001.\n",
      "Step: 3633 of 5001.\n",
      "Step: 3634 of 5001.\n",
      "Step: 3635 of 5001.\n",
      "Step: 3636 of 5001.\n",
      "Step: 3637 of 5001.\n",
      "Step: 3638 of 5001.\n",
      "Step: 3639 of 5001.\n",
      "Step: 3640 of 5001.\n",
      "Generator model loss: 1.0224271237850189.\n",
      "Discriminator model loss real: 0.689000129699707.\n",
      "Discriminator model loss generated: 0.6248835682868957.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3641 of 5001.\n",
      "Step: 3642 of 5001.\n",
      "Step: 3643 of 5001.\n",
      "Step: 3644 of 5001.\n",
      "Step: 3645 of 5001.\n",
      "Step: 3646 of 5001.\n",
      "Step: 3647 of 5001.\n",
      "Step: 3648 of 5001.\n",
      "Step: 3649 of 5001.\n",
      "Step: 3650 of 5001.\n",
      "Generator model loss: 1.0340865850448608.\n",
      "Discriminator model loss real: 0.7074484884738922.\n",
      "Discriminator model loss generated: 0.6785589039325715.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3651 of 5001.\n",
      "Step: 3652 of 5001.\n",
      "Step: 3653 of 5001.\n",
      "Step: 3654 of 5001.\n",
      "Step: 3655 of 5001.\n",
      "Step: 3656 of 5001.\n",
      "Step: 3657 of 5001.\n",
      "Step: 3658 of 5001.\n",
      "Step: 3659 of 5001.\n",
      "Step: 3660 of 5001.\n",
      "Generator model loss: 1.0544178068637848.\n",
      "Discriminator model loss real: 0.7733704686164856.\n",
      "Discriminator model loss generated: 0.6860046446323395.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 3661 of 5001.\n",
      "Step: 3662 of 5001.\n",
      "Step: 3663 of 5001.\n",
      "Step: 3664 of 5001.\n",
      "Step: 3665 of 5001.\n",
      "Step: 3666 of 5001.\n",
      "Step: 3667 of 5001.\n",
      "Step: 3668 of 5001.\n",
      "Step: 3669 of 5001.\n",
      "Step: 3670 of 5001.\n",
      "Generator model loss: 1.0924576222896576.\n",
      "Discriminator model loss real: 0.7647953271865845.\n",
      "Discriminator model loss generated: 0.6262193620204926.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3671 of 5001.\n",
      "Step: 3672 of 5001.\n",
      "Step: 3673 of 5001.\n",
      "Step: 3674 of 5001.\n",
      "Step: 3675 of 5001.\n",
      "Step: 3676 of 5001.\n",
      "Step: 3677 of 5001.\n",
      "Step: 3678 of 5001.\n",
      "Step: 3679 of 5001.\n",
      "Step: 3680 of 5001.\n",
      "Generator model loss: 1.0829325258731841.\n",
      "Discriminator model loss real: 0.730678316950798.\n",
      "Discriminator model loss generated: 0.6053413271903991.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 3681 of 5001.\n",
      "Step: 3682 of 5001.\n",
      "Step: 3683 of 5001.\n",
      "Step: 3684 of 5001.\n",
      "Step: 3685 of 5001.\n",
      "Step: 3686 of 5001.\n",
      "Step: 3687 of 5001.\n",
      "Step: 3688 of 5001.\n",
      "Step: 3689 of 5001.\n",
      "Step: 3690 of 5001.\n",
      "Generator model loss: 1.038052648305893.\n",
      "Discriminator model loss real: 0.7143587499856949.\n",
      "Discriminator model loss generated: 0.6624799549579621.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3691 of 5001.\n",
      "Step: 3692 of 5001.\n",
      "Step: 3693 of 5001.\n",
      "Step: 3694 of 5001.\n",
      "Step: 3695 of 5001.\n",
      "Step: 3696 of 5001.\n",
      "Step: 3697 of 5001.\n",
      "Step: 3698 of 5001.\n",
      "Step: 3699 of 5001.\n",
      "Step: 3700 of 5001.\n",
      "Generator model loss: 1.0373459935188294.\n",
      "Discriminator model loss real: 0.6865060150623321.\n",
      "Discriminator model loss generated: 0.6557470738887787.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3701 of 5001.\n",
      "Step: 3702 of 5001.\n",
      "Step: 3703 of 5001.\n",
      "Step: 3704 of 5001.\n",
      "Step: 3705 of 5001.\n",
      "Step: 3706 of 5001.\n",
      "Step: 3707 of 5001.\n",
      "Step: 3708 of 5001.\n",
      "Step: 3709 of 5001.\n",
      "Step: 3710 of 5001.\n",
      "Generator model loss: 1.0675326347351075.\n",
      "Discriminator model loss real: 0.735942405462265.\n",
      "Discriminator model loss generated: 0.6432673573493958.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3711 of 5001.\n",
      "Step: 3712 of 5001.\n",
      "Step: 3713 of 5001.\n",
      "Step: 3714 of 5001.\n",
      "Step: 3715 of 5001.\n",
      "Step: 3716 of 5001.\n",
      "Step: 3717 of 5001.\n",
      "Step: 3718 of 5001.\n",
      "Step: 3719 of 5001.\n",
      "Step: 3720 of 5001.\n",
      "Generator model loss: 1.0815452992916108.\n",
      "Discriminator model loss real: 0.7597525626420975.\n",
      "Discriminator model loss generated: 0.6138219118118287.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3721 of 5001.\n",
      "Step: 3722 of 5001.\n",
      "Step: 3723 of 5001.\n",
      "Step: 3724 of 5001.\n",
      "Step: 3725 of 5001.\n",
      "Step: 3726 of 5001.\n",
      "Step: 3727 of 5001.\n",
      "Step: 3728 of 5001.\n",
      "Step: 3729 of 5001.\n",
      "Step: 3730 of 5001.\n",
      "Generator model loss: 0.9923840701580048.\n",
      "Discriminator model loss real: 0.7584806650876998.\n",
      "Discriminator model loss generated: 0.6614169597625732.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3731 of 5001.\n",
      "Step: 3732 of 5001.\n",
      "Step: 3733 of 5001.\n",
      "Step: 3734 of 5001.\n",
      "Step: 3735 of 5001.\n",
      "Step: 3736 of 5001.\n",
      "Step: 3737 of 5001.\n",
      "Step: 3738 of 5001.\n",
      "Step: 3739 of 5001.\n",
      "Step: 3740 of 5001.\n",
      "Generator model loss: 0.9972566425800323.\n",
      "Discriminator model loss real: 0.732172167301178.\n",
      "Discriminator model loss generated: 0.6121887564659119.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3741 of 5001.\n",
      "Step: 3742 of 5001.\n",
      "Step: 3743 of 5001.\n",
      "Step: 3744 of 5001.\n",
      "Step: 3745 of 5001.\n",
      "Step: 3746 of 5001.\n",
      "Step: 3747 of 5001.\n",
      "Step: 3748 of 5001.\n",
      "Step: 3749 of 5001.\n",
      "Step: 3750 of 5001.\n",
      "Generator model loss: 0.9968145072460175.\n",
      "Discriminator model loss real: 0.7260288417339325.\n",
      "Discriminator model loss generated: 0.6694442391395569.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3751 of 5001.\n",
      "Step: 3752 of 5001.\n",
      "Step: 3753 of 5001.\n",
      "Step: 3754 of 5001.\n",
      "Step: 3755 of 5001.\n",
      "Step: 3756 of 5001.\n",
      "Step: 3757 of 5001.\n",
      "Step: 3758 of 5001.\n",
      "Step: 3759 of 5001.\n",
      "Step: 3760 of 5001.\n",
      "Generator model loss: 1.0304152965545654.\n",
      "Discriminator model loss real: 0.7434474140405655.\n",
      "Discriminator model loss generated: 0.6253405153751374.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3761 of 5001.\n",
      "Step: 3762 of 5001.\n",
      "Step: 3763 of 5001.\n",
      "Step: 3764 of 5001.\n",
      "Step: 3765 of 5001.\n",
      "Step: 3766 of 5001.\n",
      "Step: 3767 of 5001.\n",
      "Step: 3768 of 5001.\n",
      "Step: 3769 of 5001.\n",
      "Step: 3770 of 5001.\n",
      "Generator model loss: 1.0356069386005402.\n",
      "Discriminator model loss real: 0.7348072767257691.\n",
      "Discriminator model loss generated: 0.6426423966884613.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3771 of 5001.\n",
      "Step: 3772 of 5001.\n",
      "Step: 3773 of 5001.\n",
      "Step: 3774 of 5001.\n",
      "Step: 3775 of 5001.\n",
      "Step: 3776 of 5001.\n",
      "Step: 3777 of 5001.\n",
      "Step: 3778 of 5001.\n",
      "Step: 3779 of 5001.\n",
      "Step: 3780 of 5001.\n",
      "Generator model loss: 1.0312611162662506.\n",
      "Discriminator model loss real: 0.7424307197332383.\n",
      "Discriminator model loss generated: 0.6720057189464569.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3781 of 5001.\n",
      "Step: 3782 of 5001.\n",
      "Step: 3783 of 5001.\n",
      "Step: 3784 of 5001.\n",
      "Step: 3785 of 5001.\n",
      "Step: 3786 of 5001.\n",
      "Step: 3787 of 5001.\n",
      "Step: 3788 of 5001.\n",
      "Step: 3789 of 5001.\n",
      "Step: 3790 of 5001.\n",
      "Generator model loss: 1.050283133983612.\n",
      "Discriminator model loss real: 0.6597847253084183.\n",
      "Discriminator model loss generated: 0.6299170613288879.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3791 of 5001.\n",
      "Step: 3792 of 5001.\n",
      "Step: 3793 of 5001.\n",
      "Step: 3794 of 5001.\n",
      "Step: 3795 of 5001.\n",
      "Step: 3796 of 5001.\n",
      "Step: 3797 of 5001.\n",
      "Step: 3798 of 5001.\n",
      "Step: 3799 of 5001.\n",
      "Step: 3800 of 5001.\n",
      "Generator model loss: 1.0842701256275178.\n",
      "Discriminator model loss real: 0.6731459498405457.\n",
      "Discriminator model loss generated: 0.6465604901313782.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3801 of 5001.\n",
      "Step: 3802 of 5001.\n",
      "Step: 3803 of 5001.\n",
      "Step: 3804 of 5001.\n",
      "Step: 3805 of 5001.\n",
      "Step: 3806 of 5001.\n",
      "Step: 3807 of 5001.\n",
      "Step: 3808 of 5001.\n",
      "Step: 3809 of 5001.\n",
      "Step: 3810 of 5001.\n",
      "Generator model loss: 1.1167211472988128.\n",
      "Discriminator model loss real: 0.7615104675292969.\n",
      "Discriminator model loss generated: 0.6377050340175628.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3811 of 5001.\n",
      "Step: 3812 of 5001.\n",
      "Step: 3813 of 5001.\n",
      "Step: 3814 of 5001.\n",
      "Step: 3815 of 5001.\n",
      "Step: 3816 of 5001.\n",
      "Step: 3817 of 5001.\n",
      "Step: 3818 of 5001.\n",
      "Step: 3819 of 5001.\n",
      "Step: 3820 of 5001.\n",
      "Generator model loss: 1.0323751449584961.\n",
      "Discriminator model loss real: 0.7378158569335938.\n",
      "Discriminator model loss generated: 0.6305862724781036.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3821 of 5001.\n",
      "Step: 3822 of 5001.\n",
      "Step: 3823 of 5001.\n",
      "Step: 3824 of 5001.\n",
      "Step: 3825 of 5001.\n",
      "Step: 3826 of 5001.\n",
      "Step: 3827 of 5001.\n",
      "Step: 3828 of 5001.\n",
      "Step: 3829 of 5001.\n",
      "Step: 3830 of 5001.\n",
      "Generator model loss: 1.0572602868080139.\n",
      "Discriminator model loss real: 0.7098586022853851.\n",
      "Discriminator model loss generated: 0.6507829904556275.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3831 of 5001.\n",
      "Step: 3832 of 5001.\n",
      "Step: 3833 of 5001.\n",
      "Step: 3834 of 5001.\n",
      "Step: 3835 of 5001.\n",
      "Step: 3836 of 5001.\n",
      "Step: 3837 of 5001.\n",
      "Step: 3838 of 5001.\n",
      "Step: 3839 of 5001.\n",
      "Step: 3840 of 5001.\n",
      "Generator model loss: 1.1174840211868287.\n",
      "Discriminator model loss real: 0.7272674396634102.\n",
      "Discriminator model loss generated: 0.6490829467773438.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3841 of 5001.\n",
      "Step: 3842 of 5001.\n",
      "Step: 3843 of 5001.\n",
      "Step: 3844 of 5001.\n",
      "Step: 3845 of 5001.\n",
      "Step: 3846 of 5001.\n",
      "Step: 3847 of 5001.\n",
      "Step: 3848 of 5001.\n",
      "Step: 3849 of 5001.\n",
      "Step: 3850 of 5001.\n",
      "Generator model loss: 1.0895118176937104.\n",
      "Discriminator model loss real: 0.7195930749177932.\n",
      "Discriminator model loss generated: 0.647786122560501.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3851 of 5001.\n",
      "Step: 3852 of 5001.\n",
      "Step: 3853 of 5001.\n",
      "Step: 3854 of 5001.\n",
      "Step: 3855 of 5001.\n",
      "Step: 3856 of 5001.\n",
      "Step: 3857 of 5001.\n",
      "Step: 3858 of 5001.\n",
      "Step: 3859 of 5001.\n",
      "Step: 3860 of 5001.\n",
      "Generator model loss: 1.1437457740306853.\n",
      "Discriminator model loss real: 0.7602525353431702.\n",
      "Discriminator model loss generated: 0.6502482652664184.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3861 of 5001.\n",
      "Step: 3862 of 5001.\n",
      "Step: 3863 of 5001.\n",
      "Step: 3864 of 5001.\n",
      "Step: 3865 of 5001.\n",
      "Step: 3866 of 5001.\n",
      "Step: 3867 of 5001.\n",
      "Step: 3868 of 5001.\n",
      "Step: 3869 of 5001.\n",
      "Step: 3870 of 5001.\n",
      "Generator model loss: 1.1042966187000274.\n",
      "Discriminator model loss real: 0.7456055521965027.\n",
      "Discriminator model loss generated: 0.6391038358211517.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3871 of 5001.\n",
      "Step: 3872 of 5001.\n",
      "Step: 3873 of 5001.\n",
      "Step: 3874 of 5001.\n",
      "Step: 3875 of 5001.\n",
      "Step: 3876 of 5001.\n",
      "Step: 3877 of 5001.\n",
      "Step: 3878 of 5001.\n",
      "Step: 3879 of 5001.\n",
      "Step: 3880 of 5001.\n",
      "Generator model loss: 1.1437925100326538.\n",
      "Discriminator model loss real: 0.7259776160120964.\n",
      "Discriminator model loss generated: 0.601157158613205.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3881 of 5001.\n",
      "Step: 3882 of 5001.\n",
      "Step: 3883 of 5001.\n",
      "Step: 3884 of 5001.\n",
      "Step: 3885 of 5001.\n",
      "Step: 3886 of 5001.\n",
      "Step: 3887 of 5001.\n",
      "Step: 3888 of 5001.\n",
      "Step: 3889 of 5001.\n",
      "Step: 3890 of 5001.\n",
      "Generator model loss: 1.091966950893402.\n",
      "Discriminator model loss real: 0.7649631321430206.\n",
      "Discriminator model loss generated: 0.6633784532546997.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3891 of 5001.\n",
      "Step: 3892 of 5001.\n",
      "Step: 3893 of 5001.\n",
      "Step: 3894 of 5001.\n",
      "Step: 3895 of 5001.\n",
      "Step: 3896 of 5001.\n",
      "Step: 3897 of 5001.\n",
      "Step: 3898 of 5001.\n",
      "Step: 3899 of 5001.\n",
      "Step: 3900 of 5001.\n",
      "Generator model loss: 1.077519917488098.\n",
      "Discriminator model loss real: 0.7496196687221527.\n",
      "Discriminator model loss generated: 0.6568621039390564.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3901 of 5001.\n",
      "Step: 3902 of 5001.\n",
      "Step: 3903 of 5001.\n",
      "Step: 3904 of 5001.\n",
      "Step: 3905 of 5001.\n",
      "Step: 3906 of 5001.\n",
      "Step: 3907 of 5001.\n",
      "Step: 3908 of 5001.\n",
      "Step: 3909 of 5001.\n",
      "Step: 3910 of 5001.\n",
      "Generator model loss: 1.0838560998439788.\n",
      "Discriminator model loss real: 0.7391206443309783.\n",
      "Discriminator model loss generated: 0.5993901371955872.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3911 of 5001.\n",
      "Step: 3912 of 5001.\n",
      "Step: 3913 of 5001.\n",
      "Step: 3914 of 5001.\n",
      "Step: 3915 of 5001.\n",
      "Step: 3916 of 5001.\n",
      "Step: 3917 of 5001.\n",
      "Step: 3918 of 5001.\n",
      "Step: 3919 of 5001.\n",
      "Step: 3920 of 5001.\n",
      "Generator model loss: 1.048218011856079.\n",
      "Discriminator model loss real: 0.7243505775928497.\n",
      "Discriminator model loss generated: 0.6505217373371124.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3921 of 5001.\n",
      "Step: 3922 of 5001.\n",
      "Step: 3923 of 5001.\n",
      "Step: 3924 of 5001.\n",
      "Step: 3925 of 5001.\n",
      "Step: 3926 of 5001.\n",
      "Step: 3927 of 5001.\n",
      "Step: 3928 of 5001.\n",
      "Step: 3929 of 5001.\n",
      "Step: 3930 of 5001.\n",
      "Generator model loss: 1.0170169830322267.\n",
      "Discriminator model loss real: 0.7696052700281143.\n",
      "Discriminator model loss generated: 0.6119612991809845.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3931 of 5001.\n",
      "Step: 3932 of 5001.\n",
      "Step: 3933 of 5001.\n",
      "Step: 3934 of 5001.\n",
      "Step: 3935 of 5001.\n",
      "Step: 3936 of 5001.\n",
      "Step: 3937 of 5001.\n",
      "Step: 3938 of 5001.\n",
      "Step: 3939 of 5001.\n",
      "Step: 3940 of 5001.\n",
      "Generator model loss: 1.0286155462265014.\n",
      "Discriminator model loss real: 0.7160906314849853.\n",
      "Discriminator model loss generated: 0.6430231034755707.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3941 of 5001.\n",
      "Step: 3942 of 5001.\n",
      "Step: 3943 of 5001.\n",
      "Step: 3944 of 5001.\n",
      "Step: 3945 of 5001.\n",
      "Step: 3946 of 5001.\n",
      "Step: 3947 of 5001.\n",
      "Step: 3948 of 5001.\n",
      "Step: 3949 of 5001.\n",
      "Step: 3950 of 5001.\n",
      "Generator model loss: 1.0518519699573516.\n",
      "Discriminator model loss real: 0.754268229007721.\n",
      "Discriminator model loss generated: 0.5984742820262909.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3951 of 5001.\n",
      "Step: 3952 of 5001.\n",
      "Step: 3953 of 5001.\n",
      "Step: 3954 of 5001.\n",
      "Step: 3955 of 5001.\n",
      "Step: 3956 of 5001.\n",
      "Step: 3957 of 5001.\n",
      "Step: 3958 of 5001.\n",
      "Step: 3959 of 5001.\n",
      "Step: 3960 of 5001.\n",
      "Generator model loss: 1.0543371856212616.\n",
      "Discriminator model loss real: 0.7312236070632935.\n",
      "Discriminator model loss generated: 0.6383158028125763.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 3961 of 5001.\n",
      "Step: 3962 of 5001.\n",
      "Step: 3963 of 5001.\n",
      "Step: 3964 of 5001.\n",
      "Step: 3965 of 5001.\n",
      "Step: 3966 of 5001.\n",
      "Step: 3967 of 5001.\n",
      "Step: 3968 of 5001.\n",
      "Step: 3969 of 5001.\n",
      "Step: 3970 of 5001.\n",
      "Generator model loss: 1.049922925233841.\n",
      "Discriminator model loss real: 0.7754857063293457.\n",
      "Discriminator model loss generated: 0.627843725681305.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 3971 of 5001.\n",
      "Step: 3972 of 5001.\n",
      "Step: 3973 of 5001.\n",
      "Step: 3974 of 5001.\n",
      "Step: 3975 of 5001.\n",
      "Step: 3976 of 5001.\n",
      "Step: 3977 of 5001.\n",
      "Step: 3978 of 5001.\n",
      "Step: 3979 of 5001.\n",
      "Step: 3980 of 5001.\n",
      "Generator model loss: 1.0083653032779694.\n",
      "Discriminator model loss real: 0.7334266245365143.\n",
      "Discriminator model loss generated: 0.6450323224067688.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3981 of 5001.\n",
      "Step: 3982 of 5001.\n",
      "Step: 3983 of 5001.\n",
      "Step: 3984 of 5001.\n",
      "Step: 3985 of 5001.\n",
      "Step: 3986 of 5001.\n",
      "Step: 3987 of 5001.\n",
      "Step: 3988 of 5001.\n",
      "Step: 3989 of 5001.\n",
      "Step: 3990 of 5001.\n",
      "Generator model loss: 1.0842931687831878.\n",
      "Discriminator model loss real: 0.7336386859416961.\n",
      "Discriminator model loss generated: 0.6036939978599548.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 3991 of 5001.\n",
      "Step: 3992 of 5001.\n",
      "Step: 3993 of 5001.\n",
      "Step: 3994 of 5001.\n",
      "Step: 3995 of 5001.\n",
      "Step: 3996 of 5001.\n",
      "Step: 3997 of 5001.\n",
      "Step: 3998 of 5001.\n",
      "Step: 3999 of 5001.\n",
      "Step: 4000 of 5001.\n",
      "Generator model loss: 1.0962996244430543.\n",
      "Discriminator model loss real: 0.7535325288772583.\n",
      "Discriminator model loss generated: 0.6258023023605347.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 4001 of 5001.\n",
      "Step: 4002 of 5001.\n",
      "Step: 4003 of 5001.\n",
      "Step: 4004 of 5001.\n",
      "Step: 4005 of 5001.\n",
      "Step: 4006 of 5001.\n",
      "Step: 4007 of 5001.\n",
      "Step: 4008 of 5001.\n",
      "Step: 4009 of 5001.\n",
      "Step: 4010 of 5001.\n",
      "Generator model loss: 1.0087357878684997.\n",
      "Discriminator model loss real: 0.7254840850830078.\n",
      "Discriminator model loss generated: 0.633121258020401.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4011 of 5001.\n",
      "Step: 4012 of 5001.\n",
      "Step: 4013 of 5001.\n",
      "Step: 4014 of 5001.\n",
      "Step: 4015 of 5001.\n",
      "Step: 4016 of 5001.\n",
      "Step: 4017 of 5001.\n",
      "Step: 4018 of 5001.\n",
      "Step: 4019 of 5001.\n",
      "Step: 4020 of 5001.\n",
      "Generator model loss: 1.1048375070095062.\n",
      "Discriminator model loss real: 0.741912966966629.\n",
      "Discriminator model loss generated: 0.6533847212791443.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4021 of 5001.\n",
      "Step: 4022 of 5001.\n",
      "Step: 4023 of 5001.\n",
      "Step: 4024 of 5001.\n",
      "Step: 4025 of 5001.\n",
      "Step: 4026 of 5001.\n",
      "Step: 4027 of 5001.\n",
      "Step: 4028 of 5001.\n",
      "Step: 4029 of 5001.\n",
      "Step: 4030 of 5001.\n",
      "Generator model loss: 1.0518112659454346.\n",
      "Discriminator model loss real: 0.7171788036823272.\n",
      "Discriminator model loss generated: 0.6913010239601135.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4031 of 5001.\n",
      "Step: 4032 of 5001.\n",
      "Step: 4033 of 5001.\n",
      "Step: 4034 of 5001.\n",
      "Step: 4035 of 5001.\n",
      "Step: 4036 of 5001.\n",
      "Step: 4037 of 5001.\n",
      "Step: 4038 of 5001.\n",
      "Step: 4039 of 5001.\n",
      "Step: 4040 of 5001.\n",
      "Generator model loss: 1.0210665225982667.\n",
      "Discriminator model loss real: 0.7577626973390579.\n",
      "Discriminator model loss generated: 0.610911738872528.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4041 of 5001.\n",
      "Step: 4042 of 5001.\n",
      "Step: 4043 of 5001.\n",
      "Step: 4044 of 5001.\n",
      "Step: 4045 of 5001.\n",
      "Step: 4046 of 5001.\n",
      "Step: 4047 of 5001.\n",
      "Step: 4048 of 5001.\n",
      "Step: 4049 of 5001.\n",
      "Step: 4050 of 5001.\n",
      "Generator model loss: 1.0326329231262208.\n",
      "Discriminator model loss real: 0.729978933930397.\n",
      "Discriminator model loss generated: 0.6322130918502807.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4051 of 5001.\n",
      "Step: 4052 of 5001.\n",
      "Step: 4053 of 5001.\n",
      "Step: 4054 of 5001.\n",
      "Step: 4055 of 5001.\n",
      "Step: 4056 of 5001.\n",
      "Step: 4057 of 5001.\n",
      "Step: 4058 of 5001.\n",
      "Step: 4059 of 5001.\n",
      "Step: 4060 of 5001.\n",
      "Generator model loss: 1.09041109085083.\n",
      "Discriminator model loss real: 0.7171208411455154.\n",
      "Discriminator model loss generated: 0.6112948060035706.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4061 of 5001.\n",
      "Step: 4062 of 5001.\n",
      "Step: 4063 of 5001.\n",
      "Step: 4064 of 5001.\n",
      "Step: 4065 of 5001.\n",
      "Step: 4066 of 5001.\n",
      "Step: 4067 of 5001.\n",
      "Step: 4068 of 5001.\n",
      "Step: 4069 of 5001.\n",
      "Step: 4070 of 5001.\n",
      "Generator model loss: 0.9937656223773956.\n",
      "Discriminator model loss real: 0.7364027738571167.\n",
      "Discriminator model loss generated: 0.6133963227272033.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4071 of 5001.\n",
      "Step: 4072 of 5001.\n",
      "Step: 4073 of 5001.\n",
      "Step: 4074 of 5001.\n",
      "Step: 4075 of 5001.\n",
      "Step: 4076 of 5001.\n",
      "Step: 4077 of 5001.\n",
      "Step: 4078 of 5001.\n",
      "Step: 4079 of 5001.\n",
      "Step: 4080 of 5001.\n",
      "Generator model loss: 1.041118335723877.\n",
      "Discriminator model loss real: 0.721980756521225.\n",
      "Discriminator model loss generated: 0.6196864247322083.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4081 of 5001.\n",
      "Step: 4082 of 5001.\n",
      "Step: 4083 of 5001.\n",
      "Step: 4084 of 5001.\n",
      "Step: 4085 of 5001.\n",
      "Step: 4086 of 5001.\n",
      "Step: 4087 of 5001.\n",
      "Step: 4088 of 5001.\n",
      "Step: 4089 of 5001.\n",
      "Step: 4090 of 5001.\n",
      "Generator model loss: 1.0255120992660522.\n",
      "Discriminator model loss real: 0.723994717001915.\n",
      "Discriminator model loss generated: 0.6499007761478424.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4091 of 5001.\n",
      "Step: 4092 of 5001.\n",
      "Step: 4093 of 5001.\n",
      "Step: 4094 of 5001.\n",
      "Step: 4095 of 5001.\n",
      "Step: 4096 of 5001.\n",
      "Step: 4097 of 5001.\n",
      "Step: 4098 of 5001.\n",
      "Step: 4099 of 5001.\n",
      "Step: 4100 of 5001.\n",
      "Generator model loss: 1.058359843492508.\n",
      "Discriminator model loss real: 0.7745643109083176.\n",
      "Discriminator model loss generated: 0.6493877291679382.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4101 of 5001.\n",
      "Step: 4102 of 5001.\n",
      "Step: 4103 of 5001.\n",
      "Step: 4104 of 5001.\n",
      "Step: 4105 of 5001.\n",
      "Step: 4106 of 5001.\n",
      "Step: 4107 of 5001.\n",
      "Step: 4108 of 5001.\n",
      "Step: 4109 of 5001.\n",
      "Step: 4110 of 5001.\n",
      "Generator model loss: 1.1152119517326355.\n",
      "Discriminator model loss real: 0.7299934983253479.\n",
      "Discriminator model loss generated: 0.6283432364463806.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4111 of 5001.\n",
      "Step: 4112 of 5001.\n",
      "Step: 4113 of 5001.\n",
      "Step: 4114 of 5001.\n",
      "Step: 4115 of 5001.\n",
      "Step: 4116 of 5001.\n",
      "Step: 4117 of 5001.\n",
      "Step: 4118 of 5001.\n",
      "Step: 4119 of 5001.\n",
      "Step: 4120 of 5001.\n",
      "Generator model loss: 1.0290194392204284.\n",
      "Discriminator model loss real: 0.7233275264501572.\n",
      "Discriminator model loss generated: 0.6570539891719818.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4121 of 5001.\n",
      "Step: 4122 of 5001.\n",
      "Step: 4123 of 5001.\n",
      "Step: 4124 of 5001.\n",
      "Step: 4125 of 5001.\n",
      "Step: 4126 of 5001.\n",
      "Step: 4127 of 5001.\n",
      "Step: 4128 of 5001.\n",
      "Step: 4129 of 5001.\n",
      "Step: 4130 of 5001.\n",
      "Generator model loss: 1.063375437259674.\n",
      "Discriminator model loss real: 0.7248767375946045.\n",
      "Discriminator model loss generated: 0.645188844203949.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4131 of 5001.\n",
      "Step: 4132 of 5001.\n",
      "Step: 4133 of 5001.\n",
      "Step: 4134 of 5001.\n",
      "Step: 4135 of 5001.\n",
      "Step: 4136 of 5001.\n",
      "Step: 4137 of 5001.\n",
      "Step: 4138 of 5001.\n",
      "Step: 4139 of 5001.\n",
      "Step: 4140 of 5001.\n",
      "Generator model loss: 1.0852486133575439.\n",
      "Discriminator model loss real: 0.7222442477941513.\n",
      "Discriminator model loss generated: 0.6350034773349762.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4141 of 5001.\n",
      "Step: 4142 of 5001.\n",
      "Step: 4143 of 5001.\n",
      "Step: 4144 of 5001.\n",
      "Step: 4145 of 5001.\n",
      "Step: 4146 of 5001.\n",
      "Step: 4147 of 5001.\n",
      "Step: 4148 of 5001.\n",
      "Step: 4149 of 5001.\n",
      "Step: 4150 of 5001.\n",
      "Generator model loss: 1.0654492557048798.\n",
      "Discriminator model loss real: 0.729890713095665.\n",
      "Discriminator model loss generated: 0.6389436721801758.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4151 of 5001.\n",
      "Step: 4152 of 5001.\n",
      "Step: 4153 of 5001.\n",
      "Step: 4154 of 5001.\n",
      "Step: 4155 of 5001.\n",
      "Step: 4156 of 5001.\n",
      "Step: 4157 of 5001.\n",
      "Step: 4158 of 5001.\n",
      "Step: 4159 of 5001.\n",
      "Step: 4160 of 5001.\n",
      "Generator model loss: 1.0255897343158722.\n",
      "Discriminator model loss real: 0.694165614247322.\n",
      "Discriminator model loss generated: 0.6644511997699738.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4161 of 5001.\n",
      "Step: 4162 of 5001.\n",
      "Step: 4163 of 5001.\n",
      "Step: 4164 of 5001.\n",
      "Step: 4165 of 5001.\n",
      "Step: 4166 of 5001.\n",
      "Step: 4167 of 5001.\n",
      "Step: 4168 of 5001.\n",
      "Step: 4169 of 5001.\n",
      "Step: 4170 of 5001.\n",
      "Generator model loss: 1.0223483264446258.\n",
      "Discriminator model loss real: 0.7467493653297425.\n",
      "Discriminator model loss generated: 0.6417330384254456.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4171 of 5001.\n",
      "Step: 4172 of 5001.\n",
      "Step: 4173 of 5001.\n",
      "Step: 4174 of 5001.\n",
      "Step: 4175 of 5001.\n",
      "Step: 4176 of 5001.\n",
      "Step: 4177 of 5001.\n",
      "Step: 4178 of 5001.\n",
      "Step: 4179 of 5001.\n",
      "Step: 4180 of 5001.\n",
      "Generator model loss: 1.068914180994034.\n",
      "Discriminator model loss real: 0.6745223641395569.\n",
      "Discriminator model loss generated: 0.6701722860336303.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4181 of 5001.\n",
      "Step: 4182 of 5001.\n",
      "Step: 4183 of 5001.\n",
      "Step: 4184 of 5001.\n",
      "Step: 4185 of 5001.\n",
      "Step: 4186 of 5001.\n",
      "Step: 4187 of 5001.\n",
      "Step: 4188 of 5001.\n",
      "Step: 4189 of 5001.\n",
      "Step: 4190 of 5001.\n",
      "Generator model loss: 1.0949284791946412.\n",
      "Discriminator model loss real: 0.7573407977819443.\n",
      "Discriminator model loss generated: 0.684233295917511.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4191 of 5001.\n",
      "Step: 4192 of 5001.\n",
      "Step: 4193 of 5001.\n",
      "Step: 4194 of 5001.\n",
      "Step: 4195 of 5001.\n",
      "Step: 4196 of 5001.\n",
      "Step: 4197 of 5001.\n",
      "Step: 4198 of 5001.\n",
      "Step: 4199 of 5001.\n",
      "Step: 4200 of 5001.\n",
      "Generator model loss: 1.0891625702381134.\n",
      "Discriminator model loss real: 0.6969025284051895.\n",
      "Discriminator model loss generated: 0.6685390710830689.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4201 of 5001.\n",
      "Step: 4202 of 5001.\n",
      "Step: 4203 of 5001.\n",
      "Step: 4204 of 5001.\n",
      "Step: 4205 of 5001.\n",
      "Step: 4206 of 5001.\n",
      "Step: 4207 of 5001.\n",
      "Step: 4208 of 5001.\n",
      "Step: 4209 of 5001.\n",
      "Step: 4210 of 5001.\n",
      "Generator model loss: 1.0383086979389191.\n",
      "Discriminator model loss real: 0.7510373204946518.\n",
      "Discriminator model loss generated: 0.6438911139965058.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4211 of 5001.\n",
      "Step: 4212 of 5001.\n",
      "Step: 4213 of 5001.\n",
      "Step: 4214 of 5001.\n",
      "Step: 4215 of 5001.\n",
      "Step: 4216 of 5001.\n",
      "Step: 4217 of 5001.\n",
      "Step: 4218 of 5001.\n",
      "Step: 4219 of 5001.\n",
      "Step: 4220 of 5001.\n",
      "Generator model loss: 1.0809378445148468.\n",
      "Discriminator model loss real: 0.7047721087932587.\n",
      "Discriminator model loss generated: 0.5911620676517486.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 4221 of 5001.\n",
      "Step: 4222 of 5001.\n",
      "Step: 4223 of 5001.\n",
      "Step: 4224 of 5001.\n",
      "Step: 4225 of 5001.\n",
      "Step: 4226 of 5001.\n",
      "Step: 4227 of 5001.\n",
      "Step: 4228 of 5001.\n",
      "Step: 4229 of 5001.\n",
      "Step: 4230 of 5001.\n",
      "Generator model loss: 1.0469154119491577.\n",
      "Discriminator model loss real: 0.7050914943218232.\n",
      "Discriminator model loss generated: 0.6254115700721741.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4231 of 5001.\n",
      "Step: 4232 of 5001.\n",
      "Step: 4233 of 5001.\n",
      "Step: 4234 of 5001.\n",
      "Step: 4235 of 5001.\n",
      "Step: 4236 of 5001.\n",
      "Step: 4237 of 5001.\n",
      "Step: 4238 of 5001.\n",
      "Step: 4239 of 5001.\n",
      "Step: 4240 of 5001.\n",
      "Generator model loss: 1.0894166946411132.\n",
      "Discriminator model loss real: 0.7567866027355195.\n",
      "Discriminator model loss generated: 0.6465626776218414.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4241 of 5001.\n",
      "Step: 4242 of 5001.\n",
      "Step: 4243 of 5001.\n",
      "Step: 4244 of 5001.\n",
      "Step: 4245 of 5001.\n",
      "Step: 4246 of 5001.\n",
      "Step: 4247 of 5001.\n",
      "Step: 4248 of 5001.\n",
      "Step: 4249 of 5001.\n",
      "Step: 4250 of 5001.\n",
      "Generator model loss: 1.0610957443714142.\n",
      "Discriminator model loss real: 0.7480725944042206.\n",
      "Discriminator model loss generated: 0.6488088011741638.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4251 of 5001.\n",
      "Step: 4252 of 5001.\n",
      "Step: 4253 of 5001.\n",
      "Step: 4254 of 5001.\n",
      "Step: 4255 of 5001.\n",
      "Step: 4256 of 5001.\n",
      "Step: 4257 of 5001.\n",
      "Step: 4258 of 5001.\n",
      "Step: 4259 of 5001.\n",
      "Step: 4260 of 5001.\n",
      "Generator model loss: 1.0932888984680176.\n",
      "Discriminator model loss real: 0.6805302411317825.\n",
      "Discriminator model loss generated: 0.6811431586742401.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4261 of 5001.\n",
      "Step: 4262 of 5001.\n",
      "Step: 4263 of 5001.\n",
      "Step: 4264 of 5001.\n",
      "Step: 4265 of 5001.\n",
      "Step: 4266 of 5001.\n",
      "Step: 4267 of 5001.\n",
      "Step: 4268 of 5001.\n",
      "Step: 4269 of 5001.\n",
      "Step: 4270 of 5001.\n",
      "Generator model loss: 1.0760089695453643.\n",
      "Discriminator model loss real: 0.7291454553604126.\n",
      "Discriminator model loss generated: 0.6466997683048248.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4271 of 5001.\n",
      "Step: 4272 of 5001.\n",
      "Step: 4273 of 5001.\n",
      "Step: 4274 of 5001.\n",
      "Step: 4275 of 5001.\n",
      "Step: 4276 of 5001.\n",
      "Step: 4277 of 5001.\n",
      "Step: 4278 of 5001.\n",
      "Step: 4279 of 5001.\n",
      "Step: 4280 of 5001.\n",
      "Generator model loss: 1.15466628074646.\n",
      "Discriminator model loss real: 0.7933725714683533.\n",
      "Discriminator model loss generated: 0.582107937335968.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4281 of 5001.\n",
      "Step: 4282 of 5001.\n",
      "Step: 4283 of 5001.\n",
      "Step: 4284 of 5001.\n",
      "Step: 4285 of 5001.\n",
      "Step: 4286 of 5001.\n",
      "Step: 4287 of 5001.\n",
      "Step: 4288 of 5001.\n",
      "Step: 4289 of 5001.\n",
      "Step: 4290 of 5001.\n",
      "Generator model loss: 1.0070616900920868.\n",
      "Discriminator model loss real: 0.7114913761615753.\n",
      "Discriminator model loss generated: 0.6492101550102234.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 4291 of 5001.\n",
      "Step: 4292 of 5001.\n",
      "Step: 4293 of 5001.\n",
      "Step: 4294 of 5001.\n",
      "Step: 4295 of 5001.\n",
      "Step: 4296 of 5001.\n",
      "Step: 4297 of 5001.\n",
      "Step: 4298 of 5001.\n",
      "Step: 4299 of 5001.\n",
      "Step: 4300 of 5001.\n",
      "Generator model loss: 1.044336748123169.\n",
      "Discriminator model loss real: 0.7646254181861878.\n",
      "Discriminator model loss generated: 0.6095351994037628.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4301 of 5001.\n",
      "Step: 4302 of 5001.\n",
      "Step: 4303 of 5001.\n",
      "Step: 4304 of 5001.\n",
      "Step: 4305 of 5001.\n",
      "Step: 4306 of 5001.\n",
      "Step: 4307 of 5001.\n",
      "Step: 4308 of 5001.\n",
      "Step: 4309 of 5001.\n",
      "Step: 4310 of 5001.\n",
      "Generator model loss: 1.1151132881641388.\n",
      "Discriminator model loss real: 0.7353042006492615.\n",
      "Discriminator model loss generated: 0.694304782152176.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4311 of 5001.\n",
      "Step: 4312 of 5001.\n",
      "Step: 4313 of 5001.\n",
      "Step: 4314 of 5001.\n",
      "Step: 4315 of 5001.\n",
      "Step: 4316 of 5001.\n",
      "Step: 4317 of 5001.\n",
      "Step: 4318 of 5001.\n",
      "Step: 4319 of 5001.\n",
      "Step: 4320 of 5001.\n",
      "Generator model loss: 1.0657378435134888.\n",
      "Discriminator model loss real: 0.774147117137909.\n",
      "Discriminator model loss generated: 0.6151362001895905.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4321 of 5001.\n",
      "Step: 4322 of 5001.\n",
      "Step: 4323 of 5001.\n",
      "Step: 4324 of 5001.\n",
      "Step: 4325 of 5001.\n",
      "Step: 4326 of 5001.\n",
      "Step: 4327 of 5001.\n",
      "Step: 4328 of 5001.\n",
      "Step: 4329 of 5001.\n",
      "Step: 4330 of 5001.\n",
      "Generator model loss: 1.0349747955799102.\n",
      "Discriminator model loss real: 0.7322913110256195.\n",
      "Discriminator model loss generated: 0.6380991458892822.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4331 of 5001.\n",
      "Step: 4332 of 5001.\n",
      "Step: 4333 of 5001.\n",
      "Step: 4334 of 5001.\n",
      "Step: 4335 of 5001.\n",
      "Step: 4336 of 5001.\n",
      "Step: 4337 of 5001.\n",
      "Step: 4338 of 5001.\n",
      "Step: 4339 of 5001.\n",
      "Step: 4340 of 5001.\n",
      "Generator model loss: 1.0410270690917969.\n",
      "Discriminator model loss real: 0.7106451690196991.\n",
      "Discriminator model loss generated: 0.5998328447341919.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4341 of 5001.\n",
      "Step: 4342 of 5001.\n",
      "Step: 4343 of 5001.\n",
      "Step: 4344 of 5001.\n",
      "Step: 4345 of 5001.\n",
      "Step: 4346 of 5001.\n",
      "Step: 4347 of 5001.\n",
      "Step: 4348 of 5001.\n",
      "Step: 4349 of 5001.\n",
      "Step: 4350 of 5001.\n",
      "Generator model loss: 1.0599035143852233.\n",
      "Discriminator model loss real: 0.7357921898365021.\n",
      "Discriminator model loss generated: 0.6555516004562378.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4351 of 5001.\n",
      "Step: 4352 of 5001.\n",
      "Step: 4353 of 5001.\n",
      "Step: 4354 of 5001.\n",
      "Step: 4355 of 5001.\n",
      "Step: 4356 of 5001.\n",
      "Step: 4357 of 5001.\n",
      "Step: 4358 of 5001.\n",
      "Step: 4359 of 5001.\n",
      "Step: 4360 of 5001.\n",
      "Generator model loss: 1.0210745275020598.\n",
      "Discriminator model loss real: 0.7274935305118561.\n",
      "Discriminator model loss generated: 0.6490723133087158.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4361 of 5001.\n",
      "Step: 4362 of 5001.\n",
      "Step: 4363 of 5001.\n",
      "Step: 4364 of 5001.\n",
      "Step: 4365 of 5001.\n",
      "Step: 4366 of 5001.\n",
      "Step: 4367 of 5001.\n",
      "Step: 4368 of 5001.\n",
      "Step: 4369 of 5001.\n",
      "Step: 4370 of 5001.\n",
      "Generator model loss: 1.089615172147751.\n",
      "Discriminator model loss real: 0.7335148364305496.\n",
      "Discriminator model loss generated: 0.6690121352672577.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4371 of 5001.\n",
      "Step: 4372 of 5001.\n",
      "Step: 4373 of 5001.\n",
      "Step: 4374 of 5001.\n",
      "Step: 4375 of 5001.\n",
      "Step: 4376 of 5001.\n",
      "Step: 4377 of 5001.\n",
      "Step: 4378 of 5001.\n",
      "Step: 4379 of 5001.\n",
      "Step: 4380 of 5001.\n",
      "Generator model loss: 1.1063571929931642.\n",
      "Discriminator model loss real: 0.7166917622089386.\n",
      "Discriminator model loss generated: 0.6308975219726562.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4381 of 5001.\n",
      "Step: 4382 of 5001.\n",
      "Step: 4383 of 5001.\n",
      "Step: 4384 of 5001.\n",
      "Step: 4385 of 5001.\n",
      "Step: 4386 of 5001.\n",
      "Step: 4387 of 5001.\n",
      "Step: 4388 of 5001.\n",
      "Step: 4389 of 5001.\n",
      "Step: 4390 of 5001.\n",
      "Generator model loss: 0.9918567419052124.\n",
      "Discriminator model loss real: 0.6871049910783767.\n",
      "Discriminator model loss generated: 0.6237654745578766.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4391 of 5001.\n",
      "Step: 4392 of 5001.\n",
      "Step: 4393 of 5001.\n",
      "Step: 4394 of 5001.\n",
      "Step: 4395 of 5001.\n",
      "Step: 4396 of 5001.\n",
      "Step: 4397 of 5001.\n",
      "Step: 4398 of 5001.\n",
      "Step: 4399 of 5001.\n",
      "Step: 4400 of 5001.\n",
      "Generator model loss: 1.0918092370033263.\n",
      "Discriminator model loss real: 0.7079410403966904.\n",
      "Discriminator model loss generated: 0.6587162375450134.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4401 of 5001.\n",
      "Step: 4402 of 5001.\n",
      "Step: 4403 of 5001.\n",
      "Step: 4404 of 5001.\n",
      "Step: 4405 of 5001.\n",
      "Step: 4406 of 5001.\n",
      "Step: 4407 of 5001.\n",
      "Step: 4408 of 5001.\n",
      "Step: 4409 of 5001.\n",
      "Step: 4410 of 5001.\n",
      "Generator model loss: 1.0997484922409058.\n",
      "Discriminator model loss real: 0.7399069517850876.\n",
      "Discriminator model loss generated: 0.682632040977478.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 4411 of 5001.\n",
      "Step: 4412 of 5001.\n",
      "Step: 4413 of 5001.\n",
      "Step: 4414 of 5001.\n",
      "Step: 4415 of 5001.\n",
      "Step: 4416 of 5001.\n",
      "Step: 4417 of 5001.\n",
      "Step: 4418 of 5001.\n",
      "Step: 4419 of 5001.\n",
      "Step: 4420 of 5001.\n",
      "Generator model loss: 1.0237461626529694.\n",
      "Discriminator model loss real: 0.6918831914663315.\n",
      "Discriminator model loss generated: 0.6251191735267639.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4421 of 5001.\n",
      "Step: 4422 of 5001.\n",
      "Step: 4423 of 5001.\n",
      "Step: 4424 of 5001.\n",
      "Step: 4425 of 5001.\n",
      "Step: 4426 of 5001.\n",
      "Step: 4427 of 5001.\n",
      "Step: 4428 of 5001.\n",
      "Step: 4429 of 5001.\n",
      "Step: 4430 of 5001.\n",
      "Generator model loss: 0.9957417607307434.\n",
      "Discriminator model loss real: 0.7120225846767425.\n",
      "Discriminator model loss generated: 0.6299652993679047.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4431 of 5001.\n",
      "Step: 4432 of 5001.\n",
      "Step: 4433 of 5001.\n",
      "Step: 4434 of 5001.\n",
      "Step: 4435 of 5001.\n",
      "Step: 4436 of 5001.\n",
      "Step: 4437 of 5001.\n",
      "Step: 4438 of 5001.\n",
      "Step: 4439 of 5001.\n",
      "Step: 4440 of 5001.\n",
      "Generator model loss: 0.9984907150268555.\n",
      "Discriminator model loss real: 0.6939434379339218.\n",
      "Discriminator model loss generated: 0.6605994045734406.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4441 of 5001.\n",
      "Step: 4442 of 5001.\n",
      "Step: 4443 of 5001.\n",
      "Step: 4444 of 5001.\n",
      "Step: 4445 of 5001.\n",
      "Step: 4446 of 5001.\n",
      "Step: 4447 of 5001.\n",
      "Step: 4448 of 5001.\n",
      "Step: 4449 of 5001.\n",
      "Step: 4450 of 5001.\n",
      "Generator model loss: 0.9802038729190826.\n",
      "Discriminator model loss real: 0.6966243028640747.\n",
      "Discriminator model loss generated: 0.661544120311737.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4451 of 5001.\n",
      "Step: 4452 of 5001.\n",
      "Step: 4453 of 5001.\n",
      "Step: 4454 of 5001.\n",
      "Step: 4455 of 5001.\n",
      "Step: 4456 of 5001.\n",
      "Step: 4457 of 5001.\n",
      "Step: 4458 of 5001.\n",
      "Step: 4459 of 5001.\n",
      "Step: 4460 of 5001.\n",
      "Generator model loss: 1.0538298845291139.\n",
      "Discriminator model loss real: 0.709728118777275.\n",
      "Discriminator model loss generated: 0.6514178931713104.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4461 of 5001.\n",
      "Step: 4462 of 5001.\n",
      "Step: 4463 of 5001.\n",
      "Step: 4464 of 5001.\n",
      "Step: 4465 of 5001.\n",
      "Step: 4466 of 5001.\n",
      "Step: 4467 of 5001.\n",
      "Step: 4468 of 5001.\n",
      "Step: 4469 of 5001.\n",
      "Step: 4470 of 5001.\n",
      "Generator model loss: 1.0063500881195069.\n",
      "Discriminator model loss real: 0.7584322392940521.\n",
      "Discriminator model loss generated: 0.632279497385025.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4471 of 5001.\n",
      "Step: 4472 of 5001.\n",
      "Step: 4473 of 5001.\n",
      "Step: 4474 of 5001.\n",
      "Step: 4475 of 5001.\n",
      "Step: 4476 of 5001.\n",
      "Step: 4477 of 5001.\n",
      "Step: 4478 of 5001.\n",
      "Step: 4479 of 5001.\n",
      "Step: 4480 of 5001.\n",
      "Generator model loss: 1.0269661724567414.\n",
      "Discriminator model loss real: 0.7022661626338959.\n",
      "Discriminator model loss generated: 0.636917245388031.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4481 of 5001.\n",
      "Step: 4482 of 5001.\n",
      "Step: 4483 of 5001.\n",
      "Step: 4484 of 5001.\n",
      "Step: 4485 of 5001.\n",
      "Step: 4486 of 5001.\n",
      "Step: 4487 of 5001.\n",
      "Step: 4488 of 5001.\n",
      "Step: 4489 of 5001.\n",
      "Step: 4490 of 5001.\n",
      "Generator model loss: 1.0880389869213105.\n",
      "Discriminator model loss real: 0.7369432836771012.\n",
      "Discriminator model loss generated: 0.6379406869411468.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4491 of 5001.\n",
      "Step: 4492 of 5001.\n",
      "Step: 4493 of 5001.\n",
      "Step: 4494 of 5001.\n",
      "Step: 4495 of 5001.\n",
      "Step: 4496 of 5001.\n",
      "Step: 4497 of 5001.\n",
      "Step: 4498 of 5001.\n",
      "Step: 4499 of 5001.\n",
      "Step: 4500 of 5001.\n",
      "Generator model loss: 1.030945008993149.\n",
      "Discriminator model loss real: 0.6950448989868164.\n",
      "Discriminator model loss generated: 0.6704002141952514.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4501 of 5001.\n",
      "Step: 4502 of 5001.\n",
      "Step: 4503 of 5001.\n",
      "Step: 4504 of 5001.\n",
      "Step: 4505 of 5001.\n",
      "Step: 4506 of 5001.\n",
      "Step: 4507 of 5001.\n",
      "Step: 4508 of 5001.\n",
      "Step: 4509 of 5001.\n",
      "Step: 4510 of 5001.\n",
      "Generator model loss: 1.0490572273731231.\n",
      "Discriminator model loss real: 0.7154364496469497.\n",
      "Discriminator model loss generated: 0.63510582447052.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 4511 of 5001.\n",
      "Step: 4512 of 5001.\n",
      "Step: 4513 of 5001.\n",
      "Step: 4514 of 5001.\n",
      "Step: 4515 of 5001.\n",
      "Step: 4516 of 5001.\n",
      "Step: 4517 of 5001.\n",
      "Step: 4518 of 5001.\n",
      "Step: 4519 of 5001.\n",
      "Step: 4520 of 5001.\n",
      "Generator model loss: 0.9631605446338654.\n",
      "Discriminator model loss real: 0.7676092177629471.\n",
      "Discriminator model loss generated: 0.6695306122303009.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 4521 of 5001.\n",
      "Step: 4522 of 5001.\n",
      "Step: 4523 of 5001.\n",
      "Step: 4524 of 5001.\n",
      "Step: 4525 of 5001.\n",
      "Step: 4526 of 5001.\n",
      "Step: 4527 of 5001.\n",
      "Step: 4528 of 5001.\n",
      "Step: 4529 of 5001.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K.set_learning_phase(1) # 1 = train\n",
    "adversarial_training('', None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for continued training\n",
    "# adversarial_training('', 'cache/CGAN_generator_model_weights_step_100.h5', 'cache/CGAN_discriminator_model_weights_step_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[combined_loss, disc_loss_real, disc_loss_generated, xgb_losses] = pickle.load(open(os.path.join(cache_dir, 'CGAN_losses.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsfXm8HUWZ9vP2We6SfblJIAsJIRBC2GNkE9kFUXEYncFv\n1BlcEBXEZRTUmVFHP8VxG1xmkEHUbxRRQRyWMICEVSEkkIQQQkhIQlbIvt/ce87p+v7oru7q6qru\nOuf0Pfece+v5/fLLPb1UV1VXPf3WU2+9RYwxWFhYWFgMHjj9nQELCwsLi8bCEr+FhYXFIIMlfgsL\nC4tBBkv8FhYWFoMMlvgtLCwsBhks8VtYWFgMMljit7CwsBhksMRvYWFhMchgid/CwsJikCHf3xlQ\nYezYsWzq1Kn9nQ0LCwuLlsFzzz23nTHWZXJtUxL/1KlTsWjRov7OhoWFhUXLgIheM73WSj0WFhYW\ngwyW+C0sLCwGGSzxW1hYWAwyWOK3sLCwGGSwxG9hYWExyGCJ38LCwmKQwRK/hYWFxSCDJf4mwpIN\nu/Hipj39nQ0LC4sBjqZcwDVY8e6f/BkAsO7GS/s5JxYWFgMZ1uK3sLCwGGSwxG9hYWExyGCJ38LC\nwmKQwRK/hYWFxSCDJX4LCwuLQQZL/BYWFhaDDJb4LSwsLAYZLPFbWFhYDDJY4rewsLAYZLDEb2Fh\nYTHIYInfwsLCYpDBiPiJ6GIiWklEq4noBsX5UUR0NxG9QETPEtFs4dxIIrqTiF4mohVEdHqWBbCw\nsLCwqA6pxE9EOQA/AXAJgFkA3kdEs6TLvgRgCWPsBAAfBHCTcO4mAP/LGJsJ4EQAK7LIuIWFhYVF\nbTCx+OcCWM0YW8MY6wVwB4DLpGtmAZgPAIyxlwFMJaLxRDQCwNkAfuaf62WM7c4s9zXgjb2HsPNA\nb39mwWIAYe+hEjbuOtjf2bCwqAomxD8RwAbh90b/mIilAC4HACKaC+AIAJMATAOwDcDPiWgxEd1K\nRENUDyGiq4hoEREt2rZtW5XFMMebv/kITvn6w32WvsXgwrt+9BTO+vaj/Z0NC4uqkNXk7o0ARhLR\nEgDXAlgMoAIv3v8pAP6TMXYygAMAYnMEAMAYu4UxNocxNqerqyujbFlY9C3W7bDWvkXrwWQjlk0A\nJgu/J/nHAjDG9gK4EgCIiACsBbAGQCeAjYyxBf6ld0JD/IMdjLH+zoKFhcUggYnFvxDADCKaRkRF\nAFcAuEe8wPfcKfo/PwLgCcbYXsbY6wA2ENEx/rnzAbyUUd4HFCquJX4LC4vGINXiZ4yViegaAA8C\nyAG4jTG2nIiu9s/fDOBYAL8kIgZgOYAPC0lcC+DX/odhDfyRgUUUZUv8FhYWDYLRnruMsXkA5knH\nbhb+fhrA0Zp7lwCYU0ceBwVcK/VYWFg0CHblbpPAWvwWFhaNgiX+JoFrid/CwqJBsMTfJLCTuxYW\nFo2CJf4mgSV+CwuLRsESf5OgYid3LSwsGgRL/E2CcsUSv4WFRWNgib9JYN05Wxt25bVFK8ESf5PA\navytDfv6LFoJg4r4VVYZY6xfrDX5mVkSfytZn+WKiz0HS8pz/fVuaoEdsVm0EgYV8au49Ut3L8O0\nL86Ln+hjXHHLM5h6w/2YesP92HeolNnk7p6DJUz74jz8/M9r607rxK89hAu+/3gGudLjyl8sxIn/\n+hCm3nA//vH3SyPnbnpkFaZ9cR4OlSp9mocsYIm/b3DaNx/BWd+e39/ZGHAYVMRfdt3Ysd88u0Fx\nZd9jwdqdwd/b9vVkNrm7wd8U5HeLNtad1p7uElZv3V93Okl4+tUdwd93PhfN8389sQYA0FuJv7dm\ng+X9vsHrew9h467u/s7GgMOgIn4F7zcFKi7LzGLsKXuFLOZb49UmhargZaFGZaYO2Dkai1ZCa7BD\nRlBZ/M2Asssyi9VT8q3jtlzrv1peJ63AqVbqsWgltD47VIEk3u/PScSKyzKL1dPbYha/CVphgrcV\nPk4WFhwDhx0MkDSB2p/cUnFZZlLBQCT+ViDVVvg4WVhwDBx2MECS1NOfIRPKWRK/L/UUcs2vjJcM\nJ21bQT9vgSxaWAQYVMSfJPX0p0brMpbZh6en7Lk+FvO5TNLrS5i6abaCNW01fotWwqAiftHil8mk\nP+d9y5XsJne7e32ppwUmd7sNib8VrGlL/BathOZnhwwhkrtMJo3suLJ0keXk7sHeMoDW0Pi7e02J\nv/lJtQWyaGERoPnZIUOIckqMfBvYc2WJo+y6mVn8PO22ViB+Y4u/+Vm1FfJoYcHR/OyQISqCyS8T\nfyO3PjwoWbouy87i52RKzT+3a2zxtwKntoIcZWHBYUT8RHQxEa0kotVEdIPi/CgiupuIXiCiZ4lo\ntnQ+R0SLiei+rDJeC0QnkgpjEa+SRnbcmMVfyW5yl2v8rbCH74Cy+Fugvi0sOFKJn4hyAH4C4BIA\nswC8j4hmSZd9CcASxtgJAD4I4Cbp/HUAVtSf3fogTu5WKixCPI10GZQJL0t3zu5SOUiz2WGu8fdx\nRjJAC3ybLCwCmFj8cwGsZoytYYz1ArgDwGXSNbMAzAcAxtjLAKYS0XgAIKJJAC4FcGtmua4RrmTx\nHxKIp5EugzLhlSpudsTvp90KVnKSxR8djTV/WVohjxYWHCbEPxGAGMJyo39MxFIAlwMAEc0FcASA\nSf65fwfwBQANc5j84+JNuOzHTwW/P/nr53HK1x/Gx/57UXBs4bqdmPvNR4Lf35y3Aif960OY/ZUH\ncerXH8bxX3kQv17wGk775iP47cL1OOlfH8JJ//oQTvjqg/jtwvW4Z+lmvOvHT+H7D63E534XDSd8\nw10v4HsPrcSSDbtx5o3zsfeQF2/+uw+uxBfuXBrT+Ot15zzYW8YlNz2JD972bECmJtE+e8oVvP/W\nBXhx0x4AwKMvbw3Kv3b7gci1+3vKOOvb8/Hca2FU0evvfAHnfvcxbN5dW/TEJItflMMYY/jLq9tx\n7ncfa1iI5r/56dP43aLkyK3ie+fE/3e3PoNfL3gtdu2WPd148zf/FKtXFW64y6vXTVK97uku4cwb\n52Ppht248YGX8fnfL8VH/98i/PTxV02K1Gf4u1ufwe0L1ge/f/DwK/jUbxYrr122cQ9O/frDOPPG\n+fjAzxYor/nc75biOw++nPjMm/60Ctfc/jwA4NYn1+BDv1gYOd/dW8GlP3wS779V/Yzt+3tw+rce\nwStv7Et8ThIO9pbxln+bj2eFSLsqLN2wG2d86xHs6VbvO9EfyGpy90YAI4loCYBrASwGUCGidwDY\nyhh7Li0BIrqKiBYR0aJt27bVlZlP/3YJlm7cE/y+f9kW7DzQi817DgXHvvPgysg9f1yyGbsPlrC/\np4wdB3qxr6eML9/9Il7fewjX37UMuw+WsPtgCXsPlXH9Xcvwqd8sxgsb9+CH81fjruej4YTvWLgB\nP5q/Gt9/+BVs2t2N51/bBQD48aOr8btFG5VePTzUQi3YurcHK7bsxROvbAvSMZkzeGNPD55avR1L\nN+4GANzwhxeC8v/6mSh5vbhpDzbu6sa3/zest98u2oC12w9gnQGZqZD0sRPrw2XAv977EtZuP4A1\n22p7VrV4du1OfOHOFxKvEd87L8qfV+/Al+9+MXbtPUs24429Pbhd8VGQccdCr17XSmVdtG4nNu3u\nxk2PrMLNj7+K3z+3EQ+/9Aa+9UAySfY1/rx6B75097Lg902PrMI9Szcrr/3R/FXYcaAXm3Z348lV\n25Uj7bue34ifPJr8MfvBn17BfS9sAQB84/4VmP/y1sj57ft7sHzzXjy1ejvKihXif3rpDWzZcwg/\ne7L2fStWbNmLDTu7ceMDySr2TY+swuY9h7BoXfIHopEwIf5NACYLvyf5xwIwxvYyxq5kjJ0ET+Pv\nArAGwJkA3kVE6+BJROcR0a9UD2GM3cIYm8MYm9PV1VV9SRRImnCrV9ox8ZN3iD8relyWOEoVFli/\ntXjjiMnzUMYmk408H/xaR3i4nI+cXxiVJFVrTSbJI+JHQbyO1fy0vkVae+IfYscxf8Hyx5tXSQs4\nbGkh95u+mlsT01VJikFd1lGZ5N+cVgT+ypsp9IgJ8S8EMIOIphFREcAVAO4RLyCikf45APgIgCf8\nj8EXGWOTGGNT/fvmM8ben2H+E5EYlK3OtE385HmbkglOlnpKFTdonO01hFoQ0w+kniqIn18r9gGS\negQnflW6tX5Dk7IYsfgbvKq6FqMgrbp5kk4VTFORCs7fs/xuWgnyivJSRhsQyago+oSILOqS35nW\nXkw/EI1EPu0CxliZiK4B8CCAHIDbGGPLiehq//zNAI4F8EsiYgCWA/hwH+bZGBWXwSFNbdf5Etry\nOexDOfEa3snTLP6y4GFUhUEYQGx41Uzu8mu5JSJ2AjkbOd54Fa231onNpA6js/ipAfZuLR00rQ54\nHeeqIv7ob15ftbSRZoFs8ZdcFx3IPq6Uqk+oztdTl0H/Tr0unqf+RirxAwBjbB6AedKxm4W/nwZw\ndEoajwF4rOoc1gEv3LF6MrDeV9BeUFv84ssNv/TRp3X3Rj8YJdcNGmct+RKJ6lAVk7vc9TMkfuFk\nI6SeBIYVdVmx+hoh9dSyYU8a8bu1SD1SPmoZNfQ1qiUzmfhNtxx1XVZl3YV/qyx+/tR66tLR9G8Z\nvO80k8U/oFfuVhjTugzW+/XVST09gkTB25T8wvd2R4m/LGj8tWRLvCfQ7Y0s/uhEcFInSCT+Gusy\nqSOIEoBYlqz2Jk5CLdKS6yZ/yMJ5FPM0ZYs/C106a1SrW8tSj2riVfkcgzYmtkM3xeJ3VcZOlQj6\nd0oRuAHYn6HfZQxo4nddpnUZrF/jVw9PRY8d3RBvx4HeyO+yoPHXIpuoGnk1Gn+lEu8EsqTCz6ka\nb99M7qr9+BuxfWatFn9SnfNT1Ug9cj74aKeZLP5q3ZALManH7H6TD4xoLEQmd1VSj/9/PXUZGnbJ\neQslX0v8DUHZ1Vv89aJNI/UkDSs5dknEX3JZMOFbm9QT3nWo5FvxJsTvS06czKOTu9Fr+SO4pSSm\nX2uDTrotavGrj/cVarL4GUskAFOvHlczt+H99v9oHt6v2lCRR8rGFr9Be46GXQ+P95VXj24OL35d\nPE/9jQFN/IkWf50vQed9I3rsBK6V0sN2Kiz+YKRQp9TDd+AyknpK0cldJ2FylyfHLbySRoOvBokW\nfyT9xko9tQzJXZZMToHGn8I0pUggweg5ZphGI1Gt1FOo0avH5J1ELP4Urx4WGDuNs/hbzZ2zZZFk\n8de7xF5r8QvEfyiQb6LX7DjQE/ldErx6apm8VBXFaHK3VxodiFKP1B94ffFryxGLv4rMRtLUnxPT\nFztMqUmlHpYm9Rhq/OWIXKF252wmr55qyUweHZrWdcWgPYvGgpgv2X0ayKYueVHScmb6gWgkBjTx\nVxIs/nqhm9wVNX5u8cuNfdfB6NLtUsWta3JX1aCqsvgVlqRsCfHkeIcqldUafDVIuq9XEzm1VMcK\nZ1PUJvUkT+7y4uRSmKZU0Vv8PF/NavGbSH5ymUrlvrH4xbyownzwbFfjKRRPg8WepYKpJNRIDHzi\n13r11Jd23knX+HtKnPij18SlHtHirx4qAjWa3OUaP5/cNXgG74Ci5V1rVSb68Ws6cSOijkYmlg2f\nlz65ayj1JFj8SrfbfoZI/L0Ger1cJtMRnNnkrtriV/vxe//XU5eBxZ+StZyh22cjMbCJn/Wdxa9r\niOKw8lDZzFMn4sdfQ+NQ3VFNyAaVxS/nmf8KpJ4IMVeRWTGPSVKPzuI3nAysByIXVbNnQNJ7NpUW\nIqHDpQriJNmIRWymiGjpBn1NttxN52zMJnfFifHweNLK3XpGT4HDQ5rF78Tz1N8YkMQf+tcyHOwj\nrx45XU7Yhwwsfhn1Wvyqj4XJ0Lhb8gAS+4B4NxNITUX8tdr8SZ25FOnE/Te5a0r8zHRyN4X5Ixo/\nU59rVo3fpK7k73amXj2aUN5JH6R6qpI/Iy1ruoWc/Qmjlbutgmtufx7nHDMOBI+Kym405r6Ien1q\nn3glGkG04jLkcxRpZD2+xb9s057YhK4IMZIhY8BtT63FKUeMwkmTR0au+/2iDThsRAcmjerAdx5a\niUkjOzBhRDtmTxwRS7NcYfjL6u14es0OAMBnLzwaP31iDd4yYyxcF1iwdkco9aTE3/mvJ9cEC2/4\nSEIcov9o/mocNW4ojho3LDj24qY9ePrVHfjo2UcC8MI6f/+hV/CFi49BeyHnPyP+3BsfeBnvOXUi\nvnrP8uDY1+5dHkggusnAVW/sw92LN+FQycXlp0zEfz72KiaN6sCk0Z34wGlHxK7/9YLXMGPcMMyd\nNjpyvFRx8bV7w2fLpPHbhesxeVQnzjhqbOS4y/Sb6azbfgC/ema9X2bv2JINu7F4/S5ceea04LrH\nVm4NIrkCClnEJzYTI7VUcfHtB17GFXMn47cLN+D6i2fiNws34Jjxw/DU6u3461Mm4ogxQ9ITUmDR\nup1YsWUvPnD61EiZv3bPS/iXd4Z7NN353Ea8tuMAGPP6gssQC02c5Mcvtg8T4j9UcvGN+17CJ849\nKkKyP31iDa67YAbuW7oF63ceBOBFygWAnz21FhfPnoD7X9iCD79lGsYNa099DuDJtd+4/yUAwPqd\nB/G9h1Zi6pgh+OtTJwXX/G7hBjy1envAA4wx7Oku4YePrML1F880CvTYVxhQxP/4ym0YN6zd+8L6\nHZFXOsfYoW3Yvr8n84X/FcaQR3TlLg809ou/rDNKwyE/BPF9XoNad+OlkfOf98MEf+1dx+F+PyQt\nAPzuY6fH0nIZw/8RYpFfdtJE3PjAy/jugxQMic88aoyXd0WsHtG76JvzwrC/ZYXFv3zzXvzNT5/B\n8/98YXDsHT/y9kPgxP/Tx1/FbX9eiwkj2nDV2dP9PHqTnWKnvvnxV3GzFF/+VSE8sc79729++nQw\naX7vC5uxbV/4oVURPw+dLNfxvGVb8NjK8KMu69bX37VMeV+SO+dH/l+4DwS/5t0/+TMARIj/v59+\nDfNXbhWujabD695EnnhkxVbc+tRa3PrUWgDAqUeMxg8fWYXpXUPwzJqdeGDZFjz82bempqPCe25+\nGgBixP+/y1+PzF/94++Xxu7luPT4w3D/si2JFr9oF5iMYB966XXc+tRabN3Xg8tPiW4Z8tLmvfjC\nXfEw2z1lF+/6sfcuXttxEDd/4NTU5wDAV+9ZjoXrwo/0j+Z7HxKR+L9273Ic6K2ga1ibVwaX4TsP\nvoxfPbMeMycMw3vnTEZ/YUBJPe3FHLpLlWD4VnFZhCiufut0/OLKNwHIZg3M1DGduOGSmcGzAMm/\nvcr0Ootm32HZPU1FOPJEo2pFbyxIm3iDJvPB5K7UYXUbpPCPX+j/H5VwqpUtdEQh1kk9exvI/JLF\n5K7pbmIHeytRspMs/nIVFr9qZMQYw4Eer54OlbORQOW2ZzLBO6KjgE+c6338k/z4XQOLX3w//JoD\nPeWgHv/p0mMBGMpQVagAskGpAi8bEyQhvsCyv0WfAUX8ncUcunvLkfACYqcr5ChTVziHKJixr6iI\nrcrZnI6iWZRCuRGrOpv87IO98UiiByXiFx2VdDlXfeAA/TwGz6sqhK3Lqg+LqyNX8fn1bHweX79g\ndp84DyIj7+gnzUXI71V+rb1B26q+DfORVZYr2V2XxcjS5HXmHAoWciX58buRj6CG+IXn82f3CluZ\ncmPKZOK5kDOvV5NvBM8Pb7MuY0HbrCZ0R19gQBF/RyEXadiuG7XCiCjwo87ii0sUD15WrtLiF9//\nEEPil63rgz1xUo9Z/IoOv++QHLJBIChNR1Mt4ALiC894vfC8hpEMhXtqsPh1FmXEOqxj/kb+EJku\nUHJd/cSzuFo1ySCW36vO4q9lfsqh7Ne19JTdWJlNXqdI/EleWiYWv/iuefvtKbvB8aHtPvEbfPB0\nLtoqmLwBecUuY+Ikv/Gj+gQDivjbCzl0l9ygAZRdFmtYjvQVrgXcMnCED0lgCSfEWhHB+aWjEJJ9\nR4LUI8oXcuc9kBB9MLimJ37NXn+iLQzZEJ5Lq500t0o+Gczz6gShaWWpp0qLX0OuJiRhAtkSM/XE\nSHLnzOfMLP6YhBdb5er9NimffI3jEBhDsP9zFi6hB3vLNXmq5IiCUVCS1BOVvXRST/xYb9kNPo5D\n27z+ZbJXcz5ji5/3J1ew+Hlx+3sR3oAi/o6CJ/VAqPCYReJXuKkbmQrcWokQP4tb/En9kxOjuAI4\nyeIXLRaZIFQyjkwa+w7FN3reL3v1iJO7KQ1brlf5eu6xwPPKUxbrxGXVdwDde4uOJKLnZNJIsph1\noSrSkDS5K1qS8gdZ/J0m9fCPrZmHSzStHBEqjGG/YnRYK7pLlVheTKS7iNRjqvFr3oN4Ddfde8tu\nUHdc6lGFbZBRqMoMT38HcjhmV7D401Zw9zUGFvFLk7tll8U0xGwsfq/alFJPhIH0aRSDNMIGkKTx\nix1Z7tSyNd+Wd2Idcq+C+OUwDGJblGUGGWkxVngddUtSDySLv1rDxySMr0wS8ugkycqU+2M1Gr+u\nTRUiFn/0nHiP7Hocl3p8i99kjYaUlkMEl7FMwwYcUhG/wX05hwLrOlnjr07q4R51vRU3uHdoWxVS\nTxUWv0m7kOP1ixq/tfgzREcxh+7eijS5Kw15A4u/fuJXSj0RjV//DJUP75AEqUe0WORGLFv8KuLn\ner4KKq+eNIKV61W+mo9k+EdKtSkNy9DiFyGXXSbk5I+WXuNPXqClHx1ENH7pGtV+yeHzounwfJvt\ntSAZPE5UFsliJ7ODvSqLP/2+vEOBdZ3s1RP+rat7JpSJt7WSQPzthRyITCd3q9D4Db6g4SjXt/hd\nJhhZlvgzQ0chh0OCxu9JPbLFX3+IVE5qjoOYV0854q6oT0PVyDqTpB6R+GWNX7L42wu5GDkkEr9i\n+XpaNMS0Dyf/sAUaPzf4IdZP9ZO7tcTjl9tAdRZ/eG00FHWcwHV1khfedTw6pfe7t+zG3ll8AVdI\nIGlIClOQFbpVxG9g8zuixR/zDmPKv5Msfv7OAou/HBJ/3iF0FHKJ7Z+jGq8e3SsQ8+xIMrBoHPT3\n6usBR/wHBXfOsstilis/V09433zC5G7ZdQPSS+poKos/SeqJaPxpFn/BiZHD3u641MOhCtmQVj8x\nq1nW+H2yOxhY/Lyewmtqmtyt4b3JRF/N/I5Yj0mhqJMmdwtCL5cJjP9WEXU8rk0VFr/UJhirz9tJ\n+YxSpaY0cyRKPfq5IlN3TtmDTNT4HfKIXyV11gNdqZNWwXttJMxXf2JgEX9R4c4pW/zcnbOOPlAQ\n9HmZ+HvLDO0+qSc9g1sX4us3tfhlLVj26mnPxy1+seHL1kYo9YQn0iz6tEVShTxF8hpK/NERUbV+\n/KZhfCP3VGHxy+QtEltSKOqkBVziRJ5MlLzuVV4nsSBtdVj8ZTc7fZ8Xp7u3EiuzyagiJ0g9cjuS\nvb44xLpwpb95G+KLo3rLbqilO94IWN7nWoVqRpM6qUe3/SO/JwjlbPykvsHAIn5f6uHw3Dlljb/+\n54QaP+JePa4bxKJJQlGxg1fSyl2xI8c0fslTo72Qi3XAvcJQV/YoUFn8aVJYmh8/35OY55VLYuJV\ntfjx1zJSkz9iSa6oSRZoZHcsmfhdPSGL1p3O40ilQceJ31U+WwW+yU6YVvR3Pe6c4sR9zEvJkPgd\nxzOa5BFc1OtLTaJi+SuMBW2Le/X0CBp/ziF0FHNKrzYZ1UR+1RVTbCPxugnL0d8B24yIn4guJqKV\nRLSaiG5QnB9FRHcT0QtE9CwRzfaPTyaiR4noJSJaTkTXZV0AEVwqEbc8jPvx18/8Rd9az6mkngoz\nJP4qNX6fQPMOxYj/QJWTuzryiUg9KZ0gTS4pSl49YsRUDtetZXK3Botf9o5J+KjppBj52SqpR/ex\nTAq1zAlAdjcs5h1trJ5a3Dmz3KtYJP5YfRk8hveZvEOx9ykSYsSPX2f9M3GxoFdhpYobmbfqLJpp\n/NW0Ld3keDS6arxsgexTxxxjFkglfiLKAfgJgEsAzALwPiKaJV32JQBLGGMnAPgggJv842UAn2OM\nzQJwGoBPKu7NDHwxVEXoIHE//vqfE/HqiYVscLW7c4ngHw8xd0m+vVyzLeScmHUok4Zn8UfvFzV+\nkfiKeUc5uZumI8e8eqTLuYYb+vHHy1tTrJ4MLP6kj1acyNTEH9uvgOnrTI5PFMmLRuNvzzva6Jwq\n4k8L0RFbd1GH2MDfrWpy18TbhbfzQs5JbEc6jypZ9uHNNtzxDhEtvd1Q469mNKm7VLf9IyBb/MaP\n6hOYRAWbC2A1Y2wNABDRHQAuA/CScM0sADcCAGPsZSKaSkTjGWNbAGzxj+8johUAJkr3ZoYOydJW\n+/HXz/wRP36/Ezy5ajuee20XuksV7X68IlQWv6x3b9vXg+Wb92DSqE48/aoXXlk1CfjCxj2R36oP\nj26oO6wtj8Xrd+O1HQeMLf5Vb+zDc0L4YMCr61Vv7MOM8V5oZt6BueUZejZ4/6/fcRAL1u6sWuOf\nt+x1PLT8dZw4eSQWrtuJs4/uwqMvb0285z8fW40PnTUNJ0zywlzfK4TB/unjr+I9p07C7u4SHn7p\njVhn3bSrG//x2GoMbctHrEYxMiMvl2r4/uq2/Vi4bmfw+9GXt+LsGV3hfRqNv62Qw+7uEv73xddx\n8ewJeOKVbdi0uxuA2jK96ZFVKOYdnDdzHI49bLhC44+/z3XbD2Db/h68aaoXmvrJVdswY9wwTBgR\nDU381KrtWLpxN44cO8TzyPGJe+G6ndg1bmjkWpPRCCd+Ii/U+JcvPRY5h7B2+4EgbDIQ/Ug+tXo7\nOoo5VCoMizfsilzD0+uR5vcAT47tKOQSnRs4unsr+J8lm/CuEw/Hotd2oWtoG6aOHYLF63dhWHse\nh43owOOvbMPJU0YG4c5lcGeSR1dujX3UvJW7vlHqjxDvXboZ7zrxcLywaQ+GFHNB/+lrmBD/RAAb\nhN8bAbxZumYpgMsBPElEcwEcAWASgDf4BUQ0FcDJABZAASK6CsBVADBlyhSjzMs4sisaX9z1NX4e\nivmiWeMxzIA7AAAgAElEQVRjxD+9a0gk7K8JOGmLFv93Hlzpncs5mHX48CDEsohCjoLGILpzvv+0\nKbhnyeaY6vrem/+CdTsOwhRteQdll2HSqI7YuX2aFZtD2vLYcaAXb/3OY3jLjDDGfFIHvvAHT2iP\n83DFnGgC4vfT43357O88CgCYPDqeV45hbXllvq/67+eCvyeO7AgIUYc/LtmMV7cdwL3XnoWVr+/D\nD/0QugDwrQdeRjHv4KXNe/H75zZi4shofn69YD1WbNkbS/Pvb3s28tvVWPznf+/xyO91Ow7iyl8s\nDH7ze+RRW0chh8dWbsNjK7fhqevPxQeF56ks05seWQUAWLZxD27+wKmRuS5ALfX8+NHVWLhuJx7/\n/LkAgA/87FkcPqIdf/ni+ZHrvvzHZXhN0Q4fXP4GHlz+RuSYiSXL+wwB2NtTxootezF74gic+93H\nIteJ39HbF6zH7QvWx9KquCzoNz2KyfecQ2gvOEYrlh948XU88OLrGFLMB6G01914Kb74h2WY3jUU\n+Rzhf5ZsTkyjXHFRqri48ucLFefCBVyMMfz30+vw1XtfQnepgi/+QR3uu6+Q1eTujQBGEtESANcC\nWAwgaMlENBTAXQA+zRiL9yIAjLFbGGNzGGNzurq6VJekYs7U0UGMeSC0+E+YNALrbrwUsyeOiEgL\nMycMw51Xn1H1c4JYPU5cnumtuCjkKBbwae600Xj565cE1nhRIP5vvPt4vPDVt8VkKB3pTxrVgctP\nnhg7fv+nzsIr37gEExXEz5gXRnrOEaMix/nKRhn17nTFuUmU3bx8RNPVjcCIgMc+f07w+4WvXoQH\nrntL7Lo00ufgHX9/T9zyK1Xc4LwsCaTFePn4OXxvAZao25511FgMb4/Xtc6dUxy9xkk8TvzTxg7B\nSZNHBvM9soWvkrf2HSoFu8TxNDfvORS7rpq2oKqDs4/uwrobL8W0sZ5hxvvMv19xkrY8gNkEqCvI\nOqq5FCJCPucE15zlb6Aj1u/dnzgDMyeElvaug9E9sfcdKqOnXMGr2/an5qdU0bv1iqPCisuwxa/r\n3QezdTU1gYnFvwmAuGPAJP9YAJ/MrwQA8sbuawFwaagAj/R/zRj7QwZ5ToT4QvmiGjEsrigtcO+C\naqFauSsi7zhe9L2KeI93LW8SBZXUY/j89kJOmW+eH12UwfZCLiZDDRXISKybetY5AHFpJ/gAGBJ/\njqIhtNvyTp/FN6m4IfHKlmGa2ypvW0ya3HVdFnlH+RwprWFeP7KLbsQFVLpRlae2vOOHJff3XTDw\nZOouhZOgSSENqokGqvI44uuieF3lgv+T17uYjB7ED65qDsZzHY22IxnthVziql0emsJkn4ey62r1\n/4obBmmruCyINFvNwrGsYGLxLwQwg4imEVERwBUA7hEvIKKR/jkA+AiAJxhje/2PwM8ArGCMfT/L\njOsgkl654nn1iCQrdiiHqCb3TpUff+R83omRr0xwbYqGZqp3F3KOMt/8GaqPCuB5Pcn50HkgVaPV\nqiDv1KXeq1c/2Z5zosSfq/Fdcaj2S+BwGRM2u4+eS/Nu4nUgTtwBcQIs5OKeVkBYHzLxinUrT9Sq\nylDkxM8XMRmsXTgkTM7yD09R0S6rmYhUkXjQLv20edmC6JWa9E0s/oobWtHiuwp3K4vKqqr2XshR\nIvl2l7z1CibEXyrrLX5vLUUoefK674+AbanEzxgrA7gGwIMAVgD4HWNsORFdTURX+5cdC+BFIloJ\nz/uHu22eCeADAM4joiX+v7dnXgoBcgjcUoVFvvhiHXNf4mqh8uOPnHfiJMWtHX5YNblrmhU+eojf\nT8HzVego5CKjHyC0xoCoZWfi/teZ4LbqShZ+uHNXNF3dhhQ5h0BO9Hc9E/NcslFJN66r36Akjfjz\nAfEzrcsh4JVTRQg6d84o8cuumfE8FXOOH5ZcbfGrJndFd0x+n8oirsbnXCX18JEPJ9fA4k8Jn2Iy\n0hDrXZxj4STt+FIPh8rxIu840bAaUh66SxW4zJD4XVe7zkKM1SPGEctXESMoKxjt9ccYmwdgnnTs\nZuHvpwEcrbjvKWSzy6ExopteeCt3xYqNWpG1efmoJndF5BXELP9WbrRsmJe8hgT5IV1DktcJFP3J\nYI7ogpn0Rl7IO4BmD3nZ51wMaSFCK/VIZdSNrkzBLXrVQimX6YN4pX0AQ7kiSjzxQHGukkB17pxi\nWWX5SUn8eccPS86J33Mr5hOeqnIc7C0H+eQfFxUxVmfxx4/xPsLbJf+t2qOh2ue6rqDxC2Xk5fZC\nQId1qbL485LFL6fDmHfMZFvJcoVFAsdFzgnE78nQ9cmp9WBArdwFotvc8Vg94ksVecah2qzIcCMW\ntcWfzzkBIYjPiqZRu8afzzmJxK8btrYXolJPZzEXsWJETq5/cldD/FVJPdFj9Vj8nFh1MXF0Fn9v\nxdVOgANRjT+y/6tEZr0VpiQyXcgG0aAwlXrEkCUll2FYeyE4r9o/4VDJjVn8KqkHMF9vobLeeVeQ\nNf5gVzYN/5lN7ob1Ls5LRSx+oS/yEY24jqGYi0qzYn3zD6mpxV+uJFj80gIu/gHvSXEg6AsMPOIX\nGi6P1SO+VJE86pV6tBq/Q5D7jxzrW+3Hb/p8EibIonMWgH4LuY5CLpKPjkIuYsWIHc0kEFhS1XHL\nXiZ+05XU8uQugJom4sP8eB1NRfCM6bckLFVcDGnTS1o5wWqNWPyKRWMqUgwt7ii5Ry1+SepREFAx\n5wRhyfnzRC8ieaTF99+VNf42hUXssuRwItFrzTV+3ke0Fr+BQVwR498IyfDwDZ7GL07uqix+J3KN\nOMIKpDPXzOIvuckavxipk/v8Z7k5jikGHPFHhmyu79WTi5Oj93dtsXsC4ofe4k+b3FVb/KZSjxPK\nOhGPJf58jcYvTe52FKIWv9heTYahSZPRnOPiUo+5xS+fq3cOrLtU0cbE0Vn8jGlkOR+8rl2GmMUv\natS6EVQYqyesb3GDHyAei0lFQFzq6fEDlJUrDMM6QotfHiWUKt7HTvbq0Wn8SeFE5GtlBAaJpPHL\nO1SZpBW7xlWPpHrLLoi4O6co9fC+Gx7LS+7XYkA3LoG5pl49FVfr1uu6UXdO3sdMwklkjQFI/ILF\nzxhKrhs5JpKHRy41aPxCQ1Ja/DmKbaYsT6qqOlhVFr9kRQGiZaUnfjEfHYLUk3Ooaos/KbtyMKpw\ncleOv66+XzWZq5sINkV3r4b4E6SetOeKFr9IYK7LIguKdO6xgTun8PxCLuq6ekAgfoeSNX7AI/GS\nK1n8MS8fN7D4GWOhxq9ol4zp13vEyxM/FsbmkSx+HrhPE+fIZE5Z1057ym44txCRehRePY4T+TiI\nq9z5SMwbWaTnp6SR9ADfAymi8Xt/m6wqzhoDjvjFF8hj9ej8+GvVjDnZMqhJIe8oLH6uBQdpKDR6\nw+d76wSiVhQgWPwJUo8ol4hSTyFXPfEnQbbwufSRFJRLhIr4q/lIyx9awCd+BcEf6q0kkkySHBhq\n/FJANzcqH+m8g8TJXa6vFyQJUgy7PaQtryQWLvXwtEoVhmERqSd6kygvuEzQ+HUWf4LcFblWkTl5\n7imY3BX2aKh14xjdSKqn5CoNoXaVV0+OIgaUaIHzxVWmc17lBK+eqNQT7hWS9V4BJhhwxC9umOyt\n3GUxWYX3qVqJP5dq8cf97GUiUk2imeZHJEW1xZ+g8UsWP9eLi8LqRsAsRG1SfmWJR2fx66Ca3K1m\nPkYld3WX1MTPw0Lokk96buDV40atVlk+0hEHJ8qDvWUM78gHz9P58Q/TWN7FvBN4rPDgacOFyV1Z\nHpLzeiiQeuIEzxjQWTCz+NULuCSNX1j5zp+v9rZKJ1tde+opV4L00/z485Lnj0jEfBWvqUtrKUnq\nYUxY0Q4r9WQJscPz2XLZuuaEVat7oGjl66Qe2eoOdE3/tyoev6nJ72nA/rPE0YzwfBU6i7lIftsF\ni7+YzxltdScieXJX7dUj74iWZPHLFn41Uo/q49ddqij9+A/6k6ejh7Qp00r6wBUEjV9254wQv6Y+\nQ4vfDbxwinknUlZxa03dgrtizgl0eE5cwztEr57kiKTdCVJPvRZ/Thqd5qT+xxhTr68wklZ0xO/G\n3EgBtcXPwzpwiMS/Y79H/KYjYDlkg2jglQWNX5R6OPGbRPXNCgOO+MUOzzVW2a/dCYaatT0jJwzv\n1ZO78VAQMnkovXoMny+6oarWKOj8+FXunLyO2vJRi99kaJs8uatz5zTU+FXuqlW0ViXx91Zii6GA\ncD+D0UMKsXOAfrIcEFwSFe6cohWrI17Rq4ZLM3lHr/HrjBVR4+dEIo4Okt5nRdD4VfXGmCcxmUDF\nj7ydFCSNP5B6hOdHn2sg9WgIubeslnpUIxovb6LGH9b3zgO+xW9I/OVKdOQnrosQJ3e9OaCK/zzv\nQ2Oyj0dWMHubLQRRytiw62DsGBBqjrVKPXK8n3genLg7p3SdUuM3zA9R3FMCEN05DSd3Ba+eQ6UK\ntu4LA3TVEvdehEj4L23ei5Wv7wMALN+8N2jwgH4LOlW9VmPxq+pgzfYDQUcWseoNL/jWqM5i7Fza\nc7n3kcsYlm7cHRzv7q1g9dYwqJduIdiOAz3YeaAXB0tlDO/wwiHLhoO40Y4J8fPJQnEPZ3mkJUKU\negDgxU170F5wsOtgCZNHdcJlLBbyXAeVayLvC7JXD2+vr+04qN5jwIBrtyiCygHAytf3hfNgCj9+\nGXmNxr/Tl3pM9xYuu24k2m9bPod98CeIXRZsrtNdqmCpH06d7463p7uEZ9bswGlHjkFfY0Bb/H9e\n7cXMHil16NDiDzvRlNGdxs8IuTbq5sb7ZDGvWMDln7z0hMO8a+pYwCVa/BFSCibR1K91zJC2CKGM\nH96Otx/v5WfHgV68sTdchmvS6S46brz2HO/Iuw724u0/fBIr39gXnPvdwjDKt8sYTvcbuliUpJAU\nJjh+4ojg76P8mPH//McX8eSq7bFrX9/rkcdkTRvIOYSRnerRgEPeO9i4qzuS9id+/Tw+/dslwe8L\njh2nvP/Ld7+IU77+MLp7XYwb5hH/xcdNiHjkiCOH4w4fEUsDAE6eMgrtflvk5FvIORg71JOv+Iij\na1hczhKJf8veQ3jHj57CBd9/Au+9+Wl84GcLUr160l4Lf2/8wzrCl6D4K/7Ogytx3R1LYveZ6Opf\nv0+9tce+njL2+B/AqDtn2F9PFSLVjhLer+jVs8s3FOR1GTos27gHH/VDOnvPE6UeN1gR/6tnXguO\n7xc+NNfcvtjoOfViwFn83JK+4Nhx+Pg505F3HMyeGO0svMFxcln8zxeio5jDnu4SCjkHp3z9YQDA\nPdeciUmjOkEATvaPPf/PF+K+F8KY3J3FPB7//DkgEM773mNwmbf1omzQcwv02399Ar54ybFYumE3\nZIgd6D/+7hQ8uWo7fvNsPAY5IbSi5HUJQLShf+Kc6fiHM6di274ezDpsOOa/7MVPP/voLnz8nOlw\niLBpVzee9TcLOe3I0djfU8aLm7zo2f/2nhOw71A56GAPf+ZsMAAjOwoY0VnAz/+8LpY/ICT+PYJP\n9KjOAnYdLGHnAcGLgQE/v/JNONhbQTHv4O03PYn1Ow+qib8KM+XNR47GN/5qNgo5B7sO9Eb2EHjT\n1FE4fuJI3PbntcGxmROG4YzpY3DncxsxoqOAB657C864cT4Ar538+frzcKhUwTfuX4G7F4fBafki\nvm37vI/m+TPH4ZGXt0Y2FLn1g3NwzjFd+OXTYWeXcahUwYQR7Xj2y+djzJA29JZddA1rw7//aRV6\n/L/vveYsjB5SxF3Pb4zc+4O/PRFvPboLy3wLMtimM0eY96mzMPebjwQjjq++8zis23Eg2D8C4FEj\n/fclhSR+bcdBMN/AefbL5wMM2La/B1+75yU8u24n/uGMqfjYW4/E6d+ary0bb6PXnHcULpg1Hsce\nNiyo1yTo5JXZE4fj0+cfHcTMT4M4uhYNtV9/5M2BxHTV2dNx1owufO+hlZEPONf7k0ZMf/rs2SAi\nnP+9x2MjEFnj5yG2uZWfcygy8V7vWhVTDDji50O2MUPacOoRo5XX8IbIOXPUEM8SkTW2kR1FjB4S\nHS2MHlIM7ucGyRFjvDjjXG/0vGfUFn8h56BrWJuSxETiP37iCOw7VMJvnlVdF058ihZ8GKQtTHz8\n8HaMG9YeWJP8+rFDikF5xw0PrcBRncWI7n70+GF4fU8Y837CiPZgEjJpApifE5ejF/MOinkHB0ui\nK6H3oeR54dZgvRY/gXDYCG9fAnnicHh7AWOGRt/rrMOGB6TQWcxFzjtEGNKWx5C2PMZJFrNDnisg\nJ4jjDh+OR6QdwSaMaE8NxNVdqqCjkAveU0cxh5OneBZpb9lFMefEdsbiONwvp7glIuC1gzHc4vct\nzaHt8TKIEkSPtEipmHfQXarAIQryNm54mI+ZE4YF9cxxxJjOyMYt/L21F3I4afLI2HGOMUOK2CFI\ncTp5hTHg8JH6DXxkiH1R/Ftsd8W8g5Mmj4xJWlz2SVq81TW0He1FL13ZNVM0wlQrx0d1FrB9f1jm\nLHYINMGAk3qCzc8Thom8btMsDt07CIhfc19H0UldwKVapSu+9HxOv7hMXNkpJqvS/eUy8nxEYsVL\nH49oGAhEZCvVCEMFXv+HBD2/t+yio5CLxJ6X65DnS6WrV6Pxi5fK0ld7MRebOPR2asoFf+ekdyHn\nL/hNnkXJCWLUkPg8QdLKX46KyyKaPE8b8Mg4cYJZMCqAcLVpPhe6xHLvF4cQe05FmJhWEb/LmLYv\nqD5osoyp++bJdSnr70kT0tV45BVS3K8jeZIKakL85ITGluyaKba9/YfiYTniK/wTs5cZBhzxi14W\nOsgrB7Vpad5CWhRVlcUvPyuNw3KkD+DAdWUvL+FV4UKZ8NmxKKGKuQFHSkOO/yOWNzKloCmEuBJT\nnNTsLbuRmPFA/D3xPqqWeqoh/vBamfg7FJvR5xwKrD3Zj17eFyCSJ98VkE+oyiNEQD/ZLkO2Nvlz\ne8rR1efyh8QJ3rtv8ZdCDx0i8lf7siD/8nMqgguiHDCsmHPAmP5dq5wU5AifunvlupTjBCW5UFZD\nkEn9IZau1Lf5e02K00MI437Jq3CjbqIS8UvhJIDqFinWgwFH/EHgp8RGw6WeFIs/5X6du1lHMR+3\nDGOeRfHUSSLjpJDFKs8keYUkoCAqvp5AOBz5CFB0pCFHMDUZiuqqvrfiWfzdwlaCchXWu8YiTCf8\nW+5cncVc/LkOBYHIclIdREdE0fuIPFdAPsQfo1gLkLS7kwjZEudZ6ClXInmQLWOeV04ygdQTRJGl\nYHKXiJQWPx+hyQSnGll6CenLpo7wGYecplwunZRIVJ0RkI8Qf/K1cr/k7zVJ1hS96WSpJ+omGj3n\nOPH6q2Yeqx4MOOIPLX79NRSQi1lapsc51BuexCWCWL6Ev/NOPN6PeGWy1KO3cMQQA8GxXJTYRJ50\nnKguamKQ6DpJqeLp+d2Ce6KKgFX5rhbi3QVHZfFHH5x3CB1FKZaMIi+q9Rn5nBNY1KMUawGSZBo5\nX3LagDdSEglC9kWXN+Dhcxr8vTkOBdazOLLh8OL1eH/Lbqd8bkA3/lSNZkykLZ6vpPtMyNYkPyL5\nyt52aemabEgkrpiXrxffm3zOC+0Sb0+NwIAjfjFolg68rtMqWcc9wQIuzX0dhfgWh7GolIqORBHC\nJW1nc0htGfO/8pGGrrb4xXjkskUf+y1KPQZOp0kdVpZ6ZMgeV7VC3u9WRHshF59boKjGL+YlacTj\nSMN1tdRj1s1k54KA+CtRjV+2jENvLt/iF7x6+HlOOkqN31UHSQNCnV33OpQWv2aRlIzYdqSyxp+w\nlkQn06o3WhEMoRr7fBIoqP/4zcmL//SLS/saA474TTT+wI8/dXJXfT7t3XQU4wu44nHoFemKoWKd\neFhi8fmhZBMnpSRNU2nxRzT+6OIhh6LEldYxXJclTqyLMeO9fMQnWYH6I3HKoyc5D/Jz85LGD5hN\nljsUHVGoFoGZbqYthz7mj2Is+ow48Ufz2S2tws0JUo+jsfh1/aUk3KeCithMpR75HcsWf2If1jxC\ntUAr8v5S3kUtxBsQvyJTSXWRzzmRSL/e86t+fE0YuMSfsPA0tOSS09K1gZyCPEV0FPOxRhDzClAR\nvyTbJElNgWWs0PhFcooTVXy0InZqJu22RNLkblrHqDCWuNilvZCLLM+XDc2sNH5E6iWaVmcxLvXk\nRI1fIn7VPIqYtrgitS3vxOLB1K7xq0ct8cld71xRtviFcgRSj0rjTyR+5udFnWcV2ZnGnJFDcMgS\nVpJXj64dKjdT9/OYd9RbpUbyVEOzSwqHnhbuw1r8GYHzRbI7p5lVmbQ7FJAi9UjEJU+aKbdOFJ+R\nZPELeYjIMIobYjHtFR8tsR5cl8U8WpKIT0YlxeLvLOYifvVMqsW+mNyV0a7w6nF80lblISKdKeZq\neOftKOS8yVOJfGrV+MU6iGwYLhM/D4ngRC1+fo/jUGQrwpjFr4mHDyRo/AnSt/xh0jlBxCx+iQT1\nm7Dr20eSxZ8X9smQ2x1HTRa/9Jzos/UUm3Pio1FL/DUitPjTh4lpXj068ki7TzW5K1v8qhQiMYAS\nLH4SzqU1FDkfgdQjNHxx+Ft2mSQfyZO7KRa/ywKyUNWf59WTZPH7eap7cld/f5vvmy7Cm0wntBfC\nCTdeVNUiueC3Q8FwnVubMrHKk8s6xDV+MY3wh25yl9cZH1FxInUoJHDHiT+n4rpaZ4hSisavgqnF\nH9P4pZFSkjunrhmqto7kIy7VPhnxPCWe1tzDLf542kn9M+84sXsaxPtmxE9EFxPRSiJaTUQ3KM6P\nIqK7iegFInqWiGab3ps1zCZ3zaxKrf9xyn1t+fhm6DLxqzRTeXI3aXLZ1PtFN7kbuUa0+BmLuXdW\n42JWEWKOq7w7PK8eUeNX57cvLX4iilms/H2JozXVfIPcJMQPI/cKape1esOyxDX+8L6IV49EkDx5\nIi+u/CFpcjfnkDBJSzGyqbjp0SdjBBY8M36tzt00lmZM6jHT+ImSJnfjbY5LMOLOdXrHiRosfv8W\n1QdelVq4iDI+Smgai5+IcgB+AuASALMAvI+IZkmXfQnAEsbYCQA+COCmKu7NFLyTJXlhmRO/7v70\nPMiWdk/FwOKPPV9j8UfyUh3xB/nSTO5WJKmHSK3j6iBO7qomtuJePbVLPUlFT+s/Kovfy18++DuM\n565PTPTq4ZuVmO5PK0MeKYhlSPLqia45cIQFXOGokE/Squo1SeNX5SUNpu6csQVcVWj8uvahsrq5\n3JLPOamTu2q5NPEWYR2FWSXxENfqnfqMkqgbJo+ZC2A1Y2wNY6wXwB0ALpOumQVgPgAwxl4GMJWI\nxhvemynEfTx14O82rTFrJ1ed9GfENH5Z6lFp/NIxXfaSpAcZ1U7uVtz4JLPh3CQAvsF9uLmLjI5C\nLuLPrJ3cNWCaghPf6YwjTZLSrR9oL4Sx8IN4SEJaqgVnnGy4pW8awlhGPGSD2uLXTe4CHvnw1aOB\nH78wuauqr72HSqkbjVSzotTYjz9G/OZ+/Lr8qPz4+WimkDCKDvMUP2a6F4FKz1dlc4j/nh3SbxLV\n1zB5QxMBbBB+b/SPiVgK4HIAIKK5AI4AMMnw3kzBw+cmhVk21cd1jcTk5fAGyElg0qhoUClVEvIh\n3XMOF4J16fPo/S93ppzioyV2FlnqIUpf9CLCdRn+6Y8vAlBbvkPbo51I685pYPHnHNLG0E+6e8yQ\nIg6TgnzxOhjeURD8+aPnAPVkdPiu/Q+AhvjTmo3OTVPOw1FdQ6Xrwr8LOSfYo5d/SGSpR8bH/vs5\nZbhq3TMAYHqXF5hQ3N6Ro5gz9OOXEpUlrP87b4XyvuldQ7XtQ3Wc1+usw4cH5Z/pRwiN5Uma3wL0\n213KKCieLX80cg4F8xBqjb8xxJ9VdM4bAdxEREsALAOwGIB+lY4CRHQVgKsAYMqUKTVnZPbEEfj5\nlW8KYrwrn+X/r3pR0evC8w995mzBPU59/VPXn4tdfshh3gDnTB2FD505DadPj+ZH6dUjHRL59vNv\nOwYfOP0IPPPqDlxw7Hj8wQ8NrOsAv/3Y6Vi77UAkGqL4XL3FzyJD1rzjIEfpqxc5yi4L4qBfOGs8\nfvaUF/r4F1e+CTPGD8PQYh5fuzeMoS4bdbwOOHned+1ZQcROGTmH8F9/PweX/8dfAAD/dOmx+Mb9\nKyLllPGxs4/EmUeNxWlHjsGU0Z34wcOv4KUte4N6vPHyEyISCSC5uyryWxC8egC97/afrz8PZ317\nPlwGvG/uFFw0azz+6Y8vYtPubhT9uDoixFcrWpOfOn8G1u44iHuXbo6VlX9IT5g0AuP9KJpEQMl1\nI9fed+1ZWLfjgDb+++0feTPmvbgFv3pmfewZAPCVdx6Hi46bgFmHDwcAzP/cW3He9x73yl/jFoLt\nBgu/3nni4fjW5cdHCPMdJxyGla/vw6qt++EQ4a6Pn45yhQWL6cYNb8evPvxmnDRlJNoLOdxx1Wk4\ndsJwZfpinXPXY5XF/+Zpo7Fg7c7IMVnq+fLbj431aW9xp/8sJx6rp14vZlOYvKFNACYLvyf5xwIw\nxvYyxq5kjJ0ET+PvArDG5F4hjVsYY3MYY3O6urqqKEIc5x4zLnEbM95300Llii/t6PHDcKRvaekm\nhiaN6sTxk7zY/+IQ7tyZ8fyoUojPn4UHzp7RheHtBVx03ISo1KNpKW+aOhp/86bJ2jKKBCY+x2Us\nojsWclVO7vr7t779+AmRzTtOnjIKE0d2YERnASdMCvdH0Fn83FqdPXGEdoMUh4BTpoSbaYgfOZ3h\ndNFxE4LnXDgr3EiGE9sxE8L3LMZgCfIby4Og8fvrAHRa7+EjO3D8JC+PF80aj3NnjsNfnzJRe080\n0Jwo5ziRjV3EsnLL/q9ODgfWOYeC983rd/bEEThi9BBlPgFgztTRkXDLcn22F3I495gwD0d2DQ1G\n2UmL9twAACAASURBVLUSf5r+DgDnHN2FzmI+QvyXzD4sstr61CNG481HjsGM8aFVf9aMsUF7PO3I\nMRih2VhHrHNeDnmUCngGnQzZej/nmK7Yx7xD2Pc658QnhJtJ6lkIYAYRTSOiIoArANwjXkBEI/1z\nAPARAE8wxvaa3Nsf4Jpf2mRM2ktImg8LfKh18wQmGj+p/64mj/FneP+LWRfli5jFn0t3gRPhMm+T\n8XbJpTVCXAlEykcAJjq5/FHTRdQUIWuqoREQv54XO8niF2MZ8Y97mkEh5pXLaKo5jYjF7+glAbGs\nfL2IWH8R+UJINElOK+SiDgomEgTX5GslfpO2rLpEDGFeL3Hy+0WnBtXuYyr5M77Fa3xOQQznknOc\nfrP4U6UexliZiK4B8CCAHIDbGGPLiehq//zNAI4F8EsiYgCWA/hw0r19UxRzJHmdiNBPHHr/6xaB\nAOHXX9cOq9X4tZpmBg1FJLOyyyL1Uq3FX/a38ZMXsRUiaYZ/y0Ta68fvNyF+uZOL6erqXbeKVkUY\nqhDWqvuKeT5K8dI2CVkgWn26/EYmd/N6ghCvCzYDUmwJKv+ta1NeuJD4vgxp4KM3Uz9+GbWG6Sjm\nnKDv1KuR83LmKFyfoSR+xXPktpVz4mtxIsRP8XuaSuNnjM0DME86drPw99MAjja9t7/BLZO0OOn1\nvAQ+f2Cyd63ueSbEX73F710vSiyiD7crWfwFg0UvIlyX4WBvJbaILa/5CMhSD/d+kj1cVIhtaC/k\n2zR+PH++qi2Em3WLIxR5clfw4w8m7dLfiWzxqyS7CPHLFr9gJoi38rYtSouREB4GbUreFF1+ng6V\nOom/mlDLIsQVufVazIFk5IThFFTErxohxoifKFamjmJO4B9VdM7a814NBtzKXROEUk+NFr//v4nU\no1sYkxayAZDdKjUPqrKhBHkXjol/VwSNn8jrANVYYmXXk3o6BS3TS0uUj8K/5erhO0CZWPwyGUVW\nGGvu0X3ElAvqFOfik7uhxt8RaPzVW/xpk/1JkoDqI9dZVEs9ZED8/CNTrcXP36VpkDYZtZJe3nGC\ntlCv1BNKRmGdqzR+1XPim6rEyxSd3LXRORsKbpmkRU3UWvwG74anrQstq5R6SP878wYhEJgrWf88\n7yHxmSd7sLcCxjyfdl2eRfKVLeieKiz+eLoiwWmuiVn83v+qj1ug/ycwkujHzz9Wie2KRd0qA01Z\nlbZmlASkGwU6jT8S/yfF4k8KR62CW6fGX+tq7YKwxWRWK75zRMEHUOXOqfq2xXbdU0k9xejK8Hh0\nTkv8fQa+iLYaCUOFRIufSz2aKKFqi1/fCLJqEKr5CdHqrjAWs0Kqqaf9Pd4mKx2FnHbyvJBo8Ztr\n/DLMJnejZeH1oMyrn7eoxa+SenyLvxDGhEkDz14YF0gl9YR/qyYOw+vi94pSj5idiN6vJX5ejvQP\nqQhuQNRK/LVKq/mcE2Sw3m4ifpB5m1C5c6omd1WLsdInd/Uf9L7EoCR+3kBNl1jLMNE7+QvVRao0\nsviFv+sOUxyk6aUTyZbwo+IqIgZW0UoO+MTfmWTxi409Nrlbu8UfmdzVXCOXjRddlVeeNXE0oFq5\ny8vD3TkTLX7JwtdubSjlKUYQmus4RKlHt7+yTsLj81PRvZjT21/g1VOj1FPr5G7eCQm2fq8e/39R\n41dIPapXHJPjnHi9dRRzgtNAE8fqGYjgDdQ0TroOyV49XOrRafzxY/I7lzdBzwKBxR+ReoS/XRar\nl6osfn9DadmdU4TY1rVST50Wv3ZJf8zi948r8sqtezFd+W0ShUTJQzZUY1DkhPkUGdGQDXqCkOPa\nA9EPp250oJ/cjVv8Zl493v+1u3PWdn1B8Oqp1z4SNX7+XpVePaqYQAqffJVXDz+UcxyFH3/NWa8K\ng5L4XUOvnjQkSz3Jk7sqm5Rb4yorUGvxV+E1pH5qVOP3pB6KJF1NNe0TpB6dlJAU+6anVI/Fn/6h\n1FnjSR4lSaMt0eLvEJbimyJpcjfZjz+aBxkdGXv1mFiilTqlHsehqka2YfA18zDlqXkIJKNQ6jF3\n56TYNTGpR1rAJRsJWY3s0zAoiZ9b4YUaG6gJeNq1WPxykDDv+oykHm7xazR+lcVfjfbKLf6Oot7i\ndxIsaNUCJFOI1ryxxp/gzqkaDaiDtHnng5ANVbSrwJ1TSfxmFr+KhCIav/iRELKmIxku1chRWtPA\nR9JylE1T5IiqcgXlFrkX7sI7lpUfP+C1lZxD6n18FXUnty1HMbnbLmj8eaXGb4m/zxB49dQ4uWvy\nbgI/fg3xK6NzSvem6bixi4zgW/NCtiIrd1ncq6ca7O/x4vSI7pxyH5Hj/4voKUUDjFWDyGSkwTWA\nMKpRSj3xczE/fkeI1VM09+PnMF7AJUsLwvWqe0UC1TkJpFr8GjdQHXh91e7Hrw9wp4Jo8YsSTT1w\nhL5XyDnoKOSU9aRqL3HXzPi76RS8ehyHYvHCrNTThzAN2aCDyV28EejcOdUWvyz1pHfSWqGZ2/VC\nNtTh7bS/xyNu0bKRP1pi8jGppw6NPxqaQH1NjMAS3TlZ7Jx6cjdq8Zv48ct5Vnp5CckkTQKmhf/Q\nSj0p7rbR8N/KSyMI3aRrD9lQlcUvfKB49ur34w//zzsUkWZEqIook7hu5S5/laqVu3Zytw9h6sev\nQ+jFoScn3lF1Er/KMyhw8VPE+ZHbHs97NRYSEFpjIrGKna2zmKu5XgDgN8+uD9IP3BwT4szLPtL8\nWpNyyWEMoha/WRmSJncLCskjvvsVxSz+pPob2haGSvaeaza5G9P4xb9TihpdwCUc1/R+nv/o5G56\nfQ7zvV/kS6vZinHMUHWYbQ7xo8qjb7pM+IDWyWjRMBl6i1/pzqkIq50YskEZq6cxxJ9VWOaWArfa\narVsT5kyEp+78GhcMVcfPprLSLrNJJTunP7/ocYfnpOHlpcefxhe3XYAH3nLNNy+YL1x3t96dBc+\nfcEM/MMZU4NjnzjnKDDmEde7TjwcK1/fZ5yeDh3FHOZOG433zZ2M045Uh6SeNnYI/uuDcyLn7v7E\nGfjLqztSRziXzJ6Ay046PJpugib9wHVvwZINu2PpcI1fNXS//uKZmL9iK94yI4wW+6Ezp6G7txLM\n3YzqLOC8mePwmQuOxhF+dEqxXd39iTMiaf7gb0/C7xZuwPETvQilppO7SRq/SNB//OSZWL11f+Ra\nPucgh35uy+fwL++Yhfkvb8VTq7dHjgNSfcZyF8ddHz8DT76yDeOHt+OLl8zEhbPG4+7Fm/CJc44y\nuNsPs/3BObj29sVY9Nqu2Pm/nTMZb589Ifh92z+8Cfe/sAXjh7f1gcZP+PvTp+L1vYci7qlfe9dx\nWLFlrzLs+6XHHwaHgG/Oe9lPK5zcHdqWx0ffciTOP3YcHl251S9v8sK8vsSgJH6OmqUeIlx7/gyj\ntKsi/sC/V0H80g35nIPPXqgMj5QIxyF8+oLofR3FHP7xbccEv1/dtl++zQinHTkaz6zxYpR3FvIY\n0VnAty4/IXYdJ/UPnn4EjhoX3VTkqHHDcNQ49SYZIr79nhOUm4BwyARw7GHDcexh8RjsSRb/246b\ngLcdNyFyrL2Qw+cuOiZybOzQNlx3Qdge+Ls/b+Y4nDwlGr533LB2XHNeeG3gzqkoQ6Iff0TjD3+c\nNHlkbA8GPhJRzZt86KxpWL/zYIT424OFaNVp/NO7hmK6H9L6Y2+dDgCxukqCQ8BhIzrwiXOn40O/\nWBQ7/7mLjo7Uw6RRncFzePbq1viFcs6dNhoAsEboD+888XD8vWA0iZg8uhNXnT1dIP6w3ggI2ki4\nQU48Vo+d3G0A6vXjT047mfiTYrMoNf5GmQII66VKT9GI21t7UV+3vChJW+ulIa0+TAlANYFbLwqB\nzJdevqTJXfGYrB9Xk1su6+nmTeS2yEcIkYVfDWh+oiul8nyKW634f60ghdHVoVkMl4acsLBMbAn8\nPSgt/uqyWzMs8fdx2jp3ziSpRxUrpYG8X3O98JWrQPLqTd55TIhRh7QObq7xZ7OmQ0SwhsOgeOEC\nLpXUk2Txm+c3IH7NnJQ88uVSj8mCuCyRRt4mpJ7Vyl0RkTURVagEJGj8YqgPcb1HrapDvRjUxJ9l\nZ4+nzTt/NRZ/dFJNvKRRCzuAkAiqfaIY0ySJKHhZ6jD4Uyfxql8FmqXF74+YTCz+BDfEJD/+arKb\nNmEul51PxlYbnbNeBHNbuvMJhXYUlnotUAXNi4S4rvIBqnbK34dDVHe8sFoxqIm/EVJPuaKJzplw\nLHCnE4m/kVJPjY1xiKHvPf8o9KXUY/rVkrckzAL83ZsMaMI48iqLX0yzdrc/bmG2F9TvVe4GnPij\n7pwNsPj95+mqLalZhhp/Nha/mExkTUSVXSPY/0I4xom/7LrBJj7h9dWlXysGNfH35TAriMevc+c0\n0PjFaxop9dRaL6aLrjjRmFjEOmQm9QQeXhlKPbnk0V7k2gSpR7eHgXfOPD/8vWgtaYnNuMZfbXTO\nesEfV80eFvK5ej/gqe+hSuYPpZ7wGP8Q95Zda/H3B2q1bE3AO001Xj0BCSmklkbN9gO1r28wJX4n\nsPhreoyXRkoHr1rqyVTjN7f4Q3dO9Xl+PB4AzDw/aYvh5NFT4M4ZMTz6vv3lUkaCSaTOz2Ql9ejP\nV5ue97+44jtC/Fbjbzz6stL50FxL/IpjfCI4Kw+FWlGrFdJpuJiMl6ueyd00mBJVUqye2p/t/W/m\n1aNfwAWEdRX/GFcv9egQn9x1YscbofHzd1aNQ4R8b719Jk39rfYDqJIkuYHUW3GtV09/oG+lHt96\nqYLcXImE+o34a6wX0asnCY0gfmN3zuD67Oo6GN4bXMufqvVk4St8FXFgTJE2EotN7hZU7pwNsPid\n5HaRNK+TlR9/6HefTXnDPa7DY/zD6kk9vK9n8jhjDGri70upJ23lrupoydc+VCt3G4la/fjbq9T4\n65ncTYNp3fWFHz9PSR+SOwQ3DHRP59mK+fHXMLmrg2zlclfcalfu1gv+uGrWvsj3ZhWWOSuo/Pj5\nHEpPObT4q4nvlEm+TC4ioouJaCURrSaiGxTnRxDRvUS0lIiWE9GVwrnP+MdeJKLfEFF7lgWoB1l2\ndhlyHBkTVKTgcf1N/NXCVOqhwOKv6TFVPcP4+gyf7aRYriK41KRdtBRIPY2z+Iv5eJTRhvjxp8yL\nJfVXbqFnFbIhq+Kq8szfZakSavxBRN5mWblLRDkAPwFwCYBZAN5HRLOkyz4J4CXG2IkAzgHwPSIq\nEtFEAJ8CMIcxNhtADsAVGea/aZGmkydp/KE7Z/9KPdU+PSlonYi0IX0WMM07n3TLsqqrkXrS3EmD\n2O2yV08VbydtfwCdH39SkMC+AJdydBp/ErKSelR+/PWl5/8RkXrCyV3Z4m8mjX8ugNWMsTWMsV4A\ndwC4TLqGARhG3udqKICdAMr+uTyADiLKA+gEsDmTnDc5avGMqVSaQ+OvVQIzdufkFn8fmvymdceJ\nNytNFxAnd9OvdYPnJ6fVl8G85LS4xh+Z3G0A8zt1tIukvZOrQdZdLvTjD8vEP8S9FTfoa325pkgF\nk6dNBLBB+L3RPybixwCOhUfqywBcxxhzGWObAHwXwHoAWwDsYYw9VHeuWwC1DNm4pdPfGn9f+/Hz\nclUz8V0tjDX+Kq83QUA+VUg9aWEK4sG86sigBDmpIGSD6M6Z3eO04PZGLe2CE2tmFn9GFazy4+dG\noejOWU8o9FqQVXTOtwFYAuA8ANMBPExET8KTdi4DMA3AbgC/J6L3M8Z+JSdARFcBuAoApkzRhzvO\nAt//mxPxxCvbtOe/8s5ZWLPtQN3PuWjWeFx+yiTluZGdRZwxfUwkZO1ZM8bixEkj8Hk/UqZp27vu\n/Bl1LYaSkXcI5x7ThQ+ePjU49pkLjtZuKgMAx08cgSPHDsXFx03A5afIdkEUf3XyRPzPks348FnT\nqs7bD/72RDz6cvTd3XDJTOzY3xM5Zmr53XTFSfjx/NUYO7St6rzoMHPCMLxp6ih8+VJZEY3jxMkj\nceoRo/Av71Rfy4lMloKqsWyPnzgCc6eNxr+8Q/0MTnJvnjYavRUXp08fE3tmX2nPX377sfi/81YA\nCMt0yewJuH3BepQqLj5z4dGouAz/s2STUXr1a/zq+7/znhOwaF00VPTnLjwaB3orsWu/dfnxWLJ+\nt5+ed0zsnTPGDcNpR47G5982Ex2FHC476XA4RLh78aaGaT0mxL8JwGTh9yT/mIgrAdzIPPZZTURr\nAcwEcASAtYyxbQBARH8AcAaAGPEzxm4BcAsAzJkzpw+n/YDLT5mkJWQAuPLM6glJhVukWPMicg7h\n9o+eFjk2tC2P/7nmrOC3aef+TA3hmZNARPj5lXMjx8Swwyr8/urTUcw7uPkDp6amP2ZoG+699qzU\n61T4q5Mn4a9Ojr67q/3QvLXgjOljccb0sTXfr0J7IYffX31G+oX+tXd9XH8t39NXJrRq+K29kMPv\nPna69jxPa8b4ofjGu48Pjkf3MDZ/XjX46NlH4oePrMK+nnLwoRnZWYy1j7cff1hiOllJPbpyvnfO\nZLx3zuTIMV1o9vfNnYL3+Xt1qIK0FfMO7rgqfB83XXEybl+w3iP+BsFE6lkIYAYRTSOiIrzJ2Xuk\na9YDOB8AiGg8gGMArPGPn0ZEnb7+fz6AFVllfqCjn5SemtBf8xE6NFt+agWROpBX6MWSwTM0x0X5\noTHROfs/jazLSQqLP+m6RiHV4meMlYnoGgAPwpNubmOMLSeiq/3zNwP4OoBfENEyeO3oesbYdgDb\niehOAM/Dm+xdDN+qt0hHK5FXs2W12fJTKxxSz7kEElCGBZXVQvGD05dzu1ksostqIV7m7pyGCQXP\nbZC5Z6TxM8bmAZgnHbtZ+HszgIs0934FwFfqyOOgRSsRf7PltdnyUyscIuXeBrx4mUQV1bifFiIh\nGxrn1VMP+jpWT63ppU3BNTIWFzDIV+42O6iF3k6z0ewA4X2txS/v3VAPAldziZwaFR2WJ13PRywz\njT9hR7Sa0jNMp9HNdVDvudvsaCXuajaibbLs1AwiQl5RuVmQZfgM/pfeLG2EBFHfWoFs3Dn7KlZP\nGvrUm0UBS/xNjFaSKxo9VE1Ds+WnVjiOWsfPKv48EJJckhzRiLDx9RQlqw11+ipWjyka1WxbSEwY\nfGgl4m82DJSqc4iUAbxCjb/+Lmyy3qwh0Tkz0fhbc3K30bDE38Ro0jbTEmjWDlctvH1Zkyz++p9h\nUlONqM16SDs7r56+mdxNRYO1Hkv8TYwBwl39goFSdQ4lx3HJYuu+0Nc8QeNvhMWfgWxVv8bv/193\nTqLpGV+f0XPTYIm/iTFQrNb+wECpO0/qiZeFhy7OQns30vgbUJ31afzJMY/M85Cxxd/oHVYMYYm/\niTFQyKs/MFCqzgvZEO+mlWC3tuy6cJLa0Ii2mMWoot4kMlkXIabXpA3REn8TozmbTGugSftb1SBS\nR26sSJFc63uI91+Sxd+I+qznGdmv3M2mwOZbgGa/L0QSLPE3MQYKefUHBow7pyZWT7BbW5YLuBJs\n/mYffYZbaNaXTvaxegz9+PtgX4gkWOJvYgwU8uoPNKm0WjVmjB+Ko8cPjR0/fEQHAODKM6fW/Yw3\nTR0NAHj3Sfpw2n3ZFD9xrheaPG1vYBNkpfFnVdxmbYd2AZfFgESjLKe+xk1XnKw8PqKzgHU3XprJ\nM6aOHZKaVl8aIR8/Zzo+fk7tobUBcUOdbKSerGC8E1y2j02FtfgtBiSa1dJqVbRKfWa1A1dWdkO1\nIxCr8VtY1IMWIapWQfNr/Nm4c2ZdzGYNtNik2bKwqA/NTlSthlapzcz23M0gL2J6zQZL/BYDEs3Z\n3VoXreJokNWeuw1357QhGyws6kerEFWroNk1/qzi8WfdbKzGb2HRQDQ7UbUamlWy4OBrELIIWgf0\nX6yeRsESv8WAxEBx52wWNCuByah3pJe15GLuztlYrccSv8WARLN6U7Qqml06y0rq4ei/ePx25a6F\nRc1obppqPbSKdFZvPrO2vJu13izxWwxINLsm3WoYLBZ/1jFzqo3V0ygYET8RXUxEK4loNRHdoDg/\ngojuJaKlRLSciK4Uzo0kojuJ6GUiWkFEp2dZAAsLFZqcp1oOzWq5ymiRbPY7UomfiHIAfgLgEgCz\nALyPiGZJl30SwEuMsRMBnAPge0RU9M/dBOB/GWMzAZwIYEVGebew0MJa/NmAh31u9vrMSqIJLP5+\nKm4zuXPOBbCaMbaGMdYL4A4Al0nXMADDyBvXDAWwE0CZiEYAOBvAzwCAMdbLGNudWe4tLCz6FM26\nkYiMQCppjez2O0yIfyKADcLvjf4xET8GcCyAzQCWAbiOMeYCmAZgG4CfE9FiIrqViIbUn+3BhSO7\nmrfKDhvR3t9ZUKLZLdRWwdtmTwDQOvVZrzY/ZqgnVJx9dFcW2QlwxvQxiednjPNCb588eWSmz9Uh\nq7DMbwOwBMB5AKYDeJiInvTTPwXAtYyxBUR0E4AbAPyznAARXQXgKgCYMmVKRtlqfSz88gXoLNYf\np7yv8PBn34pDpUp/ZyOGFuGppsf33nsivvT2mSjmm9sPJKu50fHD2/HU9ediwvDsDJoFXzofIzoK\nide8+cgxeOLz52Ly6I7MnpsEk7e5CcBk4fck/5iIKwH8gXlYDWAtgJnwRgcbGWML/OvuhPchiIEx\ndgtjbA5jbE5XV7Zf21ZG17A2DGlr3m0ThrblMXZoW39nI4ZWsVCbHcW8g8NGNIaMskAWr33SqE7k\ns1oCDO9j0m6wycyUMZ0N854yKd1CADOIaJo/YXsFgHuka9YDOB8AiGg8gGMArGGMvQ5gAxEd4193\nPoCXMsm5hUUCLO0PMjR6J5MWR6opyRgrE9E1AB4EkANwG2NsORFd7Z+/GcDXAfyCiJbB63PXM8a2\n+0lcC+DX/kdjDbzRgYVFn8Ia/IMT9rWbwUhDYIzNAzBPOnaz8PdmABdp7l0CYE4debSwqBrNvuDI\nIls0OtZNq6O5Z2wsLCwsDBD639sPvgks8VtYWLQ8ws3W+zUbLQNL/BYWFgMGlvfNYInfwsKi5cEa\nHeWsxWGJ38LCYsDASj1msMRvYWHR8rD2fnWwxG9hYTGAYE1+E1jit7CwaHlYib86WOK3sLBoeVh3\nzupgid/CwqLlMXVMJwBgWBMHNGwm2FqysLBoeXzr8uPxjhMOx4zxw/o7Ky0Ba/FbWFi0PDqLeVw4\na3x/Z6NlYInfwsLCYpDBEr+FhYXFIIMlfgsLC4tBBkv8FhYWFoMMlvgtLCwsBhks8VtYWFgMMlji\nt7CwsBhksMRvYWFhMchgid/CwsJikMGI+InoYiJaSUSriegGxfkRRHQvES0louVEdKV0PkdEi4no\nvqwybmFhYWFRG1KJn4hyAH4C4BIAswC8j4hmSZd9EsBLjLETAZwD4HtEVBTOXwdgRSY5trCwsLCo\nCyYW/1wAqxljaxhjvQDuAHCZdA0DMIyICMBQADsBlAGAiCYBuBTArZnl2sLCwsKiZpgQ/0QAG4Tf\nG/1jIn4M4FgAmwEsA3AdY8z1z/07gC8AcGFhYWFh0e/IKizz2wAsAXAegOkAHiaiJwGcDWArY+w5\nIjonKQEiugrAVQAwZcqUjLJlMdjwm4+ehi17uvs7GxYWTQ0T4t8EYLLwe5J/TMSVAG5kjDEAq4lo\nLYCZAM4E8C4iejuAdgDDiehXjLH3yw9hjN0C4BYAmDNnjt1IzaImnD59TH9nwcKi6WEi9SwEMIOI\npvkTtlcAuEe6Zj2A8wGAiMYDOAbAGsbYFxljkxhjU/375qtI38LCwsKicUi1+BljZSK6BsCDAHIA\nbmOMLSeiq/3zNwP4OoBfENEyeNvcX88Y296H+bawsLCwqBHEmnB7+jlz5rBFixb1dzYsLCwsWgZE\n9BxjbI7JtXblroWFhcUggyV+CwsLi0EGS/wWFhYWgwyW+C0sLCwGGSzxW1hYWAwyNKVXDxFtA/Ba\njbePBTDYXEltmQcHbJkHB2ot8xGMsS6TC5uS+OsBES0ydWkaKLBlHhywZR4caESZrdRjYWFhMchg\nid/CwsJikGEgEv8t/Z2BfoAt8+CALfPgQJ+XecBp/BYWFhYWyRiIFr+FhYWFRQIGDPGnbQjfqiCi\n24hoKxG9KBwbTUQPE9Eq//9Rwrkv+nWwkoje1j+5rg9ENJmIHiWil4hoORFd5x8fsOUmonYiepaI\nlvpl/pp/fMCWmYOIckS0mIju838P6DIT0ToiWkZES4hokX+ssWVmjLX8P3jhol8FcCSAIoClAGb1\nd74yKtvZAE4B8KJw7N8A3OD/fQOAb/t/z/LL3gZgml8nuf4uQw1lPgzAKf7fwwC84pdtwJYbXjjz\nof7fBQALAJw2kMsslP2zAG4HcJ//e0CXGcA6AGOlYw0t80Cx+E02hG9JMMaegLd5vYjLAPzS//uX\nAN4tHL+DMdbDGFsLYDW8umkpMMa2MMae9//eB2AFvH2eB2y5mYf9/s+C/49hAJcZAIhoEoBLAdwq\nHB7QZdagoWUeKMRvsiH8QMJ4xtgW/+/XAYz3/x5w9UBEUwGcDM8CHtDl9iWPJQC2AniYMTbgywzg\n3wF8AYArHBvoZWYA/kREz/l7jQMNLnNWm61b9BMYY4yIBqRrFhENBXAXgE8zxvYSUXBuIJabMVYB\ncBIRjQRwNxHNls4PqDIT0TsAbGWM/f/27qeVgigO4/j3WUiSDVHKgoWtN8BCirCwtlAWXoWUl+Ad\n2JEdsfVvr+RPV66kbCRW9hY/i3PkJosburfOPJ+aZjozi/NMza/TmTPNuaTJn64pLXM2ERFPkgaA\nQ0n1xpOtyFzKiL+ZH8KX5EXSIEDev+b2Yu6DpA5S0d+OiN3cXHxugIh4A06BWcrOPA4sSHokTc9O\nSdqi7MxExFPevwJ7pKmblmYupfA380P4khwAy/l4GdhvaF+U1ClpBBgFztrQvz9RGtpvArcR+pUR\nEAAAAMZJREFUsdFwqtjckvrzSB9JXcA0UKfgzBGxGhFDETFMemZPImKJgjNL6pbU83kMzAA1Wp25\n3W+4//FN+Txp9ccDsNbu/vxjrh3gGXgnze+tAH3AMXAPHAG9Ddev5XtwB8y1u/+/zDxBmge9Bi7z\nNl9ybmAMuMiZa8B6bi8287f8k3yt6ik2M2nl4VXebj5rVasz+8tdM7OKKWWqx8zMmuTCb2ZWMS78\nZmYV48JvZlYxLvxmZhXjwm9mVjEu/GZmFePCb2ZWMR9IUbJPkbbgtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efccb813550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( xgb_losses[1:] ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niMhkGNxERCbD4CYiMpn/BzXznwIgFfnoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efccc367d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efca3dbd7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( combined_loss[1:], label='combined_loss' ) ; plt.show()\n",
    "\n",
    "plt.plot( disc_loss_real[1:], label='disc_loss_real' )\n",
    "plt.plot( disc_loss_generated[1:], label='disc_loss_generated' )\n",
    "plt.legend() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.4-py3.6.egg/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "generated_image_tensor = generator_network(generator_input_tensor)\n",
    "generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "\n",
    "generator_model.load_weights('cache/CGAN_generator_model_weights_step_5000.h5')\n",
    "\n",
    "temp_noise = np.random.normal(size=(batch_size, rand_dim))  # fixed noise to generate batches of generated images\n",
    "\n",
    "g_z = generator_model.predict(temp_noise)\n",
    "\n",
    "# g_z[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "print( CheckAccuracy( generator_model, 100, train_w_class ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.88'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 100\n",
    "\n",
    "np.random.seed(0)\n",
    "temp_noise = np.random.normal(size=(n_samples*2, rand_dim))  # fixed noise to generate batches of generated images\n",
    "test_samples = generator_model.predict(temp_noise)\n",
    "test_samples = np.reshape(test_samples, (n_samples*2, data_dim))\n",
    "# test_samples = np.round(test_samples,3)\n",
    "test_samples = pd.DataFrame(test_samples,columns=train_w_class.columns)\n",
    "test_samples['syn_label'] = 1\n",
    "\n",
    "test_samples['Class'] = (test_samples['Class'] > 0.5)*1\n",
    "\n",
    "real_samples = train_w_class.sample(n_samples*2,replace=False)\n",
    "# real_samples = test_w_class.sample(n_samples*2,replace=False)\n",
    "real_samples['syn_label'] = 0\n",
    "\n",
    "train_df = pd.concat([real_samples[:n_samples],test_samples[:n_samples]],axis=0)\n",
    "test_df = pd.concat([real_samples[n_samples:],test_samples[n_samples:]],axis=0)\n",
    "\n",
    "X_col = test_df.columns[:-1]\n",
    "y_col = test_df.columns[-1]\n",
    "dtrain = xgb.DMatrix(train_df[X_col], train_df[y_col], feature_names=X_col)\n",
    "dtest = xgb.DMatrix(test_df[X_col], feature_names=X_col)\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 0 }\n",
    "xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "y_pred = np.round(xgb_test.predict(dtest))\n",
    "y_true = test_df['syn_label']\n",
    "'{:.2f}'.format(SimpleAccuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 30) (80, 30) (90, 30) (90, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.84'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing by class\n",
    "\n",
    "n = 1\n",
    "real_class = real_samples[ real_samples.Class == n ].reset_index(drop=True)\n",
    "test_class = test_samples[ test_samples.Class == n ].reset_index(drop=True)\n",
    "\n",
    "train_df = pd.concat( [ real_class[:len(real_class)//2], test_class[:len(test_class)//2] ],axis=0)\n",
    "test_df = pd.concat(  [ real_class[len(real_class)//2:], test_class[len(test_class)//2:] ],axis=0)\n",
    "print( real_class.shape, test_class.shape, train_df.shape, test_df.shape )\n",
    "\n",
    "X_col = test_df.columns[:-1]\n",
    "y_col = test_df.columns[-1]\n",
    "dtrain = xgb.DMatrix(train_df[X_col], train_df[y_col], feature_names=X_col)\n",
    "dtest = xgb.DMatrix(test_df[X_col], feature_names=X_col)\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 0 }\n",
    "xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "y_pred = np.round(xgb_test.predict(dtest))\n",
    "y_true = test_df['syn_label']\n",
    "'{:.2f}'.format(SimpleAccuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_w_class.head(3)\n",
    "# test_samples.head(3)\n",
    "# real_samples.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True 0</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 1</th>\n",
       "      <td>15</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pred 0  Pred 1\n",
       "True 0      90      10\n",
       "True 1      15      85"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on validation set\n",
    "SimpleMetrics(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAHwCAYAAAA2Kxw6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wAwxgLM5ZMJkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc54f28d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importances\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "xgb.plot_importance(xgb_test, max_num_features=20, height=0.5, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value\n",
    "# import operator\n",
    "# x = xgb_test.get_fscore()\n",
    "# sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# # sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for col, imp in sorted_x:\n",
    "# # for col in xgb_model_DCGAN.get_fscore().keys():\n",
    "# # for col in ['V1','V14','V3']:\n",
    "#     plt.hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "# #     plt.title( '{}: {}'.format(col, xgb_model_DCGAN.get_fscore()[col]) )\n",
    "#     plt.title( '{}: {}'.format(col, imp) )\n",
    "#     plt.legend() ; plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/figure.py:1742: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAALICAYAAADseNpmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVIDHNAlSZIkSWrA/wL2MbJqiFmDWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efca7aeb978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for col in train.columns:\n",
    "#     plt.hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "#     plt.title( '{}'.format(col) )\n",
    "#     plt.legend() ; plt.show()\n",
    "    \n",
    "# plt.figure(figsize=(14,5))    \n",
    "f, axarr = plt.subplots(8, 4, figsize=(14,10) )\n",
    "for i in range(data_dim):\n",
    "    col = train_df.columns[i]\n",
    "#     axarr[i//4, i%4].hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "    axarr[i//4, i%4].hist( [ train_df.loc[train_df['syn_label']==0, col], train_df.loc[train_df['syn_label']==1, col]], \n",
    "                          label=['real','syn'], bins=20) #, normed=True )\n",
    "    axarr[i//4, i%4].set_title( '{}'.format(col) )\n",
    "    if i == 0: axarr[i//4, i%4].legend()\n",
    "#     axarr[i//4, i%4].set_xlim([-0.1,1.1])\n",
    "#     axarr[i//4, i%4].set_ylim([0,40])\n",
    "f.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_df.groupby('syn_label')['V2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Waya.ai WGAN dense\"><h1>Waya.ai WGAN dense</h1></a>\n",
    "\n",
    "<a href='#TOC'>Table of contents</a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "wGAN implemented on top of keras/tensorflow as described in: [Wasserstein GAN](https://arxiv.org/pdf/1701.07875.pdf)\n",
    "with improvements as described in: [Improved Training of Wasserstein GANs](https://arxiv.org/pdf/1704.00028.pdf).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adversarial_training(data_dir, generator_model_path, discriminator_model_path, evaluate=False):\n",
    "    \"\"\"\n",
    "    Adversarial training of the generator network Gθ and discriminator network Dφ.\n",
    "\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(5)\n",
    "    \n",
    "    #\n",
    "    # define model input and output tensors\n",
    "    #\n",
    "\n",
    "    generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "    generated_image_tensor = generator_network(generator_input_tensor)\n",
    "\n",
    "    generated_or_real_image_tensor = layers.Input(shape=(data_dim,))\n",
    "    discriminator_output = discriminator_network(generated_or_real_image_tensor)\n",
    "\n",
    "    #\n",
    "    # define models\n",
    "    #\n",
    "\n",
    "    generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "    discriminator_model = models.Model(inputs=[generated_or_real_image_tensor],\n",
    "                                       outputs=[discriminator_output],\n",
    "                                       name='discriminator')\n",
    "\n",
    "    combined_output = discriminator_model(generator_model(generator_input_tensor))\n",
    "    combined_model = models.Model(inputs=[generator_input_tensor], outputs=[combined_output], name='combined')\n",
    "\n",
    "    #\n",
    "    # define earth mover distance (wasserstein loss)\n",
    "    #\n",
    "\n",
    "    def em_loss(y_coefficients, y_pred):\n",
    "        return tf.reduce_mean(tf.multiply(y_coefficients, y_pred))\n",
    "\n",
    "    #\n",
    "    # construct computation graph for calculating the gradient penalty (improved wGAN) and training the discriminator\n",
    "    #\n",
    "\n",
    "    # sample a batch of noise (generator input)\n",
    "    _z = tf.placeholder(tf.float32, shape=(batch_size, rand_dim))\n",
    "\n",
    "    # sample a batch of real images\n",
    "    _x = tf.placeholder(tf.float32, shape=(batch_size, data_dim))\n",
    "\n",
    "    # generate a batch of images with the current generator\n",
    "    _g_z = generator_model(_z)\n",
    "\n",
    "    # calculate `x_hat`\n",
    "    epsilon = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
    "    x_hat = epsilon * _x + (1.0 - epsilon) * _g_z\n",
    "\n",
    "    # gradient penalty\n",
    "    gradients = tf.gradients(discriminator_model(x_hat), [x_hat])\n",
    "    _gradient_penalty = 10.0 * tf.square(tf.norm(gradients[0], ord=2) - 1.0)\n",
    "\n",
    "    # calculate discriminator's loss\n",
    "    _disc_loss = em_loss(tf.ones(batch_size), discriminator_model(_g_z)) - \\\n",
    "        em_loss(tf.ones(batch_size), discriminator_model(_x)) + \\\n",
    "        _gradient_penalty\n",
    "\n",
    "    # update φ by taking an SGD step on mini-batch loss LD(φ)\n",
    "    disc_optimizer = tf.train.AdamOptimizer(learning_rate=.0001, beta1=0.5, beta2=0.9).minimize(\n",
    "        _disc_loss, var_list=discriminator_model.trainable_weights)\n",
    "\n",
    "    sess = K.get_session()\n",
    "\n",
    "    #\n",
    "    # compile models\n",
    "    #\n",
    "\n",
    "    adam = optimizers.Adam(lr=.0001, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "    discriminator_model.trainable = False\n",
    "    combined_model.compile(optimizer=adam, loss=[em_loss])\n",
    "\n",
    "    print(generator_model.summary())\n",
    "    print(discriminator_model.summary())\n",
    "    print(combined_model.summary())\n",
    "\n",
    "    disc_loss = []\n",
    "    combined_loss = []\n",
    "    xgb_losses = []\n",
    "\n",
    "    def train_discriminator_step():\n",
    "        d_l, _ = sess.run([_disc_loss, disc_optimizer], feed_dict={\n",
    "            _z: np.random.normal(loc=0.0, scale=1.0, size=(batch_size, rand_dim)),\n",
    "            _x: get_data_batch(train, batch_size, data_dim),\n",
    "            epsilon: np.random.uniform(low=0.0, high=1.0, size=(batch_size, 1))\n",
    "        })\n",
    "\n",
    "        return d_l\n",
    "\n",
    "    if generator_model_path:\n",
    "        generator_model.load_weights(generator_model_path, by_name=True)\n",
    "    if discriminator_model_path:\n",
    "        discriminator_model.load_weights(discriminator_model_path, by_name=True)\n",
    "    else:\n",
    "        print('pre-training the critic...')\n",
    "        K.set_learning_phase(1) # 1 = train\n",
    "        for i in range(critic_pre_train_steps):\n",
    "            print('Step: {} of {} critic pre-training.'.format(i, critic_pre_train_steps))\n",
    "            loss = train_discriminator_step()\n",
    "\n",
    "        print('Last batch of critic pre-training disc_loss: {}.'.format(loss))\n",
    "        discriminator_model.save(os.path.join(cache_dir, 'WGAN_discriminator_model_pre_trained.h5'))\n",
    "\n",
    "    for i in range(nb_steps):\n",
    "        print('Step: {} of {}.'.format(i, nb_steps))\n",
    "        K.set_learning_phase(1) # 1 = train\n",
    "        # train the discriminator\n",
    "        for _ in range(k_d):\n",
    "#                 print('train the discriminator')\n",
    "            # when plotting loss we will have to take `k_d` and `k_g` into account so the two plots align\n",
    "            loss = train_discriminator_step()\n",
    "            disc_loss.append(loss)\n",
    "        # train the generator\n",
    "        for _ in range(k_g):\n",
    "#                 print('train the generator')\n",
    "            z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, rand_dim))\n",
    "            # update θ by taking an SGD step on mini-batch loss LG(θ)\n",
    "            loss = combined_model.train_on_batch(z, [-np.ones(batch_size)])\n",
    "            combined_loss.append(loss)\n",
    "\n",
    "        if not i % log_interval and i != 0:\n",
    "            K.set_learning_phase(0) # 0 = test\n",
    "\n",
    "            g_z = generator_model.predict(fixed_noise)\n",
    "            x = get_data_batch(train, batch_size, data_dim)\n",
    "\n",
    "            # log loss summary\n",
    "            print('Generator model loss: {}.'.format(np.mean(np.asarray(combined_loss[-log_interval:]), axis=0)))\n",
    "            print('Discriminator model loss: {}.'.format(np.mean(np.asarray(disc_loss[-log_interval:]), axis=0)))\n",
    "\n",
    "            xgb_loss = CheckAccuracy( generator_model, 100, train )\n",
    "#             xgb_loss = CheckAccuracy( generator_model, 100, test )\n",
    "            xgb_losses = np.append(xgb_losses, xgb_loss)\n",
    "            print('xgboost accuracy: {}'.format(xgb_loss) )\n",
    "\n",
    "            # save model checkpoints\n",
    "            model_checkpoint_base_name = os.path.join(cache_dir, 'WGAN_{}_model_weights_step_{}.h5')\n",
    "            generator_model.save_weights(model_checkpoint_base_name.format('generator', i))\n",
    "            discriminator_model.save_weights(model_checkpoint_base_name.format('discriminator', i))\n",
    "    \n",
    "    pickle.dump([combined_loss, disc_loss, xgb_losses], \n",
    "                open(os.path.join(cache_dir, 'WGAN_losses.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_130 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_131 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 28)                924       \n",
      "=================================================================\n",
      "Total params: 3,036\n",
      "Trainable params: 3,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_57 (InputLayer)        (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_132 (LeakyReLU)  (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 32)                928       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_133 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_134 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,829\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,829\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            multiple                  3036      \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        multiple                  2829      \n",
      "=================================================================\n",
      "Total params: 5,865\n",
      "Trainable params: 3,036\n",
      "Non-trainable params: 2,829\n",
      "_________________________________________________________________\n",
      "None\n",
      "pre-training the critic...\n",
      "Step: 0 of 100 critic pre-training.\n",
      "Step: 1 of 100 critic pre-training.\n",
      "Step: 2 of 100 critic pre-training.\n",
      "Step: 3 of 100 critic pre-training.\n",
      "Step: 4 of 100 critic pre-training.\n",
      "Step: 5 of 100 critic pre-training.\n",
      "Step: 6 of 100 critic pre-training.\n",
      "Step: 7 of 100 critic pre-training.\n",
      "Step: 8 of 100 critic pre-training.\n",
      "Step: 9 of 100 critic pre-training.\n",
      "Step: 10 of 100 critic pre-training.\n",
      "Step: 11 of 100 critic pre-training.\n",
      "Step: 12 of 100 critic pre-training.\n",
      "Step: 13 of 100 critic pre-training.\n",
      "Step: 14 of 100 critic pre-training.\n",
      "Step: 15 of 100 critic pre-training.\n",
      "Step: 16 of 100 critic pre-training.\n",
      "Step: 17 of 100 critic pre-training.\n",
      "Step: 18 of 100 critic pre-training.\n",
      "Step: 19 of 100 critic pre-training.\n",
      "Step: 20 of 100 critic pre-training.\n",
      "Step: 21 of 100 critic pre-training.\n",
      "Step: 22 of 100 critic pre-training.\n",
      "Step: 23 of 100 critic pre-training.\n",
      "Step: 24 of 100 critic pre-training.\n",
      "Step: 25 of 100 critic pre-training.\n",
      "Step: 26 of 100 critic pre-training.\n",
      "Step: 27 of 100 critic pre-training.\n",
      "Step: 28 of 100 critic pre-training.\n",
      "Step: 29 of 100 critic pre-training.\n",
      "Step: 30 of 100 critic pre-training.\n",
      "Step: 31 of 100 critic pre-training.\n",
      "Step: 32 of 100 critic pre-training.\n",
      "Step: 33 of 100 critic pre-training.\n",
      "Step: 34 of 100 critic pre-training.\n",
      "Step: 35 of 100 critic pre-training.\n",
      "Step: 36 of 100 critic pre-training.\n",
      "Step: 37 of 100 critic pre-training.\n",
      "Step: 38 of 100 critic pre-training.\n",
      "Step: 39 of 100 critic pre-training.\n",
      "Step: 40 of 100 critic pre-training.\n",
      "Step: 41 of 100 critic pre-training.\n",
      "Step: 42 of 100 critic pre-training.\n",
      "Step: 43 of 100 critic pre-training.\n",
      "Step: 44 of 100 critic pre-training.\n",
      "Step: 45 of 100 critic pre-training.\n",
      "Step: 46 of 100 critic pre-training.\n",
      "Step: 47 of 100 critic pre-training.\n",
      "Step: 48 of 100 critic pre-training.\n",
      "Step: 49 of 100 critic pre-training.\n",
      "Step: 50 of 100 critic pre-training.\n",
      "Step: 51 of 100 critic pre-training.\n",
      "Step: 52 of 100 critic pre-training.\n",
      "Step: 53 of 100 critic pre-training.\n",
      "Step: 54 of 100 critic pre-training.\n",
      "Step: 55 of 100 critic pre-training.\n",
      "Step: 56 of 100 critic pre-training.\n",
      "Step: 57 of 100 critic pre-training.\n",
      "Step: 58 of 100 critic pre-training.\n",
      "Step: 59 of 100 critic pre-training.\n",
      "Step: 60 of 100 critic pre-training.\n",
      "Step: 61 of 100 critic pre-training.\n",
      "Step: 62 of 100 critic pre-training.\n",
      "Step: 63 of 100 critic pre-training.\n",
      "Step: 64 of 100 critic pre-training.\n",
      "Step: 65 of 100 critic pre-training.\n",
      "Step: 66 of 100 critic pre-training.\n",
      "Step: 67 of 100 critic pre-training.\n",
      "Step: 68 of 100 critic pre-training.\n",
      "Step: 69 of 100 critic pre-training.\n",
      "Step: 70 of 100 critic pre-training.\n",
      "Step: 71 of 100 critic pre-training.\n",
      "Step: 72 of 100 critic pre-training.\n",
      "Step: 73 of 100 critic pre-training.\n",
      "Step: 74 of 100 critic pre-training.\n",
      "Step: 75 of 100 critic pre-training.\n",
      "Step: 76 of 100 critic pre-training.\n",
      "Step: 77 of 100 critic pre-training.\n",
      "Step: 78 of 100 critic pre-training.\n",
      "Step: 79 of 100 critic pre-training.\n",
      "Step: 80 of 100 critic pre-training.\n",
      "Step: 81 of 100 critic pre-training.\n",
      "Step: 82 of 100 critic pre-training.\n",
      "Step: 83 of 100 critic pre-training.\n",
      "Step: 84 of 100 critic pre-training.\n",
      "Step: 85 of 100 critic pre-training.\n",
      "Step: 86 of 100 critic pre-training.\n",
      "Step: 87 of 100 critic pre-training.\n",
      "Step: 88 of 100 critic pre-training.\n",
      "Step: 89 of 100 critic pre-training.\n",
      "Step: 90 of 100 critic pre-training.\n",
      "Step: 91 of 100 critic pre-training.\n",
      "Step: 92 of 100 critic pre-training.\n",
      "Step: 93 of 100 critic pre-training.\n",
      "Step: 94 of 100 critic pre-training.\n",
      "Step: 95 of 100 critic pre-training.\n",
      "Step: 96 of 100 critic pre-training.\n",
      "Step: 97 of 100 critic pre-training.\n",
      "Step: 98 of 100 critic pre-training.\n",
      "Step: 99 of 100 critic pre-training.\n",
      "Last batch of critic pre-training disc_loss: 172.5767364501953.\n",
      "Step: 0 of 5001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.4-py3.6.egg/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 of 5001.\n",
      "Step: 2 of 5001.\n",
      "Step: 3 of 5001.\n",
      "Step: 4 of 5001.\n",
      "Step: 5 of 5001.\n",
      "Step: 6 of 5001.\n",
      "Step: 7 of 5001.\n",
      "Step: 8 of 5001.\n",
      "Step: 9 of 5001.\n",
      "Step: 10 of 5001.\n",
      "Generator model loss: -0.013435149565339088.\n",
      "Discriminator model loss: 154.9313201904297.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 11 of 5001.\n",
      "Step: 12 of 5001.\n",
      "Step: 13 of 5001.\n",
      "Step: 14 of 5001.\n",
      "Step: 15 of 5001.\n",
      "Step: 16 of 5001.\n",
      "Step: 17 of 5001.\n",
      "Step: 18 of 5001.\n",
      "Step: 19 of 5001.\n",
      "Step: 20 of 5001.\n",
      "Generator model loss: -0.009220552630722523.\n",
      "Discriminator model loss: 118.15766906738281.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 21 of 5001.\n",
      "Step: 22 of 5001.\n",
      "Step: 23 of 5001.\n",
      "Step: 24 of 5001.\n",
      "Step: 25 of 5001.\n",
      "Step: 26 of 5001.\n",
      "Step: 27 of 5001.\n",
      "Step: 28 of 5001.\n",
      "Step: 29 of 5001.\n",
      "Step: 30 of 5001.\n",
      "Generator model loss: 0.0011707473313435912.\n",
      "Discriminator model loss: 89.83705139160156.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 31 of 5001.\n",
      "Step: 32 of 5001.\n",
      "Step: 33 of 5001.\n",
      "Step: 34 of 5001.\n",
      "Step: 35 of 5001.\n",
      "Step: 36 of 5001.\n",
      "Step: 37 of 5001.\n",
      "Step: 38 of 5001.\n",
      "Step: 39 of 5001.\n",
      "Step: 40 of 5001.\n",
      "Generator model loss: 0.01238046120852232.\n",
      "Discriminator model loss: 66.54621887207031.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 41 of 5001.\n",
      "Step: 42 of 5001.\n",
      "Step: 43 of 5001.\n",
      "Step: 44 of 5001.\n",
      "Step: 45 of 5001.\n",
      "Step: 46 of 5001.\n",
      "Step: 47 of 5001.\n",
      "Step: 48 of 5001.\n",
      "Step: 49 of 5001.\n",
      "Step: 50 of 5001.\n",
      "Generator model loss: 0.023874277248978615.\n",
      "Discriminator model loss: 50.815956115722656.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 51 of 5001.\n",
      "Step: 52 of 5001.\n",
      "Step: 53 of 5001.\n",
      "Step: 54 of 5001.\n",
      "Step: 55 of 5001.\n",
      "Step: 56 of 5001.\n",
      "Step: 57 of 5001.\n",
      "Step: 58 of 5001.\n",
      "Step: 59 of 5001.\n",
      "Step: 60 of 5001.\n",
      "Generator model loss: 0.005147592164576054.\n",
      "Discriminator model loss: 37.81975555419922.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 61 of 5001.\n",
      "Step: 62 of 5001.\n",
      "Step: 63 of 5001.\n",
      "Step: 64 of 5001.\n",
      "Step: 65 of 5001.\n",
      "Step: 66 of 5001.\n",
      "Step: 67 of 5001.\n",
      "Step: 68 of 5001.\n",
      "Step: 69 of 5001.\n",
      "Step: 70 of 5001.\n",
      "Generator model loss: 0.005129160825163126.\n",
      "Discriminator model loss: 28.346744537353516.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 71 of 5001.\n",
      "Step: 72 of 5001.\n",
      "Step: 73 of 5001.\n",
      "Step: 74 of 5001.\n",
      "Step: 75 of 5001.\n",
      "Step: 76 of 5001.\n",
      "Step: 77 of 5001.\n",
      "Step: 78 of 5001.\n",
      "Step: 79 of 5001.\n",
      "Step: 80 of 5001.\n",
      "Generator model loss: 0.021442590281367302.\n",
      "Discriminator model loss: 22.867313385009766.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 81 of 5001.\n",
      "Step: 82 of 5001.\n",
      "Step: 83 of 5001.\n",
      "Step: 84 of 5001.\n",
      "Step: 85 of 5001.\n",
      "Step: 86 of 5001.\n",
      "Step: 87 of 5001.\n",
      "Step: 88 of 5001.\n",
      "Step: 89 of 5001.\n",
      "Step: 90 of 5001.\n",
      "Generator model loss: 0.012760763987898827.\n",
      "Discriminator model loss: 16.420093536376953.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 91 of 5001.\n",
      "Step: 92 of 5001.\n",
      "Step: 93 of 5001.\n",
      "Step: 94 of 5001.\n",
      "Step: 95 of 5001.\n",
      "Step: 96 of 5001.\n",
      "Step: 97 of 5001.\n",
      "Step: 98 of 5001.\n",
      "Step: 99 of 5001.\n",
      "Step: 100 of 5001.\n",
      "Generator model loss: 0.017257999628782272.\n",
      "Discriminator model loss: 11.95055866241455.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 101 of 5001.\n",
      "Step: 102 of 5001.\n",
      "Step: 103 of 5001.\n",
      "Step: 104 of 5001.\n",
      "Step: 105 of 5001.\n",
      "Step: 106 of 5001.\n",
      "Step: 107 of 5001.\n",
      "Step: 108 of 5001.\n",
      "Step: 109 of 5001.\n",
      "Step: 110 of 5001.\n",
      "Generator model loss: 0.017130043357610703.\n",
      "Discriminator model loss: 7.510237216949463.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 111 of 5001.\n",
      "Step: 112 of 5001.\n",
      "Step: 113 of 5001.\n",
      "Step: 114 of 5001.\n",
      "Step: 115 of 5001.\n",
      "Step: 116 of 5001.\n",
      "Step: 117 of 5001.\n",
      "Step: 118 of 5001.\n",
      "Step: 119 of 5001.\n",
      "Step: 120 of 5001.\n",
      "Generator model loss: 0.028398524969816208.\n",
      "Discriminator model loss: 5.0255961418151855.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 121 of 5001.\n",
      "Step: 122 of 5001.\n",
      "Step: 123 of 5001.\n",
      "Step: 124 of 5001.\n",
      "Step: 125 of 5001.\n",
      "Step: 126 of 5001.\n",
      "Step: 127 of 5001.\n",
      "Step: 128 of 5001.\n",
      "Step: 129 of 5001.\n",
      "Step: 130 of 5001.\n",
      "Generator model loss: 0.025249993428587914.\n",
      "Discriminator model loss: 3.4439826011657715.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 131 of 5001.\n",
      "Step: 132 of 5001.\n",
      "Step: 133 of 5001.\n",
      "Step: 134 of 5001.\n",
      "Step: 135 of 5001.\n",
      "Step: 136 of 5001.\n",
      "Step: 137 of 5001.\n",
      "Step: 138 of 5001.\n",
      "Step: 139 of 5001.\n",
      "Step: 140 of 5001.\n",
      "Generator model loss: 0.03552234545350075.\n",
      "Discriminator model loss: 1.9995613098144531.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 141 of 5001.\n",
      "Step: 142 of 5001.\n",
      "Step: 143 of 5001.\n",
      "Step: 144 of 5001.\n",
      "Step: 145 of 5001.\n",
      "Step: 146 of 5001.\n",
      "Step: 147 of 5001.\n",
      "Step: 148 of 5001.\n",
      "Step: 149 of 5001.\n",
      "Step: 150 of 5001.\n",
      "Generator model loss: 0.03983026370406151.\n",
      "Discriminator model loss: 1.2389103174209595.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 151 of 5001.\n",
      "Step: 152 of 5001.\n",
      "Step: 153 of 5001.\n",
      "Step: 154 of 5001.\n",
      "Step: 155 of 5001.\n",
      "Step: 156 of 5001.\n",
      "Step: 157 of 5001.\n",
      "Step: 158 of 5001.\n",
      "Step: 159 of 5001.\n",
      "Step: 160 of 5001.\n",
      "Generator model loss: 0.0383542962372303.\n",
      "Discriminator model loss: 0.5522929430007935.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 161 of 5001.\n",
      "Step: 162 of 5001.\n",
      "Step: 163 of 5001.\n",
      "Step: 164 of 5001.\n",
      "Step: 165 of 5001.\n",
      "Step: 166 of 5001.\n",
      "Step: 167 of 5001.\n",
      "Step: 168 of 5001.\n",
      "Step: 169 of 5001.\n",
      "Step: 170 of 5001.\n",
      "Generator model loss: 0.039689142256975174.\n",
      "Discriminator model loss: 0.15208378434181213.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 171 of 5001.\n",
      "Step: 172 of 5001.\n",
      "Step: 173 of 5001.\n",
      "Step: 174 of 5001.\n",
      "Step: 175 of 5001.\n",
      "Step: 176 of 5001.\n",
      "Step: 177 of 5001.\n",
      "Step: 178 of 5001.\n",
      "Step: 179 of 5001.\n",
      "Step: 180 of 5001.\n",
      "Generator model loss: 0.04708361625671387.\n",
      "Discriminator model loss: -0.09823999553918839.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 181 of 5001.\n",
      "Step: 182 of 5001.\n",
      "Step: 183 of 5001.\n",
      "Step: 184 of 5001.\n",
      "Step: 185 of 5001.\n",
      "Step: 186 of 5001.\n",
      "Step: 187 of 5001.\n",
      "Step: 188 of 5001.\n",
      "Step: 189 of 5001.\n",
      "Step: 190 of 5001.\n",
      "Generator model loss: 0.04654299467802048.\n",
      "Discriminator model loss: -0.2970852553844452.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 191 of 5001.\n",
      "Step: 192 of 5001.\n",
      "Step: 193 of 5001.\n",
      "Step: 194 of 5001.\n",
      "Step: 195 of 5001.\n",
      "Step: 196 of 5001.\n",
      "Step: 197 of 5001.\n",
      "Step: 198 of 5001.\n",
      "Step: 199 of 5001.\n",
      "Step: 200 of 5001.\n",
      "Generator model loss: 0.04286516457796097.\n",
      "Discriminator model loss: -0.3640733063220978.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 201 of 5001.\n",
      "Step: 202 of 5001.\n",
      "Step: 203 of 5001.\n",
      "Step: 204 of 5001.\n",
      "Step: 205 of 5001.\n",
      "Step: 206 of 5001.\n",
      "Step: 207 of 5001.\n",
      "Step: 208 of 5001.\n",
      "Step: 209 of 5001.\n",
      "Step: 210 of 5001.\n",
      "Generator model loss: 0.03652152419090271.\n",
      "Discriminator model loss: -0.5143439769744873.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 211 of 5001.\n",
      "Step: 212 of 5001.\n",
      "Step: 213 of 5001.\n",
      "Step: 214 of 5001.\n",
      "Step: 215 of 5001.\n",
      "Step: 216 of 5001.\n",
      "Step: 217 of 5001.\n",
      "Step: 218 of 5001.\n",
      "Step: 219 of 5001.\n",
      "Step: 220 of 5001.\n",
      "Generator model loss: 0.02466636896133423.\n",
      "Discriminator model loss: -0.5324147343635559.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 221 of 5001.\n",
      "Step: 222 of 5001.\n",
      "Step: 223 of 5001.\n",
      "Step: 224 of 5001.\n",
      "Step: 225 of 5001.\n",
      "Step: 226 of 5001.\n",
      "Step: 227 of 5001.\n",
      "Step: 228 of 5001.\n",
      "Step: 229 of 5001.\n",
      "Step: 230 of 5001.\n",
      "Generator model loss: 0.019167449325323105.\n",
      "Discriminator model loss: -0.6699000000953674.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 231 of 5001.\n",
      "Step: 232 of 5001.\n",
      "Step: 233 of 5001.\n",
      "Step: 234 of 5001.\n",
      "Step: 235 of 5001.\n",
      "Step: 236 of 5001.\n",
      "Step: 237 of 5001.\n",
      "Step: 238 of 5001.\n",
      "Step: 239 of 5001.\n",
      "Step: 240 of 5001.\n",
      "Generator model loss: 0.008490601554512978.\n",
      "Discriminator model loss: -0.8031667470932007.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 241 of 5001.\n",
      "Step: 242 of 5001.\n",
      "Step: 243 of 5001.\n",
      "Step: 244 of 5001.\n",
      "Step: 245 of 5001.\n",
      "Step: 246 of 5001.\n",
      "Step: 247 of 5001.\n",
      "Step: 248 of 5001.\n",
      "Step: 249 of 5001.\n",
      "Step: 250 of 5001.\n",
      "Generator model loss: -0.00764851039275527.\n",
      "Discriminator model loss: -0.8029215931892395.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 251 of 5001.\n",
      "Step: 252 of 5001.\n",
      "Step: 253 of 5001.\n",
      "Step: 254 of 5001.\n",
      "Step: 255 of 5001.\n",
      "Step: 256 of 5001.\n",
      "Step: 257 of 5001.\n",
      "Step: 258 of 5001.\n",
      "Step: 259 of 5001.\n",
      "Step: 260 of 5001.\n",
      "Generator model loss: -0.003489881753921509.\n",
      "Discriminator model loss: -0.8118012547492981.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 261 of 5001.\n",
      "Step: 262 of 5001.\n",
      "Step: 263 of 5001.\n",
      "Step: 264 of 5001.\n",
      "Step: 265 of 5001.\n",
      "Step: 266 of 5001.\n",
      "Step: 267 of 5001.\n",
      "Step: 268 of 5001.\n",
      "Step: 269 of 5001.\n",
      "Step: 270 of 5001.\n",
      "Generator model loss: -0.01794709824025631.\n",
      "Discriminator model loss: -0.9254290461540222.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 271 of 5001.\n",
      "Step: 272 of 5001.\n",
      "Step: 273 of 5001.\n",
      "Step: 274 of 5001.\n",
      "Step: 275 of 5001.\n",
      "Step: 276 of 5001.\n",
      "Step: 277 of 5001.\n",
      "Step: 278 of 5001.\n",
      "Step: 279 of 5001.\n",
      "Step: 280 of 5001.\n",
      "Generator model loss: -0.028213104233145714.\n",
      "Discriminator model loss: -0.9673277139663696.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 281 of 5001.\n",
      "Step: 282 of 5001.\n",
      "Step: 283 of 5001.\n",
      "Step: 284 of 5001.\n",
      "Step: 285 of 5001.\n",
      "Step: 286 of 5001.\n",
      "Step: 287 of 5001.\n",
      "Step: 288 of 5001.\n",
      "Step: 289 of 5001.\n",
      "Step: 290 of 5001.\n",
      "Generator model loss: -0.03690241649746895.\n",
      "Discriminator model loss: -0.9691126942634583.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 291 of 5001.\n",
      "Step: 292 of 5001.\n",
      "Step: 293 of 5001.\n",
      "Step: 294 of 5001.\n",
      "Step: 295 of 5001.\n",
      "Step: 296 of 5001.\n",
      "Step: 297 of 5001.\n",
      "Step: 298 of 5001.\n",
      "Step: 299 of 5001.\n",
      "Step: 300 of 5001.\n",
      "Generator model loss: -0.03598644584417343.\n",
      "Discriminator model loss: -0.9150483012199402.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 301 of 5001.\n",
      "Step: 302 of 5001.\n",
      "Step: 303 of 5001.\n",
      "Step: 304 of 5001.\n",
      "Step: 305 of 5001.\n",
      "Step: 306 of 5001.\n",
      "Step: 307 of 5001.\n",
      "Step: 308 of 5001.\n",
      "Step: 309 of 5001.\n",
      "Step: 310 of 5001.\n",
      "Generator model loss: -0.05238380283117294.\n",
      "Discriminator model loss: -0.9359866976737976.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 311 of 5001.\n",
      "Step: 312 of 5001.\n",
      "Step: 313 of 5001.\n",
      "Step: 314 of 5001.\n",
      "Step: 315 of 5001.\n",
      "Step: 316 of 5001.\n",
      "Step: 317 of 5001.\n",
      "Step: 318 of 5001.\n",
      "Step: 319 of 5001.\n",
      "Step: 320 of 5001.\n",
      "Generator model loss: -0.05125480890274048.\n",
      "Discriminator model loss: -0.97676020860672.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 321 of 5001.\n",
      "Step: 322 of 5001.\n",
      "Step: 323 of 5001.\n",
      "Step: 324 of 5001.\n",
      "Step: 325 of 5001.\n",
      "Step: 326 of 5001.\n",
      "Step: 327 of 5001.\n",
      "Step: 328 of 5001.\n",
      "Step: 329 of 5001.\n",
      "Step: 330 of 5001.\n",
      "Generator model loss: -0.06421050429344177.\n",
      "Discriminator model loss: -1.0110291242599487.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 331 of 5001.\n",
      "Step: 332 of 5001.\n",
      "Step: 333 of 5001.\n",
      "Step: 334 of 5001.\n",
      "Step: 335 of 5001.\n",
      "Step: 336 of 5001.\n",
      "Step: 337 of 5001.\n",
      "Step: 338 of 5001.\n",
      "Step: 339 of 5001.\n",
      "Step: 340 of 5001.\n",
      "Generator model loss: -0.06427808105945587.\n",
      "Discriminator model loss: -1.0181310176849365.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 341 of 5001.\n",
      "Step: 342 of 5001.\n",
      "Step: 343 of 5001.\n",
      "Step: 344 of 5001.\n",
      "Step: 345 of 5001.\n",
      "Step: 346 of 5001.\n",
      "Step: 347 of 5001.\n",
      "Step: 348 of 5001.\n",
      "Step: 349 of 5001.\n",
      "Step: 350 of 5001.\n",
      "Generator model loss: -0.07975231111049652.\n",
      "Discriminator model loss: -1.0310715436935425.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 351 of 5001.\n",
      "Step: 352 of 5001.\n",
      "Step: 353 of 5001.\n",
      "Step: 354 of 5001.\n",
      "Step: 355 of 5001.\n",
      "Step: 356 of 5001.\n",
      "Step: 357 of 5001.\n",
      "Step: 358 of 5001.\n",
      "Step: 359 of 5001.\n",
      "Step: 360 of 5001.\n",
      "Generator model loss: -0.07183533161878586.\n",
      "Discriminator model loss: -1.0655937194824219.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 361 of 5001.\n",
      "Step: 362 of 5001.\n",
      "Step: 363 of 5001.\n",
      "Step: 364 of 5001.\n",
      "Step: 365 of 5001.\n",
      "Step: 366 of 5001.\n",
      "Step: 367 of 5001.\n",
      "Step: 368 of 5001.\n",
      "Step: 369 of 5001.\n",
      "Step: 370 of 5001.\n",
      "Generator model loss: -0.09420383721590042.\n",
      "Discriminator model loss: -1.0978695154190063.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 371 of 5001.\n",
      "Step: 372 of 5001.\n",
      "Step: 373 of 5001.\n",
      "Step: 374 of 5001.\n",
      "Step: 375 of 5001.\n",
      "Step: 376 of 5001.\n",
      "Step: 377 of 5001.\n",
      "Step: 378 of 5001.\n",
      "Step: 379 of 5001.\n",
      "Step: 380 of 5001.\n",
      "Generator model loss: -0.09162779152393341.\n",
      "Discriminator model loss: -1.0546557903289795.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 381 of 5001.\n",
      "Step: 382 of 5001.\n",
      "Step: 383 of 5001.\n",
      "Step: 384 of 5001.\n",
      "Step: 385 of 5001.\n",
      "Step: 386 of 5001.\n",
      "Step: 387 of 5001.\n",
      "Step: 388 of 5001.\n",
      "Step: 389 of 5001.\n",
      "Step: 390 of 5001.\n",
      "Generator model loss: -0.10435251891613007.\n",
      "Discriminator model loss: -1.0455214977264404.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 391 of 5001.\n",
      "Step: 392 of 5001.\n",
      "Step: 393 of 5001.\n",
      "Step: 394 of 5001.\n",
      "Step: 395 of 5001.\n",
      "Step: 396 of 5001.\n",
      "Step: 397 of 5001.\n",
      "Step: 398 of 5001.\n",
      "Step: 399 of 5001.\n",
      "Step: 400 of 5001.\n",
      "Generator model loss: -0.10204465687274933.\n",
      "Discriminator model loss: -1.0703651905059814.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 401 of 5001.\n",
      "Step: 402 of 5001.\n",
      "Step: 403 of 5001.\n",
      "Step: 404 of 5001.\n",
      "Step: 405 of 5001.\n",
      "Step: 406 of 5001.\n",
      "Step: 407 of 5001.\n",
      "Step: 408 of 5001.\n",
      "Step: 409 of 5001.\n",
      "Step: 410 of 5001.\n",
      "Generator model loss: -0.10724017769098282.\n",
      "Discriminator model loss: -1.1348463296890259.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 411 of 5001.\n",
      "Step: 412 of 5001.\n",
      "Step: 413 of 5001.\n",
      "Step: 414 of 5001.\n",
      "Step: 415 of 5001.\n",
      "Step: 416 of 5001.\n",
      "Step: 417 of 5001.\n",
      "Step: 418 of 5001.\n",
      "Step: 419 of 5001.\n",
      "Step: 420 of 5001.\n",
      "Generator model loss: -0.10546443611383438.\n",
      "Discriminator model loss: -1.1250035762786865.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 421 of 5001.\n",
      "Step: 422 of 5001.\n",
      "Step: 423 of 5001.\n",
      "Step: 424 of 5001.\n",
      "Step: 425 of 5001.\n",
      "Step: 426 of 5001.\n",
      "Step: 427 of 5001.\n",
      "Step: 428 of 5001.\n",
      "Step: 429 of 5001.\n",
      "Step: 430 of 5001.\n",
      "Generator model loss: -0.1230708584189415.\n",
      "Discriminator model loss: -1.0794538259506226.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 431 of 5001.\n",
      "Step: 432 of 5001.\n",
      "Step: 433 of 5001.\n",
      "Step: 434 of 5001.\n",
      "Step: 435 of 5001.\n",
      "Step: 436 of 5001.\n",
      "Step: 437 of 5001.\n",
      "Step: 438 of 5001.\n",
      "Step: 439 of 5001.\n",
      "Step: 440 of 5001.\n",
      "Generator model loss: -0.12243826687335968.\n",
      "Discriminator model loss: -1.092591643333435.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 441 of 5001.\n",
      "Step: 442 of 5001.\n",
      "Step: 443 of 5001.\n",
      "Step: 444 of 5001.\n",
      "Step: 445 of 5001.\n",
      "Step: 446 of 5001.\n",
      "Step: 447 of 5001.\n",
      "Step: 448 of 5001.\n",
      "Step: 449 of 5001.\n",
      "Step: 450 of 5001.\n",
      "Generator model loss: -0.13742636144161224.\n",
      "Discriminator model loss: -1.0895559787750244.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 451 of 5001.\n",
      "Step: 452 of 5001.\n",
      "Step: 453 of 5001.\n",
      "Step: 454 of 5001.\n",
      "Step: 455 of 5001.\n",
      "Step: 456 of 5001.\n",
      "Step: 457 of 5001.\n",
      "Step: 458 of 5001.\n",
      "Step: 459 of 5001.\n",
      "Step: 460 of 5001.\n",
      "Generator model loss: -0.12590953707695007.\n",
      "Discriminator model loss: -1.1037685871124268.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 461 of 5001.\n",
      "Step: 462 of 5001.\n",
      "Step: 463 of 5001.\n",
      "Step: 464 of 5001.\n",
      "Step: 465 of 5001.\n",
      "Step: 466 of 5001.\n",
      "Step: 467 of 5001.\n",
      "Step: 468 of 5001.\n",
      "Step: 469 of 5001.\n",
      "Step: 470 of 5001.\n",
      "Generator model loss: -0.14651772379875183.\n",
      "Discriminator model loss: -1.0390256643295288.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 471 of 5001.\n",
      "Step: 472 of 5001.\n",
      "Step: 473 of 5001.\n",
      "Step: 474 of 5001.\n",
      "Step: 475 of 5001.\n",
      "Step: 476 of 5001.\n",
      "Step: 477 of 5001.\n",
      "Step: 478 of 5001.\n",
      "Step: 479 of 5001.\n",
      "Step: 480 of 5001.\n",
      "Generator model loss: -0.13151197135448456.\n",
      "Discriminator model loss: -1.016422986984253.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 481 of 5001.\n",
      "Step: 482 of 5001.\n",
      "Step: 483 of 5001.\n",
      "Step: 484 of 5001.\n",
      "Step: 485 of 5001.\n",
      "Step: 486 of 5001.\n",
      "Step: 487 of 5001.\n",
      "Step: 488 of 5001.\n",
      "Step: 489 of 5001.\n",
      "Step: 490 of 5001.\n",
      "Generator model loss: -0.1444973647594452.\n",
      "Discriminator model loss: -1.0251896381378174.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 491 of 5001.\n",
      "Step: 492 of 5001.\n",
      "Step: 493 of 5001.\n",
      "Step: 494 of 5001.\n",
      "Step: 495 of 5001.\n",
      "Step: 496 of 5001.\n",
      "Step: 497 of 5001.\n",
      "Step: 498 of 5001.\n",
      "Step: 499 of 5001.\n",
      "Step: 500 of 5001.\n",
      "Generator model loss: -0.1513868272304535.\n",
      "Discriminator model loss: -1.1153608560562134.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 501 of 5001.\n",
      "Step: 502 of 5001.\n",
      "Step: 503 of 5001.\n",
      "Step: 504 of 5001.\n",
      "Step: 505 of 5001.\n",
      "Step: 506 of 5001.\n",
      "Step: 507 of 5001.\n",
      "Step: 508 of 5001.\n",
      "Step: 509 of 5001.\n",
      "Step: 510 of 5001.\n",
      "Generator model loss: -0.1647467017173767.\n",
      "Discriminator model loss: -1.0766346454620361.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 511 of 5001.\n",
      "Step: 512 of 5001.\n",
      "Step: 513 of 5001.\n",
      "Step: 514 of 5001.\n",
      "Step: 515 of 5001.\n",
      "Step: 516 of 5001.\n",
      "Step: 517 of 5001.\n",
      "Step: 518 of 5001.\n",
      "Step: 519 of 5001.\n",
      "Step: 520 of 5001.\n",
      "Generator model loss: -0.16422846913337708.\n",
      "Discriminator model loss: -1.118491768836975.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 521 of 5001.\n",
      "Step: 522 of 5001.\n",
      "Step: 523 of 5001.\n",
      "Step: 524 of 5001.\n",
      "Step: 525 of 5001.\n",
      "Step: 526 of 5001.\n",
      "Step: 527 of 5001.\n",
      "Step: 528 of 5001.\n",
      "Step: 529 of 5001.\n",
      "Step: 530 of 5001.\n",
      "Generator model loss: -0.16967599093914032.\n",
      "Discriminator model loss: -1.012658715248108.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 531 of 5001.\n",
      "Step: 532 of 5001.\n",
      "Step: 533 of 5001.\n",
      "Step: 534 of 5001.\n",
      "Step: 535 of 5001.\n",
      "Step: 536 of 5001.\n",
      "Step: 537 of 5001.\n",
      "Step: 538 of 5001.\n",
      "Step: 539 of 5001.\n",
      "Step: 540 of 5001.\n",
      "Generator model loss: -0.18080979585647583.\n",
      "Discriminator model loss: -1.098388433456421.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 541 of 5001.\n",
      "Step: 542 of 5001.\n",
      "Step: 543 of 5001.\n",
      "Step: 544 of 5001.\n",
      "Step: 545 of 5001.\n",
      "Step: 546 of 5001.\n",
      "Step: 547 of 5001.\n",
      "Step: 548 of 5001.\n",
      "Step: 549 of 5001.\n",
      "Step: 550 of 5001.\n",
      "Generator model loss: -0.1872875690460205.\n",
      "Discriminator model loss: -1.051523208618164.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 551 of 5001.\n",
      "Step: 552 of 5001.\n",
      "Step: 553 of 5001.\n",
      "Step: 554 of 5001.\n",
      "Step: 555 of 5001.\n",
      "Step: 556 of 5001.\n",
      "Step: 557 of 5001.\n",
      "Step: 558 of 5001.\n",
      "Step: 559 of 5001.\n",
      "Step: 560 of 5001.\n",
      "Generator model loss: -0.1813722550868988.\n",
      "Discriminator model loss: -1.1567943096160889.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 561 of 5001.\n",
      "Step: 562 of 5001.\n",
      "Step: 563 of 5001.\n",
      "Step: 564 of 5001.\n",
      "Step: 565 of 5001.\n",
      "Step: 566 of 5001.\n",
      "Step: 567 of 5001.\n",
      "Step: 568 of 5001.\n",
      "Step: 569 of 5001.\n",
      "Step: 570 of 5001.\n",
      "Generator model loss: -0.1822843849658966.\n",
      "Discriminator model loss: -1.0951323509216309.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 571 of 5001.\n",
      "Step: 572 of 5001.\n",
      "Step: 573 of 5001.\n",
      "Step: 574 of 5001.\n",
      "Step: 575 of 5001.\n",
      "Step: 576 of 5001.\n",
      "Step: 577 of 5001.\n",
      "Step: 578 of 5001.\n",
      "Step: 579 of 5001.\n",
      "Step: 580 of 5001.\n",
      "Generator model loss: -0.18280074000358582.\n",
      "Discriminator model loss: -1.0944428443908691.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 581 of 5001.\n",
      "Step: 582 of 5001.\n",
      "Step: 583 of 5001.\n",
      "Step: 584 of 5001.\n",
      "Step: 585 of 5001.\n",
      "Step: 586 of 5001.\n",
      "Step: 587 of 5001.\n",
      "Step: 588 of 5001.\n",
      "Step: 589 of 5001.\n",
      "Step: 590 of 5001.\n",
      "Generator model loss: -0.19031749665737152.\n",
      "Discriminator model loss: -1.0945827960968018.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 591 of 5001.\n",
      "Step: 592 of 5001.\n",
      "Step: 593 of 5001.\n",
      "Step: 594 of 5001.\n",
      "Step: 595 of 5001.\n",
      "Step: 596 of 5001.\n",
      "Step: 597 of 5001.\n",
      "Step: 598 of 5001.\n",
      "Step: 599 of 5001.\n",
      "Step: 600 of 5001.\n",
      "Generator model loss: -0.21654415130615234.\n",
      "Discriminator model loss: -1.0538418292999268.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 601 of 5001.\n",
      "Step: 602 of 5001.\n",
      "Step: 603 of 5001.\n",
      "Step: 604 of 5001.\n",
      "Step: 605 of 5001.\n",
      "Step: 606 of 5001.\n",
      "Step: 607 of 5001.\n",
      "Step: 608 of 5001.\n",
      "Step: 609 of 5001.\n",
      "Step: 610 of 5001.\n",
      "Generator model loss: -0.21333034336566925.\n",
      "Discriminator model loss: -1.004921555519104.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 611 of 5001.\n",
      "Step: 612 of 5001.\n",
      "Step: 613 of 5001.\n",
      "Step: 614 of 5001.\n",
      "Step: 615 of 5001.\n",
      "Step: 616 of 5001.\n",
      "Step: 617 of 5001.\n",
      "Step: 618 of 5001.\n",
      "Step: 619 of 5001.\n",
      "Step: 620 of 5001.\n",
      "Generator model loss: -0.22128471732139587.\n",
      "Discriminator model loss: -1.0802110433578491.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 621 of 5001.\n",
      "Step: 622 of 5001.\n",
      "Step: 623 of 5001.\n",
      "Step: 624 of 5001.\n",
      "Step: 625 of 5001.\n",
      "Step: 626 of 5001.\n",
      "Step: 627 of 5001.\n",
      "Step: 628 of 5001.\n",
      "Step: 629 of 5001.\n",
      "Step: 630 of 5001.\n",
      "Generator model loss: -0.22505705058574677.\n",
      "Discriminator model loss: -1.049377202987671.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 631 of 5001.\n",
      "Step: 632 of 5001.\n",
      "Step: 633 of 5001.\n",
      "Step: 634 of 5001.\n",
      "Step: 635 of 5001.\n",
      "Step: 636 of 5001.\n",
      "Step: 637 of 5001.\n",
      "Step: 638 of 5001.\n",
      "Step: 639 of 5001.\n",
      "Step: 640 of 5001.\n",
      "Generator model loss: -0.22552542388439178.\n",
      "Discriminator model loss: -1.0603610277175903.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 641 of 5001.\n",
      "Step: 642 of 5001.\n",
      "Step: 643 of 5001.\n",
      "Step: 644 of 5001.\n",
      "Step: 645 of 5001.\n",
      "Step: 646 of 5001.\n",
      "Step: 647 of 5001.\n",
      "Step: 648 of 5001.\n",
      "Step: 649 of 5001.\n",
      "Step: 650 of 5001.\n",
      "Generator model loss: -0.22344887256622314.\n",
      "Discriminator model loss: -1.0316078662872314.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 651 of 5001.\n",
      "Step: 652 of 5001.\n",
      "Step: 653 of 5001.\n",
      "Step: 654 of 5001.\n",
      "Step: 655 of 5001.\n",
      "Step: 656 of 5001.\n",
      "Step: 657 of 5001.\n",
      "Step: 658 of 5001.\n",
      "Step: 659 of 5001.\n",
      "Step: 660 of 5001.\n",
      "Generator model loss: -0.22692525386810303.\n",
      "Discriminator model loss: -1.0403118133544922.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 661 of 5001.\n",
      "Step: 662 of 5001.\n",
      "Step: 663 of 5001.\n",
      "Step: 664 of 5001.\n",
      "Step: 665 of 5001.\n",
      "Step: 666 of 5001.\n",
      "Step: 667 of 5001.\n",
      "Step: 668 of 5001.\n",
      "Step: 669 of 5001.\n",
      "Step: 670 of 5001.\n",
      "Generator model loss: -0.24903185665607452.\n",
      "Discriminator model loss: -0.9901548624038696.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 671 of 5001.\n",
      "Step: 672 of 5001.\n",
      "Step: 673 of 5001.\n",
      "Step: 674 of 5001.\n",
      "Step: 675 of 5001.\n",
      "Step: 676 of 5001.\n",
      "Step: 677 of 5001.\n",
      "Step: 678 of 5001.\n",
      "Step: 679 of 5001.\n",
      "Step: 680 of 5001.\n",
      "Generator model loss: -0.24649278819561005.\n",
      "Discriminator model loss: -0.8959251642227173.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 681 of 5001.\n",
      "Step: 682 of 5001.\n",
      "Step: 683 of 5001.\n",
      "Step: 684 of 5001.\n",
      "Step: 685 of 5001.\n",
      "Step: 686 of 5001.\n",
      "Step: 687 of 5001.\n",
      "Step: 688 of 5001.\n",
      "Step: 689 of 5001.\n",
      "Step: 690 of 5001.\n",
      "Generator model loss: -0.24969951808452606.\n",
      "Discriminator model loss: -0.9498924016952515.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 691 of 5001.\n",
      "Step: 692 of 5001.\n",
      "Step: 693 of 5001.\n",
      "Step: 694 of 5001.\n",
      "Step: 695 of 5001.\n",
      "Step: 696 of 5001.\n",
      "Step: 697 of 5001.\n",
      "Step: 698 of 5001.\n",
      "Step: 699 of 5001.\n",
      "Step: 700 of 5001.\n",
      "Generator model loss: -0.27502748370170593.\n",
      "Discriminator model loss: -1.040619134902954.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 701 of 5001.\n",
      "Step: 702 of 5001.\n",
      "Step: 703 of 5001.\n",
      "Step: 704 of 5001.\n",
      "Step: 705 of 5001.\n",
      "Step: 706 of 5001.\n",
      "Step: 707 of 5001.\n",
      "Step: 708 of 5001.\n",
      "Step: 709 of 5001.\n",
      "Step: 710 of 5001.\n",
      "Generator model loss: -0.2656593322753906.\n",
      "Discriminator model loss: -0.9926061630249023.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 711 of 5001.\n",
      "Step: 712 of 5001.\n",
      "Step: 713 of 5001.\n",
      "Step: 714 of 5001.\n",
      "Step: 715 of 5001.\n",
      "Step: 716 of 5001.\n",
      "Step: 717 of 5001.\n",
      "Step: 718 of 5001.\n",
      "Step: 719 of 5001.\n",
      "Step: 720 of 5001.\n",
      "Generator model loss: -0.26193660497665405.\n",
      "Discriminator model loss: -0.9587713479995728.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 721 of 5001.\n",
      "Step: 722 of 5001.\n",
      "Step: 723 of 5001.\n",
      "Step: 724 of 5001.\n",
      "Step: 725 of 5001.\n",
      "Step: 726 of 5001.\n",
      "Step: 727 of 5001.\n",
      "Step: 728 of 5001.\n",
      "Step: 729 of 5001.\n",
      "Step: 730 of 5001.\n",
      "Generator model loss: -0.27513745427131653.\n",
      "Discriminator model loss: -0.979729175567627.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 731 of 5001.\n",
      "Step: 732 of 5001.\n",
      "Step: 733 of 5001.\n",
      "Step: 734 of 5001.\n",
      "Step: 735 of 5001.\n",
      "Step: 736 of 5001.\n",
      "Step: 737 of 5001.\n",
      "Step: 738 of 5001.\n",
      "Step: 739 of 5001.\n",
      "Step: 740 of 5001.\n",
      "Generator model loss: -0.2990902066230774.\n",
      "Discriminator model loss: -1.004982590675354.\n",
      "xgboost accuracy: 0.98\n",
      "Step: 741 of 5001.\n",
      "Step: 742 of 5001.\n",
      "Step: 743 of 5001.\n",
      "Step: 744 of 5001.\n",
      "Step: 745 of 5001.\n",
      "Step: 746 of 5001.\n",
      "Step: 747 of 5001.\n",
      "Step: 748 of 5001.\n",
      "Step: 749 of 5001.\n",
      "Step: 750 of 5001.\n",
      "Generator model loss: -0.29370182752609253.\n",
      "Discriminator model loss: -0.9925273656845093.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 751 of 5001.\n",
      "Step: 752 of 5001.\n",
      "Step: 753 of 5001.\n",
      "Step: 754 of 5001.\n",
      "Step: 755 of 5001.\n",
      "Step: 756 of 5001.\n",
      "Step: 757 of 5001.\n",
      "Step: 758 of 5001.\n",
      "Step: 759 of 5001.\n",
      "Step: 760 of 5001.\n",
      "Generator model loss: -0.3114328682422638.\n",
      "Discriminator model loss: -0.9535317420959473.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 761 of 5001.\n",
      "Step: 762 of 5001.\n",
      "Step: 763 of 5001.\n",
      "Step: 764 of 5001.\n",
      "Step: 765 of 5001.\n",
      "Step: 766 of 5001.\n",
      "Step: 767 of 5001.\n",
      "Step: 768 of 5001.\n",
      "Step: 769 of 5001.\n",
      "Step: 770 of 5001.\n",
      "Generator model loss: -0.30563968420028687.\n",
      "Discriminator model loss: -0.9994478225708008.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 771 of 5001.\n",
      "Step: 772 of 5001.\n",
      "Step: 773 of 5001.\n",
      "Step: 774 of 5001.\n",
      "Step: 775 of 5001.\n",
      "Step: 776 of 5001.\n",
      "Step: 777 of 5001.\n",
      "Step: 778 of 5001.\n",
      "Step: 779 of 5001.\n",
      "Step: 780 of 5001.\n",
      "Generator model loss: -0.3256855607032776.\n",
      "Discriminator model loss: -1.0044022798538208.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 781 of 5001.\n",
      "Step: 782 of 5001.\n",
      "Step: 783 of 5001.\n",
      "Step: 784 of 5001.\n",
      "Step: 785 of 5001.\n",
      "Step: 786 of 5001.\n",
      "Step: 787 of 5001.\n",
      "Step: 788 of 5001.\n",
      "Step: 789 of 5001.\n",
      "Step: 790 of 5001.\n",
      "Generator model loss: -0.3264910578727722.\n",
      "Discriminator model loss: -0.9888452291488647.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 791 of 5001.\n",
      "Step: 792 of 5001.\n",
      "Step: 793 of 5001.\n",
      "Step: 794 of 5001.\n",
      "Step: 795 of 5001.\n",
      "Step: 796 of 5001.\n",
      "Step: 797 of 5001.\n",
      "Step: 798 of 5001.\n",
      "Step: 799 of 5001.\n",
      "Step: 800 of 5001.\n",
      "Generator model loss: -0.33513301610946655.\n",
      "Discriminator model loss: -0.924798846244812.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 801 of 5001.\n",
      "Step: 802 of 5001.\n",
      "Step: 803 of 5001.\n",
      "Step: 804 of 5001.\n",
      "Step: 805 of 5001.\n",
      "Step: 806 of 5001.\n",
      "Step: 807 of 5001.\n",
      "Step: 808 of 5001.\n",
      "Step: 809 of 5001.\n",
      "Step: 810 of 5001.\n",
      "Generator model loss: -0.3308236598968506.\n",
      "Discriminator model loss: -0.9800541996955872.\n",
      "xgboost accuracy: 0.98\n",
      "Step: 811 of 5001.\n",
      "Step: 812 of 5001.\n",
      "Step: 813 of 5001.\n",
      "Step: 814 of 5001.\n",
      "Step: 815 of 5001.\n",
      "Step: 816 of 5001.\n",
      "Step: 817 of 5001.\n",
      "Step: 818 of 5001.\n",
      "Step: 819 of 5001.\n",
      "Step: 820 of 5001.\n",
      "Generator model loss: -0.3483971357345581.\n",
      "Discriminator model loss: -0.9129785299301147.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 821 of 5001.\n",
      "Step: 822 of 5001.\n",
      "Step: 823 of 5001.\n",
      "Step: 824 of 5001.\n",
      "Step: 825 of 5001.\n",
      "Step: 826 of 5001.\n",
      "Step: 827 of 5001.\n",
      "Step: 828 of 5001.\n",
      "Step: 829 of 5001.\n",
      "Step: 830 of 5001.\n",
      "Generator model loss: -0.3522018790245056.\n",
      "Discriminator model loss: -0.9736191630363464.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 831 of 5001.\n",
      "Step: 832 of 5001.\n",
      "Step: 833 of 5001.\n",
      "Step: 834 of 5001.\n",
      "Step: 835 of 5001.\n",
      "Step: 836 of 5001.\n",
      "Step: 837 of 5001.\n",
      "Step: 838 of 5001.\n",
      "Step: 839 of 5001.\n",
      "Step: 840 of 5001.\n",
      "Generator model loss: -0.36466822028160095.\n",
      "Discriminator model loss: -0.9239241480827332.\n",
      "xgboost accuracy: 0.98\n",
      "Step: 841 of 5001.\n",
      "Step: 842 of 5001.\n",
      "Step: 843 of 5001.\n",
      "Step: 844 of 5001.\n",
      "Step: 845 of 5001.\n",
      "Step: 846 of 5001.\n",
      "Step: 847 of 5001.\n",
      "Step: 848 of 5001.\n",
      "Step: 849 of 5001.\n",
      "Step: 850 of 5001.\n",
      "Generator model loss: -0.36479732394218445.\n",
      "Discriminator model loss: -0.9900901913642883.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 851 of 5001.\n",
      "Step: 852 of 5001.\n",
      "Step: 853 of 5001.\n",
      "Step: 854 of 5001.\n",
      "Step: 855 of 5001.\n",
      "Step: 856 of 5001.\n",
      "Step: 857 of 5001.\n",
      "Step: 858 of 5001.\n",
      "Step: 859 of 5001.\n",
      "Step: 860 of 5001.\n",
      "Generator model loss: -0.3655303716659546.\n",
      "Discriminator model loss: -0.9134575128555298.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 861 of 5001.\n",
      "Step: 862 of 5001.\n",
      "Step: 863 of 5001.\n",
      "Step: 864 of 5001.\n",
      "Step: 865 of 5001.\n",
      "Step: 866 of 5001.\n",
      "Step: 867 of 5001.\n",
      "Step: 868 of 5001.\n",
      "Step: 869 of 5001.\n",
      "Step: 870 of 5001.\n",
      "Generator model loss: -0.3745948374271393.\n",
      "Discriminator model loss: -0.8910782933235168.\n",
      "xgboost accuracy: 0.98\n",
      "Step: 871 of 5001.\n",
      "Step: 872 of 5001.\n",
      "Step: 873 of 5001.\n",
      "Step: 874 of 5001.\n",
      "Step: 875 of 5001.\n",
      "Step: 876 of 5001.\n",
      "Step: 877 of 5001.\n",
      "Step: 878 of 5001.\n",
      "Step: 879 of 5001.\n",
      "Step: 880 of 5001.\n",
      "Generator model loss: -0.3790566325187683.\n",
      "Discriminator model loss: -0.9117758870124817.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 881 of 5001.\n",
      "Step: 882 of 5001.\n",
      "Step: 883 of 5001.\n",
      "Step: 884 of 5001.\n",
      "Step: 885 of 5001.\n",
      "Step: 886 of 5001.\n",
      "Step: 887 of 5001.\n",
      "Step: 888 of 5001.\n",
      "Step: 889 of 5001.\n",
      "Step: 890 of 5001.\n",
      "Generator model loss: -0.3984290659427643.\n",
      "Discriminator model loss: -0.8179785013198853.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 891 of 5001.\n",
      "Step: 892 of 5001.\n",
      "Step: 893 of 5001.\n",
      "Step: 894 of 5001.\n",
      "Step: 895 of 5001.\n",
      "Step: 896 of 5001.\n",
      "Step: 897 of 5001.\n",
      "Step: 898 of 5001.\n",
      "Step: 899 of 5001.\n",
      "Step: 900 of 5001.\n",
      "Generator model loss: -0.37492385506629944.\n",
      "Discriminator model loss: -0.893067479133606.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 901 of 5001.\n",
      "Step: 902 of 5001.\n",
      "Step: 903 of 5001.\n",
      "Step: 904 of 5001.\n",
      "Step: 905 of 5001.\n",
      "Step: 906 of 5001.\n",
      "Step: 907 of 5001.\n",
      "Step: 908 of 5001.\n",
      "Step: 909 of 5001.\n",
      "Step: 910 of 5001.\n",
      "Generator model loss: -0.40308934450149536.\n",
      "Discriminator model loss: -0.8558884859085083.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 911 of 5001.\n",
      "Step: 912 of 5001.\n",
      "Step: 913 of 5001.\n",
      "Step: 914 of 5001.\n",
      "Step: 915 of 5001.\n",
      "Step: 916 of 5001.\n",
      "Step: 917 of 5001.\n",
      "Step: 918 of 5001.\n",
      "Step: 919 of 5001.\n",
      "Step: 920 of 5001.\n",
      "Generator model loss: -0.42665085196495056.\n",
      "Discriminator model loss: -0.8363782167434692.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 921 of 5001.\n",
      "Step: 922 of 5001.\n",
      "Step: 923 of 5001.\n",
      "Step: 924 of 5001.\n",
      "Step: 925 of 5001.\n",
      "Step: 926 of 5001.\n",
      "Step: 927 of 5001.\n",
      "Step: 928 of 5001.\n",
      "Step: 929 of 5001.\n",
      "Step: 930 of 5001.\n",
      "Generator model loss: -0.40277719497680664.\n",
      "Discriminator model loss: -0.8245797157287598.\n",
      "xgboost accuracy: 0.98\n",
      "Step: 931 of 5001.\n",
      "Step: 932 of 5001.\n",
      "Step: 933 of 5001.\n",
      "Step: 934 of 5001.\n",
      "Step: 935 of 5001.\n",
      "Step: 936 of 5001.\n",
      "Step: 937 of 5001.\n",
      "Step: 938 of 5001.\n",
      "Step: 939 of 5001.\n",
      "Step: 940 of 5001.\n",
      "Generator model loss: -0.4163881242275238.\n",
      "Discriminator model loss: -0.8944414258003235.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 941 of 5001.\n",
      "Step: 942 of 5001.\n",
      "Step: 943 of 5001.\n",
      "Step: 944 of 5001.\n",
      "Step: 945 of 5001.\n",
      "Step: 946 of 5001.\n",
      "Step: 947 of 5001.\n",
      "Step: 948 of 5001.\n",
      "Step: 949 of 5001.\n",
      "Step: 950 of 5001.\n",
      "Generator model loss: -0.40251272916793823.\n",
      "Discriminator model loss: -0.7704616785049438.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 951 of 5001.\n",
      "Step: 952 of 5001.\n",
      "Step: 953 of 5001.\n",
      "Step: 954 of 5001.\n",
      "Step: 955 of 5001.\n",
      "Step: 956 of 5001.\n",
      "Step: 957 of 5001.\n",
      "Step: 958 of 5001.\n",
      "Step: 959 of 5001.\n",
      "Step: 960 of 5001.\n",
      "Generator model loss: -0.40730947256088257.\n",
      "Discriminator model loss: -0.8976060748100281.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 961 of 5001.\n",
      "Step: 962 of 5001.\n",
      "Step: 963 of 5001.\n",
      "Step: 964 of 5001.\n",
      "Step: 965 of 5001.\n",
      "Step: 966 of 5001.\n",
      "Step: 967 of 5001.\n",
      "Step: 968 of 5001.\n",
      "Step: 969 of 5001.\n",
      "Step: 970 of 5001.\n",
      "Generator model loss: -0.4306458830833435.\n",
      "Discriminator model loss: -0.8610326647758484.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 971 of 5001.\n",
      "Step: 972 of 5001.\n",
      "Step: 973 of 5001.\n",
      "Step: 974 of 5001.\n",
      "Step: 975 of 5001.\n",
      "Step: 976 of 5001.\n",
      "Step: 977 of 5001.\n",
      "Step: 978 of 5001.\n",
      "Step: 979 of 5001.\n",
      "Step: 980 of 5001.\n",
      "Generator model loss: -0.41926470398902893.\n",
      "Discriminator model loss: -0.7876089811325073.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 981 of 5001.\n",
      "Step: 982 of 5001.\n",
      "Step: 983 of 5001.\n",
      "Step: 984 of 5001.\n",
      "Step: 985 of 5001.\n",
      "Step: 986 of 5001.\n",
      "Step: 987 of 5001.\n",
      "Step: 988 of 5001.\n",
      "Step: 989 of 5001.\n",
      "Step: 990 of 5001.\n",
      "Generator model loss: -0.4093361794948578.\n",
      "Discriminator model loss: -0.8999911546707153.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 991 of 5001.\n",
      "Step: 992 of 5001.\n",
      "Step: 993 of 5001.\n",
      "Step: 994 of 5001.\n",
      "Step: 995 of 5001.\n",
      "Step: 996 of 5001.\n",
      "Step: 997 of 5001.\n",
      "Step: 998 of 5001.\n",
      "Step: 999 of 5001.\n",
      "Step: 1000 of 5001.\n",
      "Generator model loss: -0.42104440927505493.\n",
      "Discriminator model loss: -0.7962093949317932.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 1001 of 5001.\n",
      "Step: 1002 of 5001.\n",
      "Step: 1003 of 5001.\n",
      "Step: 1004 of 5001.\n",
      "Step: 1005 of 5001.\n",
      "Step: 1006 of 5001.\n",
      "Step: 1007 of 5001.\n",
      "Step: 1008 of 5001.\n",
      "Step: 1009 of 5001.\n",
      "Step: 1010 of 5001.\n",
      "Generator model loss: -0.46045780181884766.\n",
      "Discriminator model loss: -0.8573576211929321.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1011 of 5001.\n",
      "Step: 1012 of 5001.\n",
      "Step: 1013 of 5001.\n",
      "Step: 1014 of 5001.\n",
      "Step: 1015 of 5001.\n",
      "Step: 1016 of 5001.\n",
      "Step: 1017 of 5001.\n",
      "Step: 1018 of 5001.\n",
      "Step: 1019 of 5001.\n",
      "Step: 1020 of 5001.\n",
      "Generator model loss: -0.4531022608280182.\n",
      "Discriminator model loss: -0.9212878346443176.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1021 of 5001.\n",
      "Step: 1022 of 5001.\n",
      "Step: 1023 of 5001.\n",
      "Step: 1024 of 5001.\n",
      "Step: 1025 of 5001.\n",
      "Step: 1026 of 5001.\n",
      "Step: 1027 of 5001.\n",
      "Step: 1028 of 5001.\n",
      "Step: 1029 of 5001.\n",
      "Step: 1030 of 5001.\n",
      "Generator model loss: -0.45728176832199097.\n",
      "Discriminator model loss: -0.7973290681838989.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1031 of 5001.\n",
      "Step: 1032 of 5001.\n",
      "Step: 1033 of 5001.\n",
      "Step: 1034 of 5001.\n",
      "Step: 1035 of 5001.\n",
      "Step: 1036 of 5001.\n",
      "Step: 1037 of 5001.\n",
      "Step: 1038 of 5001.\n",
      "Step: 1039 of 5001.\n",
      "Step: 1040 of 5001.\n",
      "Generator model loss: -0.45089396834373474.\n",
      "Discriminator model loss: -0.7913085222244263.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1041 of 5001.\n",
      "Step: 1042 of 5001.\n",
      "Step: 1043 of 5001.\n",
      "Step: 1044 of 5001.\n",
      "Step: 1045 of 5001.\n",
      "Step: 1046 of 5001.\n",
      "Step: 1047 of 5001.\n",
      "Step: 1048 of 5001.\n",
      "Step: 1049 of 5001.\n",
      "Step: 1050 of 5001.\n",
      "Generator model loss: -0.46167826652526855.\n",
      "Discriminator model loss: -0.845018208026886.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1051 of 5001.\n",
      "Step: 1052 of 5001.\n",
      "Step: 1053 of 5001.\n",
      "Step: 1054 of 5001.\n",
      "Step: 1055 of 5001.\n",
      "Step: 1056 of 5001.\n",
      "Step: 1057 of 5001.\n",
      "Step: 1058 of 5001.\n",
      "Step: 1059 of 5001.\n",
      "Step: 1060 of 5001.\n",
      "Generator model loss: -0.4533539414405823.\n",
      "Discriminator model loss: -0.844631016254425.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1061 of 5001.\n",
      "Step: 1062 of 5001.\n",
      "Step: 1063 of 5001.\n",
      "Step: 1064 of 5001.\n",
      "Step: 1065 of 5001.\n",
      "Step: 1066 of 5001.\n",
      "Step: 1067 of 5001.\n",
      "Step: 1068 of 5001.\n",
      "Step: 1069 of 5001.\n",
      "Step: 1070 of 5001.\n",
      "Generator model loss: -0.47990837693214417.\n",
      "Discriminator model loss: -0.8677594065666199.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 1071 of 5001.\n",
      "Step: 1072 of 5001.\n",
      "Step: 1073 of 5001.\n",
      "Step: 1074 of 5001.\n",
      "Step: 1075 of 5001.\n",
      "Step: 1076 of 5001.\n",
      "Step: 1077 of 5001.\n",
      "Step: 1078 of 5001.\n",
      "Step: 1079 of 5001.\n",
      "Step: 1080 of 5001.\n",
      "Generator model loss: -0.47469717264175415.\n",
      "Discriminator model loss: -0.7808805704116821.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1081 of 5001.\n",
      "Step: 1082 of 5001.\n",
      "Step: 1083 of 5001.\n",
      "Step: 1084 of 5001.\n",
      "Step: 1085 of 5001.\n",
      "Step: 1086 of 5001.\n",
      "Step: 1087 of 5001.\n",
      "Step: 1088 of 5001.\n",
      "Step: 1089 of 5001.\n",
      "Step: 1090 of 5001.\n",
      "Generator model loss: -0.49319592118263245.\n",
      "Discriminator model loss: -0.8024161458015442.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1091 of 5001.\n",
      "Step: 1092 of 5001.\n",
      "Step: 1093 of 5001.\n",
      "Step: 1094 of 5001.\n",
      "Step: 1095 of 5001.\n",
      "Step: 1096 of 5001.\n",
      "Step: 1097 of 5001.\n",
      "Step: 1098 of 5001.\n",
      "Step: 1099 of 5001.\n",
      "Step: 1100 of 5001.\n",
      "Generator model loss: -0.48379239439964294.\n",
      "Discriminator model loss: -0.7978494167327881.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1101 of 5001.\n",
      "Step: 1102 of 5001.\n",
      "Step: 1103 of 5001.\n",
      "Step: 1104 of 5001.\n",
      "Step: 1105 of 5001.\n",
      "Step: 1106 of 5001.\n",
      "Step: 1107 of 5001.\n",
      "Step: 1108 of 5001.\n",
      "Step: 1109 of 5001.\n",
      "Step: 1110 of 5001.\n",
      "Generator model loss: -0.49440088868141174.\n",
      "Discriminator model loss: -0.8245885968208313.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1111 of 5001.\n",
      "Step: 1112 of 5001.\n",
      "Step: 1113 of 5001.\n",
      "Step: 1114 of 5001.\n",
      "Step: 1115 of 5001.\n",
      "Step: 1116 of 5001.\n",
      "Step: 1117 of 5001.\n",
      "Step: 1118 of 5001.\n",
      "Step: 1119 of 5001.\n",
      "Step: 1120 of 5001.\n",
      "Generator model loss: -0.5041828751564026.\n",
      "Discriminator model loss: -0.7408259510993958.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 1121 of 5001.\n",
      "Step: 1122 of 5001.\n",
      "Step: 1123 of 5001.\n",
      "Step: 1124 of 5001.\n",
      "Step: 1125 of 5001.\n",
      "Step: 1126 of 5001.\n",
      "Step: 1127 of 5001.\n",
      "Step: 1128 of 5001.\n",
      "Step: 1129 of 5001.\n",
      "Step: 1130 of 5001.\n",
      "Generator model loss: -0.5186538100242615.\n",
      "Discriminator model loss: -0.8007125854492188.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1131 of 5001.\n",
      "Step: 1132 of 5001.\n",
      "Step: 1133 of 5001.\n",
      "Step: 1134 of 5001.\n",
      "Step: 1135 of 5001.\n",
      "Step: 1136 of 5001.\n",
      "Step: 1137 of 5001.\n",
      "Step: 1138 of 5001.\n",
      "Step: 1139 of 5001.\n",
      "Step: 1140 of 5001.\n",
      "Generator model loss: -0.46538248658180237.\n",
      "Discriminator model loss: -0.725371241569519.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1141 of 5001.\n",
      "Step: 1142 of 5001.\n",
      "Step: 1143 of 5001.\n",
      "Step: 1144 of 5001.\n",
      "Step: 1145 of 5001.\n",
      "Step: 1146 of 5001.\n",
      "Step: 1147 of 5001.\n",
      "Step: 1148 of 5001.\n",
      "Step: 1149 of 5001.\n",
      "Step: 1150 of 5001.\n",
      "Generator model loss: -0.49047836661338806.\n",
      "Discriminator model loss: -0.7904042601585388.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1151 of 5001.\n",
      "Step: 1152 of 5001.\n",
      "Step: 1153 of 5001.\n",
      "Step: 1154 of 5001.\n",
      "Step: 1155 of 5001.\n",
      "Step: 1156 of 5001.\n",
      "Step: 1157 of 5001.\n",
      "Step: 1158 of 5001.\n",
      "Step: 1159 of 5001.\n",
      "Step: 1160 of 5001.\n",
      "Generator model loss: -0.5041017532348633.\n",
      "Discriminator model loss: -0.8183408975601196.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 1161 of 5001.\n",
      "Step: 1162 of 5001.\n",
      "Step: 1163 of 5001.\n",
      "Step: 1164 of 5001.\n",
      "Step: 1165 of 5001.\n",
      "Step: 1166 of 5001.\n",
      "Step: 1167 of 5001.\n",
      "Step: 1168 of 5001.\n",
      "Step: 1169 of 5001.\n",
      "Step: 1170 of 5001.\n",
      "Generator model loss: -0.5274950265884399.\n",
      "Discriminator model loss: -0.7672837376594543.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1171 of 5001.\n",
      "Step: 1172 of 5001.\n",
      "Step: 1173 of 5001.\n",
      "Step: 1174 of 5001.\n",
      "Step: 1175 of 5001.\n",
      "Step: 1176 of 5001.\n",
      "Step: 1177 of 5001.\n",
      "Step: 1178 of 5001.\n",
      "Step: 1179 of 5001.\n",
      "Step: 1180 of 5001.\n",
      "Generator model loss: -0.5141069293022156.\n",
      "Discriminator model loss: -0.7773336172103882.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1181 of 5001.\n",
      "Step: 1182 of 5001.\n",
      "Step: 1183 of 5001.\n",
      "Step: 1184 of 5001.\n",
      "Step: 1185 of 5001.\n",
      "Step: 1186 of 5001.\n",
      "Step: 1187 of 5001.\n",
      "Step: 1188 of 5001.\n",
      "Step: 1189 of 5001.\n",
      "Step: 1190 of 5001.\n",
      "Generator model loss: -0.49636945128440857.\n",
      "Discriminator model loss: -0.8039382100105286.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1191 of 5001.\n",
      "Step: 1192 of 5001.\n",
      "Step: 1193 of 5001.\n",
      "Step: 1194 of 5001.\n",
      "Step: 1195 of 5001.\n",
      "Step: 1196 of 5001.\n",
      "Step: 1197 of 5001.\n",
      "Step: 1198 of 5001.\n",
      "Step: 1199 of 5001.\n",
      "Step: 1200 of 5001.\n",
      "Generator model loss: -0.5006157755851746.\n",
      "Discriminator model loss: -0.8089221119880676.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1201 of 5001.\n",
      "Step: 1202 of 5001.\n",
      "Step: 1203 of 5001.\n",
      "Step: 1204 of 5001.\n",
      "Step: 1205 of 5001.\n",
      "Step: 1206 of 5001.\n",
      "Step: 1207 of 5001.\n",
      "Step: 1208 of 5001.\n",
      "Step: 1209 of 5001.\n",
      "Step: 1210 of 5001.\n",
      "Generator model loss: -0.5184058547019958.\n",
      "Discriminator model loss: -0.7698078751564026.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1211 of 5001.\n",
      "Step: 1212 of 5001.\n",
      "Step: 1213 of 5001.\n",
      "Step: 1214 of 5001.\n",
      "Step: 1215 of 5001.\n",
      "Step: 1216 of 5001.\n",
      "Step: 1217 of 5001.\n",
      "Step: 1218 of 5001.\n",
      "Step: 1219 of 5001.\n",
      "Step: 1220 of 5001.\n",
      "Generator model loss: -0.502936065196991.\n",
      "Discriminator model loss: -0.8056080937385559.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1221 of 5001.\n",
      "Step: 1222 of 5001.\n",
      "Step: 1223 of 5001.\n",
      "Step: 1224 of 5001.\n",
      "Step: 1225 of 5001.\n",
      "Step: 1226 of 5001.\n",
      "Step: 1227 of 5001.\n",
      "Step: 1228 of 5001.\n",
      "Step: 1229 of 5001.\n",
      "Step: 1230 of 5001.\n",
      "Generator model loss: -0.5119897723197937.\n",
      "Discriminator model loss: -0.7616245150566101.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1231 of 5001.\n",
      "Step: 1232 of 5001.\n",
      "Step: 1233 of 5001.\n",
      "Step: 1234 of 5001.\n",
      "Step: 1235 of 5001.\n",
      "Step: 1236 of 5001.\n",
      "Step: 1237 of 5001.\n",
      "Step: 1238 of 5001.\n",
      "Step: 1239 of 5001.\n",
      "Step: 1240 of 5001.\n",
      "Generator model loss: -0.5336028933525085.\n",
      "Discriminator model loss: -0.8127222061157227.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1241 of 5001.\n",
      "Step: 1242 of 5001.\n",
      "Step: 1243 of 5001.\n",
      "Step: 1244 of 5001.\n",
      "Step: 1245 of 5001.\n",
      "Step: 1246 of 5001.\n",
      "Step: 1247 of 5001.\n",
      "Step: 1248 of 5001.\n",
      "Step: 1249 of 5001.\n",
      "Step: 1250 of 5001.\n",
      "Generator model loss: -0.5317137241363525.\n",
      "Discriminator model loss: -0.7539898157119751.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1251 of 5001.\n",
      "Step: 1252 of 5001.\n",
      "Step: 1253 of 5001.\n",
      "Step: 1254 of 5001.\n",
      "Step: 1255 of 5001.\n",
      "Step: 1256 of 5001.\n",
      "Step: 1257 of 5001.\n",
      "Step: 1258 of 5001.\n",
      "Step: 1259 of 5001.\n",
      "Step: 1260 of 5001.\n",
      "Generator model loss: -0.5442578196525574.\n",
      "Discriminator model loss: -0.704663872718811.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1261 of 5001.\n",
      "Step: 1262 of 5001.\n",
      "Step: 1263 of 5001.\n",
      "Step: 1264 of 5001.\n",
      "Step: 1265 of 5001.\n",
      "Step: 1266 of 5001.\n",
      "Step: 1267 of 5001.\n",
      "Step: 1268 of 5001.\n",
      "Step: 1269 of 5001.\n",
      "Step: 1270 of 5001.\n",
      "Generator model loss: -0.5438830256462097.\n",
      "Discriminator model loss: -0.800541877746582.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1271 of 5001.\n",
      "Step: 1272 of 5001.\n",
      "Step: 1273 of 5001.\n",
      "Step: 1274 of 5001.\n",
      "Step: 1275 of 5001.\n",
      "Step: 1276 of 5001.\n",
      "Step: 1277 of 5001.\n",
      "Step: 1278 of 5001.\n",
      "Step: 1279 of 5001.\n",
      "Step: 1280 of 5001.\n",
      "Generator model loss: -0.5645133256912231.\n",
      "Discriminator model loss: -0.7605269551277161.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1281 of 5001.\n",
      "Step: 1282 of 5001.\n",
      "Step: 1283 of 5001.\n",
      "Step: 1284 of 5001.\n",
      "Step: 1285 of 5001.\n",
      "Step: 1286 of 5001.\n",
      "Step: 1287 of 5001.\n",
      "Step: 1288 of 5001.\n",
      "Step: 1289 of 5001.\n",
      "Step: 1290 of 5001.\n",
      "Generator model loss: -0.575244128704071.\n",
      "Discriminator model loss: -0.7636737823486328.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1291 of 5001.\n",
      "Step: 1292 of 5001.\n",
      "Step: 1293 of 5001.\n",
      "Step: 1294 of 5001.\n",
      "Step: 1295 of 5001.\n",
      "Step: 1296 of 5001.\n",
      "Step: 1297 of 5001.\n",
      "Step: 1298 of 5001.\n",
      "Step: 1299 of 5001.\n",
      "Step: 1300 of 5001.\n",
      "Generator model loss: -0.5682269334793091.\n",
      "Discriminator model loss: -0.7566912770271301.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1301 of 5001.\n",
      "Step: 1302 of 5001.\n",
      "Step: 1303 of 5001.\n",
      "Step: 1304 of 5001.\n",
      "Step: 1305 of 5001.\n",
      "Step: 1306 of 5001.\n",
      "Step: 1307 of 5001.\n",
      "Step: 1308 of 5001.\n",
      "Step: 1309 of 5001.\n",
      "Step: 1310 of 5001.\n",
      "Generator model loss: -0.5535035133361816.\n",
      "Discriminator model loss: -0.8012459874153137.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1311 of 5001.\n",
      "Step: 1312 of 5001.\n",
      "Step: 1313 of 5001.\n",
      "Step: 1314 of 5001.\n",
      "Step: 1315 of 5001.\n",
      "Step: 1316 of 5001.\n",
      "Step: 1317 of 5001.\n",
      "Step: 1318 of 5001.\n",
      "Step: 1319 of 5001.\n",
      "Step: 1320 of 5001.\n",
      "Generator model loss: -0.5940600633621216.\n",
      "Discriminator model loss: -0.7944340705871582.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1321 of 5001.\n",
      "Step: 1322 of 5001.\n",
      "Step: 1323 of 5001.\n",
      "Step: 1324 of 5001.\n",
      "Step: 1325 of 5001.\n",
      "Step: 1326 of 5001.\n",
      "Step: 1327 of 5001.\n",
      "Step: 1328 of 5001.\n",
      "Step: 1329 of 5001.\n",
      "Step: 1330 of 5001.\n",
      "Generator model loss: -0.5789811611175537.\n",
      "Discriminator model loss: -0.7565299272537231.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1331 of 5001.\n",
      "Step: 1332 of 5001.\n",
      "Step: 1333 of 5001.\n",
      "Step: 1334 of 5001.\n",
      "Step: 1335 of 5001.\n",
      "Step: 1336 of 5001.\n",
      "Step: 1337 of 5001.\n",
      "Step: 1338 of 5001.\n",
      "Step: 1339 of 5001.\n",
      "Step: 1340 of 5001.\n",
      "Generator model loss: -0.6368967294692993.\n",
      "Discriminator model loss: -0.758158802986145.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1341 of 5001.\n",
      "Step: 1342 of 5001.\n",
      "Step: 1343 of 5001.\n",
      "Step: 1344 of 5001.\n",
      "Step: 1345 of 5001.\n",
      "Step: 1346 of 5001.\n",
      "Step: 1347 of 5001.\n",
      "Step: 1348 of 5001.\n",
      "Step: 1349 of 5001.\n",
      "Step: 1350 of 5001.\n",
      "Generator model loss: -0.5832494497299194.\n",
      "Discriminator model loss: -0.7364628314971924.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1351 of 5001.\n",
      "Step: 1352 of 5001.\n",
      "Step: 1353 of 5001.\n",
      "Step: 1354 of 5001.\n",
      "Step: 1355 of 5001.\n",
      "Step: 1356 of 5001.\n",
      "Step: 1357 of 5001.\n",
      "Step: 1358 of 5001.\n",
      "Step: 1359 of 5001.\n",
      "Step: 1360 of 5001.\n",
      "Generator model loss: -0.5851972103118896.\n",
      "Discriminator model loss: -0.7636200189590454.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1361 of 5001.\n",
      "Step: 1362 of 5001.\n",
      "Step: 1363 of 5001.\n",
      "Step: 1364 of 5001.\n",
      "Step: 1365 of 5001.\n",
      "Step: 1366 of 5001.\n",
      "Step: 1367 of 5001.\n",
      "Step: 1368 of 5001.\n",
      "Step: 1369 of 5001.\n",
      "Step: 1370 of 5001.\n",
      "Generator model loss: -0.6171713471412659.\n",
      "Discriminator model loss: -0.7564452886581421.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1371 of 5001.\n",
      "Step: 1372 of 5001.\n",
      "Step: 1373 of 5001.\n",
      "Step: 1374 of 5001.\n",
      "Step: 1375 of 5001.\n",
      "Step: 1376 of 5001.\n",
      "Step: 1377 of 5001.\n",
      "Step: 1378 of 5001.\n",
      "Step: 1379 of 5001.\n",
      "Step: 1380 of 5001.\n",
      "Generator model loss: -0.6374127268791199.\n",
      "Discriminator model loss: -0.7396031618118286.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1381 of 5001.\n",
      "Step: 1382 of 5001.\n",
      "Step: 1383 of 5001.\n",
      "Step: 1384 of 5001.\n",
      "Step: 1385 of 5001.\n",
      "Step: 1386 of 5001.\n",
      "Step: 1387 of 5001.\n",
      "Step: 1388 of 5001.\n",
      "Step: 1389 of 5001.\n",
      "Step: 1390 of 5001.\n",
      "Generator model loss: -0.6476725339889526.\n",
      "Discriminator model loss: -0.7755171656608582.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1391 of 5001.\n",
      "Step: 1392 of 5001.\n",
      "Step: 1393 of 5001.\n",
      "Step: 1394 of 5001.\n",
      "Step: 1395 of 5001.\n",
      "Step: 1396 of 5001.\n",
      "Step: 1397 of 5001.\n",
      "Step: 1398 of 5001.\n",
      "Step: 1399 of 5001.\n",
      "Step: 1400 of 5001.\n",
      "Generator model loss: -0.5986589193344116.\n",
      "Discriminator model loss: -0.7547118663787842.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1401 of 5001.\n",
      "Step: 1402 of 5001.\n",
      "Step: 1403 of 5001.\n",
      "Step: 1404 of 5001.\n",
      "Step: 1405 of 5001.\n",
      "Step: 1406 of 5001.\n",
      "Step: 1407 of 5001.\n",
      "Step: 1408 of 5001.\n",
      "Step: 1409 of 5001.\n",
      "Step: 1410 of 5001.\n",
      "Generator model loss: -0.6683370471000671.\n",
      "Discriminator model loss: -0.7542842626571655.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1411 of 5001.\n",
      "Step: 1412 of 5001.\n",
      "Step: 1413 of 5001.\n",
      "Step: 1414 of 5001.\n",
      "Step: 1415 of 5001.\n",
      "Step: 1416 of 5001.\n",
      "Step: 1417 of 5001.\n",
      "Step: 1418 of 5001.\n",
      "Step: 1419 of 5001.\n",
      "Step: 1420 of 5001.\n",
      "Generator model loss: -0.6650460958480835.\n",
      "Discriminator model loss: -0.7367026805877686.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1421 of 5001.\n",
      "Step: 1422 of 5001.\n",
      "Step: 1423 of 5001.\n",
      "Step: 1424 of 5001.\n",
      "Step: 1425 of 5001.\n",
      "Step: 1426 of 5001.\n",
      "Step: 1427 of 5001.\n",
      "Step: 1428 of 5001.\n",
      "Step: 1429 of 5001.\n",
      "Step: 1430 of 5001.\n",
      "Generator model loss: -0.6717782616615295.\n",
      "Discriminator model loss: -0.6629810929298401.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1431 of 5001.\n",
      "Step: 1432 of 5001.\n",
      "Step: 1433 of 5001.\n",
      "Step: 1434 of 5001.\n",
      "Step: 1435 of 5001.\n",
      "Step: 1436 of 5001.\n",
      "Step: 1437 of 5001.\n",
      "Step: 1438 of 5001.\n",
      "Step: 1439 of 5001.\n",
      "Step: 1440 of 5001.\n",
      "Generator model loss: -0.6549388766288757.\n",
      "Discriminator model loss: -0.7105090618133545.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1441 of 5001.\n",
      "Step: 1442 of 5001.\n",
      "Step: 1443 of 5001.\n",
      "Step: 1444 of 5001.\n",
      "Step: 1445 of 5001.\n",
      "Step: 1446 of 5001.\n",
      "Step: 1447 of 5001.\n",
      "Step: 1448 of 5001.\n",
      "Step: 1449 of 5001.\n",
      "Step: 1450 of 5001.\n",
      "Generator model loss: -0.6981992721557617.\n",
      "Discriminator model loss: -0.7387019395828247.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1451 of 5001.\n",
      "Step: 1452 of 5001.\n",
      "Step: 1453 of 5001.\n",
      "Step: 1454 of 5001.\n",
      "Step: 1455 of 5001.\n",
      "Step: 1456 of 5001.\n",
      "Step: 1457 of 5001.\n",
      "Step: 1458 of 5001.\n",
      "Step: 1459 of 5001.\n",
      "Step: 1460 of 5001.\n",
      "Generator model loss: -0.7235715985298157.\n",
      "Discriminator model loss: -0.7493998408317566.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1461 of 5001.\n",
      "Step: 1462 of 5001.\n",
      "Step: 1463 of 5001.\n",
      "Step: 1464 of 5001.\n",
      "Step: 1465 of 5001.\n",
      "Step: 1466 of 5001.\n",
      "Step: 1467 of 5001.\n",
      "Step: 1468 of 5001.\n",
      "Step: 1469 of 5001.\n",
      "Step: 1470 of 5001.\n",
      "Generator model loss: -0.7155965566635132.\n",
      "Discriminator model loss: -0.6844993829727173.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1471 of 5001.\n",
      "Step: 1472 of 5001.\n",
      "Step: 1473 of 5001.\n",
      "Step: 1474 of 5001.\n",
      "Step: 1475 of 5001.\n",
      "Step: 1476 of 5001.\n",
      "Step: 1477 of 5001.\n",
      "Step: 1478 of 5001.\n",
      "Step: 1479 of 5001.\n",
      "Step: 1480 of 5001.\n",
      "Generator model loss: -0.7006992697715759.\n",
      "Discriminator model loss: -0.7274898290634155.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1481 of 5001.\n",
      "Step: 1482 of 5001.\n",
      "Step: 1483 of 5001.\n",
      "Step: 1484 of 5001.\n",
      "Step: 1485 of 5001.\n",
      "Step: 1486 of 5001.\n",
      "Step: 1487 of 5001.\n",
      "Step: 1488 of 5001.\n",
      "Step: 1489 of 5001.\n",
      "Step: 1490 of 5001.\n",
      "Generator model loss: -0.7435652017593384.\n",
      "Discriminator model loss: -0.6676923632621765.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1491 of 5001.\n",
      "Step: 1492 of 5001.\n",
      "Step: 1493 of 5001.\n",
      "Step: 1494 of 5001.\n",
      "Step: 1495 of 5001.\n",
      "Step: 1496 of 5001.\n",
      "Step: 1497 of 5001.\n",
      "Step: 1498 of 5001.\n",
      "Step: 1499 of 5001.\n",
      "Step: 1500 of 5001.\n",
      "Generator model loss: -0.7183598279953003.\n",
      "Discriminator model loss: -0.6706470251083374.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1501 of 5001.\n",
      "Step: 1502 of 5001.\n",
      "Step: 1503 of 5001.\n",
      "Step: 1504 of 5001.\n",
      "Step: 1505 of 5001.\n",
      "Step: 1506 of 5001.\n",
      "Step: 1507 of 5001.\n",
      "Step: 1508 of 5001.\n",
      "Step: 1509 of 5001.\n",
      "Step: 1510 of 5001.\n",
      "Generator model loss: -0.7187027335166931.\n",
      "Discriminator model loss: -0.7054376602172852.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1511 of 5001.\n",
      "Step: 1512 of 5001.\n",
      "Step: 1513 of 5001.\n",
      "Step: 1514 of 5001.\n",
      "Step: 1515 of 5001.\n",
      "Step: 1516 of 5001.\n",
      "Step: 1517 of 5001.\n",
      "Step: 1518 of 5001.\n",
      "Step: 1519 of 5001.\n",
      "Step: 1520 of 5001.\n",
      "Generator model loss: -0.7868406772613525.\n",
      "Discriminator model loss: -0.6788227558135986.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1521 of 5001.\n",
      "Step: 1522 of 5001.\n",
      "Step: 1523 of 5001.\n",
      "Step: 1524 of 5001.\n",
      "Step: 1525 of 5001.\n",
      "Step: 1526 of 5001.\n",
      "Step: 1527 of 5001.\n",
      "Step: 1528 of 5001.\n",
      "Step: 1529 of 5001.\n",
      "Step: 1530 of 5001.\n",
      "Generator model loss: -0.7834964990615845.\n",
      "Discriminator model loss: -0.7281056642532349.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1531 of 5001.\n",
      "Step: 1532 of 5001.\n",
      "Step: 1533 of 5001.\n",
      "Step: 1534 of 5001.\n",
      "Step: 1535 of 5001.\n",
      "Step: 1536 of 5001.\n",
      "Step: 1537 of 5001.\n",
      "Step: 1538 of 5001.\n",
      "Step: 1539 of 5001.\n",
      "Step: 1540 of 5001.\n",
      "Generator model loss: -0.7804167866706848.\n",
      "Discriminator model loss: -0.6975255608558655.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1541 of 5001.\n",
      "Step: 1542 of 5001.\n",
      "Step: 1543 of 5001.\n",
      "Step: 1544 of 5001.\n",
      "Step: 1545 of 5001.\n",
      "Step: 1546 of 5001.\n",
      "Step: 1547 of 5001.\n",
      "Step: 1548 of 5001.\n",
      "Step: 1549 of 5001.\n",
      "Step: 1550 of 5001.\n",
      "Generator model loss: -0.7957950830459595.\n",
      "Discriminator model loss: -0.7005132436752319.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1551 of 5001.\n",
      "Step: 1552 of 5001.\n",
      "Step: 1553 of 5001.\n",
      "Step: 1554 of 5001.\n",
      "Step: 1555 of 5001.\n",
      "Step: 1556 of 5001.\n",
      "Step: 1557 of 5001.\n",
      "Step: 1558 of 5001.\n",
      "Step: 1559 of 5001.\n",
      "Step: 1560 of 5001.\n",
      "Generator model loss: -0.7761865854263306.\n",
      "Discriminator model loss: -0.6336967349052429.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1561 of 5001.\n",
      "Step: 1562 of 5001.\n",
      "Step: 1563 of 5001.\n",
      "Step: 1564 of 5001.\n",
      "Step: 1565 of 5001.\n",
      "Step: 1566 of 5001.\n",
      "Step: 1567 of 5001.\n",
      "Step: 1568 of 5001.\n",
      "Step: 1569 of 5001.\n",
      "Step: 1570 of 5001.\n",
      "Generator model loss: -0.8226255178451538.\n",
      "Discriminator model loss: -0.6601446866989136.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1571 of 5001.\n",
      "Step: 1572 of 5001.\n",
      "Step: 1573 of 5001.\n",
      "Step: 1574 of 5001.\n",
      "Step: 1575 of 5001.\n",
      "Step: 1576 of 5001.\n",
      "Step: 1577 of 5001.\n",
      "Step: 1578 of 5001.\n",
      "Step: 1579 of 5001.\n",
      "Step: 1580 of 5001.\n",
      "Generator model loss: -0.815808892250061.\n",
      "Discriminator model loss: -0.6446666717529297.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1581 of 5001.\n",
      "Step: 1582 of 5001.\n",
      "Step: 1583 of 5001.\n",
      "Step: 1584 of 5001.\n",
      "Step: 1585 of 5001.\n",
      "Step: 1586 of 5001.\n",
      "Step: 1587 of 5001.\n",
      "Step: 1588 of 5001.\n",
      "Step: 1589 of 5001.\n",
      "Step: 1590 of 5001.\n",
      "Generator model loss: -0.8273422122001648.\n",
      "Discriminator model loss: -0.6513288617134094.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1591 of 5001.\n",
      "Step: 1592 of 5001.\n",
      "Step: 1593 of 5001.\n",
      "Step: 1594 of 5001.\n",
      "Step: 1595 of 5001.\n",
      "Step: 1596 of 5001.\n",
      "Step: 1597 of 5001.\n",
      "Step: 1598 of 5001.\n",
      "Step: 1599 of 5001.\n",
      "Step: 1600 of 5001.\n",
      "Generator model loss: -0.857062816619873.\n",
      "Discriminator model loss: -0.7014992833137512.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1601 of 5001.\n",
      "Step: 1602 of 5001.\n",
      "Step: 1603 of 5001.\n",
      "Step: 1604 of 5001.\n",
      "Step: 1605 of 5001.\n",
      "Step: 1606 of 5001.\n",
      "Step: 1607 of 5001.\n",
      "Step: 1608 of 5001.\n",
      "Step: 1609 of 5001.\n",
      "Step: 1610 of 5001.\n",
      "Generator model loss: -0.8158701658248901.\n",
      "Discriminator model loss: -0.7243767976760864.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1611 of 5001.\n",
      "Step: 1612 of 5001.\n",
      "Step: 1613 of 5001.\n",
      "Step: 1614 of 5001.\n",
      "Step: 1615 of 5001.\n",
      "Step: 1616 of 5001.\n",
      "Step: 1617 of 5001.\n",
      "Step: 1618 of 5001.\n",
      "Step: 1619 of 5001.\n",
      "Step: 1620 of 5001.\n",
      "Generator model loss: -0.8575863838195801.\n",
      "Discriminator model loss: -0.6911866068840027.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1621 of 5001.\n",
      "Step: 1622 of 5001.\n",
      "Step: 1623 of 5001.\n",
      "Step: 1624 of 5001.\n",
      "Step: 1625 of 5001.\n",
      "Step: 1626 of 5001.\n",
      "Step: 1627 of 5001.\n",
      "Step: 1628 of 5001.\n",
      "Step: 1629 of 5001.\n",
      "Step: 1630 of 5001.\n",
      "Generator model loss: -0.8929599523544312.\n",
      "Discriminator model loss: -0.6446834802627563.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1631 of 5001.\n",
      "Step: 1632 of 5001.\n",
      "Step: 1633 of 5001.\n",
      "Step: 1634 of 5001.\n",
      "Step: 1635 of 5001.\n",
      "Step: 1636 of 5001.\n",
      "Step: 1637 of 5001.\n",
      "Step: 1638 of 5001.\n",
      "Step: 1639 of 5001.\n",
      "Step: 1640 of 5001.\n",
      "Generator model loss: -0.8837499618530273.\n",
      "Discriminator model loss: -0.6442747116088867.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1641 of 5001.\n",
      "Step: 1642 of 5001.\n",
      "Step: 1643 of 5001.\n",
      "Step: 1644 of 5001.\n",
      "Step: 1645 of 5001.\n",
      "Step: 1646 of 5001.\n",
      "Step: 1647 of 5001.\n",
      "Step: 1648 of 5001.\n",
      "Step: 1649 of 5001.\n",
      "Step: 1650 of 5001.\n",
      "Generator model loss: -0.851336658000946.\n",
      "Discriminator model loss: -0.6370681524276733.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1651 of 5001.\n",
      "Step: 1652 of 5001.\n",
      "Step: 1653 of 5001.\n",
      "Step: 1654 of 5001.\n",
      "Step: 1655 of 5001.\n",
      "Step: 1656 of 5001.\n",
      "Step: 1657 of 5001.\n",
      "Step: 1658 of 5001.\n",
      "Step: 1659 of 5001.\n",
      "Step: 1660 of 5001.\n",
      "Generator model loss: -0.8789290189743042.\n",
      "Discriminator model loss: -0.6208958625793457.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 1661 of 5001.\n",
      "Step: 1662 of 5001.\n",
      "Step: 1663 of 5001.\n",
      "Step: 1664 of 5001.\n",
      "Step: 1665 of 5001.\n",
      "Step: 1666 of 5001.\n",
      "Step: 1667 of 5001.\n",
      "Step: 1668 of 5001.\n",
      "Step: 1669 of 5001.\n",
      "Step: 1670 of 5001.\n",
      "Generator model loss: -0.9168450236320496.\n",
      "Discriminator model loss: -0.6589136719703674.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1671 of 5001.\n",
      "Step: 1672 of 5001.\n",
      "Step: 1673 of 5001.\n",
      "Step: 1674 of 5001.\n",
      "Step: 1675 of 5001.\n",
      "Step: 1676 of 5001.\n",
      "Step: 1677 of 5001.\n",
      "Step: 1678 of 5001.\n",
      "Step: 1679 of 5001.\n",
      "Step: 1680 of 5001.\n",
      "Generator model loss: -0.9009131193161011.\n",
      "Discriminator model loss: -0.59929358959198.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1681 of 5001.\n",
      "Step: 1682 of 5001.\n",
      "Step: 1683 of 5001.\n",
      "Step: 1684 of 5001.\n",
      "Step: 1685 of 5001.\n",
      "Step: 1686 of 5001.\n",
      "Step: 1687 of 5001.\n",
      "Step: 1688 of 5001.\n",
      "Step: 1689 of 5001.\n",
      "Step: 1690 of 5001.\n",
      "Generator model loss: -0.9010794758796692.\n",
      "Discriminator model loss: -0.6025621294975281.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1691 of 5001.\n",
      "Step: 1692 of 5001.\n",
      "Step: 1693 of 5001.\n",
      "Step: 1694 of 5001.\n",
      "Step: 1695 of 5001.\n",
      "Step: 1696 of 5001.\n",
      "Step: 1697 of 5001.\n",
      "Step: 1698 of 5001.\n",
      "Step: 1699 of 5001.\n",
      "Step: 1700 of 5001.\n",
      "Generator model loss: -0.9075444936752319.\n",
      "Discriminator model loss: -0.6732177734375.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1701 of 5001.\n",
      "Step: 1702 of 5001.\n",
      "Step: 1703 of 5001.\n",
      "Step: 1704 of 5001.\n",
      "Step: 1705 of 5001.\n",
      "Step: 1706 of 5001.\n",
      "Step: 1707 of 5001.\n",
      "Step: 1708 of 5001.\n",
      "Step: 1709 of 5001.\n",
      "Step: 1710 of 5001.\n",
      "Generator model loss: -0.9264097213745117.\n",
      "Discriminator model loss: -0.6554900407791138.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1711 of 5001.\n",
      "Step: 1712 of 5001.\n",
      "Step: 1713 of 5001.\n",
      "Step: 1714 of 5001.\n",
      "Step: 1715 of 5001.\n",
      "Step: 1716 of 5001.\n",
      "Step: 1717 of 5001.\n",
      "Step: 1718 of 5001.\n",
      "Step: 1719 of 5001.\n",
      "Step: 1720 of 5001.\n",
      "Generator model loss: -0.9338889122009277.\n",
      "Discriminator model loss: -0.7410789728164673.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1721 of 5001.\n",
      "Step: 1722 of 5001.\n",
      "Step: 1723 of 5001.\n",
      "Step: 1724 of 5001.\n",
      "Step: 1725 of 5001.\n",
      "Step: 1726 of 5001.\n",
      "Step: 1727 of 5001.\n",
      "Step: 1728 of 5001.\n",
      "Step: 1729 of 5001.\n",
      "Step: 1730 of 5001.\n",
      "Generator model loss: -0.9440817832946777.\n",
      "Discriminator model loss: -0.609981894493103.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1731 of 5001.\n",
      "Step: 1732 of 5001.\n",
      "Step: 1733 of 5001.\n",
      "Step: 1734 of 5001.\n",
      "Step: 1735 of 5001.\n",
      "Step: 1736 of 5001.\n",
      "Step: 1737 of 5001.\n",
      "Step: 1738 of 5001.\n",
      "Step: 1739 of 5001.\n",
      "Step: 1740 of 5001.\n",
      "Generator model loss: -0.9330245852470398.\n",
      "Discriminator model loss: -0.624760627746582.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1741 of 5001.\n",
      "Step: 1742 of 5001.\n",
      "Step: 1743 of 5001.\n",
      "Step: 1744 of 5001.\n",
      "Step: 1745 of 5001.\n",
      "Step: 1746 of 5001.\n",
      "Step: 1747 of 5001.\n",
      "Step: 1748 of 5001.\n",
      "Step: 1749 of 5001.\n",
      "Step: 1750 of 5001.\n",
      "Generator model loss: -0.9484345316886902.\n",
      "Discriminator model loss: -0.6149066686630249.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 1751 of 5001.\n",
      "Step: 1752 of 5001.\n",
      "Step: 1753 of 5001.\n",
      "Step: 1754 of 5001.\n",
      "Step: 1755 of 5001.\n",
      "Step: 1756 of 5001.\n",
      "Step: 1757 of 5001.\n",
      "Step: 1758 of 5001.\n",
      "Step: 1759 of 5001.\n",
      "Step: 1760 of 5001.\n",
      "Generator model loss: -0.9761269688606262.\n",
      "Discriminator model loss: -0.5796604156494141.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 1761 of 5001.\n",
      "Step: 1762 of 5001.\n",
      "Step: 1763 of 5001.\n",
      "Step: 1764 of 5001.\n",
      "Step: 1765 of 5001.\n",
      "Step: 1766 of 5001.\n",
      "Step: 1767 of 5001.\n",
      "Step: 1768 of 5001.\n",
      "Step: 1769 of 5001.\n",
      "Step: 1770 of 5001.\n",
      "Generator model loss: -0.998668372631073.\n",
      "Discriminator model loss: -0.6566063761711121.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1771 of 5001.\n",
      "Step: 1772 of 5001.\n",
      "Step: 1773 of 5001.\n",
      "Step: 1774 of 5001.\n",
      "Step: 1775 of 5001.\n",
      "Step: 1776 of 5001.\n",
      "Step: 1777 of 5001.\n",
      "Step: 1778 of 5001.\n",
      "Step: 1779 of 5001.\n",
      "Step: 1780 of 5001.\n",
      "Generator model loss: -0.9919523000717163.\n",
      "Discriminator model loss: -0.6305102109909058.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1781 of 5001.\n",
      "Step: 1782 of 5001.\n",
      "Step: 1783 of 5001.\n",
      "Step: 1784 of 5001.\n",
      "Step: 1785 of 5001.\n",
      "Step: 1786 of 5001.\n",
      "Step: 1787 of 5001.\n",
      "Step: 1788 of 5001.\n",
      "Step: 1789 of 5001.\n",
      "Step: 1790 of 5001.\n",
      "Generator model loss: -0.9413822293281555.\n",
      "Discriminator model loss: -0.6402983665466309.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1791 of 5001.\n",
      "Step: 1792 of 5001.\n",
      "Step: 1793 of 5001.\n",
      "Step: 1794 of 5001.\n",
      "Step: 1795 of 5001.\n",
      "Step: 1796 of 5001.\n",
      "Step: 1797 of 5001.\n",
      "Step: 1798 of 5001.\n",
      "Step: 1799 of 5001.\n",
      "Step: 1800 of 5001.\n",
      "Generator model loss: -0.9743043184280396.\n",
      "Discriminator model loss: -0.6501389741897583.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1801 of 5001.\n",
      "Step: 1802 of 5001.\n",
      "Step: 1803 of 5001.\n",
      "Step: 1804 of 5001.\n",
      "Step: 1805 of 5001.\n",
      "Step: 1806 of 5001.\n",
      "Step: 1807 of 5001.\n",
      "Step: 1808 of 5001.\n",
      "Step: 1809 of 5001.\n",
      "Step: 1810 of 5001.\n",
      "Generator model loss: -1.014939785003662.\n",
      "Discriminator model loss: -0.6506358981132507.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1811 of 5001.\n",
      "Step: 1812 of 5001.\n",
      "Step: 1813 of 5001.\n",
      "Step: 1814 of 5001.\n",
      "Step: 1815 of 5001.\n",
      "Step: 1816 of 5001.\n",
      "Step: 1817 of 5001.\n",
      "Step: 1818 of 5001.\n",
      "Step: 1819 of 5001.\n",
      "Step: 1820 of 5001.\n",
      "Generator model loss: -1.008462905883789.\n",
      "Discriminator model loss: -0.5711417198181152.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1821 of 5001.\n",
      "Step: 1822 of 5001.\n",
      "Step: 1823 of 5001.\n",
      "Step: 1824 of 5001.\n",
      "Step: 1825 of 5001.\n",
      "Step: 1826 of 5001.\n",
      "Step: 1827 of 5001.\n",
      "Step: 1828 of 5001.\n",
      "Step: 1829 of 5001.\n",
      "Step: 1830 of 5001.\n",
      "Generator model loss: -1.04642653465271.\n",
      "Discriminator model loss: -0.6044657230377197.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1831 of 5001.\n",
      "Step: 1832 of 5001.\n",
      "Step: 1833 of 5001.\n",
      "Step: 1834 of 5001.\n",
      "Step: 1835 of 5001.\n",
      "Step: 1836 of 5001.\n",
      "Step: 1837 of 5001.\n",
      "Step: 1838 of 5001.\n",
      "Step: 1839 of 5001.\n",
      "Step: 1840 of 5001.\n",
      "Generator model loss: -1.010324239730835.\n",
      "Discriminator model loss: -0.5353282690048218.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1841 of 5001.\n",
      "Step: 1842 of 5001.\n",
      "Step: 1843 of 5001.\n",
      "Step: 1844 of 5001.\n",
      "Step: 1845 of 5001.\n",
      "Step: 1846 of 5001.\n",
      "Step: 1847 of 5001.\n",
      "Step: 1848 of 5001.\n",
      "Step: 1849 of 5001.\n",
      "Step: 1850 of 5001.\n",
      "Generator model loss: -1.0472573041915894.\n",
      "Discriminator model loss: -0.6551485061645508.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1851 of 5001.\n",
      "Step: 1852 of 5001.\n",
      "Step: 1853 of 5001.\n",
      "Step: 1854 of 5001.\n",
      "Step: 1855 of 5001.\n",
      "Step: 1856 of 5001.\n",
      "Step: 1857 of 5001.\n",
      "Step: 1858 of 5001.\n",
      "Step: 1859 of 5001.\n",
      "Step: 1860 of 5001.\n",
      "Generator model loss: -1.030022382736206.\n",
      "Discriminator model loss: -0.6200931668281555.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 1861 of 5001.\n",
      "Step: 1862 of 5001.\n",
      "Step: 1863 of 5001.\n",
      "Step: 1864 of 5001.\n",
      "Step: 1865 of 5001.\n",
      "Step: 1866 of 5001.\n",
      "Step: 1867 of 5001.\n",
      "Step: 1868 of 5001.\n",
      "Step: 1869 of 5001.\n",
      "Step: 1870 of 5001.\n",
      "Generator model loss: -1.0537965297698975.\n",
      "Discriminator model loss: -0.5631569623947144.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1871 of 5001.\n",
      "Step: 1872 of 5001.\n",
      "Step: 1873 of 5001.\n",
      "Step: 1874 of 5001.\n",
      "Step: 1875 of 5001.\n",
      "Step: 1876 of 5001.\n",
      "Step: 1877 of 5001.\n",
      "Step: 1878 of 5001.\n",
      "Step: 1879 of 5001.\n",
      "Step: 1880 of 5001.\n",
      "Generator model loss: -1.0547335147857666.\n",
      "Discriminator model loss: -0.5656415224075317.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1881 of 5001.\n",
      "Step: 1882 of 5001.\n",
      "Step: 1883 of 5001.\n",
      "Step: 1884 of 5001.\n",
      "Step: 1885 of 5001.\n",
      "Step: 1886 of 5001.\n",
      "Step: 1887 of 5001.\n",
      "Step: 1888 of 5001.\n",
      "Step: 1889 of 5001.\n",
      "Step: 1890 of 5001.\n",
      "Generator model loss: -1.093324899673462.\n",
      "Discriminator model loss: -0.562346875667572.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 1891 of 5001.\n",
      "Step: 1892 of 5001.\n",
      "Step: 1893 of 5001.\n",
      "Step: 1894 of 5001.\n",
      "Step: 1895 of 5001.\n",
      "Step: 1896 of 5001.\n",
      "Step: 1897 of 5001.\n",
      "Step: 1898 of 5001.\n",
      "Step: 1899 of 5001.\n",
      "Step: 1900 of 5001.\n",
      "Generator model loss: -1.0982242822647095.\n",
      "Discriminator model loss: -0.6066638231277466.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1901 of 5001.\n",
      "Step: 1902 of 5001.\n",
      "Step: 1903 of 5001.\n",
      "Step: 1904 of 5001.\n",
      "Step: 1905 of 5001.\n",
      "Step: 1906 of 5001.\n",
      "Step: 1907 of 5001.\n",
      "Step: 1908 of 5001.\n",
      "Step: 1909 of 5001.\n",
      "Step: 1910 of 5001.\n",
      "Generator model loss: -1.0838881731033325.\n",
      "Discriminator model loss: -0.5776448845863342.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 1911 of 5001.\n",
      "Step: 1912 of 5001.\n",
      "Step: 1913 of 5001.\n",
      "Step: 1914 of 5001.\n",
      "Step: 1915 of 5001.\n",
      "Step: 1916 of 5001.\n",
      "Step: 1917 of 5001.\n",
      "Step: 1918 of 5001.\n",
      "Step: 1919 of 5001.\n",
      "Step: 1920 of 5001.\n",
      "Generator model loss: -1.0624016523361206.\n",
      "Discriminator model loss: -0.5729577541351318.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1921 of 5001.\n",
      "Step: 1922 of 5001.\n",
      "Step: 1923 of 5001.\n",
      "Step: 1924 of 5001.\n",
      "Step: 1925 of 5001.\n",
      "Step: 1926 of 5001.\n",
      "Step: 1927 of 5001.\n",
      "Step: 1928 of 5001.\n",
      "Step: 1929 of 5001.\n",
      "Step: 1930 of 5001.\n",
      "Generator model loss: -1.0878942012786865.\n",
      "Discriminator model loss: -0.5362714529037476.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1931 of 5001.\n",
      "Step: 1932 of 5001.\n",
      "Step: 1933 of 5001.\n",
      "Step: 1934 of 5001.\n",
      "Step: 1935 of 5001.\n",
      "Step: 1936 of 5001.\n",
      "Step: 1937 of 5001.\n",
      "Step: 1938 of 5001.\n",
      "Step: 1939 of 5001.\n",
      "Step: 1940 of 5001.\n",
      "Generator model loss: -1.1054441928863525.\n",
      "Discriminator model loss: -0.5533053278923035.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 1941 of 5001.\n",
      "Step: 1942 of 5001.\n",
      "Step: 1943 of 5001.\n",
      "Step: 1944 of 5001.\n",
      "Step: 1945 of 5001.\n",
      "Step: 1946 of 5001.\n",
      "Step: 1947 of 5001.\n",
      "Step: 1948 of 5001.\n",
      "Step: 1949 of 5001.\n",
      "Step: 1950 of 5001.\n",
      "Generator model loss: -1.080976963043213.\n",
      "Discriminator model loss: -0.5406326651573181.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 1951 of 5001.\n",
      "Step: 1952 of 5001.\n",
      "Step: 1953 of 5001.\n",
      "Step: 1954 of 5001.\n",
      "Step: 1955 of 5001.\n",
      "Step: 1956 of 5001.\n",
      "Step: 1957 of 5001.\n",
      "Step: 1958 of 5001.\n",
      "Step: 1959 of 5001.\n",
      "Step: 1960 of 5001.\n",
      "Generator model loss: -1.089210867881775.\n",
      "Discriminator model loss: -0.5841046571731567.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1961 of 5001.\n",
      "Step: 1962 of 5001.\n",
      "Step: 1963 of 5001.\n",
      "Step: 1964 of 5001.\n",
      "Step: 1965 of 5001.\n",
      "Step: 1966 of 5001.\n",
      "Step: 1967 of 5001.\n",
      "Step: 1968 of 5001.\n",
      "Step: 1969 of 5001.\n",
      "Step: 1970 of 5001.\n",
      "Generator model loss: -1.1008182764053345.\n",
      "Discriminator model loss: -0.5604842901229858.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 1971 of 5001.\n",
      "Step: 1972 of 5001.\n",
      "Step: 1973 of 5001.\n",
      "Step: 1974 of 5001.\n",
      "Step: 1975 of 5001.\n",
      "Step: 1976 of 5001.\n",
      "Step: 1977 of 5001.\n",
      "Step: 1978 of 5001.\n",
      "Step: 1979 of 5001.\n",
      "Step: 1980 of 5001.\n",
      "Generator model loss: -1.1251838207244873.\n",
      "Discriminator model loss: -0.6002842783927917.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1981 of 5001.\n",
      "Step: 1982 of 5001.\n",
      "Step: 1983 of 5001.\n",
      "Step: 1984 of 5001.\n",
      "Step: 1985 of 5001.\n",
      "Step: 1986 of 5001.\n",
      "Step: 1987 of 5001.\n",
      "Step: 1988 of 5001.\n",
      "Step: 1989 of 5001.\n",
      "Step: 1990 of 5001.\n",
      "Generator model loss: -1.0997889041900635.\n",
      "Discriminator model loss: -0.5569471716880798.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1991 of 5001.\n",
      "Step: 1992 of 5001.\n",
      "Step: 1993 of 5001.\n",
      "Step: 1994 of 5001.\n",
      "Step: 1995 of 5001.\n",
      "Step: 1996 of 5001.\n",
      "Step: 1997 of 5001.\n",
      "Step: 1998 of 5001.\n",
      "Step: 1999 of 5001.\n",
      "Step: 2000 of 5001.\n",
      "Generator model loss: -1.163398027420044.\n",
      "Discriminator model loss: -0.5904620289802551.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2001 of 5001.\n",
      "Step: 2002 of 5001.\n",
      "Step: 2003 of 5001.\n",
      "Step: 2004 of 5001.\n",
      "Step: 2005 of 5001.\n",
      "Step: 2006 of 5001.\n",
      "Step: 2007 of 5001.\n",
      "Step: 2008 of 5001.\n",
      "Step: 2009 of 5001.\n",
      "Step: 2010 of 5001.\n",
      "Generator model loss: -1.196890115737915.\n",
      "Discriminator model loss: -0.551339328289032.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2011 of 5001.\n",
      "Step: 2012 of 5001.\n",
      "Step: 2013 of 5001.\n",
      "Step: 2014 of 5001.\n",
      "Step: 2015 of 5001.\n",
      "Step: 2016 of 5001.\n",
      "Step: 2017 of 5001.\n",
      "Step: 2018 of 5001.\n",
      "Step: 2019 of 5001.\n",
      "Step: 2020 of 5001.\n",
      "Generator model loss: -1.166734218597412.\n",
      "Discriminator model loss: -0.5169859528541565.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2021 of 5001.\n",
      "Step: 2022 of 5001.\n",
      "Step: 2023 of 5001.\n",
      "Step: 2024 of 5001.\n",
      "Step: 2025 of 5001.\n",
      "Step: 2026 of 5001.\n",
      "Step: 2027 of 5001.\n",
      "Step: 2028 of 5001.\n",
      "Step: 2029 of 5001.\n",
      "Step: 2030 of 5001.\n",
      "Generator model loss: -1.1527886390686035.\n",
      "Discriminator model loss: -0.5876938104629517.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2031 of 5001.\n",
      "Step: 2032 of 5001.\n",
      "Step: 2033 of 5001.\n",
      "Step: 2034 of 5001.\n",
      "Step: 2035 of 5001.\n",
      "Step: 2036 of 5001.\n",
      "Step: 2037 of 5001.\n",
      "Step: 2038 of 5001.\n",
      "Step: 2039 of 5001.\n",
      "Step: 2040 of 5001.\n",
      "Generator model loss: -1.1777350902557373.\n",
      "Discriminator model loss: -0.5761324167251587.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2041 of 5001.\n",
      "Step: 2042 of 5001.\n",
      "Step: 2043 of 5001.\n",
      "Step: 2044 of 5001.\n",
      "Step: 2045 of 5001.\n",
      "Step: 2046 of 5001.\n",
      "Step: 2047 of 5001.\n",
      "Step: 2048 of 5001.\n",
      "Step: 2049 of 5001.\n",
      "Step: 2050 of 5001.\n",
      "Generator model loss: -1.1847379207611084.\n",
      "Discriminator model loss: -0.5793309211730957.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2051 of 5001.\n",
      "Step: 2052 of 5001.\n",
      "Step: 2053 of 5001.\n",
      "Step: 2054 of 5001.\n",
      "Step: 2055 of 5001.\n",
      "Step: 2056 of 5001.\n",
      "Step: 2057 of 5001.\n",
      "Step: 2058 of 5001.\n",
      "Step: 2059 of 5001.\n",
      "Step: 2060 of 5001.\n",
      "Generator model loss: -1.1520729064941406.\n",
      "Discriminator model loss: -0.5462850332260132.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2061 of 5001.\n",
      "Step: 2062 of 5001.\n",
      "Step: 2063 of 5001.\n",
      "Step: 2064 of 5001.\n",
      "Step: 2065 of 5001.\n",
      "Step: 2066 of 5001.\n",
      "Step: 2067 of 5001.\n",
      "Step: 2068 of 5001.\n",
      "Step: 2069 of 5001.\n",
      "Step: 2070 of 5001.\n",
      "Generator model loss: -1.1722333431243896.\n",
      "Discriminator model loss: -0.5624449253082275.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2071 of 5001.\n",
      "Step: 2072 of 5001.\n",
      "Step: 2073 of 5001.\n",
      "Step: 2074 of 5001.\n",
      "Step: 2075 of 5001.\n",
      "Step: 2076 of 5001.\n",
      "Step: 2077 of 5001.\n",
      "Step: 2078 of 5001.\n",
      "Step: 2079 of 5001.\n",
      "Step: 2080 of 5001.\n",
      "Generator model loss: -1.1812255382537842.\n",
      "Discriminator model loss: -0.49957141280174255.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2081 of 5001.\n",
      "Step: 2082 of 5001.\n",
      "Step: 2083 of 5001.\n",
      "Step: 2084 of 5001.\n",
      "Step: 2085 of 5001.\n",
      "Step: 2086 of 5001.\n",
      "Step: 2087 of 5001.\n",
      "Step: 2088 of 5001.\n",
      "Step: 2089 of 5001.\n",
      "Step: 2090 of 5001.\n",
      "Generator model loss: -1.2004116773605347.\n",
      "Discriminator model loss: -0.4827660024166107.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2091 of 5001.\n",
      "Step: 2092 of 5001.\n",
      "Step: 2093 of 5001.\n",
      "Step: 2094 of 5001.\n",
      "Step: 2095 of 5001.\n",
      "Step: 2096 of 5001.\n",
      "Step: 2097 of 5001.\n",
      "Step: 2098 of 5001.\n",
      "Step: 2099 of 5001.\n",
      "Step: 2100 of 5001.\n",
      "Generator model loss: -1.2269535064697266.\n",
      "Discriminator model loss: -0.5652031898498535.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2101 of 5001.\n",
      "Step: 2102 of 5001.\n",
      "Step: 2103 of 5001.\n",
      "Step: 2104 of 5001.\n",
      "Step: 2105 of 5001.\n",
      "Step: 2106 of 5001.\n",
      "Step: 2107 of 5001.\n",
      "Step: 2108 of 5001.\n",
      "Step: 2109 of 5001.\n",
      "Step: 2110 of 5001.\n",
      "Generator model loss: -1.1849830150604248.\n",
      "Discriminator model loss: -0.45260342955589294.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2111 of 5001.\n",
      "Step: 2112 of 5001.\n",
      "Step: 2113 of 5001.\n",
      "Step: 2114 of 5001.\n",
      "Step: 2115 of 5001.\n",
      "Step: 2116 of 5001.\n",
      "Step: 2117 of 5001.\n",
      "Step: 2118 of 5001.\n",
      "Step: 2119 of 5001.\n",
      "Step: 2120 of 5001.\n",
      "Generator model loss: -1.2425193786621094.\n",
      "Discriminator model loss: -0.5556483864784241.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2121 of 5001.\n",
      "Step: 2122 of 5001.\n",
      "Step: 2123 of 5001.\n",
      "Step: 2124 of 5001.\n",
      "Step: 2125 of 5001.\n",
      "Step: 2126 of 5001.\n",
      "Step: 2127 of 5001.\n",
      "Step: 2128 of 5001.\n",
      "Step: 2129 of 5001.\n",
      "Step: 2130 of 5001.\n",
      "Generator model loss: -1.2274768352508545.\n",
      "Discriminator model loss: -0.5281414985656738.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2131 of 5001.\n",
      "Step: 2132 of 5001.\n",
      "Step: 2133 of 5001.\n",
      "Step: 2134 of 5001.\n",
      "Step: 2135 of 5001.\n",
      "Step: 2136 of 5001.\n",
      "Step: 2137 of 5001.\n",
      "Step: 2138 of 5001.\n",
      "Step: 2139 of 5001.\n",
      "Step: 2140 of 5001.\n",
      "Generator model loss: -1.2349003553390503.\n",
      "Discriminator model loss: -0.4718230366706848.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2141 of 5001.\n",
      "Step: 2142 of 5001.\n",
      "Step: 2143 of 5001.\n",
      "Step: 2144 of 5001.\n",
      "Step: 2145 of 5001.\n",
      "Step: 2146 of 5001.\n",
      "Step: 2147 of 5001.\n",
      "Step: 2148 of 5001.\n",
      "Step: 2149 of 5001.\n",
      "Step: 2150 of 5001.\n",
      "Generator model loss: -1.2691782712936401.\n",
      "Discriminator model loss: -0.4482033848762512.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2151 of 5001.\n",
      "Step: 2152 of 5001.\n",
      "Step: 2153 of 5001.\n",
      "Step: 2154 of 5001.\n",
      "Step: 2155 of 5001.\n",
      "Step: 2156 of 5001.\n",
      "Step: 2157 of 5001.\n",
      "Step: 2158 of 5001.\n",
      "Step: 2159 of 5001.\n",
      "Step: 2160 of 5001.\n",
      "Generator model loss: -1.2332843542099.\n",
      "Discriminator model loss: -0.5501049757003784.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2161 of 5001.\n",
      "Step: 2162 of 5001.\n",
      "Step: 2163 of 5001.\n",
      "Step: 2164 of 5001.\n",
      "Step: 2165 of 5001.\n",
      "Step: 2166 of 5001.\n",
      "Step: 2167 of 5001.\n",
      "Step: 2168 of 5001.\n",
      "Step: 2169 of 5001.\n",
      "Step: 2170 of 5001.\n",
      "Generator model loss: -1.2696807384490967.\n",
      "Discriminator model loss: -0.5271678566932678.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2171 of 5001.\n",
      "Step: 2172 of 5001.\n",
      "Step: 2173 of 5001.\n",
      "Step: 2174 of 5001.\n",
      "Step: 2175 of 5001.\n",
      "Step: 2176 of 5001.\n",
      "Step: 2177 of 5001.\n",
      "Step: 2178 of 5001.\n",
      "Step: 2179 of 5001.\n",
      "Step: 2180 of 5001.\n",
      "Generator model loss: -1.2816452980041504.\n",
      "Discriminator model loss: -0.5464709997177124.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2181 of 5001.\n",
      "Step: 2182 of 5001.\n",
      "Step: 2183 of 5001.\n",
      "Step: 2184 of 5001.\n",
      "Step: 2185 of 5001.\n",
      "Step: 2186 of 5001.\n",
      "Step: 2187 of 5001.\n",
      "Step: 2188 of 5001.\n",
      "Step: 2189 of 5001.\n",
      "Step: 2190 of 5001.\n",
      "Generator model loss: -1.3234772682189941.\n",
      "Discriminator model loss: -0.4867342412471771.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2191 of 5001.\n",
      "Step: 2192 of 5001.\n",
      "Step: 2193 of 5001.\n",
      "Step: 2194 of 5001.\n",
      "Step: 2195 of 5001.\n",
      "Step: 2196 of 5001.\n",
      "Step: 2197 of 5001.\n",
      "Step: 2198 of 5001.\n",
      "Step: 2199 of 5001.\n",
      "Step: 2200 of 5001.\n",
      "Generator model loss: -1.280316948890686.\n",
      "Discriminator model loss: -0.5363253951072693.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2201 of 5001.\n",
      "Step: 2202 of 5001.\n",
      "Step: 2203 of 5001.\n",
      "Step: 2204 of 5001.\n",
      "Step: 2205 of 5001.\n",
      "Step: 2206 of 5001.\n",
      "Step: 2207 of 5001.\n",
      "Step: 2208 of 5001.\n",
      "Step: 2209 of 5001.\n",
      "Step: 2210 of 5001.\n",
      "Generator model loss: -1.2844687700271606.\n",
      "Discriminator model loss: -0.493156760931015.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2211 of 5001.\n",
      "Step: 2212 of 5001.\n",
      "Step: 2213 of 5001.\n",
      "Step: 2214 of 5001.\n",
      "Step: 2215 of 5001.\n",
      "Step: 2216 of 5001.\n",
      "Step: 2217 of 5001.\n",
      "Step: 2218 of 5001.\n",
      "Step: 2219 of 5001.\n",
      "Step: 2220 of 5001.\n",
      "Generator model loss: -1.2390928268432617.\n",
      "Discriminator model loss: -0.4015556871891022.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2221 of 5001.\n",
      "Step: 2222 of 5001.\n",
      "Step: 2223 of 5001.\n",
      "Step: 2224 of 5001.\n",
      "Step: 2225 of 5001.\n",
      "Step: 2226 of 5001.\n",
      "Step: 2227 of 5001.\n",
      "Step: 2228 of 5001.\n",
      "Step: 2229 of 5001.\n",
      "Step: 2230 of 5001.\n",
      "Generator model loss: -1.3202154636383057.\n",
      "Discriminator model loss: -0.5456563234329224.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2231 of 5001.\n",
      "Step: 2232 of 5001.\n",
      "Step: 2233 of 5001.\n",
      "Step: 2234 of 5001.\n",
      "Step: 2235 of 5001.\n",
      "Step: 2236 of 5001.\n",
      "Step: 2237 of 5001.\n",
      "Step: 2238 of 5001.\n",
      "Step: 2239 of 5001.\n",
      "Step: 2240 of 5001.\n",
      "Generator model loss: -1.287197232246399.\n",
      "Discriminator model loss: -0.47108808159828186.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2241 of 5001.\n",
      "Step: 2242 of 5001.\n",
      "Step: 2243 of 5001.\n",
      "Step: 2244 of 5001.\n",
      "Step: 2245 of 5001.\n",
      "Step: 2246 of 5001.\n",
      "Step: 2247 of 5001.\n",
      "Step: 2248 of 5001.\n",
      "Step: 2249 of 5001.\n",
      "Step: 2250 of 5001.\n",
      "Generator model loss: -1.3079993724822998.\n",
      "Discriminator model loss: -0.4634636342525482.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2251 of 5001.\n",
      "Step: 2252 of 5001.\n",
      "Step: 2253 of 5001.\n",
      "Step: 2254 of 5001.\n",
      "Step: 2255 of 5001.\n",
      "Step: 2256 of 5001.\n",
      "Step: 2257 of 5001.\n",
      "Step: 2258 of 5001.\n",
      "Step: 2259 of 5001.\n",
      "Step: 2260 of 5001.\n",
      "Generator model loss: -1.3315328359603882.\n",
      "Discriminator model loss: -0.4809182584285736.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2261 of 5001.\n",
      "Step: 2262 of 5001.\n",
      "Step: 2263 of 5001.\n",
      "Step: 2264 of 5001.\n",
      "Step: 2265 of 5001.\n",
      "Step: 2266 of 5001.\n",
      "Step: 2267 of 5001.\n",
      "Step: 2268 of 5001.\n",
      "Step: 2269 of 5001.\n",
      "Step: 2270 of 5001.\n",
      "Generator model loss: -1.3361023664474487.\n",
      "Discriminator model loss: -0.4614921510219574.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2271 of 5001.\n",
      "Step: 2272 of 5001.\n",
      "Step: 2273 of 5001.\n",
      "Step: 2274 of 5001.\n",
      "Step: 2275 of 5001.\n",
      "Step: 2276 of 5001.\n",
      "Step: 2277 of 5001.\n",
      "Step: 2278 of 5001.\n",
      "Step: 2279 of 5001.\n",
      "Step: 2280 of 5001.\n",
      "Generator model loss: -1.2898576259613037.\n",
      "Discriminator model loss: -0.4449889659881592.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2281 of 5001.\n",
      "Step: 2282 of 5001.\n",
      "Step: 2283 of 5001.\n",
      "Step: 2284 of 5001.\n",
      "Step: 2285 of 5001.\n",
      "Step: 2286 of 5001.\n",
      "Step: 2287 of 5001.\n",
      "Step: 2288 of 5001.\n",
      "Step: 2289 of 5001.\n",
      "Step: 2290 of 5001.\n",
      "Generator model loss: -1.3122799396514893.\n",
      "Discriminator model loss: -0.4735925793647766.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2291 of 5001.\n",
      "Step: 2292 of 5001.\n",
      "Step: 2293 of 5001.\n",
      "Step: 2294 of 5001.\n",
      "Step: 2295 of 5001.\n",
      "Step: 2296 of 5001.\n",
      "Step: 2297 of 5001.\n",
      "Step: 2298 of 5001.\n",
      "Step: 2299 of 5001.\n",
      "Step: 2300 of 5001.\n",
      "Generator model loss: -1.3508590459823608.\n",
      "Discriminator model loss: -0.44549769163131714.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2301 of 5001.\n",
      "Step: 2302 of 5001.\n",
      "Step: 2303 of 5001.\n",
      "Step: 2304 of 5001.\n",
      "Step: 2305 of 5001.\n",
      "Step: 2306 of 5001.\n",
      "Step: 2307 of 5001.\n",
      "Step: 2308 of 5001.\n",
      "Step: 2309 of 5001.\n",
      "Step: 2310 of 5001.\n",
      "Generator model loss: -1.3704458475112915.\n",
      "Discriminator model loss: -0.440473735332489.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2311 of 5001.\n",
      "Step: 2312 of 5001.\n",
      "Step: 2313 of 5001.\n",
      "Step: 2314 of 5001.\n",
      "Step: 2315 of 5001.\n",
      "Step: 2316 of 5001.\n",
      "Step: 2317 of 5001.\n",
      "Step: 2318 of 5001.\n",
      "Step: 2319 of 5001.\n",
      "Step: 2320 of 5001.\n",
      "Generator model loss: -1.3674734830856323.\n",
      "Discriminator model loss: -0.4633842408657074.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2321 of 5001.\n",
      "Step: 2322 of 5001.\n",
      "Step: 2323 of 5001.\n",
      "Step: 2324 of 5001.\n",
      "Step: 2325 of 5001.\n",
      "Step: 2326 of 5001.\n",
      "Step: 2327 of 5001.\n",
      "Step: 2328 of 5001.\n",
      "Step: 2329 of 5001.\n",
      "Step: 2330 of 5001.\n",
      "Generator model loss: -1.3487374782562256.\n",
      "Discriminator model loss: -0.4640982747077942.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2331 of 5001.\n",
      "Step: 2332 of 5001.\n",
      "Step: 2333 of 5001.\n",
      "Step: 2334 of 5001.\n",
      "Step: 2335 of 5001.\n",
      "Step: 2336 of 5001.\n",
      "Step: 2337 of 5001.\n",
      "Step: 2338 of 5001.\n",
      "Step: 2339 of 5001.\n",
      "Step: 2340 of 5001.\n",
      "Generator model loss: -1.360669732093811.\n",
      "Discriminator model loss: -0.3568844199180603.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2341 of 5001.\n",
      "Step: 2342 of 5001.\n",
      "Step: 2343 of 5001.\n",
      "Step: 2344 of 5001.\n",
      "Step: 2345 of 5001.\n",
      "Step: 2346 of 5001.\n",
      "Step: 2347 of 5001.\n",
      "Step: 2348 of 5001.\n",
      "Step: 2349 of 5001.\n",
      "Step: 2350 of 5001.\n",
      "Generator model loss: -1.3376396894454956.\n",
      "Discriminator model loss: -0.4736228585243225.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2351 of 5001.\n",
      "Step: 2352 of 5001.\n",
      "Step: 2353 of 5001.\n",
      "Step: 2354 of 5001.\n",
      "Step: 2355 of 5001.\n",
      "Step: 2356 of 5001.\n",
      "Step: 2357 of 5001.\n",
      "Step: 2358 of 5001.\n",
      "Step: 2359 of 5001.\n",
      "Step: 2360 of 5001.\n",
      "Generator model loss: -1.3667633533477783.\n",
      "Discriminator model loss: -0.4178501069545746.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2361 of 5001.\n",
      "Step: 2362 of 5001.\n",
      "Step: 2363 of 5001.\n",
      "Step: 2364 of 5001.\n",
      "Step: 2365 of 5001.\n",
      "Step: 2366 of 5001.\n",
      "Step: 2367 of 5001.\n",
      "Step: 2368 of 5001.\n",
      "Step: 2369 of 5001.\n",
      "Step: 2370 of 5001.\n",
      "Generator model loss: -1.344205617904663.\n",
      "Discriminator model loss: -0.3659701645374298.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2371 of 5001.\n",
      "Step: 2372 of 5001.\n",
      "Step: 2373 of 5001.\n",
      "Step: 2374 of 5001.\n",
      "Step: 2375 of 5001.\n",
      "Step: 2376 of 5001.\n",
      "Step: 2377 of 5001.\n",
      "Step: 2378 of 5001.\n",
      "Step: 2379 of 5001.\n",
      "Step: 2380 of 5001.\n",
      "Generator model loss: -1.378939151763916.\n",
      "Discriminator model loss: -0.36950474977493286.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2381 of 5001.\n",
      "Step: 2382 of 5001.\n",
      "Step: 2383 of 5001.\n",
      "Step: 2384 of 5001.\n",
      "Step: 2385 of 5001.\n",
      "Step: 2386 of 5001.\n",
      "Step: 2387 of 5001.\n",
      "Step: 2388 of 5001.\n",
      "Step: 2389 of 5001.\n",
      "Step: 2390 of 5001.\n",
      "Generator model loss: -1.431625485420227.\n",
      "Discriminator model loss: -0.4348451495170593.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2391 of 5001.\n",
      "Step: 2392 of 5001.\n",
      "Step: 2393 of 5001.\n",
      "Step: 2394 of 5001.\n",
      "Step: 2395 of 5001.\n",
      "Step: 2396 of 5001.\n",
      "Step: 2397 of 5001.\n",
      "Step: 2398 of 5001.\n",
      "Step: 2399 of 5001.\n",
      "Step: 2400 of 5001.\n",
      "Generator model loss: -1.4105889797210693.\n",
      "Discriminator model loss: -0.504357099533081.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2401 of 5001.\n",
      "Step: 2402 of 5001.\n",
      "Step: 2403 of 5001.\n",
      "Step: 2404 of 5001.\n",
      "Step: 2405 of 5001.\n",
      "Step: 2406 of 5001.\n",
      "Step: 2407 of 5001.\n",
      "Step: 2408 of 5001.\n",
      "Step: 2409 of 5001.\n",
      "Step: 2410 of 5001.\n",
      "Generator model loss: -1.4249098300933838.\n",
      "Discriminator model loss: -0.4472653269767761.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2411 of 5001.\n",
      "Step: 2412 of 5001.\n",
      "Step: 2413 of 5001.\n",
      "Step: 2414 of 5001.\n",
      "Step: 2415 of 5001.\n",
      "Step: 2416 of 5001.\n",
      "Step: 2417 of 5001.\n",
      "Step: 2418 of 5001.\n",
      "Step: 2419 of 5001.\n",
      "Step: 2420 of 5001.\n",
      "Generator model loss: -1.4512091875076294.\n",
      "Discriminator model loss: -0.43931689858436584.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2421 of 5001.\n",
      "Step: 2422 of 5001.\n",
      "Step: 2423 of 5001.\n",
      "Step: 2424 of 5001.\n",
      "Step: 2425 of 5001.\n",
      "Step: 2426 of 5001.\n",
      "Step: 2427 of 5001.\n",
      "Step: 2428 of 5001.\n",
      "Step: 2429 of 5001.\n",
      "Step: 2430 of 5001.\n",
      "Generator model loss: -1.4168192148208618.\n",
      "Discriminator model loss: -0.4705607295036316.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 2431 of 5001.\n",
      "Step: 2432 of 5001.\n",
      "Step: 2433 of 5001.\n",
      "Step: 2434 of 5001.\n",
      "Step: 2435 of 5001.\n",
      "Step: 2436 of 5001.\n",
      "Step: 2437 of 5001.\n",
      "Step: 2438 of 5001.\n",
      "Step: 2439 of 5001.\n",
      "Step: 2440 of 5001.\n",
      "Generator model loss: -1.402377963066101.\n",
      "Discriminator model loss: -0.45138758420944214.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2441 of 5001.\n",
      "Step: 2442 of 5001.\n",
      "Step: 2443 of 5001.\n",
      "Step: 2444 of 5001.\n",
      "Step: 2445 of 5001.\n",
      "Step: 2446 of 5001.\n",
      "Step: 2447 of 5001.\n",
      "Step: 2448 of 5001.\n",
      "Step: 2449 of 5001.\n",
      "Step: 2450 of 5001.\n",
      "Generator model loss: -1.4161485433578491.\n",
      "Discriminator model loss: -0.4180780053138733.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2451 of 5001.\n",
      "Step: 2452 of 5001.\n",
      "Step: 2453 of 5001.\n",
      "Step: 2454 of 5001.\n",
      "Step: 2455 of 5001.\n",
      "Step: 2456 of 5001.\n",
      "Step: 2457 of 5001.\n",
      "Step: 2458 of 5001.\n",
      "Step: 2459 of 5001.\n",
      "Step: 2460 of 5001.\n",
      "Generator model loss: -1.4614813327789307.\n",
      "Discriminator model loss: -0.4918084740638733.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2461 of 5001.\n",
      "Step: 2462 of 5001.\n",
      "Step: 2463 of 5001.\n",
      "Step: 2464 of 5001.\n",
      "Step: 2465 of 5001.\n",
      "Step: 2466 of 5001.\n",
      "Step: 2467 of 5001.\n",
      "Step: 2468 of 5001.\n",
      "Step: 2469 of 5001.\n",
      "Step: 2470 of 5001.\n",
      "Generator model loss: -1.4480831623077393.\n",
      "Discriminator model loss: -0.455831915140152.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2471 of 5001.\n",
      "Step: 2472 of 5001.\n",
      "Step: 2473 of 5001.\n",
      "Step: 2474 of 5001.\n",
      "Step: 2475 of 5001.\n",
      "Step: 2476 of 5001.\n",
      "Step: 2477 of 5001.\n",
      "Step: 2478 of 5001.\n",
      "Step: 2479 of 5001.\n",
      "Step: 2480 of 5001.\n",
      "Generator model loss: -1.3907947540283203.\n",
      "Discriminator model loss: -0.48385387659072876.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2481 of 5001.\n",
      "Step: 2482 of 5001.\n",
      "Step: 2483 of 5001.\n",
      "Step: 2484 of 5001.\n",
      "Step: 2485 of 5001.\n",
      "Step: 2486 of 5001.\n",
      "Step: 2487 of 5001.\n",
      "Step: 2488 of 5001.\n",
      "Step: 2489 of 5001.\n",
      "Step: 2490 of 5001.\n",
      "Generator model loss: -1.4377219676971436.\n",
      "Discriminator model loss: -0.46918314695358276.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 2491 of 5001.\n",
      "Step: 2492 of 5001.\n",
      "Step: 2493 of 5001.\n",
      "Step: 2494 of 5001.\n",
      "Step: 2495 of 5001.\n",
      "Step: 2496 of 5001.\n",
      "Step: 2497 of 5001.\n",
      "Step: 2498 of 5001.\n",
      "Step: 2499 of 5001.\n",
      "Step: 2500 of 5001.\n",
      "Generator model loss: -1.4603190422058105.\n",
      "Discriminator model loss: -0.4075303077697754.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2501 of 5001.\n",
      "Step: 2502 of 5001.\n",
      "Step: 2503 of 5001.\n",
      "Step: 2504 of 5001.\n",
      "Step: 2505 of 5001.\n",
      "Step: 2506 of 5001.\n",
      "Step: 2507 of 5001.\n",
      "Step: 2508 of 5001.\n",
      "Step: 2509 of 5001.\n",
      "Step: 2510 of 5001.\n",
      "Generator model loss: -1.4372390508651733.\n",
      "Discriminator model loss: -0.4234708845615387.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2511 of 5001.\n",
      "Step: 2512 of 5001.\n",
      "Step: 2513 of 5001.\n",
      "Step: 2514 of 5001.\n",
      "Step: 2515 of 5001.\n",
      "Step: 2516 of 5001.\n",
      "Step: 2517 of 5001.\n",
      "Step: 2518 of 5001.\n",
      "Step: 2519 of 5001.\n",
      "Step: 2520 of 5001.\n",
      "Generator model loss: -1.420025110244751.\n",
      "Discriminator model loss: -0.4250718057155609.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2521 of 5001.\n",
      "Step: 2522 of 5001.\n",
      "Step: 2523 of 5001.\n",
      "Step: 2524 of 5001.\n",
      "Step: 2525 of 5001.\n",
      "Step: 2526 of 5001.\n",
      "Step: 2527 of 5001.\n",
      "Step: 2528 of 5001.\n",
      "Step: 2529 of 5001.\n",
      "Step: 2530 of 5001.\n",
      "Generator model loss: -1.370328664779663.\n",
      "Discriminator model loss: -0.43394502997398376.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2531 of 5001.\n",
      "Step: 2532 of 5001.\n",
      "Step: 2533 of 5001.\n",
      "Step: 2534 of 5001.\n",
      "Step: 2535 of 5001.\n",
      "Step: 2536 of 5001.\n",
      "Step: 2537 of 5001.\n",
      "Step: 2538 of 5001.\n",
      "Step: 2539 of 5001.\n",
      "Step: 2540 of 5001.\n",
      "Generator model loss: -1.470780372619629.\n",
      "Discriminator model loss: -0.421499639749527.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2541 of 5001.\n",
      "Step: 2542 of 5001.\n",
      "Step: 2543 of 5001.\n",
      "Step: 2544 of 5001.\n",
      "Step: 2545 of 5001.\n",
      "Step: 2546 of 5001.\n",
      "Step: 2547 of 5001.\n",
      "Step: 2548 of 5001.\n",
      "Step: 2549 of 5001.\n",
      "Step: 2550 of 5001.\n",
      "Generator model loss: -1.4156091213226318.\n",
      "Discriminator model loss: -0.523605227470398.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2551 of 5001.\n",
      "Step: 2552 of 5001.\n",
      "Step: 2553 of 5001.\n",
      "Step: 2554 of 5001.\n",
      "Step: 2555 of 5001.\n",
      "Step: 2556 of 5001.\n",
      "Step: 2557 of 5001.\n",
      "Step: 2558 of 5001.\n",
      "Step: 2559 of 5001.\n",
      "Step: 2560 of 5001.\n",
      "Generator model loss: -1.4083826541900635.\n",
      "Discriminator model loss: -0.4281657338142395.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2561 of 5001.\n",
      "Step: 2562 of 5001.\n",
      "Step: 2563 of 5001.\n",
      "Step: 2564 of 5001.\n",
      "Step: 2565 of 5001.\n",
      "Step: 2566 of 5001.\n",
      "Step: 2567 of 5001.\n",
      "Step: 2568 of 5001.\n",
      "Step: 2569 of 5001.\n",
      "Step: 2570 of 5001.\n",
      "Generator model loss: -1.4256412982940674.\n",
      "Discriminator model loss: -0.46649283170700073.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2571 of 5001.\n",
      "Step: 2572 of 5001.\n",
      "Step: 2573 of 5001.\n",
      "Step: 2574 of 5001.\n",
      "Step: 2575 of 5001.\n",
      "Step: 2576 of 5001.\n",
      "Step: 2577 of 5001.\n",
      "Step: 2578 of 5001.\n",
      "Step: 2579 of 5001.\n",
      "Step: 2580 of 5001.\n",
      "Generator model loss: -1.3909828662872314.\n",
      "Discriminator model loss: -0.48688721656799316.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2581 of 5001.\n",
      "Step: 2582 of 5001.\n",
      "Step: 2583 of 5001.\n",
      "Step: 2584 of 5001.\n",
      "Step: 2585 of 5001.\n",
      "Step: 2586 of 5001.\n",
      "Step: 2587 of 5001.\n",
      "Step: 2588 of 5001.\n",
      "Step: 2589 of 5001.\n",
      "Step: 2590 of 5001.\n",
      "Generator model loss: -1.4389029741287231.\n",
      "Discriminator model loss: -0.46398887038230896.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2591 of 5001.\n",
      "Step: 2592 of 5001.\n",
      "Step: 2593 of 5001.\n",
      "Step: 2594 of 5001.\n",
      "Step: 2595 of 5001.\n",
      "Step: 2596 of 5001.\n",
      "Step: 2597 of 5001.\n",
      "Step: 2598 of 5001.\n",
      "Step: 2599 of 5001.\n",
      "Step: 2600 of 5001.\n",
      "Generator model loss: -1.451966643333435.\n",
      "Discriminator model loss: -0.42094117403030396.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2601 of 5001.\n",
      "Step: 2602 of 5001.\n",
      "Step: 2603 of 5001.\n",
      "Step: 2604 of 5001.\n",
      "Step: 2605 of 5001.\n",
      "Step: 2606 of 5001.\n",
      "Step: 2607 of 5001.\n",
      "Step: 2608 of 5001.\n",
      "Step: 2609 of 5001.\n",
      "Step: 2610 of 5001.\n",
      "Generator model loss: -1.410576343536377.\n",
      "Discriminator model loss: -0.4096096158027649.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2611 of 5001.\n",
      "Step: 2612 of 5001.\n",
      "Step: 2613 of 5001.\n",
      "Step: 2614 of 5001.\n",
      "Step: 2615 of 5001.\n",
      "Step: 2616 of 5001.\n",
      "Step: 2617 of 5001.\n",
      "Step: 2618 of 5001.\n",
      "Step: 2619 of 5001.\n",
      "Step: 2620 of 5001.\n",
      "Generator model loss: -1.430234432220459.\n",
      "Discriminator model loss: -0.5513320565223694.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 2621 of 5001.\n",
      "Step: 2622 of 5001.\n",
      "Step: 2623 of 5001.\n",
      "Step: 2624 of 5001.\n",
      "Step: 2625 of 5001.\n",
      "Step: 2626 of 5001.\n",
      "Step: 2627 of 5001.\n",
      "Step: 2628 of 5001.\n",
      "Step: 2629 of 5001.\n",
      "Step: 2630 of 5001.\n",
      "Generator model loss: -1.3674077987670898.\n",
      "Discriminator model loss: -0.4644719660282135.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2631 of 5001.\n",
      "Step: 2632 of 5001.\n",
      "Step: 2633 of 5001.\n",
      "Step: 2634 of 5001.\n",
      "Step: 2635 of 5001.\n",
      "Step: 2636 of 5001.\n",
      "Step: 2637 of 5001.\n",
      "Step: 2638 of 5001.\n",
      "Step: 2639 of 5001.\n",
      "Step: 2640 of 5001.\n",
      "Generator model loss: -1.4548019170761108.\n",
      "Discriminator model loss: -0.4014280438423157.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 2641 of 5001.\n",
      "Step: 2642 of 5001.\n",
      "Step: 2643 of 5001.\n",
      "Step: 2644 of 5001.\n",
      "Step: 2645 of 5001.\n",
      "Step: 2646 of 5001.\n",
      "Step: 2647 of 5001.\n",
      "Step: 2648 of 5001.\n",
      "Step: 2649 of 5001.\n",
      "Step: 2650 of 5001.\n",
      "Generator model loss: -1.4032158851623535.\n",
      "Discriminator model loss: -0.384971022605896.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2651 of 5001.\n",
      "Step: 2652 of 5001.\n",
      "Step: 2653 of 5001.\n",
      "Step: 2654 of 5001.\n",
      "Step: 2655 of 5001.\n",
      "Step: 2656 of 5001.\n",
      "Step: 2657 of 5001.\n",
      "Step: 2658 of 5001.\n",
      "Step: 2659 of 5001.\n",
      "Step: 2660 of 5001.\n",
      "Generator model loss: -1.4193732738494873.\n",
      "Discriminator model loss: -0.42566949129104614.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2661 of 5001.\n",
      "Step: 2662 of 5001.\n",
      "Step: 2663 of 5001.\n",
      "Step: 2664 of 5001.\n",
      "Step: 2665 of 5001.\n",
      "Step: 2666 of 5001.\n",
      "Step: 2667 of 5001.\n",
      "Step: 2668 of 5001.\n",
      "Step: 2669 of 5001.\n",
      "Step: 2670 of 5001.\n",
      "Generator model loss: -1.411561131477356.\n",
      "Discriminator model loss: -0.45691409707069397.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2671 of 5001.\n",
      "Step: 2672 of 5001.\n",
      "Step: 2673 of 5001.\n",
      "Step: 2674 of 5001.\n",
      "Step: 2675 of 5001.\n",
      "Step: 2676 of 5001.\n",
      "Step: 2677 of 5001.\n",
      "Step: 2678 of 5001.\n",
      "Step: 2679 of 5001.\n",
      "Step: 2680 of 5001.\n",
      "Generator model loss: -1.4220070838928223.\n",
      "Discriminator model loss: -0.5153242349624634.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2681 of 5001.\n",
      "Step: 2682 of 5001.\n",
      "Step: 2683 of 5001.\n",
      "Step: 2684 of 5001.\n",
      "Step: 2685 of 5001.\n",
      "Step: 2686 of 5001.\n",
      "Step: 2687 of 5001.\n",
      "Step: 2688 of 5001.\n",
      "Step: 2689 of 5001.\n",
      "Step: 2690 of 5001.\n",
      "Generator model loss: -1.4370546340942383.\n",
      "Discriminator model loss: -0.4466480314731598.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2691 of 5001.\n",
      "Step: 2692 of 5001.\n",
      "Step: 2693 of 5001.\n",
      "Step: 2694 of 5001.\n",
      "Step: 2695 of 5001.\n",
      "Step: 2696 of 5001.\n",
      "Step: 2697 of 5001.\n",
      "Step: 2698 of 5001.\n",
      "Step: 2699 of 5001.\n",
      "Step: 2700 of 5001.\n",
      "Generator model loss: -1.4116188287734985.\n",
      "Discriminator model loss: -0.5010935068130493.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 2701 of 5001.\n",
      "Step: 2702 of 5001.\n",
      "Step: 2703 of 5001.\n",
      "Step: 2704 of 5001.\n",
      "Step: 2705 of 5001.\n",
      "Step: 2706 of 5001.\n",
      "Step: 2707 of 5001.\n",
      "Step: 2708 of 5001.\n",
      "Step: 2709 of 5001.\n",
      "Step: 2710 of 5001.\n",
      "Generator model loss: -1.3997561931610107.\n",
      "Discriminator model loss: -0.47246164083480835.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2711 of 5001.\n",
      "Step: 2712 of 5001.\n",
      "Step: 2713 of 5001.\n",
      "Step: 2714 of 5001.\n",
      "Step: 2715 of 5001.\n",
      "Step: 2716 of 5001.\n",
      "Step: 2717 of 5001.\n",
      "Step: 2718 of 5001.\n",
      "Step: 2719 of 5001.\n",
      "Step: 2720 of 5001.\n",
      "Generator model loss: -1.4505125284194946.\n",
      "Discriminator model loss: -0.3993028998374939.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2721 of 5001.\n",
      "Step: 2722 of 5001.\n",
      "Step: 2723 of 5001.\n",
      "Step: 2724 of 5001.\n",
      "Step: 2725 of 5001.\n",
      "Step: 2726 of 5001.\n",
      "Step: 2727 of 5001.\n",
      "Step: 2728 of 5001.\n",
      "Step: 2729 of 5001.\n",
      "Step: 2730 of 5001.\n",
      "Generator model loss: -1.4588488340377808.\n",
      "Discriminator model loss: -0.48622816801071167.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2731 of 5001.\n",
      "Step: 2732 of 5001.\n",
      "Step: 2733 of 5001.\n",
      "Step: 2734 of 5001.\n",
      "Step: 2735 of 5001.\n",
      "Step: 2736 of 5001.\n",
      "Step: 2737 of 5001.\n",
      "Step: 2738 of 5001.\n",
      "Step: 2739 of 5001.\n",
      "Step: 2740 of 5001.\n",
      "Generator model loss: -1.4124729633331299.\n",
      "Discriminator model loss: -0.4710102081298828.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2741 of 5001.\n",
      "Step: 2742 of 5001.\n",
      "Step: 2743 of 5001.\n",
      "Step: 2744 of 5001.\n",
      "Step: 2745 of 5001.\n",
      "Step: 2746 of 5001.\n",
      "Step: 2747 of 5001.\n",
      "Step: 2748 of 5001.\n",
      "Step: 2749 of 5001.\n",
      "Step: 2750 of 5001.\n",
      "Generator model loss: -1.3974077701568604.\n",
      "Discriminator model loss: -0.5136208534240723.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2751 of 5001.\n",
      "Step: 2752 of 5001.\n",
      "Step: 2753 of 5001.\n",
      "Step: 2754 of 5001.\n",
      "Step: 2755 of 5001.\n",
      "Step: 2756 of 5001.\n",
      "Step: 2757 of 5001.\n",
      "Step: 2758 of 5001.\n",
      "Step: 2759 of 5001.\n",
      "Step: 2760 of 5001.\n",
      "Generator model loss: -1.39888596534729.\n",
      "Discriminator model loss: -0.41374415159225464.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 2761 of 5001.\n",
      "Step: 2762 of 5001.\n",
      "Step: 2763 of 5001.\n",
      "Step: 2764 of 5001.\n",
      "Step: 2765 of 5001.\n",
      "Step: 2766 of 5001.\n",
      "Step: 2767 of 5001.\n",
      "Step: 2768 of 5001.\n",
      "Step: 2769 of 5001.\n",
      "Step: 2770 of 5001.\n",
      "Generator model loss: -1.3870705366134644.\n",
      "Discriminator model loss: -0.46508508920669556.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2771 of 5001.\n",
      "Step: 2772 of 5001.\n",
      "Step: 2773 of 5001.\n",
      "Step: 2774 of 5001.\n",
      "Step: 2775 of 5001.\n",
      "Step: 2776 of 5001.\n",
      "Step: 2777 of 5001.\n",
      "Step: 2778 of 5001.\n",
      "Step: 2779 of 5001.\n",
      "Step: 2780 of 5001.\n",
      "Generator model loss: -1.3856383562088013.\n",
      "Discriminator model loss: -0.5256981253623962.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2781 of 5001.\n",
      "Step: 2782 of 5001.\n",
      "Step: 2783 of 5001.\n",
      "Step: 2784 of 5001.\n",
      "Step: 2785 of 5001.\n",
      "Step: 2786 of 5001.\n",
      "Step: 2787 of 5001.\n",
      "Step: 2788 of 5001.\n",
      "Step: 2789 of 5001.\n",
      "Step: 2790 of 5001.\n",
      "Generator model loss: -1.3804980516433716.\n",
      "Discriminator model loss: -0.504717230796814.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2791 of 5001.\n",
      "Step: 2792 of 5001.\n",
      "Step: 2793 of 5001.\n",
      "Step: 2794 of 5001.\n",
      "Step: 2795 of 5001.\n",
      "Step: 2796 of 5001.\n",
      "Step: 2797 of 5001.\n",
      "Step: 2798 of 5001.\n",
      "Step: 2799 of 5001.\n",
      "Step: 2800 of 5001.\n",
      "Generator model loss: -1.3779548406600952.\n",
      "Discriminator model loss: -0.5230610370635986.\n",
      "xgboost accuracy: 0.71\n",
      "Step: 2801 of 5001.\n",
      "Step: 2802 of 5001.\n",
      "Step: 2803 of 5001.\n",
      "Step: 2804 of 5001.\n",
      "Step: 2805 of 5001.\n",
      "Step: 2806 of 5001.\n",
      "Step: 2807 of 5001.\n",
      "Step: 2808 of 5001.\n",
      "Step: 2809 of 5001.\n",
      "Step: 2810 of 5001.\n",
      "Generator model loss: -1.4030406475067139.\n",
      "Discriminator model loss: -0.39606207609176636.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 2811 of 5001.\n",
      "Step: 2812 of 5001.\n",
      "Step: 2813 of 5001.\n",
      "Step: 2814 of 5001.\n",
      "Step: 2815 of 5001.\n",
      "Step: 2816 of 5001.\n",
      "Step: 2817 of 5001.\n",
      "Step: 2818 of 5001.\n",
      "Step: 2819 of 5001.\n",
      "Step: 2820 of 5001.\n",
      "Generator model loss: -1.3750041723251343.\n",
      "Discriminator model loss: -0.48541125655174255.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2821 of 5001.\n",
      "Step: 2822 of 5001.\n",
      "Step: 2823 of 5001.\n",
      "Step: 2824 of 5001.\n",
      "Step: 2825 of 5001.\n",
      "Step: 2826 of 5001.\n",
      "Step: 2827 of 5001.\n",
      "Step: 2828 of 5001.\n",
      "Step: 2829 of 5001.\n",
      "Step: 2830 of 5001.\n",
      "Generator model loss: -1.370278000831604.\n",
      "Discriminator model loss: -0.3945067524909973.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2831 of 5001.\n",
      "Step: 2832 of 5001.\n",
      "Step: 2833 of 5001.\n",
      "Step: 2834 of 5001.\n",
      "Step: 2835 of 5001.\n",
      "Step: 2836 of 5001.\n",
      "Step: 2837 of 5001.\n",
      "Step: 2838 of 5001.\n",
      "Step: 2839 of 5001.\n",
      "Step: 2840 of 5001.\n",
      "Generator model loss: -1.411634922027588.\n",
      "Discriminator model loss: -0.4134635329246521.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2841 of 5001.\n",
      "Step: 2842 of 5001.\n",
      "Step: 2843 of 5001.\n",
      "Step: 2844 of 5001.\n",
      "Step: 2845 of 5001.\n",
      "Step: 2846 of 5001.\n",
      "Step: 2847 of 5001.\n",
      "Step: 2848 of 5001.\n",
      "Step: 2849 of 5001.\n",
      "Step: 2850 of 5001.\n",
      "Generator model loss: -1.4166783094406128.\n",
      "Discriminator model loss: -0.3933611214160919.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 2851 of 5001.\n",
      "Step: 2852 of 5001.\n",
      "Step: 2853 of 5001.\n",
      "Step: 2854 of 5001.\n",
      "Step: 2855 of 5001.\n",
      "Step: 2856 of 5001.\n",
      "Step: 2857 of 5001.\n",
      "Step: 2858 of 5001.\n",
      "Step: 2859 of 5001.\n",
      "Step: 2860 of 5001.\n",
      "Generator model loss: -1.4526264667510986.\n",
      "Discriminator model loss: -0.47279834747314453.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2861 of 5001.\n",
      "Step: 2862 of 5001.\n",
      "Step: 2863 of 5001.\n",
      "Step: 2864 of 5001.\n",
      "Step: 2865 of 5001.\n",
      "Step: 2866 of 5001.\n",
      "Step: 2867 of 5001.\n",
      "Step: 2868 of 5001.\n",
      "Step: 2869 of 5001.\n",
      "Step: 2870 of 5001.\n",
      "Generator model loss: -1.4274879693984985.\n",
      "Discriminator model loss: -0.44153743982315063.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2871 of 5001.\n",
      "Step: 2872 of 5001.\n",
      "Step: 2873 of 5001.\n",
      "Step: 2874 of 5001.\n",
      "Step: 2875 of 5001.\n",
      "Step: 2876 of 5001.\n",
      "Step: 2877 of 5001.\n",
      "Step: 2878 of 5001.\n",
      "Step: 2879 of 5001.\n",
      "Step: 2880 of 5001.\n",
      "Generator model loss: -1.3636932373046875.\n",
      "Discriminator model loss: -0.4043566584587097.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2881 of 5001.\n",
      "Step: 2882 of 5001.\n",
      "Step: 2883 of 5001.\n",
      "Step: 2884 of 5001.\n",
      "Step: 2885 of 5001.\n",
      "Step: 2886 of 5001.\n",
      "Step: 2887 of 5001.\n",
      "Step: 2888 of 5001.\n",
      "Step: 2889 of 5001.\n",
      "Step: 2890 of 5001.\n",
      "Generator model loss: -1.3949294090270996.\n",
      "Discriminator model loss: -0.4868331849575043.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2891 of 5001.\n",
      "Step: 2892 of 5001.\n",
      "Step: 2893 of 5001.\n",
      "Step: 2894 of 5001.\n",
      "Step: 2895 of 5001.\n",
      "Step: 2896 of 5001.\n",
      "Step: 2897 of 5001.\n",
      "Step: 2898 of 5001.\n",
      "Step: 2899 of 5001.\n",
      "Step: 2900 of 5001.\n",
      "Generator model loss: -1.397949457168579.\n",
      "Discriminator model loss: -0.4844387471675873.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2901 of 5001.\n",
      "Step: 2902 of 5001.\n",
      "Step: 2903 of 5001.\n",
      "Step: 2904 of 5001.\n",
      "Step: 2905 of 5001.\n",
      "Step: 2906 of 5001.\n",
      "Step: 2907 of 5001.\n",
      "Step: 2908 of 5001.\n",
      "Step: 2909 of 5001.\n",
      "Step: 2910 of 5001.\n",
      "Generator model loss: -1.458129644393921.\n",
      "Discriminator model loss: -0.4692469537258148.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2911 of 5001.\n",
      "Step: 2912 of 5001.\n",
      "Step: 2913 of 5001.\n",
      "Step: 2914 of 5001.\n",
      "Step: 2915 of 5001.\n",
      "Step: 2916 of 5001.\n",
      "Step: 2917 of 5001.\n",
      "Step: 2918 of 5001.\n",
      "Step: 2919 of 5001.\n",
      "Step: 2920 of 5001.\n",
      "Generator model loss: -1.4472110271453857.\n",
      "Discriminator model loss: -0.4044191837310791.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2921 of 5001.\n",
      "Step: 2922 of 5001.\n",
      "Step: 2923 of 5001.\n",
      "Step: 2924 of 5001.\n",
      "Step: 2925 of 5001.\n",
      "Step: 2926 of 5001.\n",
      "Step: 2927 of 5001.\n",
      "Step: 2928 of 5001.\n",
      "Step: 2929 of 5001.\n",
      "Step: 2930 of 5001.\n",
      "Generator model loss: -1.4860440492630005.\n",
      "Discriminator model loss: -0.4270154535770416.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2931 of 5001.\n",
      "Step: 2932 of 5001.\n",
      "Step: 2933 of 5001.\n",
      "Step: 2934 of 5001.\n",
      "Step: 2935 of 5001.\n",
      "Step: 2936 of 5001.\n",
      "Step: 2937 of 5001.\n",
      "Step: 2938 of 5001.\n",
      "Step: 2939 of 5001.\n",
      "Step: 2940 of 5001.\n",
      "Generator model loss: -1.4092066287994385.\n",
      "Discriminator model loss: -0.4985949993133545.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 2941 of 5001.\n",
      "Step: 2942 of 5001.\n",
      "Step: 2943 of 5001.\n",
      "Step: 2944 of 5001.\n",
      "Step: 2945 of 5001.\n",
      "Step: 2946 of 5001.\n",
      "Step: 2947 of 5001.\n",
      "Step: 2948 of 5001.\n",
      "Step: 2949 of 5001.\n",
      "Step: 2950 of 5001.\n",
      "Generator model loss: -1.449532389640808.\n",
      "Discriminator model loss: -0.38239535689353943.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2951 of 5001.\n",
      "Step: 2952 of 5001.\n",
      "Step: 2953 of 5001.\n",
      "Step: 2954 of 5001.\n",
      "Step: 2955 of 5001.\n",
      "Step: 2956 of 5001.\n",
      "Step: 2957 of 5001.\n",
      "Step: 2958 of 5001.\n",
      "Step: 2959 of 5001.\n",
      "Step: 2960 of 5001.\n",
      "Generator model loss: -1.4359080791473389.\n",
      "Discriminator model loss: -0.46483737230300903.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2961 of 5001.\n",
      "Step: 2962 of 5001.\n",
      "Step: 2963 of 5001.\n",
      "Step: 2964 of 5001.\n",
      "Step: 2965 of 5001.\n",
      "Step: 2966 of 5001.\n",
      "Step: 2967 of 5001.\n",
      "Step: 2968 of 5001.\n",
      "Step: 2969 of 5001.\n",
      "Step: 2970 of 5001.\n",
      "Generator model loss: -1.4644502401351929.\n",
      "Discriminator model loss: -0.4815053343772888.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2971 of 5001.\n",
      "Step: 2972 of 5001.\n",
      "Step: 2973 of 5001.\n",
      "Step: 2974 of 5001.\n",
      "Step: 2975 of 5001.\n",
      "Step: 2976 of 5001.\n",
      "Step: 2977 of 5001.\n",
      "Step: 2978 of 5001.\n",
      "Step: 2979 of 5001.\n",
      "Step: 2980 of 5001.\n",
      "Generator model loss: -1.4152963161468506.\n",
      "Discriminator model loss: -0.347622811794281.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2981 of 5001.\n",
      "Step: 2982 of 5001.\n",
      "Step: 2983 of 5001.\n",
      "Step: 2984 of 5001.\n",
      "Step: 2985 of 5001.\n",
      "Step: 2986 of 5001.\n",
      "Step: 2987 of 5001.\n",
      "Step: 2988 of 5001.\n",
      "Step: 2989 of 5001.\n",
      "Step: 2990 of 5001.\n",
      "Generator model loss: -1.4569121599197388.\n",
      "Discriminator model loss: -0.45975810289382935.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2991 of 5001.\n",
      "Step: 2992 of 5001.\n",
      "Step: 2993 of 5001.\n",
      "Step: 2994 of 5001.\n",
      "Step: 2995 of 5001.\n",
      "Step: 2996 of 5001.\n",
      "Step: 2997 of 5001.\n",
      "Step: 2998 of 5001.\n",
      "Step: 2999 of 5001.\n",
      "Step: 3000 of 5001.\n",
      "Generator model loss: -1.443007469177246.\n",
      "Discriminator model loss: -0.5026412606239319.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3001 of 5001.\n",
      "Step: 3002 of 5001.\n",
      "Step: 3003 of 5001.\n",
      "Step: 3004 of 5001.\n",
      "Step: 3005 of 5001.\n",
      "Step: 3006 of 5001.\n",
      "Step: 3007 of 5001.\n",
      "Step: 3008 of 5001.\n",
      "Step: 3009 of 5001.\n",
      "Step: 3010 of 5001.\n",
      "Generator model loss: -1.4712036848068237.\n",
      "Discriminator model loss: -0.45467615127563477.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3011 of 5001.\n",
      "Step: 3012 of 5001.\n",
      "Step: 3013 of 5001.\n",
      "Step: 3014 of 5001.\n",
      "Step: 3015 of 5001.\n",
      "Step: 3016 of 5001.\n",
      "Step: 3017 of 5001.\n",
      "Step: 3018 of 5001.\n",
      "Step: 3019 of 5001.\n",
      "Step: 3020 of 5001.\n",
      "Generator model loss: -1.4904474020004272.\n",
      "Discriminator model loss: -0.4134763181209564.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3021 of 5001.\n",
      "Step: 3022 of 5001.\n",
      "Step: 3023 of 5001.\n",
      "Step: 3024 of 5001.\n",
      "Step: 3025 of 5001.\n",
      "Step: 3026 of 5001.\n",
      "Step: 3027 of 5001.\n",
      "Step: 3028 of 5001.\n",
      "Step: 3029 of 5001.\n",
      "Step: 3030 of 5001.\n",
      "Generator model loss: -1.4567030668258667.\n",
      "Discriminator model loss: -0.4485153257846832.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3031 of 5001.\n",
      "Step: 3032 of 5001.\n",
      "Step: 3033 of 5001.\n",
      "Step: 3034 of 5001.\n",
      "Step: 3035 of 5001.\n",
      "Step: 3036 of 5001.\n",
      "Step: 3037 of 5001.\n",
      "Step: 3038 of 5001.\n",
      "Step: 3039 of 5001.\n",
      "Step: 3040 of 5001.\n",
      "Generator model loss: -1.5040132999420166.\n",
      "Discriminator model loss: -0.47700968384742737.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3041 of 5001.\n",
      "Step: 3042 of 5001.\n",
      "Step: 3043 of 5001.\n",
      "Step: 3044 of 5001.\n",
      "Step: 3045 of 5001.\n",
      "Step: 3046 of 5001.\n",
      "Step: 3047 of 5001.\n",
      "Step: 3048 of 5001.\n",
      "Step: 3049 of 5001.\n",
      "Step: 3050 of 5001.\n",
      "Generator model loss: -1.4028542041778564.\n",
      "Discriminator model loss: -0.4734014868736267.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3051 of 5001.\n",
      "Step: 3052 of 5001.\n",
      "Step: 3053 of 5001.\n",
      "Step: 3054 of 5001.\n",
      "Step: 3055 of 5001.\n",
      "Step: 3056 of 5001.\n",
      "Step: 3057 of 5001.\n",
      "Step: 3058 of 5001.\n",
      "Step: 3059 of 5001.\n",
      "Step: 3060 of 5001.\n",
      "Generator model loss: -1.4572336673736572.\n",
      "Discriminator model loss: -0.4549887180328369.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3061 of 5001.\n",
      "Step: 3062 of 5001.\n",
      "Step: 3063 of 5001.\n",
      "Step: 3064 of 5001.\n",
      "Step: 3065 of 5001.\n",
      "Step: 3066 of 5001.\n",
      "Step: 3067 of 5001.\n",
      "Step: 3068 of 5001.\n",
      "Step: 3069 of 5001.\n",
      "Step: 3070 of 5001.\n",
      "Generator model loss: -1.4804539680480957.\n",
      "Discriminator model loss: -0.4291935861110687.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3071 of 5001.\n",
      "Step: 3072 of 5001.\n",
      "Step: 3073 of 5001.\n",
      "Step: 3074 of 5001.\n",
      "Step: 3075 of 5001.\n",
      "Step: 3076 of 5001.\n",
      "Step: 3077 of 5001.\n",
      "Step: 3078 of 5001.\n",
      "Step: 3079 of 5001.\n",
      "Step: 3080 of 5001.\n",
      "Generator model loss: -1.4609798192977905.\n",
      "Discriminator model loss: -0.3689633309841156.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 3081 of 5001.\n",
      "Step: 3082 of 5001.\n",
      "Step: 3083 of 5001.\n",
      "Step: 3084 of 5001.\n",
      "Step: 3085 of 5001.\n",
      "Step: 3086 of 5001.\n",
      "Step: 3087 of 5001.\n",
      "Step: 3088 of 5001.\n",
      "Step: 3089 of 5001.\n",
      "Step: 3090 of 5001.\n",
      "Generator model loss: -1.5191460847854614.\n",
      "Discriminator model loss: -0.48400259017944336.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3091 of 5001.\n",
      "Step: 3092 of 5001.\n",
      "Step: 3093 of 5001.\n",
      "Step: 3094 of 5001.\n",
      "Step: 3095 of 5001.\n",
      "Step: 3096 of 5001.\n",
      "Step: 3097 of 5001.\n",
      "Step: 3098 of 5001.\n",
      "Step: 3099 of 5001.\n",
      "Step: 3100 of 5001.\n",
      "Generator model loss: -1.4832581281661987.\n",
      "Discriminator model loss: -0.5174683928489685.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3101 of 5001.\n",
      "Step: 3102 of 5001.\n",
      "Step: 3103 of 5001.\n",
      "Step: 3104 of 5001.\n",
      "Step: 3105 of 5001.\n",
      "Step: 3106 of 5001.\n",
      "Step: 3107 of 5001.\n",
      "Step: 3108 of 5001.\n",
      "Step: 3109 of 5001.\n",
      "Step: 3110 of 5001.\n",
      "Generator model loss: -1.5220696926116943.\n",
      "Discriminator model loss: -0.4376670718193054.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3111 of 5001.\n",
      "Step: 3112 of 5001.\n",
      "Step: 3113 of 5001.\n",
      "Step: 3114 of 5001.\n",
      "Step: 3115 of 5001.\n",
      "Step: 3116 of 5001.\n",
      "Step: 3117 of 5001.\n",
      "Step: 3118 of 5001.\n",
      "Step: 3119 of 5001.\n",
      "Step: 3120 of 5001.\n",
      "Generator model loss: -1.4751619100570679.\n",
      "Discriminator model loss: -0.4067201614379883.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3121 of 5001.\n",
      "Step: 3122 of 5001.\n",
      "Step: 3123 of 5001.\n",
      "Step: 3124 of 5001.\n",
      "Step: 3125 of 5001.\n",
      "Step: 3126 of 5001.\n",
      "Step: 3127 of 5001.\n",
      "Step: 3128 of 5001.\n",
      "Step: 3129 of 5001.\n",
      "Step: 3130 of 5001.\n",
      "Generator model loss: -1.5196701288223267.\n",
      "Discriminator model loss: -0.4557780623435974.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3131 of 5001.\n",
      "Step: 3132 of 5001.\n",
      "Step: 3133 of 5001.\n",
      "Step: 3134 of 5001.\n",
      "Step: 3135 of 5001.\n",
      "Step: 3136 of 5001.\n",
      "Step: 3137 of 5001.\n",
      "Step: 3138 of 5001.\n",
      "Step: 3139 of 5001.\n",
      "Step: 3140 of 5001.\n",
      "Generator model loss: -1.500663161277771.\n",
      "Discriminator model loss: -0.4196895956993103.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3141 of 5001.\n",
      "Step: 3142 of 5001.\n",
      "Step: 3143 of 5001.\n",
      "Step: 3144 of 5001.\n",
      "Step: 3145 of 5001.\n",
      "Step: 3146 of 5001.\n",
      "Step: 3147 of 5001.\n",
      "Step: 3148 of 5001.\n",
      "Step: 3149 of 5001.\n",
      "Step: 3150 of 5001.\n",
      "Generator model loss: -1.5588575601577759.\n",
      "Discriminator model loss: -0.4291613698005676.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3151 of 5001.\n",
      "Step: 3152 of 5001.\n",
      "Step: 3153 of 5001.\n",
      "Step: 3154 of 5001.\n",
      "Step: 3155 of 5001.\n",
      "Step: 3156 of 5001.\n",
      "Step: 3157 of 5001.\n",
      "Step: 3158 of 5001.\n",
      "Step: 3159 of 5001.\n",
      "Step: 3160 of 5001.\n",
      "Generator model loss: -1.5112278461456299.\n",
      "Discriminator model loss: -0.5289124250411987.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3161 of 5001.\n",
      "Step: 3162 of 5001.\n",
      "Step: 3163 of 5001.\n",
      "Step: 3164 of 5001.\n",
      "Step: 3165 of 5001.\n",
      "Step: 3166 of 5001.\n",
      "Step: 3167 of 5001.\n",
      "Step: 3168 of 5001.\n",
      "Step: 3169 of 5001.\n",
      "Step: 3170 of 5001.\n",
      "Generator model loss: -1.516858458518982.\n",
      "Discriminator model loss: -0.4703977108001709.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3171 of 5001.\n",
      "Step: 3172 of 5001.\n",
      "Step: 3173 of 5001.\n",
      "Step: 3174 of 5001.\n",
      "Step: 3175 of 5001.\n",
      "Step: 3176 of 5001.\n",
      "Step: 3177 of 5001.\n",
      "Step: 3178 of 5001.\n",
      "Step: 3179 of 5001.\n",
      "Step: 3180 of 5001.\n",
      "Generator model loss: -1.5526217222213745.\n",
      "Discriminator model loss: -0.5620359778404236.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3181 of 5001.\n",
      "Step: 3182 of 5001.\n",
      "Step: 3183 of 5001.\n",
      "Step: 3184 of 5001.\n",
      "Step: 3185 of 5001.\n",
      "Step: 3186 of 5001.\n",
      "Step: 3187 of 5001.\n",
      "Step: 3188 of 5001.\n",
      "Step: 3189 of 5001.\n",
      "Step: 3190 of 5001.\n",
      "Generator model loss: -1.4675012826919556.\n",
      "Discriminator model loss: -0.3985437750816345.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3191 of 5001.\n",
      "Step: 3192 of 5001.\n",
      "Step: 3193 of 5001.\n",
      "Step: 3194 of 5001.\n",
      "Step: 3195 of 5001.\n",
      "Step: 3196 of 5001.\n",
      "Step: 3197 of 5001.\n",
      "Step: 3198 of 5001.\n",
      "Step: 3199 of 5001.\n",
      "Step: 3200 of 5001.\n",
      "Generator model loss: -1.4797228574752808.\n",
      "Discriminator model loss: -0.38706475496292114.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3201 of 5001.\n",
      "Step: 3202 of 5001.\n",
      "Step: 3203 of 5001.\n",
      "Step: 3204 of 5001.\n",
      "Step: 3205 of 5001.\n",
      "Step: 3206 of 5001.\n",
      "Step: 3207 of 5001.\n",
      "Step: 3208 of 5001.\n",
      "Step: 3209 of 5001.\n",
      "Step: 3210 of 5001.\n",
      "Generator model loss: -1.5147926807403564.\n",
      "Discriminator model loss: -0.44054657220840454.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3211 of 5001.\n",
      "Step: 3212 of 5001.\n",
      "Step: 3213 of 5001.\n",
      "Step: 3214 of 5001.\n",
      "Step: 3215 of 5001.\n",
      "Step: 3216 of 5001.\n",
      "Step: 3217 of 5001.\n",
      "Step: 3218 of 5001.\n",
      "Step: 3219 of 5001.\n",
      "Step: 3220 of 5001.\n",
      "Generator model loss: -1.5665100812911987.\n",
      "Discriminator model loss: -0.4732104241847992.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 3221 of 5001.\n",
      "Step: 3222 of 5001.\n",
      "Step: 3223 of 5001.\n",
      "Step: 3224 of 5001.\n",
      "Step: 3225 of 5001.\n",
      "Step: 3226 of 5001.\n",
      "Step: 3227 of 5001.\n",
      "Step: 3228 of 5001.\n",
      "Step: 3229 of 5001.\n",
      "Step: 3230 of 5001.\n",
      "Generator model loss: -1.5201175212860107.\n",
      "Discriminator model loss: -0.500085711479187.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3231 of 5001.\n",
      "Step: 3232 of 5001.\n",
      "Step: 3233 of 5001.\n",
      "Step: 3234 of 5001.\n",
      "Step: 3235 of 5001.\n",
      "Step: 3236 of 5001.\n",
      "Step: 3237 of 5001.\n",
      "Step: 3238 of 5001.\n",
      "Step: 3239 of 5001.\n",
      "Step: 3240 of 5001.\n",
      "Generator model loss: -1.532105803489685.\n",
      "Discriminator model loss: -0.352084219455719.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3241 of 5001.\n",
      "Step: 3242 of 5001.\n",
      "Step: 3243 of 5001.\n",
      "Step: 3244 of 5001.\n",
      "Step: 3245 of 5001.\n",
      "Step: 3246 of 5001.\n",
      "Step: 3247 of 5001.\n",
      "Step: 3248 of 5001.\n",
      "Step: 3249 of 5001.\n",
      "Step: 3250 of 5001.\n",
      "Generator model loss: -1.5522775650024414.\n",
      "Discriminator model loss: -0.4676951766014099.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3251 of 5001.\n",
      "Step: 3252 of 5001.\n",
      "Step: 3253 of 5001.\n",
      "Step: 3254 of 5001.\n",
      "Step: 3255 of 5001.\n",
      "Step: 3256 of 5001.\n",
      "Step: 3257 of 5001.\n",
      "Step: 3258 of 5001.\n",
      "Step: 3259 of 5001.\n",
      "Step: 3260 of 5001.\n",
      "Generator model loss: -1.573523998260498.\n",
      "Discriminator model loss: -0.43794775009155273.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3261 of 5001.\n",
      "Step: 3262 of 5001.\n",
      "Step: 3263 of 5001.\n",
      "Step: 3264 of 5001.\n",
      "Step: 3265 of 5001.\n",
      "Step: 3266 of 5001.\n",
      "Step: 3267 of 5001.\n",
      "Step: 3268 of 5001.\n",
      "Step: 3269 of 5001.\n",
      "Step: 3270 of 5001.\n",
      "Generator model loss: -1.5599783658981323.\n",
      "Discriminator model loss: -0.4401906132698059.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3271 of 5001.\n",
      "Step: 3272 of 5001.\n",
      "Step: 3273 of 5001.\n",
      "Step: 3274 of 5001.\n",
      "Step: 3275 of 5001.\n",
      "Step: 3276 of 5001.\n",
      "Step: 3277 of 5001.\n",
      "Step: 3278 of 5001.\n",
      "Step: 3279 of 5001.\n",
      "Step: 3280 of 5001.\n",
      "Generator model loss: -1.5000736713409424.\n",
      "Discriminator model loss: -0.390753835439682.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3281 of 5001.\n",
      "Step: 3282 of 5001.\n",
      "Step: 3283 of 5001.\n",
      "Step: 3284 of 5001.\n",
      "Step: 3285 of 5001.\n",
      "Step: 3286 of 5001.\n",
      "Step: 3287 of 5001.\n",
      "Step: 3288 of 5001.\n",
      "Step: 3289 of 5001.\n",
      "Step: 3290 of 5001.\n",
      "Generator model loss: -1.5807896852493286.\n",
      "Discriminator model loss: -0.4053317904472351.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3291 of 5001.\n",
      "Step: 3292 of 5001.\n",
      "Step: 3293 of 5001.\n",
      "Step: 3294 of 5001.\n",
      "Step: 3295 of 5001.\n",
      "Step: 3296 of 5001.\n",
      "Step: 3297 of 5001.\n",
      "Step: 3298 of 5001.\n",
      "Step: 3299 of 5001.\n",
      "Step: 3300 of 5001.\n",
      "Generator model loss: -1.575050711631775.\n",
      "Discriminator model loss: -0.40776506066322327.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3301 of 5001.\n",
      "Step: 3302 of 5001.\n",
      "Step: 3303 of 5001.\n",
      "Step: 3304 of 5001.\n",
      "Step: 3305 of 5001.\n",
      "Step: 3306 of 5001.\n",
      "Step: 3307 of 5001.\n",
      "Step: 3308 of 5001.\n",
      "Step: 3309 of 5001.\n",
      "Step: 3310 of 5001.\n",
      "Generator model loss: -1.5387448072433472.\n",
      "Discriminator model loss: -0.410626083612442.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3311 of 5001.\n",
      "Step: 3312 of 5001.\n",
      "Step: 3313 of 5001.\n",
      "Step: 3314 of 5001.\n",
      "Step: 3315 of 5001.\n",
      "Step: 3316 of 5001.\n",
      "Step: 3317 of 5001.\n",
      "Step: 3318 of 5001.\n",
      "Step: 3319 of 5001.\n",
      "Step: 3320 of 5001.\n",
      "Generator model loss: -1.5983178615570068.\n",
      "Discriminator model loss: -0.4399835467338562.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3321 of 5001.\n",
      "Step: 3322 of 5001.\n",
      "Step: 3323 of 5001.\n",
      "Step: 3324 of 5001.\n",
      "Step: 3325 of 5001.\n",
      "Step: 3326 of 5001.\n",
      "Step: 3327 of 5001.\n",
      "Step: 3328 of 5001.\n",
      "Step: 3329 of 5001.\n",
      "Step: 3330 of 5001.\n",
      "Generator model loss: -1.5642057657241821.\n",
      "Discriminator model loss: -0.4094746708869934.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 3331 of 5001.\n",
      "Step: 3332 of 5001.\n",
      "Step: 3333 of 5001.\n",
      "Step: 3334 of 5001.\n",
      "Step: 3335 of 5001.\n",
      "Step: 3336 of 5001.\n",
      "Step: 3337 of 5001.\n",
      "Step: 3338 of 5001.\n",
      "Step: 3339 of 5001.\n",
      "Step: 3340 of 5001.\n",
      "Generator model loss: -1.6057443618774414.\n",
      "Discriminator model loss: -0.4063514769077301.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3341 of 5001.\n",
      "Step: 3342 of 5001.\n",
      "Step: 3343 of 5001.\n",
      "Step: 3344 of 5001.\n",
      "Step: 3345 of 5001.\n",
      "Step: 3346 of 5001.\n",
      "Step: 3347 of 5001.\n",
      "Step: 3348 of 5001.\n",
      "Step: 3349 of 5001.\n",
      "Step: 3350 of 5001.\n",
      "Generator model loss: -1.5799977779388428.\n",
      "Discriminator model loss: -0.3511630594730377.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3351 of 5001.\n",
      "Step: 3352 of 5001.\n",
      "Step: 3353 of 5001.\n",
      "Step: 3354 of 5001.\n",
      "Step: 3355 of 5001.\n",
      "Step: 3356 of 5001.\n",
      "Step: 3357 of 5001.\n",
      "Step: 3358 of 5001.\n",
      "Step: 3359 of 5001.\n",
      "Step: 3360 of 5001.\n",
      "Generator model loss: -1.5751873254776.\n",
      "Discriminator model loss: -0.44522255659103394.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3361 of 5001.\n",
      "Step: 3362 of 5001.\n",
      "Step: 3363 of 5001.\n",
      "Step: 3364 of 5001.\n",
      "Step: 3365 of 5001.\n",
      "Step: 3366 of 5001.\n",
      "Step: 3367 of 5001.\n",
      "Step: 3368 of 5001.\n",
      "Step: 3369 of 5001.\n",
      "Step: 3370 of 5001.\n",
      "Generator model loss: -1.5935251712799072.\n",
      "Discriminator model loss: -0.4504566192626953.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3371 of 5001.\n",
      "Step: 3372 of 5001.\n",
      "Step: 3373 of 5001.\n",
      "Step: 3374 of 5001.\n",
      "Step: 3375 of 5001.\n",
      "Step: 3376 of 5001.\n",
      "Step: 3377 of 5001.\n",
      "Step: 3378 of 5001.\n",
      "Step: 3379 of 5001.\n",
      "Step: 3380 of 5001.\n",
      "Generator model loss: -1.5481752157211304.\n",
      "Discriminator model loss: -0.41570454835891724.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3381 of 5001.\n",
      "Step: 3382 of 5001.\n",
      "Step: 3383 of 5001.\n",
      "Step: 3384 of 5001.\n",
      "Step: 3385 of 5001.\n",
      "Step: 3386 of 5001.\n",
      "Step: 3387 of 5001.\n",
      "Step: 3388 of 5001.\n",
      "Step: 3389 of 5001.\n",
      "Step: 3390 of 5001.\n",
      "Generator model loss: -1.5963021516799927.\n",
      "Discriminator model loss: -0.43246254324913025.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3391 of 5001.\n",
      "Step: 3392 of 5001.\n",
      "Step: 3393 of 5001.\n",
      "Step: 3394 of 5001.\n",
      "Step: 3395 of 5001.\n",
      "Step: 3396 of 5001.\n",
      "Step: 3397 of 5001.\n",
      "Step: 3398 of 5001.\n",
      "Step: 3399 of 5001.\n",
      "Step: 3400 of 5001.\n",
      "Generator model loss: -1.6374824047088623.\n",
      "Discriminator model loss: -0.5244356989860535.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 3401 of 5001.\n",
      "Step: 3402 of 5001.\n",
      "Step: 3403 of 5001.\n",
      "Step: 3404 of 5001.\n",
      "Step: 3405 of 5001.\n",
      "Step: 3406 of 5001.\n",
      "Step: 3407 of 5001.\n",
      "Step: 3408 of 5001.\n",
      "Step: 3409 of 5001.\n",
      "Step: 3410 of 5001.\n",
      "Generator model loss: -1.5840256214141846.\n",
      "Discriminator model loss: -0.41176700592041016.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3411 of 5001.\n",
      "Step: 3412 of 5001.\n",
      "Step: 3413 of 5001.\n",
      "Step: 3414 of 5001.\n",
      "Step: 3415 of 5001.\n",
      "Step: 3416 of 5001.\n",
      "Step: 3417 of 5001.\n",
      "Step: 3418 of 5001.\n",
      "Step: 3419 of 5001.\n",
      "Step: 3420 of 5001.\n",
      "Generator model loss: -1.6501786708831787.\n",
      "Discriminator model loss: -0.3709578216075897.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3421 of 5001.\n",
      "Step: 3422 of 5001.\n",
      "Step: 3423 of 5001.\n",
      "Step: 3424 of 5001.\n",
      "Step: 3425 of 5001.\n",
      "Step: 3426 of 5001.\n",
      "Step: 3427 of 5001.\n",
      "Step: 3428 of 5001.\n",
      "Step: 3429 of 5001.\n",
      "Step: 3430 of 5001.\n",
      "Generator model loss: -1.6066582202911377.\n",
      "Discriminator model loss: -0.4943716526031494.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3431 of 5001.\n",
      "Step: 3432 of 5001.\n",
      "Step: 3433 of 5001.\n",
      "Step: 3434 of 5001.\n",
      "Step: 3435 of 5001.\n",
      "Step: 3436 of 5001.\n",
      "Step: 3437 of 5001.\n",
      "Step: 3438 of 5001.\n",
      "Step: 3439 of 5001.\n",
      "Step: 3440 of 5001.\n",
      "Generator model loss: -1.6145744323730469.\n",
      "Discriminator model loss: -0.4112474322319031.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3441 of 5001.\n",
      "Step: 3442 of 5001.\n",
      "Step: 3443 of 5001.\n",
      "Step: 3444 of 5001.\n",
      "Step: 3445 of 5001.\n",
      "Step: 3446 of 5001.\n",
      "Step: 3447 of 5001.\n",
      "Step: 3448 of 5001.\n",
      "Step: 3449 of 5001.\n",
      "Step: 3450 of 5001.\n",
      "Generator model loss: -1.6611487865447998.\n",
      "Discriminator model loss: -0.44980835914611816.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 3451 of 5001.\n",
      "Step: 3452 of 5001.\n",
      "Step: 3453 of 5001.\n",
      "Step: 3454 of 5001.\n",
      "Step: 3455 of 5001.\n",
      "Step: 3456 of 5001.\n",
      "Step: 3457 of 5001.\n",
      "Step: 3458 of 5001.\n",
      "Step: 3459 of 5001.\n",
      "Step: 3460 of 5001.\n",
      "Generator model loss: -1.6109485626220703.\n",
      "Discriminator model loss: -0.4298498034477234.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 3461 of 5001.\n",
      "Step: 3462 of 5001.\n",
      "Step: 3463 of 5001.\n",
      "Step: 3464 of 5001.\n",
      "Step: 3465 of 5001.\n",
      "Step: 3466 of 5001.\n",
      "Step: 3467 of 5001.\n",
      "Step: 3468 of 5001.\n",
      "Step: 3469 of 5001.\n",
      "Step: 3470 of 5001.\n",
      "Generator model loss: -1.637652039527893.\n",
      "Discriminator model loss: -0.4662511944770813.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3471 of 5001.\n",
      "Step: 3472 of 5001.\n",
      "Step: 3473 of 5001.\n",
      "Step: 3474 of 5001.\n",
      "Step: 3475 of 5001.\n",
      "Step: 3476 of 5001.\n",
      "Step: 3477 of 5001.\n",
      "Step: 3478 of 5001.\n",
      "Step: 3479 of 5001.\n",
      "Step: 3480 of 5001.\n",
      "Generator model loss: -1.6990842819213867.\n",
      "Discriminator model loss: -0.3697376251220703.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3481 of 5001.\n",
      "Step: 3482 of 5001.\n",
      "Step: 3483 of 5001.\n",
      "Step: 3484 of 5001.\n",
      "Step: 3485 of 5001.\n",
      "Step: 3486 of 5001.\n",
      "Step: 3487 of 5001.\n",
      "Step: 3488 of 5001.\n",
      "Step: 3489 of 5001.\n",
      "Step: 3490 of 5001.\n",
      "Generator model loss: -1.6279382705688477.\n",
      "Discriminator model loss: -0.4062291979789734.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3491 of 5001.\n",
      "Step: 3492 of 5001.\n",
      "Step: 3493 of 5001.\n",
      "Step: 3494 of 5001.\n",
      "Step: 3495 of 5001.\n",
      "Step: 3496 of 5001.\n",
      "Step: 3497 of 5001.\n",
      "Step: 3498 of 5001.\n",
      "Step: 3499 of 5001.\n",
      "Step: 3500 of 5001.\n",
      "Generator model loss: -1.704810380935669.\n",
      "Discriminator model loss: -0.3517359793186188.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3501 of 5001.\n",
      "Step: 3502 of 5001.\n",
      "Step: 3503 of 5001.\n",
      "Step: 3504 of 5001.\n",
      "Step: 3505 of 5001.\n",
      "Step: 3506 of 5001.\n",
      "Step: 3507 of 5001.\n",
      "Step: 3508 of 5001.\n",
      "Step: 3509 of 5001.\n",
      "Step: 3510 of 5001.\n",
      "Generator model loss: -1.6144249439239502.\n",
      "Discriminator model loss: -0.3550902009010315.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3511 of 5001.\n",
      "Step: 3512 of 5001.\n",
      "Step: 3513 of 5001.\n",
      "Step: 3514 of 5001.\n",
      "Step: 3515 of 5001.\n",
      "Step: 3516 of 5001.\n",
      "Step: 3517 of 5001.\n",
      "Step: 3518 of 5001.\n",
      "Step: 3519 of 5001.\n",
      "Step: 3520 of 5001.\n",
      "Generator model loss: -1.664136290550232.\n",
      "Discriminator model loss: -0.3828126788139343.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3521 of 5001.\n",
      "Step: 3522 of 5001.\n",
      "Step: 3523 of 5001.\n",
      "Step: 3524 of 5001.\n",
      "Step: 3525 of 5001.\n",
      "Step: 3526 of 5001.\n",
      "Step: 3527 of 5001.\n",
      "Step: 3528 of 5001.\n",
      "Step: 3529 of 5001.\n",
      "Step: 3530 of 5001.\n",
      "Generator model loss: -1.673919916152954.\n",
      "Discriminator model loss: -0.40881118178367615.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3531 of 5001.\n",
      "Step: 3532 of 5001.\n",
      "Step: 3533 of 5001.\n",
      "Step: 3534 of 5001.\n",
      "Step: 3535 of 5001.\n",
      "Step: 3536 of 5001.\n",
      "Step: 3537 of 5001.\n",
      "Step: 3538 of 5001.\n",
      "Step: 3539 of 5001.\n",
      "Step: 3540 of 5001.\n",
      "Generator model loss: -1.6678390502929688.\n",
      "Discriminator model loss: -0.5367738008499146.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3541 of 5001.\n",
      "Step: 3542 of 5001.\n",
      "Step: 3543 of 5001.\n",
      "Step: 3544 of 5001.\n",
      "Step: 3545 of 5001.\n",
      "Step: 3546 of 5001.\n",
      "Step: 3547 of 5001.\n",
      "Step: 3548 of 5001.\n",
      "Step: 3549 of 5001.\n",
      "Step: 3550 of 5001.\n",
      "Generator model loss: -1.616445779800415.\n",
      "Discriminator model loss: -0.4129221439361572.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3551 of 5001.\n",
      "Step: 3552 of 5001.\n",
      "Step: 3553 of 5001.\n",
      "Step: 3554 of 5001.\n",
      "Step: 3555 of 5001.\n",
      "Step: 3556 of 5001.\n",
      "Step: 3557 of 5001.\n",
      "Step: 3558 of 5001.\n",
      "Step: 3559 of 5001.\n",
      "Step: 3560 of 5001.\n",
      "Generator model loss: -1.6830543279647827.\n",
      "Discriminator model loss: -0.3666549324989319.\n",
      "xgboost accuracy: 0.73\n",
      "Step: 3561 of 5001.\n",
      "Step: 3562 of 5001.\n",
      "Step: 3563 of 5001.\n",
      "Step: 3564 of 5001.\n",
      "Step: 3565 of 5001.\n",
      "Step: 3566 of 5001.\n",
      "Step: 3567 of 5001.\n",
      "Step: 3568 of 5001.\n",
      "Step: 3569 of 5001.\n",
      "Step: 3570 of 5001.\n",
      "Generator model loss: -1.6145210266113281.\n",
      "Discriminator model loss: -0.43071430921554565.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3571 of 5001.\n",
      "Step: 3572 of 5001.\n",
      "Step: 3573 of 5001.\n",
      "Step: 3574 of 5001.\n",
      "Step: 3575 of 5001.\n",
      "Step: 3576 of 5001.\n",
      "Step: 3577 of 5001.\n",
      "Step: 3578 of 5001.\n",
      "Step: 3579 of 5001.\n",
      "Step: 3580 of 5001.\n",
      "Generator model loss: -1.6423261165618896.\n",
      "Discriminator model loss: -0.3990059494972229.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3581 of 5001.\n",
      "Step: 3582 of 5001.\n",
      "Step: 3583 of 5001.\n",
      "Step: 3584 of 5001.\n",
      "Step: 3585 of 5001.\n",
      "Step: 3586 of 5001.\n",
      "Step: 3587 of 5001.\n",
      "Step: 3588 of 5001.\n",
      "Step: 3589 of 5001.\n",
      "Step: 3590 of 5001.\n",
      "Generator model loss: -1.63037109375.\n",
      "Discriminator model loss: -0.3308012783527374.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3591 of 5001.\n",
      "Step: 3592 of 5001.\n",
      "Step: 3593 of 5001.\n",
      "Step: 3594 of 5001.\n",
      "Step: 3595 of 5001.\n",
      "Step: 3596 of 5001.\n",
      "Step: 3597 of 5001.\n",
      "Step: 3598 of 5001.\n",
      "Step: 3599 of 5001.\n",
      "Step: 3600 of 5001.\n",
      "Generator model loss: -1.716247320175171.\n",
      "Discriminator model loss: -0.40157461166381836.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3601 of 5001.\n",
      "Step: 3602 of 5001.\n",
      "Step: 3603 of 5001.\n",
      "Step: 3604 of 5001.\n",
      "Step: 3605 of 5001.\n",
      "Step: 3606 of 5001.\n",
      "Step: 3607 of 5001.\n",
      "Step: 3608 of 5001.\n",
      "Step: 3609 of 5001.\n",
      "Step: 3610 of 5001.\n",
      "Generator model loss: -1.6889845132827759.\n",
      "Discriminator model loss: -0.4721852242946625.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 3611 of 5001.\n",
      "Step: 3612 of 5001.\n",
      "Step: 3613 of 5001.\n",
      "Step: 3614 of 5001.\n",
      "Step: 3615 of 5001.\n",
      "Step: 3616 of 5001.\n",
      "Step: 3617 of 5001.\n",
      "Step: 3618 of 5001.\n",
      "Step: 3619 of 5001.\n",
      "Step: 3620 of 5001.\n",
      "Generator model loss: -1.6897201538085938.\n",
      "Discriminator model loss: -0.45810666680336.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3621 of 5001.\n",
      "Step: 3622 of 5001.\n",
      "Step: 3623 of 5001.\n",
      "Step: 3624 of 5001.\n",
      "Step: 3625 of 5001.\n",
      "Step: 3626 of 5001.\n",
      "Step: 3627 of 5001.\n",
      "Step: 3628 of 5001.\n",
      "Step: 3629 of 5001.\n",
      "Step: 3630 of 5001.\n",
      "Generator model loss: -1.7562406063079834.\n",
      "Discriminator model loss: -0.3406532108783722.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3631 of 5001.\n",
      "Step: 3632 of 5001.\n",
      "Step: 3633 of 5001.\n",
      "Step: 3634 of 5001.\n",
      "Step: 3635 of 5001.\n",
      "Step: 3636 of 5001.\n",
      "Step: 3637 of 5001.\n",
      "Step: 3638 of 5001.\n",
      "Step: 3639 of 5001.\n",
      "Step: 3640 of 5001.\n",
      "Generator model loss: -1.7609083652496338.\n",
      "Discriminator model loss: -0.4134969115257263.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3641 of 5001.\n",
      "Step: 3642 of 5001.\n",
      "Step: 3643 of 5001.\n",
      "Step: 3644 of 5001.\n",
      "Step: 3645 of 5001.\n",
      "Step: 3646 of 5001.\n",
      "Step: 3647 of 5001.\n",
      "Step: 3648 of 5001.\n",
      "Step: 3649 of 5001.\n",
      "Step: 3650 of 5001.\n",
      "Generator model loss: -1.7175136804580688.\n",
      "Discriminator model loss: -0.41376394033432007.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3651 of 5001.\n",
      "Step: 3652 of 5001.\n",
      "Step: 3653 of 5001.\n",
      "Step: 3654 of 5001.\n",
      "Step: 3655 of 5001.\n",
      "Step: 3656 of 5001.\n",
      "Step: 3657 of 5001.\n",
      "Step: 3658 of 5001.\n",
      "Step: 3659 of 5001.\n",
      "Step: 3660 of 5001.\n",
      "Generator model loss: -1.7335386276245117.\n",
      "Discriminator model loss: -0.4436628818511963.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3661 of 5001.\n",
      "Step: 3662 of 5001.\n",
      "Step: 3663 of 5001.\n",
      "Step: 3664 of 5001.\n",
      "Step: 3665 of 5001.\n",
      "Step: 3666 of 5001.\n",
      "Step: 3667 of 5001.\n",
      "Step: 3668 of 5001.\n",
      "Step: 3669 of 5001.\n",
      "Step: 3670 of 5001.\n",
      "Generator model loss: -1.6932560205459595.\n",
      "Discriminator model loss: -0.37678617238998413.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3671 of 5001.\n",
      "Step: 3672 of 5001.\n",
      "Step: 3673 of 5001.\n",
      "Step: 3674 of 5001.\n",
      "Step: 3675 of 5001.\n",
      "Step: 3676 of 5001.\n",
      "Step: 3677 of 5001.\n",
      "Step: 3678 of 5001.\n",
      "Step: 3679 of 5001.\n",
      "Step: 3680 of 5001.\n",
      "Generator model loss: -1.7480223178863525.\n",
      "Discriminator model loss: -0.5495280027389526.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 3681 of 5001.\n",
      "Step: 3682 of 5001.\n",
      "Step: 3683 of 5001.\n",
      "Step: 3684 of 5001.\n",
      "Step: 3685 of 5001.\n",
      "Step: 3686 of 5001.\n",
      "Step: 3687 of 5001.\n",
      "Step: 3688 of 5001.\n",
      "Step: 3689 of 5001.\n",
      "Step: 3690 of 5001.\n",
      "Generator model loss: -1.8064947128295898.\n",
      "Discriminator model loss: -0.4171110987663269.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 3691 of 5001.\n",
      "Step: 3692 of 5001.\n",
      "Step: 3693 of 5001.\n",
      "Step: 3694 of 5001.\n",
      "Step: 3695 of 5001.\n",
      "Step: 3696 of 5001.\n",
      "Step: 3697 of 5001.\n",
      "Step: 3698 of 5001.\n",
      "Step: 3699 of 5001.\n",
      "Step: 3700 of 5001.\n",
      "Generator model loss: -1.7448383569717407.\n",
      "Discriminator model loss: -0.4004901051521301.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3701 of 5001.\n",
      "Step: 3702 of 5001.\n",
      "Step: 3703 of 5001.\n",
      "Step: 3704 of 5001.\n",
      "Step: 3705 of 5001.\n",
      "Step: 3706 of 5001.\n",
      "Step: 3707 of 5001.\n",
      "Step: 3708 of 5001.\n",
      "Step: 3709 of 5001.\n",
      "Step: 3710 of 5001.\n",
      "Generator model loss: -1.730291724205017.\n",
      "Discriminator model loss: -0.4807107448577881.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3711 of 5001.\n",
      "Step: 3712 of 5001.\n",
      "Step: 3713 of 5001.\n",
      "Step: 3714 of 5001.\n",
      "Step: 3715 of 5001.\n",
      "Step: 3716 of 5001.\n",
      "Step: 3717 of 5001.\n",
      "Step: 3718 of 5001.\n",
      "Step: 3719 of 5001.\n",
      "Step: 3720 of 5001.\n",
      "Generator model loss: -1.789383888244629.\n",
      "Discriminator model loss: -0.47823968529701233.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3721 of 5001.\n",
      "Step: 3722 of 5001.\n",
      "Step: 3723 of 5001.\n",
      "Step: 3724 of 5001.\n",
      "Step: 3725 of 5001.\n",
      "Step: 3726 of 5001.\n",
      "Step: 3727 of 5001.\n",
      "Step: 3728 of 5001.\n",
      "Step: 3729 of 5001.\n",
      "Step: 3730 of 5001.\n",
      "Generator model loss: -1.800686240196228.\n",
      "Discriminator model loss: -0.37402981519699097.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3731 of 5001.\n",
      "Step: 3732 of 5001.\n",
      "Step: 3733 of 5001.\n",
      "Step: 3734 of 5001.\n",
      "Step: 3735 of 5001.\n",
      "Step: 3736 of 5001.\n",
      "Step: 3737 of 5001.\n",
      "Step: 3738 of 5001.\n",
      "Step: 3739 of 5001.\n",
      "Step: 3740 of 5001.\n",
      "Generator model loss: -1.7999120950698853.\n",
      "Discriminator model loss: -0.46064192056655884.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3741 of 5001.\n",
      "Step: 3742 of 5001.\n",
      "Step: 3743 of 5001.\n",
      "Step: 3744 of 5001.\n",
      "Step: 3745 of 5001.\n",
      "Step: 3746 of 5001.\n",
      "Step: 3747 of 5001.\n",
      "Step: 3748 of 5001.\n",
      "Step: 3749 of 5001.\n",
      "Step: 3750 of 5001.\n",
      "Generator model loss: -1.827954649925232.\n",
      "Discriminator model loss: -0.36148005723953247.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3751 of 5001.\n",
      "Step: 3752 of 5001.\n",
      "Step: 3753 of 5001.\n",
      "Step: 3754 of 5001.\n",
      "Step: 3755 of 5001.\n",
      "Step: 3756 of 5001.\n",
      "Step: 3757 of 5001.\n",
      "Step: 3758 of 5001.\n",
      "Step: 3759 of 5001.\n",
      "Step: 3760 of 5001.\n",
      "Generator model loss: -1.7620656490325928.\n",
      "Discriminator model loss: -0.43147358298301697.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3761 of 5001.\n",
      "Step: 3762 of 5001.\n",
      "Step: 3763 of 5001.\n",
      "Step: 3764 of 5001.\n",
      "Step: 3765 of 5001.\n",
      "Step: 3766 of 5001.\n",
      "Step: 3767 of 5001.\n",
      "Step: 3768 of 5001.\n",
      "Step: 3769 of 5001.\n",
      "Step: 3770 of 5001.\n",
      "Generator model loss: -1.7973161935806274.\n",
      "Discriminator model loss: -0.40997129678726196.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3771 of 5001.\n",
      "Step: 3772 of 5001.\n",
      "Step: 3773 of 5001.\n",
      "Step: 3774 of 5001.\n",
      "Step: 3775 of 5001.\n",
      "Step: 3776 of 5001.\n",
      "Step: 3777 of 5001.\n",
      "Step: 3778 of 5001.\n",
      "Step: 3779 of 5001.\n",
      "Step: 3780 of 5001.\n",
      "Generator model loss: -1.7067819833755493.\n",
      "Discriminator model loss: -0.34572848677635193.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3781 of 5001.\n",
      "Step: 3782 of 5001.\n",
      "Step: 3783 of 5001.\n",
      "Step: 3784 of 5001.\n",
      "Step: 3785 of 5001.\n",
      "Step: 3786 of 5001.\n",
      "Step: 3787 of 5001.\n",
      "Step: 3788 of 5001.\n",
      "Step: 3789 of 5001.\n",
      "Step: 3790 of 5001.\n",
      "Generator model loss: -1.8029905557632446.\n",
      "Discriminator model loss: -0.3988393247127533.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3791 of 5001.\n",
      "Step: 3792 of 5001.\n",
      "Step: 3793 of 5001.\n",
      "Step: 3794 of 5001.\n",
      "Step: 3795 of 5001.\n",
      "Step: 3796 of 5001.\n",
      "Step: 3797 of 5001.\n",
      "Step: 3798 of 5001.\n",
      "Step: 3799 of 5001.\n",
      "Step: 3800 of 5001.\n",
      "Generator model loss: -1.7702808380126953.\n",
      "Discriminator model loss: -0.44396305084228516.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3801 of 5001.\n",
      "Step: 3802 of 5001.\n",
      "Step: 3803 of 5001.\n",
      "Step: 3804 of 5001.\n",
      "Step: 3805 of 5001.\n",
      "Step: 3806 of 5001.\n",
      "Step: 3807 of 5001.\n",
      "Step: 3808 of 5001.\n",
      "Step: 3809 of 5001.\n",
      "Step: 3810 of 5001.\n",
      "Generator model loss: -1.7259585857391357.\n",
      "Discriminator model loss: -0.4425883889198303.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3811 of 5001.\n",
      "Step: 3812 of 5001.\n",
      "Step: 3813 of 5001.\n",
      "Step: 3814 of 5001.\n",
      "Step: 3815 of 5001.\n",
      "Step: 3816 of 5001.\n",
      "Step: 3817 of 5001.\n",
      "Step: 3818 of 5001.\n",
      "Step: 3819 of 5001.\n",
      "Step: 3820 of 5001.\n",
      "Generator model loss: -1.8377599716186523.\n",
      "Discriminator model loss: -0.48251715302467346.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3821 of 5001.\n",
      "Step: 3822 of 5001.\n",
      "Step: 3823 of 5001.\n",
      "Step: 3824 of 5001.\n",
      "Step: 3825 of 5001.\n",
      "Step: 3826 of 5001.\n",
      "Step: 3827 of 5001.\n",
      "Step: 3828 of 5001.\n",
      "Step: 3829 of 5001.\n",
      "Step: 3830 of 5001.\n",
      "Generator model loss: -1.719748854637146.\n",
      "Discriminator model loss: -0.4714673161506653.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3831 of 5001.\n",
      "Step: 3832 of 5001.\n",
      "Step: 3833 of 5001.\n",
      "Step: 3834 of 5001.\n",
      "Step: 3835 of 5001.\n",
      "Step: 3836 of 5001.\n",
      "Step: 3837 of 5001.\n",
      "Step: 3838 of 5001.\n",
      "Step: 3839 of 5001.\n",
      "Step: 3840 of 5001.\n",
      "Generator model loss: -1.761021614074707.\n",
      "Discriminator model loss: -0.43788737058639526.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3841 of 5001.\n",
      "Step: 3842 of 5001.\n",
      "Step: 3843 of 5001.\n",
      "Step: 3844 of 5001.\n",
      "Step: 3845 of 5001.\n",
      "Step: 3846 of 5001.\n",
      "Step: 3847 of 5001.\n",
      "Step: 3848 of 5001.\n",
      "Step: 3849 of 5001.\n",
      "Step: 3850 of 5001.\n",
      "Generator model loss: -1.7832229137420654.\n",
      "Discriminator model loss: -0.4353163242340088.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3851 of 5001.\n",
      "Step: 3852 of 5001.\n",
      "Step: 3853 of 5001.\n",
      "Step: 3854 of 5001.\n",
      "Step: 3855 of 5001.\n",
      "Step: 3856 of 5001.\n",
      "Step: 3857 of 5001.\n",
      "Step: 3858 of 5001.\n",
      "Step: 3859 of 5001.\n",
      "Step: 3860 of 5001.\n",
      "Generator model loss: -1.7888696193695068.\n",
      "Discriminator model loss: -0.40961408615112305.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3861 of 5001.\n",
      "Step: 3862 of 5001.\n",
      "Step: 3863 of 5001.\n",
      "Step: 3864 of 5001.\n",
      "Step: 3865 of 5001.\n",
      "Step: 3866 of 5001.\n",
      "Step: 3867 of 5001.\n",
      "Step: 3868 of 5001.\n",
      "Step: 3869 of 5001.\n",
      "Step: 3870 of 5001.\n",
      "Generator model loss: -1.8272777795791626.\n",
      "Discriminator model loss: -0.44007277488708496.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3871 of 5001.\n",
      "Step: 3872 of 5001.\n",
      "Step: 3873 of 5001.\n",
      "Step: 3874 of 5001.\n",
      "Step: 3875 of 5001.\n",
      "Step: 3876 of 5001.\n",
      "Step: 3877 of 5001.\n",
      "Step: 3878 of 5001.\n",
      "Step: 3879 of 5001.\n",
      "Step: 3880 of 5001.\n",
      "Generator model loss: -1.7814899682998657.\n",
      "Discriminator model loss: -0.4616905152797699.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3881 of 5001.\n",
      "Step: 3882 of 5001.\n",
      "Step: 3883 of 5001.\n",
      "Step: 3884 of 5001.\n",
      "Step: 3885 of 5001.\n",
      "Step: 3886 of 5001.\n",
      "Step: 3887 of 5001.\n",
      "Step: 3888 of 5001.\n",
      "Step: 3889 of 5001.\n",
      "Step: 3890 of 5001.\n",
      "Generator model loss: -1.7547333240509033.\n",
      "Discriminator model loss: -0.4241562783718109.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3891 of 5001.\n",
      "Step: 3892 of 5001.\n",
      "Step: 3893 of 5001.\n",
      "Step: 3894 of 5001.\n",
      "Step: 3895 of 5001.\n",
      "Step: 3896 of 5001.\n",
      "Step: 3897 of 5001.\n",
      "Step: 3898 of 5001.\n",
      "Step: 3899 of 5001.\n",
      "Step: 3900 of 5001.\n",
      "Generator model loss: -1.831052541732788.\n",
      "Discriminator model loss: -0.4417933523654938.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3901 of 5001.\n",
      "Step: 3902 of 5001.\n",
      "Step: 3903 of 5001.\n",
      "Step: 3904 of 5001.\n",
      "Step: 3905 of 5001.\n",
      "Step: 3906 of 5001.\n",
      "Step: 3907 of 5001.\n",
      "Step: 3908 of 5001.\n",
      "Step: 3909 of 5001.\n",
      "Step: 3910 of 5001.\n",
      "Generator model loss: -1.8061485290527344.\n",
      "Discriminator model loss: -0.4783247411251068.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3911 of 5001.\n",
      "Step: 3912 of 5001.\n",
      "Step: 3913 of 5001.\n",
      "Step: 3914 of 5001.\n",
      "Step: 3915 of 5001.\n",
      "Step: 3916 of 5001.\n",
      "Step: 3917 of 5001.\n",
      "Step: 3918 of 5001.\n",
      "Step: 3919 of 5001.\n",
      "Step: 3920 of 5001.\n",
      "Generator model loss: -1.81870436668396.\n",
      "Discriminator model loss: -0.4353008270263672.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 3921 of 5001.\n",
      "Step: 3922 of 5001.\n",
      "Step: 3923 of 5001.\n",
      "Step: 3924 of 5001.\n",
      "Step: 3925 of 5001.\n",
      "Step: 3926 of 5001.\n",
      "Step: 3927 of 5001.\n",
      "Step: 3928 of 5001.\n",
      "Step: 3929 of 5001.\n",
      "Step: 3930 of 5001.\n",
      "Generator model loss: -1.8291162252426147.\n",
      "Discriminator model loss: -0.49206632375717163.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3931 of 5001.\n",
      "Step: 3932 of 5001.\n",
      "Step: 3933 of 5001.\n",
      "Step: 3934 of 5001.\n",
      "Step: 3935 of 5001.\n",
      "Step: 3936 of 5001.\n",
      "Step: 3937 of 5001.\n",
      "Step: 3938 of 5001.\n",
      "Step: 3939 of 5001.\n",
      "Step: 3940 of 5001.\n",
      "Generator model loss: -1.814828634262085.\n",
      "Discriminator model loss: -0.4204154908657074.\n",
      "xgboost accuracy: 0.73\n",
      "Step: 3941 of 5001.\n",
      "Step: 3942 of 5001.\n",
      "Step: 3943 of 5001.\n",
      "Step: 3944 of 5001.\n",
      "Step: 3945 of 5001.\n",
      "Step: 3946 of 5001.\n",
      "Step: 3947 of 5001.\n",
      "Step: 3948 of 5001.\n",
      "Step: 3949 of 5001.\n",
      "Step: 3950 of 5001.\n",
      "Generator model loss: -1.813576102256775.\n",
      "Discriminator model loss: -0.4564417898654938.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3951 of 5001.\n",
      "Step: 3952 of 5001.\n",
      "Step: 3953 of 5001.\n",
      "Step: 3954 of 5001.\n",
      "Step: 3955 of 5001.\n",
      "Step: 3956 of 5001.\n",
      "Step: 3957 of 5001.\n",
      "Step: 3958 of 5001.\n",
      "Step: 3959 of 5001.\n",
      "Step: 3960 of 5001.\n",
      "Generator model loss: -1.8124847412109375.\n",
      "Discriminator model loss: -0.48150426149368286.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3961 of 5001.\n",
      "Step: 3962 of 5001.\n",
      "Step: 3963 of 5001.\n",
      "Step: 3964 of 5001.\n",
      "Step: 3965 of 5001.\n",
      "Step: 3966 of 5001.\n",
      "Step: 3967 of 5001.\n",
      "Step: 3968 of 5001.\n",
      "Step: 3969 of 5001.\n",
      "Step: 3970 of 5001.\n",
      "Generator model loss: -1.8805561065673828.\n",
      "Discriminator model loss: -0.41991186141967773.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3971 of 5001.\n",
      "Step: 3972 of 5001.\n",
      "Step: 3973 of 5001.\n",
      "Step: 3974 of 5001.\n",
      "Step: 3975 of 5001.\n",
      "Step: 3976 of 5001.\n",
      "Step: 3977 of 5001.\n",
      "Step: 3978 of 5001.\n",
      "Step: 3979 of 5001.\n",
      "Step: 3980 of 5001.\n",
      "Generator model loss: -1.889190912246704.\n",
      "Discriminator model loss: -0.4635356366634369.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 3981 of 5001.\n",
      "Step: 3982 of 5001.\n",
      "Step: 3983 of 5001.\n",
      "Step: 3984 of 5001.\n",
      "Step: 3985 of 5001.\n",
      "Step: 3986 of 5001.\n",
      "Step: 3987 of 5001.\n",
      "Step: 3988 of 5001.\n",
      "Step: 3989 of 5001.\n",
      "Step: 3990 of 5001.\n",
      "Generator model loss: -1.9029947519302368.\n",
      "Discriminator model loss: -0.4169241487979889.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3991 of 5001.\n",
      "Step: 3992 of 5001.\n",
      "Step: 3993 of 5001.\n",
      "Step: 3994 of 5001.\n",
      "Step: 3995 of 5001.\n",
      "Step: 3996 of 5001.\n",
      "Step: 3997 of 5001.\n",
      "Step: 3998 of 5001.\n",
      "Step: 3999 of 5001.\n",
      "Step: 4000 of 5001.\n",
      "Generator model loss: -1.8724195957183838.\n",
      "Discriminator model loss: -0.37231990694999695.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4001 of 5001.\n",
      "Step: 4002 of 5001.\n",
      "Step: 4003 of 5001.\n",
      "Step: 4004 of 5001.\n",
      "Step: 4005 of 5001.\n",
      "Step: 4006 of 5001.\n",
      "Step: 4007 of 5001.\n",
      "Step: 4008 of 5001.\n",
      "Step: 4009 of 5001.\n",
      "Step: 4010 of 5001.\n",
      "Generator model loss: -1.9026215076446533.\n",
      "Discriminator model loss: -0.5235651731491089.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4011 of 5001.\n",
      "Step: 4012 of 5001.\n",
      "Step: 4013 of 5001.\n",
      "Step: 4014 of 5001.\n",
      "Step: 4015 of 5001.\n",
      "Step: 4016 of 5001.\n",
      "Step: 4017 of 5001.\n",
      "Step: 4018 of 5001.\n",
      "Step: 4019 of 5001.\n",
      "Step: 4020 of 5001.\n",
      "Generator model loss: -1.878043532371521.\n",
      "Discriminator model loss: -0.3468513786792755.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4021 of 5001.\n",
      "Step: 4022 of 5001.\n",
      "Step: 4023 of 5001.\n",
      "Step: 4024 of 5001.\n",
      "Step: 4025 of 5001.\n",
      "Step: 4026 of 5001.\n",
      "Step: 4027 of 5001.\n",
      "Step: 4028 of 5001.\n",
      "Step: 4029 of 5001.\n",
      "Step: 4030 of 5001.\n",
      "Generator model loss: -1.8577314615249634.\n",
      "Discriminator model loss: -0.44853949546813965.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4031 of 5001.\n",
      "Step: 4032 of 5001.\n",
      "Step: 4033 of 5001.\n",
      "Step: 4034 of 5001.\n",
      "Step: 4035 of 5001.\n",
      "Step: 4036 of 5001.\n",
      "Step: 4037 of 5001.\n",
      "Step: 4038 of 5001.\n",
      "Step: 4039 of 5001.\n",
      "Step: 4040 of 5001.\n",
      "Generator model loss: -1.8959782123565674.\n",
      "Discriminator model loss: -0.364883691072464.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4041 of 5001.\n",
      "Step: 4042 of 5001.\n",
      "Step: 4043 of 5001.\n",
      "Step: 4044 of 5001.\n",
      "Step: 4045 of 5001.\n",
      "Step: 4046 of 5001.\n",
      "Step: 4047 of 5001.\n",
      "Step: 4048 of 5001.\n",
      "Step: 4049 of 5001.\n",
      "Step: 4050 of 5001.\n",
      "Generator model loss: -1.8507236242294312.\n",
      "Discriminator model loss: -0.3587971329689026.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4051 of 5001.\n",
      "Step: 4052 of 5001.\n",
      "Step: 4053 of 5001.\n",
      "Step: 4054 of 5001.\n",
      "Step: 4055 of 5001.\n",
      "Step: 4056 of 5001.\n",
      "Step: 4057 of 5001.\n",
      "Step: 4058 of 5001.\n",
      "Step: 4059 of 5001.\n",
      "Step: 4060 of 5001.\n",
      "Generator model loss: -1.8788681030273438.\n",
      "Discriminator model loss: -0.4921588897705078.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4061 of 5001.\n",
      "Step: 4062 of 5001.\n",
      "Step: 4063 of 5001.\n",
      "Step: 4064 of 5001.\n",
      "Step: 4065 of 5001.\n",
      "Step: 4066 of 5001.\n",
      "Step: 4067 of 5001.\n",
      "Step: 4068 of 5001.\n",
      "Step: 4069 of 5001.\n",
      "Step: 4070 of 5001.\n",
      "Generator model loss: -1.880807638168335.\n",
      "Discriminator model loss: -0.4490016996860504.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 4071 of 5001.\n",
      "Step: 4072 of 5001.\n",
      "Step: 4073 of 5001.\n",
      "Step: 4074 of 5001.\n",
      "Step: 4075 of 5001.\n",
      "Step: 4076 of 5001.\n",
      "Step: 4077 of 5001.\n",
      "Step: 4078 of 5001.\n",
      "Step: 4079 of 5001.\n",
      "Step: 4080 of 5001.\n",
      "Generator model loss: -1.934142827987671.\n",
      "Discriminator model loss: -0.37311434745788574.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4081 of 5001.\n",
      "Step: 4082 of 5001.\n",
      "Step: 4083 of 5001.\n",
      "Step: 4084 of 5001.\n",
      "Step: 4085 of 5001.\n",
      "Step: 4086 of 5001.\n",
      "Step: 4087 of 5001.\n",
      "Step: 4088 of 5001.\n",
      "Step: 4089 of 5001.\n",
      "Step: 4090 of 5001.\n",
      "Generator model loss: -1.9059619903564453.\n",
      "Discriminator model loss: -0.4074983596801758.\n",
      "xgboost accuracy: 0.69\n",
      "Step: 4091 of 5001.\n",
      "Step: 4092 of 5001.\n",
      "Step: 4093 of 5001.\n",
      "Step: 4094 of 5001.\n",
      "Step: 4095 of 5001.\n",
      "Step: 4096 of 5001.\n",
      "Step: 4097 of 5001.\n",
      "Step: 4098 of 5001.\n",
      "Step: 4099 of 5001.\n",
      "Step: 4100 of 5001.\n",
      "Generator model loss: -1.8405702114105225.\n",
      "Discriminator model loss: -0.4732646942138672.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4101 of 5001.\n",
      "Step: 4102 of 5001.\n",
      "Step: 4103 of 5001.\n",
      "Step: 4104 of 5001.\n",
      "Step: 4105 of 5001.\n",
      "Step: 4106 of 5001.\n",
      "Step: 4107 of 5001.\n",
      "Step: 4108 of 5001.\n",
      "Step: 4109 of 5001.\n",
      "Step: 4110 of 5001.\n",
      "Generator model loss: -1.942842721939087.\n",
      "Discriminator model loss: -0.4429141879081726.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4111 of 5001.\n",
      "Step: 4112 of 5001.\n",
      "Step: 4113 of 5001.\n",
      "Step: 4114 of 5001.\n",
      "Step: 4115 of 5001.\n",
      "Step: 4116 of 5001.\n",
      "Step: 4117 of 5001.\n",
      "Step: 4118 of 5001.\n",
      "Step: 4119 of 5001.\n",
      "Step: 4120 of 5001.\n",
      "Generator model loss: -1.921755075454712.\n",
      "Discriminator model loss: -0.3799625635147095.\n",
      "xgboost accuracy: 0.72\n",
      "Step: 4121 of 5001.\n",
      "Step: 4122 of 5001.\n",
      "Step: 4123 of 5001.\n",
      "Step: 4124 of 5001.\n",
      "Step: 4125 of 5001.\n",
      "Step: 4126 of 5001.\n",
      "Step: 4127 of 5001.\n",
      "Step: 4128 of 5001.\n",
      "Step: 4129 of 5001.\n",
      "Step: 4130 of 5001.\n",
      "Generator model loss: -1.8906614780426025.\n",
      "Discriminator model loss: -0.330933153629303.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4131 of 5001.\n",
      "Step: 4132 of 5001.\n",
      "Step: 4133 of 5001.\n",
      "Step: 4134 of 5001.\n",
      "Step: 4135 of 5001.\n",
      "Step: 4136 of 5001.\n",
      "Step: 4137 of 5001.\n",
      "Step: 4138 of 5001.\n",
      "Step: 4139 of 5001.\n",
      "Step: 4140 of 5001.\n",
      "Generator model loss: -1.858660101890564.\n",
      "Discriminator model loss: -0.36948737502098083.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4141 of 5001.\n",
      "Step: 4142 of 5001.\n",
      "Step: 4143 of 5001.\n",
      "Step: 4144 of 5001.\n",
      "Step: 4145 of 5001.\n",
      "Step: 4146 of 5001.\n",
      "Step: 4147 of 5001.\n",
      "Step: 4148 of 5001.\n",
      "Step: 4149 of 5001.\n",
      "Step: 4150 of 5001.\n",
      "Generator model loss: -1.9581420421600342.\n",
      "Discriminator model loss: -0.33339986205101013.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4151 of 5001.\n",
      "Step: 4152 of 5001.\n",
      "Step: 4153 of 5001.\n",
      "Step: 4154 of 5001.\n",
      "Step: 4155 of 5001.\n",
      "Step: 4156 of 5001.\n",
      "Step: 4157 of 5001.\n",
      "Step: 4158 of 5001.\n",
      "Step: 4159 of 5001.\n",
      "Step: 4160 of 5001.\n",
      "Generator model loss: -1.882723093032837.\n",
      "Discriminator model loss: -0.40395426750183105.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4161 of 5001.\n",
      "Step: 4162 of 5001.\n",
      "Step: 4163 of 5001.\n",
      "Step: 4164 of 5001.\n",
      "Step: 4165 of 5001.\n",
      "Step: 4166 of 5001.\n",
      "Step: 4167 of 5001.\n",
      "Step: 4168 of 5001.\n",
      "Step: 4169 of 5001.\n",
      "Step: 4170 of 5001.\n",
      "Generator model loss: -1.8478214740753174.\n",
      "Discriminator model loss: -0.37566059827804565.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4171 of 5001.\n",
      "Step: 4172 of 5001.\n",
      "Step: 4173 of 5001.\n",
      "Step: 4174 of 5001.\n",
      "Step: 4175 of 5001.\n",
      "Step: 4176 of 5001.\n",
      "Step: 4177 of 5001.\n",
      "Step: 4178 of 5001.\n",
      "Step: 4179 of 5001.\n",
      "Step: 4180 of 5001.\n",
      "Generator model loss: -1.9141080379486084.\n",
      "Discriminator model loss: -0.4348002076148987.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4181 of 5001.\n",
      "Step: 4182 of 5001.\n",
      "Step: 4183 of 5001.\n",
      "Step: 4184 of 5001.\n",
      "Step: 4185 of 5001.\n",
      "Step: 4186 of 5001.\n",
      "Step: 4187 of 5001.\n",
      "Step: 4188 of 5001.\n",
      "Step: 4189 of 5001.\n",
      "Step: 4190 of 5001.\n",
      "Generator model loss: -1.9067306518554688.\n",
      "Discriminator model loss: -0.29082968831062317.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4191 of 5001.\n",
      "Step: 4192 of 5001.\n",
      "Step: 4193 of 5001.\n",
      "Step: 4194 of 5001.\n",
      "Step: 4195 of 5001.\n",
      "Step: 4196 of 5001.\n",
      "Step: 4197 of 5001.\n",
      "Step: 4198 of 5001.\n",
      "Step: 4199 of 5001.\n",
      "Step: 4200 of 5001.\n",
      "Generator model loss: -1.8829796314239502.\n",
      "Discriminator model loss: -0.3596876561641693.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4201 of 5001.\n",
      "Step: 4202 of 5001.\n",
      "Step: 4203 of 5001.\n",
      "Step: 4204 of 5001.\n",
      "Step: 4205 of 5001.\n",
      "Step: 4206 of 5001.\n",
      "Step: 4207 of 5001.\n",
      "Step: 4208 of 5001.\n",
      "Step: 4209 of 5001.\n",
      "Step: 4210 of 5001.\n",
      "Generator model loss: -1.9092906713485718.\n",
      "Discriminator model loss: -0.5004484057426453.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4211 of 5001.\n",
      "Step: 4212 of 5001.\n",
      "Step: 4213 of 5001.\n",
      "Step: 4214 of 5001.\n",
      "Step: 4215 of 5001.\n",
      "Step: 4216 of 5001.\n",
      "Step: 4217 of 5001.\n",
      "Step: 4218 of 5001.\n",
      "Step: 4219 of 5001.\n",
      "Step: 4220 of 5001.\n",
      "Generator model loss: -1.8913408517837524.\n",
      "Discriminator model loss: -0.4510117471218109.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4221 of 5001.\n",
      "Step: 4222 of 5001.\n",
      "Step: 4223 of 5001.\n",
      "Step: 4224 of 5001.\n",
      "Step: 4225 of 5001.\n",
      "Step: 4226 of 5001.\n",
      "Step: 4227 of 5001.\n",
      "Step: 4228 of 5001.\n",
      "Step: 4229 of 5001.\n",
      "Step: 4230 of 5001.\n",
      "Generator model loss: -1.9135442972183228.\n",
      "Discriminator model loss: -0.39115825295448303.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4231 of 5001.\n",
      "Step: 4232 of 5001.\n",
      "Step: 4233 of 5001.\n",
      "Step: 4234 of 5001.\n",
      "Step: 4235 of 5001.\n",
      "Step: 4236 of 5001.\n",
      "Step: 4237 of 5001.\n",
      "Step: 4238 of 5001.\n",
      "Step: 4239 of 5001.\n",
      "Step: 4240 of 5001.\n",
      "Generator model loss: -1.915099859237671.\n",
      "Discriminator model loss: -0.5135637521743774.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4241 of 5001.\n",
      "Step: 4242 of 5001.\n",
      "Step: 4243 of 5001.\n",
      "Step: 4244 of 5001.\n",
      "Step: 4245 of 5001.\n",
      "Step: 4246 of 5001.\n",
      "Step: 4247 of 5001.\n",
      "Step: 4248 of 5001.\n",
      "Step: 4249 of 5001.\n",
      "Step: 4250 of 5001.\n",
      "Generator model loss: -1.9524799585342407.\n",
      "Discriminator model loss: -0.32994019985198975.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4251 of 5001.\n",
      "Step: 4252 of 5001.\n",
      "Step: 4253 of 5001.\n",
      "Step: 4254 of 5001.\n",
      "Step: 4255 of 5001.\n",
      "Step: 4256 of 5001.\n",
      "Step: 4257 of 5001.\n",
      "Step: 4258 of 5001.\n",
      "Step: 4259 of 5001.\n",
      "Step: 4260 of 5001.\n",
      "Generator model loss: -1.9317748546600342.\n",
      "Discriminator model loss: -0.33486026525497437.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4261 of 5001.\n",
      "Step: 4262 of 5001.\n",
      "Step: 4263 of 5001.\n",
      "Step: 4264 of 5001.\n",
      "Step: 4265 of 5001.\n",
      "Step: 4266 of 5001.\n",
      "Step: 4267 of 5001.\n",
      "Step: 4268 of 5001.\n",
      "Step: 4269 of 5001.\n",
      "Step: 4270 of 5001.\n",
      "Generator model loss: -1.8878090381622314.\n",
      "Discriminator model loss: -0.3668736517429352.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4271 of 5001.\n",
      "Step: 4272 of 5001.\n",
      "Step: 4273 of 5001.\n",
      "Step: 4274 of 5001.\n",
      "Step: 4275 of 5001.\n",
      "Step: 4276 of 5001.\n",
      "Step: 4277 of 5001.\n",
      "Step: 4278 of 5001.\n",
      "Step: 4279 of 5001.\n",
      "Step: 4280 of 5001.\n",
      "Generator model loss: -1.944079041481018.\n",
      "Discriminator model loss: -0.40842676162719727.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4281 of 5001.\n",
      "Step: 4282 of 5001.\n",
      "Step: 4283 of 5001.\n",
      "Step: 4284 of 5001.\n",
      "Step: 4285 of 5001.\n",
      "Step: 4286 of 5001.\n",
      "Step: 4287 of 5001.\n",
      "Step: 4288 of 5001.\n",
      "Step: 4289 of 5001.\n",
      "Step: 4290 of 5001.\n",
      "Generator model loss: -1.8872950077056885.\n",
      "Discriminator model loss: -0.4869464933872223.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4291 of 5001.\n",
      "Step: 4292 of 5001.\n",
      "Step: 4293 of 5001.\n",
      "Step: 4294 of 5001.\n",
      "Step: 4295 of 5001.\n",
      "Step: 4296 of 5001.\n",
      "Step: 4297 of 5001.\n",
      "Step: 4298 of 5001.\n",
      "Step: 4299 of 5001.\n",
      "Step: 4300 of 5001.\n",
      "Generator model loss: -1.8966811895370483.\n",
      "Discriminator model loss: -0.45653820037841797.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4301 of 5001.\n",
      "Step: 4302 of 5001.\n",
      "Step: 4303 of 5001.\n",
      "Step: 4304 of 5001.\n",
      "Step: 4305 of 5001.\n",
      "Step: 4306 of 5001.\n",
      "Step: 4307 of 5001.\n",
      "Step: 4308 of 5001.\n",
      "Step: 4309 of 5001.\n",
      "Step: 4310 of 5001.\n",
      "Generator model loss: -1.9136720895767212.\n",
      "Discriminator model loss: -0.45568981766700745.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4311 of 5001.\n",
      "Step: 4312 of 5001.\n",
      "Step: 4313 of 5001.\n",
      "Step: 4314 of 5001.\n",
      "Step: 4315 of 5001.\n",
      "Step: 4316 of 5001.\n",
      "Step: 4317 of 5001.\n",
      "Step: 4318 of 5001.\n",
      "Step: 4319 of 5001.\n",
      "Step: 4320 of 5001.\n",
      "Generator model loss: -1.929745078086853.\n",
      "Discriminator model loss: -0.3209154009819031.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4321 of 5001.\n",
      "Step: 4322 of 5001.\n",
      "Step: 4323 of 5001.\n",
      "Step: 4324 of 5001.\n",
      "Step: 4325 of 5001.\n",
      "Step: 4326 of 5001.\n",
      "Step: 4327 of 5001.\n",
      "Step: 4328 of 5001.\n",
      "Step: 4329 of 5001.\n",
      "Step: 4330 of 5001.\n",
      "Generator model loss: -1.931314468383789.\n",
      "Discriminator model loss: -0.3562368154525757.\n",
      "xgboost accuracy: 0.72\n",
      "Step: 4331 of 5001.\n",
      "Step: 4332 of 5001.\n",
      "Step: 4333 of 5001.\n",
      "Step: 4334 of 5001.\n",
      "Step: 4335 of 5001.\n",
      "Step: 4336 of 5001.\n",
      "Step: 4337 of 5001.\n",
      "Step: 4338 of 5001.\n",
      "Step: 4339 of 5001.\n",
      "Step: 4340 of 5001.\n",
      "Generator model loss: -1.9181913137435913.\n",
      "Discriminator model loss: -0.3655761778354645.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4341 of 5001.\n",
      "Step: 4342 of 5001.\n",
      "Step: 4343 of 5001.\n",
      "Step: 4344 of 5001.\n",
      "Step: 4345 of 5001.\n",
      "Step: 4346 of 5001.\n",
      "Step: 4347 of 5001.\n",
      "Step: 4348 of 5001.\n",
      "Step: 4349 of 5001.\n",
      "Step: 4350 of 5001.\n",
      "Generator model loss: -1.9147374629974365.\n",
      "Discriminator model loss: -0.3388810157775879.\n",
      "xgboost accuracy: 0.73\n",
      "Step: 4351 of 5001.\n",
      "Step: 4352 of 5001.\n",
      "Step: 4353 of 5001.\n",
      "Step: 4354 of 5001.\n",
      "Step: 4355 of 5001.\n",
      "Step: 4356 of 5001.\n",
      "Step: 4357 of 5001.\n",
      "Step: 4358 of 5001.\n",
      "Step: 4359 of 5001.\n",
      "Step: 4360 of 5001.\n",
      "Generator model loss: -1.977799654006958.\n",
      "Discriminator model loss: -0.3961079716682434.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4361 of 5001.\n",
      "Step: 4362 of 5001.\n",
      "Step: 4363 of 5001.\n",
      "Step: 4364 of 5001.\n",
      "Step: 4365 of 5001.\n",
      "Step: 4366 of 5001.\n",
      "Step: 4367 of 5001.\n",
      "Step: 4368 of 5001.\n",
      "Step: 4369 of 5001.\n",
      "Step: 4370 of 5001.\n",
      "Generator model loss: -1.915051817893982.\n",
      "Discriminator model loss: -0.3927413821220398.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4371 of 5001.\n",
      "Step: 4372 of 5001.\n",
      "Step: 4373 of 5001.\n",
      "Step: 4374 of 5001.\n",
      "Step: 4375 of 5001.\n",
      "Step: 4376 of 5001.\n",
      "Step: 4377 of 5001.\n",
      "Step: 4378 of 5001.\n",
      "Step: 4379 of 5001.\n",
      "Step: 4380 of 5001.\n",
      "Generator model loss: -1.9019384384155273.\n",
      "Discriminator model loss: -0.4084354043006897.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4381 of 5001.\n",
      "Step: 4382 of 5001.\n",
      "Step: 4383 of 5001.\n",
      "Step: 4384 of 5001.\n",
      "Step: 4385 of 5001.\n",
      "Step: 4386 of 5001.\n",
      "Step: 4387 of 5001.\n",
      "Step: 4388 of 5001.\n",
      "Step: 4389 of 5001.\n",
      "Step: 4390 of 5001.\n",
      "Generator model loss: -1.8991626501083374.\n",
      "Discriminator model loss: -0.32143473625183105.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 4391 of 5001.\n",
      "Step: 4392 of 5001.\n",
      "Step: 4393 of 5001.\n",
      "Step: 4394 of 5001.\n",
      "Step: 4395 of 5001.\n",
      "Step: 4396 of 5001.\n",
      "Step: 4397 of 5001.\n",
      "Step: 4398 of 5001.\n",
      "Step: 4399 of 5001.\n",
      "Step: 4400 of 5001.\n",
      "Generator model loss: -1.924391746520996.\n",
      "Discriminator model loss: -0.3860616981983185.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 4401 of 5001.\n",
      "Step: 4402 of 5001.\n",
      "Step: 4403 of 5001.\n",
      "Step: 4404 of 5001.\n",
      "Step: 4405 of 5001.\n",
      "Step: 4406 of 5001.\n",
      "Step: 4407 of 5001.\n",
      "Step: 4408 of 5001.\n",
      "Step: 4409 of 5001.\n",
      "Step: 4410 of 5001.\n",
      "Generator model loss: -1.8930823802947998.\n",
      "Discriminator model loss: -0.3620612621307373.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4411 of 5001.\n",
      "Step: 4412 of 5001.\n",
      "Step: 4413 of 5001.\n",
      "Step: 4414 of 5001.\n",
      "Step: 4415 of 5001.\n",
      "Step: 4416 of 5001.\n",
      "Step: 4417 of 5001.\n",
      "Step: 4418 of 5001.\n",
      "Step: 4419 of 5001.\n",
      "Step: 4420 of 5001.\n",
      "Generator model loss: -1.9198964834213257.\n",
      "Discriminator model loss: -0.37045758962631226.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4421 of 5001.\n",
      "Step: 4422 of 5001.\n",
      "Step: 4423 of 5001.\n",
      "Step: 4424 of 5001.\n",
      "Step: 4425 of 5001.\n",
      "Step: 4426 of 5001.\n",
      "Step: 4427 of 5001.\n",
      "Step: 4428 of 5001.\n",
      "Step: 4429 of 5001.\n",
      "Step: 4430 of 5001.\n",
      "Generator model loss: -1.8559296131134033.\n",
      "Discriminator model loss: -0.3795207440853119.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4431 of 5001.\n",
      "Step: 4432 of 5001.\n",
      "Step: 4433 of 5001.\n",
      "Step: 4434 of 5001.\n",
      "Step: 4435 of 5001.\n",
      "Step: 4436 of 5001.\n",
      "Step: 4437 of 5001.\n",
      "Step: 4438 of 5001.\n",
      "Step: 4439 of 5001.\n",
      "Step: 4440 of 5001.\n",
      "Generator model loss: -1.945062279701233.\n",
      "Discriminator model loss: -0.3943052589893341.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4441 of 5001.\n",
      "Step: 4442 of 5001.\n",
      "Step: 4443 of 5001.\n",
      "Step: 4444 of 5001.\n",
      "Step: 4445 of 5001.\n",
      "Step: 4446 of 5001.\n",
      "Step: 4447 of 5001.\n",
      "Step: 4448 of 5001.\n",
      "Step: 4449 of 5001.\n",
      "Step: 4450 of 5001.\n",
      "Generator model loss: -1.911807656288147.\n",
      "Discriminator model loss: -0.33211201429367065.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4451 of 5001.\n",
      "Step: 4452 of 5001.\n",
      "Step: 4453 of 5001.\n",
      "Step: 4454 of 5001.\n",
      "Step: 4455 of 5001.\n",
      "Step: 4456 of 5001.\n",
      "Step: 4457 of 5001.\n",
      "Step: 4458 of 5001.\n",
      "Step: 4459 of 5001.\n",
      "Step: 4460 of 5001.\n",
      "Generator model loss: -1.9318794012069702.\n",
      "Discriminator model loss: -0.34377002716064453.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4461 of 5001.\n",
      "Step: 4462 of 5001.\n",
      "Step: 4463 of 5001.\n",
      "Step: 4464 of 5001.\n",
      "Step: 4465 of 5001.\n",
      "Step: 4466 of 5001.\n",
      "Step: 4467 of 5001.\n",
      "Step: 4468 of 5001.\n",
      "Step: 4469 of 5001.\n",
      "Step: 4470 of 5001.\n",
      "Generator model loss: -1.8783533573150635.\n",
      "Discriminator model loss: -0.3364294171333313.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4471 of 5001.\n",
      "Step: 4472 of 5001.\n",
      "Step: 4473 of 5001.\n",
      "Step: 4474 of 5001.\n",
      "Step: 4475 of 5001.\n",
      "Step: 4476 of 5001.\n",
      "Step: 4477 of 5001.\n",
      "Step: 4478 of 5001.\n",
      "Step: 4479 of 5001.\n",
      "Step: 4480 of 5001.\n",
      "Generator model loss: -1.923663854598999.\n",
      "Discriminator model loss: -0.46592360734939575.\n",
      "xgboost accuracy: 0.73\n",
      "Step: 4481 of 5001.\n",
      "Step: 4482 of 5001.\n",
      "Step: 4483 of 5001.\n",
      "Step: 4484 of 5001.\n",
      "Step: 4485 of 5001.\n",
      "Step: 4486 of 5001.\n",
      "Step: 4487 of 5001.\n",
      "Step: 4488 of 5001.\n",
      "Step: 4489 of 5001.\n",
      "Step: 4490 of 5001.\n",
      "Generator model loss: -1.9557876586914062.\n",
      "Discriminator model loss: -0.44066181778907776.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4491 of 5001.\n",
      "Step: 4492 of 5001.\n",
      "Step: 4493 of 5001.\n",
      "Step: 4494 of 5001.\n",
      "Step: 4495 of 5001.\n",
      "Step: 4496 of 5001.\n",
      "Step: 4497 of 5001.\n",
      "Step: 4498 of 5001.\n",
      "Step: 4499 of 5001.\n",
      "Step: 4500 of 5001.\n",
      "Generator model loss: -1.916275978088379.\n",
      "Discriminator model loss: -0.32343918085098267.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4501 of 5001.\n",
      "Step: 4502 of 5001.\n",
      "Step: 4503 of 5001.\n",
      "Step: 4504 of 5001.\n",
      "Step: 4505 of 5001.\n",
      "Step: 4506 of 5001.\n",
      "Step: 4507 of 5001.\n",
      "Step: 4508 of 5001.\n",
      "Step: 4509 of 5001.\n",
      "Step: 4510 of 5001.\n",
      "Generator model loss: -1.962268590927124.\n",
      "Discriminator model loss: -0.39444416761398315.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4511 of 5001.\n",
      "Step: 4512 of 5001.\n",
      "Step: 4513 of 5001.\n",
      "Step: 4514 of 5001.\n",
      "Step: 4515 of 5001.\n",
      "Step: 4516 of 5001.\n",
      "Step: 4517 of 5001.\n",
      "Step: 4518 of 5001.\n",
      "Step: 4519 of 5001.\n",
      "Step: 4520 of 5001.\n",
      "Generator model loss: -1.8753511905670166.\n",
      "Discriminator model loss: -0.3757026493549347.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4521 of 5001.\n",
      "Step: 4522 of 5001.\n",
      "Step: 4523 of 5001.\n",
      "Step: 4524 of 5001.\n",
      "Step: 4525 of 5001.\n",
      "Step: 4526 of 5001.\n",
      "Step: 4527 of 5001.\n",
      "Step: 4528 of 5001.\n",
      "Step: 4529 of 5001.\n",
      "Step: 4530 of 5001.\n",
      "Generator model loss: -1.8960578441619873.\n",
      "Discriminator model loss: -0.3628303110599518.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4531 of 5001.\n",
      "Step: 4532 of 5001.\n",
      "Step: 4533 of 5001.\n",
      "Step: 4534 of 5001.\n",
      "Step: 4535 of 5001.\n",
      "Step: 4536 of 5001.\n",
      "Step: 4537 of 5001.\n",
      "Step: 4538 of 5001.\n",
      "Step: 4539 of 5001.\n",
      "Step: 4540 of 5001.\n",
      "Generator model loss: -1.940306305885315.\n",
      "Discriminator model loss: -0.41244202852249146.\n",
      "xgboost accuracy: 0.73\n",
      "Step: 4541 of 5001.\n",
      "Step: 4542 of 5001.\n",
      "Step: 4543 of 5001.\n",
      "Step: 4544 of 5001.\n",
      "Step: 4545 of 5001.\n",
      "Step: 4546 of 5001.\n",
      "Step: 4547 of 5001.\n",
      "Step: 4548 of 5001.\n",
      "Step: 4549 of 5001.\n",
      "Step: 4550 of 5001.\n",
      "Generator model loss: -1.8830242156982422.\n",
      "Discriminator model loss: -0.4382762908935547.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4551 of 5001.\n",
      "Step: 4552 of 5001.\n",
      "Step: 4553 of 5001.\n",
      "Step: 4554 of 5001.\n",
      "Step: 4555 of 5001.\n",
      "Step: 4556 of 5001.\n",
      "Step: 4557 of 5001.\n",
      "Step: 4558 of 5001.\n",
      "Step: 4559 of 5001.\n",
      "Step: 4560 of 5001.\n",
      "Generator model loss: -1.9083064794540405.\n",
      "Discriminator model loss: -0.39346519112586975.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4561 of 5001.\n",
      "Step: 4562 of 5001.\n",
      "Step: 4563 of 5001.\n",
      "Step: 4564 of 5001.\n",
      "Step: 4565 of 5001.\n",
      "Step: 4566 of 5001.\n",
      "Step: 4567 of 5001.\n",
      "Step: 4568 of 5001.\n",
      "Step: 4569 of 5001.\n",
      "Step: 4570 of 5001.\n",
      "Generator model loss: -1.9419111013412476.\n",
      "Discriminator model loss: -0.4709114134311676.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 4571 of 5001.\n",
      "Step: 4572 of 5001.\n",
      "Step: 4573 of 5001.\n",
      "Step: 4574 of 5001.\n",
      "Step: 4575 of 5001.\n",
      "Step: 4576 of 5001.\n",
      "Step: 4577 of 5001.\n",
      "Step: 4578 of 5001.\n",
      "Step: 4579 of 5001.\n",
      "Step: 4580 of 5001.\n",
      "Generator model loss: -1.9873406887054443.\n",
      "Discriminator model loss: -0.40995708107948303.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4581 of 5001.\n",
      "Step: 4582 of 5001.\n",
      "Step: 4583 of 5001.\n",
      "Step: 4584 of 5001.\n",
      "Step: 4585 of 5001.\n",
      "Step: 4586 of 5001.\n",
      "Step: 4587 of 5001.\n",
      "Step: 4588 of 5001.\n",
      "Step: 4589 of 5001.\n",
      "Step: 4590 of 5001.\n",
      "Generator model loss: -1.9573132991790771.\n",
      "Discriminator model loss: -0.3461918234825134.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4591 of 5001.\n",
      "Step: 4592 of 5001.\n",
      "Step: 4593 of 5001.\n",
      "Step: 4594 of 5001.\n",
      "Step: 4595 of 5001.\n",
      "Step: 4596 of 5001.\n",
      "Step: 4597 of 5001.\n",
      "Step: 4598 of 5001.\n",
      "Step: 4599 of 5001.\n",
      "Step: 4600 of 5001.\n",
      "Generator model loss: -1.941467523574829.\n",
      "Discriminator model loss: -0.3554297983646393.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4601 of 5001.\n",
      "Step: 4602 of 5001.\n",
      "Step: 4603 of 5001.\n",
      "Step: 4604 of 5001.\n",
      "Step: 4605 of 5001.\n",
      "Step: 4606 of 5001.\n",
      "Step: 4607 of 5001.\n",
      "Step: 4608 of 5001.\n",
      "Step: 4609 of 5001.\n",
      "Step: 4610 of 5001.\n",
      "Generator model loss: -1.9448463916778564.\n",
      "Discriminator model loss: -0.26047658920288086.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4611 of 5001.\n",
      "Step: 4612 of 5001.\n",
      "Step: 4613 of 5001.\n",
      "Step: 4614 of 5001.\n",
      "Step: 4615 of 5001.\n",
      "Step: 4616 of 5001.\n",
      "Step: 4617 of 5001.\n",
      "Step: 4618 of 5001.\n",
      "Step: 4619 of 5001.\n",
      "Step: 4620 of 5001.\n",
      "Generator model loss: -1.9903061389923096.\n",
      "Discriminator model loss: -0.30031466484069824.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4621 of 5001.\n",
      "Step: 4622 of 5001.\n",
      "Step: 4623 of 5001.\n",
      "Step: 4624 of 5001.\n",
      "Step: 4625 of 5001.\n",
      "Step: 4626 of 5001.\n",
      "Step: 4627 of 5001.\n",
      "Step: 4628 of 5001.\n",
      "Step: 4629 of 5001.\n",
      "Step: 4630 of 5001.\n",
      "Generator model loss: -1.9269883632659912.\n",
      "Discriminator model loss: -0.40380120277404785.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4631 of 5001.\n",
      "Step: 4632 of 5001.\n",
      "Step: 4633 of 5001.\n",
      "Step: 4634 of 5001.\n",
      "Step: 4635 of 5001.\n",
      "Step: 4636 of 5001.\n",
      "Step: 4637 of 5001.\n",
      "Step: 4638 of 5001.\n",
      "Step: 4639 of 5001.\n",
      "Step: 4640 of 5001.\n",
      "Generator model loss: -1.9237966537475586.\n",
      "Discriminator model loss: -0.31242114305496216.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4641 of 5001.\n",
      "Step: 4642 of 5001.\n",
      "Step: 4643 of 5001.\n",
      "Step: 4644 of 5001.\n",
      "Step: 4645 of 5001.\n",
      "Step: 4646 of 5001.\n",
      "Step: 4647 of 5001.\n",
      "Step: 4648 of 5001.\n",
      "Step: 4649 of 5001.\n",
      "Step: 4650 of 5001.\n",
      "Generator model loss: -1.9652538299560547.\n",
      "Discriminator model loss: -0.4056347906589508.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4651 of 5001.\n",
      "Step: 4652 of 5001.\n",
      "Step: 4653 of 5001.\n",
      "Step: 4654 of 5001.\n",
      "Step: 4655 of 5001.\n",
      "Step: 4656 of 5001.\n",
      "Step: 4657 of 5001.\n",
      "Step: 4658 of 5001.\n",
      "Step: 4659 of 5001.\n",
      "Step: 4660 of 5001.\n",
      "Generator model loss: -1.8676977157592773.\n",
      "Discriminator model loss: -0.3751893937587738.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4661 of 5001.\n",
      "Step: 4662 of 5001.\n",
      "Step: 4663 of 5001.\n",
      "Step: 4664 of 5001.\n",
      "Step: 4665 of 5001.\n",
      "Step: 4666 of 5001.\n",
      "Step: 4667 of 5001.\n",
      "Step: 4668 of 5001.\n",
      "Step: 4669 of 5001.\n",
      "Step: 4670 of 5001.\n",
      "Generator model loss: -1.9064788818359375.\n",
      "Discriminator model loss: -0.34307920932769775.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4671 of 5001.\n",
      "Step: 4672 of 5001.\n",
      "Step: 4673 of 5001.\n",
      "Step: 4674 of 5001.\n",
      "Step: 4675 of 5001.\n",
      "Step: 4676 of 5001.\n",
      "Step: 4677 of 5001.\n",
      "Step: 4678 of 5001.\n",
      "Step: 4679 of 5001.\n",
      "Step: 4680 of 5001.\n",
      "Generator model loss: -1.921076774597168.\n",
      "Discriminator model loss: -0.3982735574245453.\n",
      "xgboost accuracy: 0.72\n",
      "Step: 4681 of 5001.\n",
      "Step: 4682 of 5001.\n",
      "Step: 4683 of 5001.\n",
      "Step: 4684 of 5001.\n",
      "Step: 4685 of 5001.\n",
      "Step: 4686 of 5001.\n",
      "Step: 4687 of 5001.\n",
      "Step: 4688 of 5001.\n",
      "Step: 4689 of 5001.\n",
      "Step: 4690 of 5001.\n",
      "Generator model loss: -1.9449046850204468.\n",
      "Discriminator model loss: -0.373244047164917.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4691 of 5001.\n",
      "Step: 4692 of 5001.\n",
      "Step: 4693 of 5001.\n",
      "Step: 4694 of 5001.\n",
      "Step: 4695 of 5001.\n",
      "Step: 4696 of 5001.\n",
      "Step: 4697 of 5001.\n",
      "Step: 4698 of 5001.\n",
      "Step: 4699 of 5001.\n",
      "Step: 4700 of 5001.\n",
      "Generator model loss: -1.9720131158828735.\n",
      "Discriminator model loss: -0.41370734572410583.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4701 of 5001.\n",
      "Step: 4702 of 5001.\n",
      "Step: 4703 of 5001.\n",
      "Step: 4704 of 5001.\n",
      "Step: 4705 of 5001.\n",
      "Step: 4706 of 5001.\n",
      "Step: 4707 of 5001.\n",
      "Step: 4708 of 5001.\n",
      "Step: 4709 of 5001.\n",
      "Step: 4710 of 5001.\n",
      "Generator model loss: -1.878950834274292.\n",
      "Discriminator model loss: -0.4087672233581543.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4711 of 5001.\n",
      "Step: 4712 of 5001.\n",
      "Step: 4713 of 5001.\n",
      "Step: 4714 of 5001.\n",
      "Step: 4715 of 5001.\n",
      "Step: 4716 of 5001.\n",
      "Step: 4717 of 5001.\n",
      "Step: 4718 of 5001.\n",
      "Step: 4719 of 5001.\n",
      "Step: 4720 of 5001.\n",
      "Generator model loss: -1.9188206195831299.\n",
      "Discriminator model loss: -0.4520145356655121.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4721 of 5001.\n",
      "Step: 4722 of 5001.\n",
      "Step: 4723 of 5001.\n",
      "Step: 4724 of 5001.\n",
      "Step: 4725 of 5001.\n",
      "Step: 4726 of 5001.\n",
      "Step: 4727 of 5001.\n",
      "Step: 4728 of 5001.\n",
      "Step: 4729 of 5001.\n",
      "Step: 4730 of 5001.\n",
      "Generator model loss: -1.880279302597046.\n",
      "Discriminator model loss: -0.40184131264686584.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4731 of 5001.\n",
      "Step: 4732 of 5001.\n",
      "Step: 4733 of 5001.\n",
      "Step: 4734 of 5001.\n",
      "Step: 4735 of 5001.\n",
      "Step: 4736 of 5001.\n",
      "Step: 4737 of 5001.\n",
      "Step: 4738 of 5001.\n",
      "Step: 4739 of 5001.\n",
      "Step: 4740 of 5001.\n",
      "Generator model loss: -1.9470033645629883.\n",
      "Discriminator model loss: -0.36014193296432495.\n",
      "xgboost accuracy: 0.73\n",
      "Step: 4741 of 5001.\n",
      "Step: 4742 of 5001.\n",
      "Step: 4743 of 5001.\n",
      "Step: 4744 of 5001.\n",
      "Step: 4745 of 5001.\n",
      "Step: 4746 of 5001.\n",
      "Step: 4747 of 5001.\n",
      "Step: 4748 of 5001.\n",
      "Step: 4749 of 5001.\n",
      "Step: 4750 of 5001.\n",
      "Generator model loss: -1.929138422012329.\n",
      "Discriminator model loss: -0.39102494716644287.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4751 of 5001.\n",
      "Step: 4752 of 5001.\n",
      "Step: 4753 of 5001.\n",
      "Step: 4754 of 5001.\n",
      "Step: 4755 of 5001.\n",
      "Step: 4756 of 5001.\n",
      "Step: 4757 of 5001.\n",
      "Step: 4758 of 5001.\n",
      "Step: 4759 of 5001.\n",
      "Step: 4760 of 5001.\n",
      "Generator model loss: -1.9233570098876953.\n",
      "Discriminator model loss: -0.4332491457462311.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4761 of 5001.\n",
      "Step: 4762 of 5001.\n",
      "Step: 4763 of 5001.\n",
      "Step: 4764 of 5001.\n",
      "Step: 4765 of 5001.\n",
      "Step: 4766 of 5001.\n",
      "Step: 4767 of 5001.\n",
      "Step: 4768 of 5001.\n",
      "Step: 4769 of 5001.\n",
      "Step: 4770 of 5001.\n",
      "Generator model loss: -1.9720475673675537.\n",
      "Discriminator model loss: -0.36165350675582886.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4771 of 5001.\n",
      "Step: 4772 of 5001.\n",
      "Step: 4773 of 5001.\n",
      "Step: 4774 of 5001.\n",
      "Step: 4775 of 5001.\n",
      "Step: 4776 of 5001.\n",
      "Step: 4777 of 5001.\n",
      "Step: 4778 of 5001.\n",
      "Step: 4779 of 5001.\n",
      "Step: 4780 of 5001.\n",
      "Generator model loss: -1.9220707416534424.\n",
      "Discriminator model loss: -0.35523825883865356.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4781 of 5001.\n",
      "Step: 4782 of 5001.\n",
      "Step: 4783 of 5001.\n",
      "Step: 4784 of 5001.\n",
      "Step: 4785 of 5001.\n",
      "Step: 4786 of 5001.\n",
      "Step: 4787 of 5001.\n",
      "Step: 4788 of 5001.\n",
      "Step: 4789 of 5001.\n",
      "Step: 4790 of 5001.\n",
      "Generator model loss: -1.9356565475463867.\n",
      "Discriminator model loss: -0.34816184639930725.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4791 of 5001.\n",
      "Step: 4792 of 5001.\n",
      "Step: 4793 of 5001.\n",
      "Step: 4794 of 5001.\n",
      "Step: 4795 of 5001.\n",
      "Step: 4796 of 5001.\n",
      "Step: 4797 of 5001.\n",
      "Step: 4798 of 5001.\n",
      "Step: 4799 of 5001.\n",
      "Step: 4800 of 5001.\n",
      "Generator model loss: -1.9271634817123413.\n",
      "Discriminator model loss: -0.25049635767936707.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4801 of 5001.\n",
      "Step: 4802 of 5001.\n",
      "Step: 4803 of 5001.\n",
      "Step: 4804 of 5001.\n",
      "Step: 4805 of 5001.\n",
      "Step: 4806 of 5001.\n",
      "Step: 4807 of 5001.\n",
      "Step: 4808 of 5001.\n",
      "Step: 4809 of 5001.\n",
      "Step: 4810 of 5001.\n",
      "Generator model loss: -1.9355604648590088.\n",
      "Discriminator model loss: -0.44796696305274963.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4811 of 5001.\n",
      "Step: 4812 of 5001.\n",
      "Step: 4813 of 5001.\n",
      "Step: 4814 of 5001.\n",
      "Step: 4815 of 5001.\n",
      "Step: 4816 of 5001.\n",
      "Step: 4817 of 5001.\n",
      "Step: 4818 of 5001.\n",
      "Step: 4819 of 5001.\n",
      "Step: 4820 of 5001.\n",
      "Generator model loss: -2.002119779586792.\n",
      "Discriminator model loss: -0.3832090497016907.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4821 of 5001.\n",
      "Step: 4822 of 5001.\n",
      "Step: 4823 of 5001.\n",
      "Step: 4824 of 5001.\n",
      "Step: 4825 of 5001.\n",
      "Step: 4826 of 5001.\n",
      "Step: 4827 of 5001.\n",
      "Step: 4828 of 5001.\n",
      "Step: 4829 of 5001.\n",
      "Step: 4830 of 5001.\n",
      "Generator model loss: -1.9978967905044556.\n",
      "Discriminator model loss: -0.3984191119670868.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4831 of 5001.\n",
      "Step: 4832 of 5001.\n",
      "Step: 4833 of 5001.\n",
      "Step: 4834 of 5001.\n",
      "Step: 4835 of 5001.\n",
      "Step: 4836 of 5001.\n",
      "Step: 4837 of 5001.\n",
      "Step: 4838 of 5001.\n",
      "Step: 4839 of 5001.\n",
      "Step: 4840 of 5001.\n",
      "Generator model loss: -1.8967536687850952.\n",
      "Discriminator model loss: -0.4354667663574219.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4841 of 5001.\n",
      "Step: 4842 of 5001.\n",
      "Step: 4843 of 5001.\n",
      "Step: 4844 of 5001.\n",
      "Step: 4845 of 5001.\n",
      "Step: 4846 of 5001.\n",
      "Step: 4847 of 5001.\n",
      "Step: 4848 of 5001.\n",
      "Step: 4849 of 5001.\n",
      "Step: 4850 of 5001.\n",
      "Generator model loss: -2.0285232067108154.\n",
      "Discriminator model loss: -0.49818968772888184.\n",
      "xgboost accuracy: 0.73\n",
      "Step: 4851 of 5001.\n",
      "Step: 4852 of 5001.\n",
      "Step: 4853 of 5001.\n",
      "Step: 4854 of 5001.\n",
      "Step: 4855 of 5001.\n",
      "Step: 4856 of 5001.\n",
      "Step: 4857 of 5001.\n",
      "Step: 4858 of 5001.\n",
      "Step: 4859 of 5001.\n",
      "Step: 4860 of 5001.\n",
      "Generator model loss: -1.984025239944458.\n",
      "Discriminator model loss: -0.41533857583999634.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4861 of 5001.\n",
      "Step: 4862 of 5001.\n",
      "Step: 4863 of 5001.\n",
      "Step: 4864 of 5001.\n",
      "Step: 4865 of 5001.\n",
      "Step: 4866 of 5001.\n",
      "Step: 4867 of 5001.\n",
      "Step: 4868 of 5001.\n",
      "Step: 4869 of 5001.\n",
      "Step: 4870 of 5001.\n",
      "Generator model loss: -1.9504859447479248.\n",
      "Discriminator model loss: -0.3162163197994232.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4871 of 5001.\n",
      "Step: 4872 of 5001.\n",
      "Step: 4873 of 5001.\n",
      "Step: 4874 of 5001.\n",
      "Step: 4875 of 5001.\n",
      "Step: 4876 of 5001.\n",
      "Step: 4877 of 5001.\n",
      "Step: 4878 of 5001.\n",
      "Step: 4879 of 5001.\n",
      "Step: 4880 of 5001.\n",
      "Generator model loss: -1.968858003616333.\n",
      "Discriminator model loss: -0.36253634095191956.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4881 of 5001.\n",
      "Step: 4882 of 5001.\n",
      "Step: 4883 of 5001.\n",
      "Step: 4884 of 5001.\n",
      "Step: 4885 of 5001.\n",
      "Step: 4886 of 5001.\n",
      "Step: 4887 of 5001.\n",
      "Step: 4888 of 5001.\n",
      "Step: 4889 of 5001.\n",
      "Step: 4890 of 5001.\n",
      "Generator model loss: -1.9842395782470703.\n",
      "Discriminator model loss: -0.42408761382102966.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4891 of 5001.\n",
      "Step: 4892 of 5001.\n",
      "Step: 4893 of 5001.\n",
      "Step: 4894 of 5001.\n",
      "Step: 4895 of 5001.\n",
      "Step: 4896 of 5001.\n",
      "Step: 4897 of 5001.\n",
      "Step: 4898 of 5001.\n",
      "Step: 4899 of 5001.\n",
      "Step: 4900 of 5001.\n",
      "Generator model loss: -2.070941925048828.\n",
      "Discriminator model loss: -0.4797908365726471.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4901 of 5001.\n",
      "Step: 4902 of 5001.\n",
      "Step: 4903 of 5001.\n",
      "Step: 4904 of 5001.\n",
      "Step: 4905 of 5001.\n",
      "Step: 4906 of 5001.\n",
      "Step: 4907 of 5001.\n",
      "Step: 4908 of 5001.\n",
      "Step: 4909 of 5001.\n",
      "Step: 4910 of 5001.\n",
      "Generator model loss: -1.9930458068847656.\n",
      "Discriminator model loss: -0.48684000968933105.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4911 of 5001.\n",
      "Step: 4912 of 5001.\n",
      "Step: 4913 of 5001.\n",
      "Step: 4914 of 5001.\n",
      "Step: 4915 of 5001.\n",
      "Step: 4916 of 5001.\n",
      "Step: 4917 of 5001.\n",
      "Step: 4918 of 5001.\n",
      "Step: 4919 of 5001.\n",
      "Step: 4920 of 5001.\n",
      "Generator model loss: -2.0007436275482178.\n",
      "Discriminator model loss: -0.3154210150241852.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4921 of 5001.\n",
      "Step: 4922 of 5001.\n",
      "Step: 4923 of 5001.\n",
      "Step: 4924 of 5001.\n",
      "Step: 4925 of 5001.\n",
      "Step: 4926 of 5001.\n",
      "Step: 4927 of 5001.\n",
      "Step: 4928 of 5001.\n",
      "Step: 4929 of 5001.\n",
      "Step: 4930 of 5001.\n",
      "Generator model loss: -1.9765822887420654.\n",
      "Discriminator model loss: -0.3869568705558777.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4931 of 5001.\n",
      "Step: 4932 of 5001.\n",
      "Step: 4933 of 5001.\n",
      "Step: 4934 of 5001.\n",
      "Step: 4935 of 5001.\n",
      "Step: 4936 of 5001.\n",
      "Step: 4937 of 5001.\n",
      "Step: 4938 of 5001.\n",
      "Step: 4939 of 5001.\n",
      "Step: 4940 of 5001.\n",
      "Generator model loss: -1.9974441528320312.\n",
      "Discriminator model loss: -0.3739408552646637.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4941 of 5001.\n",
      "Step: 4942 of 5001.\n",
      "Step: 4943 of 5001.\n",
      "Step: 4944 of 5001.\n",
      "Step: 4945 of 5001.\n",
      "Step: 4946 of 5001.\n",
      "Step: 4947 of 5001.\n",
      "Step: 4948 of 5001.\n",
      "Step: 4949 of 5001.\n",
      "Step: 4950 of 5001.\n",
      "Generator model loss: -1.924772024154663.\n",
      "Discriminator model loss: -0.40866145491600037.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4951 of 5001.\n",
      "Step: 4952 of 5001.\n",
      "Step: 4953 of 5001.\n",
      "Step: 4954 of 5001.\n",
      "Step: 4955 of 5001.\n",
      "Step: 4956 of 5001.\n",
      "Step: 4957 of 5001.\n",
      "Step: 4958 of 5001.\n",
      "Step: 4959 of 5001.\n",
      "Step: 4960 of 5001.\n",
      "Generator model loss: -2.00663423538208.\n",
      "Discriminator model loss: -0.29812684655189514.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4961 of 5001.\n",
      "Step: 4962 of 5001.\n",
      "Step: 4963 of 5001.\n",
      "Step: 4964 of 5001.\n",
      "Step: 4965 of 5001.\n",
      "Step: 4966 of 5001.\n",
      "Step: 4967 of 5001.\n",
      "Step: 4968 of 5001.\n",
      "Step: 4969 of 5001.\n",
      "Step: 4970 of 5001.\n",
      "Generator model loss: -1.8796418905258179.\n",
      "Discriminator model loss: -0.4556194841861725.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4971 of 5001.\n",
      "Step: 4972 of 5001.\n",
      "Step: 4973 of 5001.\n",
      "Step: 4974 of 5001.\n",
      "Step: 4975 of 5001.\n",
      "Step: 4976 of 5001.\n",
      "Step: 4977 of 5001.\n",
      "Step: 4978 of 5001.\n",
      "Step: 4979 of 5001.\n",
      "Step: 4980 of 5001.\n",
      "Generator model loss: -1.9246606826782227.\n",
      "Discriminator model loss: -0.36161693930625916.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4981 of 5001.\n",
      "Step: 4982 of 5001.\n",
      "Step: 4983 of 5001.\n",
      "Step: 4984 of 5001.\n",
      "Step: 4985 of 5001.\n",
      "Step: 4986 of 5001.\n",
      "Step: 4987 of 5001.\n",
      "Step: 4988 of 5001.\n",
      "Step: 4989 of 5001.\n",
      "Step: 4990 of 5001.\n",
      "Generator model loss: -1.963213324546814.\n",
      "Discriminator model loss: -0.3378252387046814.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4991 of 5001.\n",
      "Step: 4992 of 5001.\n",
      "Step: 4993 of 5001.\n",
      "Step: 4994 of 5001.\n",
      "Step: 4995 of 5001.\n",
      "Step: 4996 of 5001.\n",
      "Step: 4997 of 5001.\n",
      "Step: 4998 of 5001.\n",
      "Step: 4999 of 5001.\n",
      "Step: 5000 of 5001.\n",
      "Generator model loss: -1.9480085372924805.\n",
      "Discriminator model loss: -0.37741631269454956.\n",
      "xgboost accuracy: 0.81\n",
      "CPU times: user 7min 45s, sys: 31.7 s, total: 8min 17s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K.set_learning_phase(1) # 1 = train\n",
    "adversarial_training('', None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for continued training\n",
    "# adversarial_training('', 'cache/WGAN_generator_model_weights_step_100.h5', 'cache/WGAN_discriminator_model_weights_step_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[combined_loss, disc_loss, xgb_losses] = pickle.load(open(os.path.join(cache_dir, 'WGAN_losses.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efca7b23080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( xgb_losses[1:] ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYTwU/8P2CfxKqeP83UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc1667668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nInLA4EBERA7+H61tRlMh5pXvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcca746048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( combined_loss[1:], label='combined_loss' ) ; plt.legend() ; plt.show()\n",
    "\n",
    "plt.plot( disc_loss[800:], label='disc_loss' ) ; plt.legend() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.4-py3.6.egg/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "    \n",
    "generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "generated_image_tensor = generator_network(generator_input_tensor)\n",
    "generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "\n",
    "generator_model.load_weights('cache/WGAN_generator_model_weights_step_5000.h5')\n",
    "\n",
    "temp_noise = np.random.normal(size=(batch_size, rand_dim))  # fixed noise to generate batches of generated images\n",
    "\n",
    "g_z = generator_model.predict(temp_noise)\n",
    "\n",
    "# g_z[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80\n"
     ]
    }
   ],
   "source": [
    "print( CheckAccuracy( generator_model, 100, train ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.80'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 100\n",
    "\n",
    "np.random.seed(0)\n",
    "temp_noise = np.random.normal(size=(n_samples*2, rand_dim))  # fixed noise to generate batches of generated images\n",
    "test_samples = generator_model.predict(temp_noise)\n",
    "test_samples = np.reshape(test_samples, (n_samples*2, data_dim))\n",
    "test_samples = pd.DataFrame(test_samples,columns=train.columns)\n",
    "test_samples['syn_label'] = 1\n",
    "\n",
    "# real_samples = test.sample(n_samples*2,replace=False)\n",
    "real_samples = train.sample(n_samples*2,replace=False)\n",
    "real_samples['syn_label'] = 0\n",
    "\n",
    "train_df = pd.concat([real_samples[:n_samples],test_samples[:n_samples]],axis=0)\n",
    "test_df = pd.concat([real_samples[n_samples:],test_samples[n_samples:]],axis=0)\n",
    "\n",
    "X_col = test_df.columns[:-1]\n",
    "y_col = test_df.columns[-1]\n",
    "dtrain = xgb.DMatrix(train_df[X_col], train_df[y_col], feature_names=X_col)\n",
    "dtest = xgb.DMatrix(test_df[X_col], feature_names=X_col)\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 0 }\n",
    "xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "y_pred = np.round(xgb_test.predict(dtest))\n",
    "y_true = test_df['syn_label']\n",
    "'{:.2f}'.format(SimpleAccuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True 0</th>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 1</th>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pred 0  Pred 1\n",
       "True 0      72      28\n",
       "True 1      12      88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on validation set\n",
    "SimpleMetrics(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAHwCAYAAADU9wdDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc6f5a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importances\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "xgb.plot_importance(xgb_test, max_num_features=20, height=0.5, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value\n",
    "# import operator\n",
    "# x = xgb_test.get_fscore()\n",
    "# sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# # sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for col, imp in sorted_x:\n",
    "# # for col in xgb_model_DCGAN.get_fscore().keys():\n",
    "# # for col in ['V1','V14','V3']:\n",
    "#     plt.hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "# #     plt.title( '{}: {}'.format(col, xgb_model_DCGAN.get_fscore()[col]) )\n",
    "#     plt.title( '{}: {}'.format(col, imp) )\n",
    "#     plt.legend() ; plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/figure.py:1742: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+8AAALICAYAAAAOpMEfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc6fe5f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for col in train.columns:\n",
    "#     plt.hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "#     plt.title( '{}'.format(col) )\n",
    "#     plt.legend() ; plt.show()\n",
    "    \n",
    "# plt.figure(figsize=(14,5))    \n",
    "f, axarr = plt.subplots(7, 4, figsize=(14,10) )\n",
    "for i in range(28):\n",
    "    col = train_df.columns[i]\n",
    "    axarr[i//4, i%4].hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "    axarr[i//4, i%4].set_title( '{}'.format(col) )\n",
    "    if i == 0: axarr[i//4, i%4].legend()\n",
    "#     axarr[i//4, i%4].set_xlim([-0.1,1.1])\n",
    "#     axarr[i//4, i%4].set_ylim([0,40])\n",
    "f.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Waya.ai WCGAN dense\"><h1>Waya.ai WCGAN dense</h1></a>\n",
    "\n",
    "<a href='#TOC'>Table of contents</a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "wGAN implemented on top of keras/tensorflow as described in: [Wasserstein GAN](https://arxiv.org/pdf/1701.07875.pdf)\n",
    "with improvements as described in: [Improved Training of Wasserstein GANs](https://arxiv.org/pdf/1704.00028.pdf).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 29 # Add 1 for class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adversarial_training(data_dir, generator_model_path, discriminator_model_path, evaluate=False):\n",
    "    \"\"\"\n",
    "    Adversarial training of the generator network Gθ and discriminator network Dφ.\n",
    "\n",
    "    \"\"\"\n",
    "    # set random seed\n",
    "    np.random.seed(5)\n",
    "    \n",
    "    #\n",
    "    # define model input and output tensors\n",
    "    #\n",
    "\n",
    "    generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "    generated_image_tensor = generator_network(generator_input_tensor)\n",
    "\n",
    "    generated_or_real_image_tensor = layers.Input(shape=(data_dim,))\n",
    "    discriminator_output = discriminator_network(generated_or_real_image_tensor)\n",
    "\n",
    "    #\n",
    "    # define models\n",
    "    #\n",
    "\n",
    "    generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "    discriminator_model = models.Model(inputs=[generated_or_real_image_tensor],\n",
    "                                       outputs=[discriminator_output],\n",
    "                                       name='discriminator')\n",
    "\n",
    "    combined_output = discriminator_model(generator_model(generator_input_tensor))\n",
    "    combined_model = models.Model(inputs=[generator_input_tensor], outputs=[combined_output], name='combined')\n",
    "\n",
    "    #\n",
    "    # define earth mover distance (wasserstein loss)\n",
    "    #\n",
    "\n",
    "    def em_loss(y_coefficients, y_pred):\n",
    "        return tf.reduce_mean(tf.multiply(y_coefficients, y_pred))\n",
    "\n",
    "    #\n",
    "    # construct computation graph for calculating the gradient penalty (improved wGAN) and training the discriminator\n",
    "    #\n",
    "\n",
    "    # sample a batch of noise (generator input)\n",
    "    _z = tf.placeholder(tf.float32, shape=(batch_size, rand_dim))\n",
    "\n",
    "    # sample a batch of real images\n",
    "    _x = tf.placeholder(tf.float32, shape=(batch_size, data_dim))\n",
    "\n",
    "    # generate a batch of images with the current generator\n",
    "    _g_z = generator_model(_z)\n",
    "\n",
    "    # calculate `x_hat`\n",
    "    epsilon = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
    "    x_hat = epsilon * _x + (1.0 - epsilon) * _g_z\n",
    "\n",
    "    # gradient penalty\n",
    "    gradients = tf.gradients(discriminator_model(x_hat), [x_hat])\n",
    "    _gradient_penalty = 10.0 * tf.square(tf.norm(gradients[0], ord=2) - 1.0)\n",
    "\n",
    "    # calculate discriminator's loss\n",
    "    _disc_loss = em_loss(tf.ones(batch_size), discriminator_model(_g_z)) - \\\n",
    "        em_loss(tf.ones(batch_size), discriminator_model(_x)) + \\\n",
    "        _gradient_penalty\n",
    "\n",
    "    # update φ by taking an SGD step on mini-batch loss LD(φ)\n",
    "    disc_optimizer = tf.train.AdamOptimizer(learning_rate=.0001, beta1=0.5, beta2=0.9).minimize(\n",
    "        _disc_loss, var_list=discriminator_model.trainable_weights)\n",
    "\n",
    "    sess = K.get_session()\n",
    "\n",
    "    #\n",
    "    # compile models\n",
    "    #\n",
    "\n",
    "    adam = optimizers.Adam(lr=.0001, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "    discriminator_model.trainable = False\n",
    "    combined_model.compile(optimizer=adam, loss=[em_loss])\n",
    "\n",
    "    print(generator_model.summary())\n",
    "    print(discriminator_model.summary())\n",
    "    print(combined_model.summary())\n",
    "\n",
    "    disc_loss = []\n",
    "    combined_loss = []\n",
    "    xgb_losses = []\n",
    "\n",
    "    def train_discriminator_step():\n",
    "        d_l, _ = sess.run([_disc_loss, disc_optimizer], feed_dict={\n",
    "            _z: np.random.normal(loc=0.0, scale=1.0, size=(batch_size, rand_dim)),\n",
    "            _x: get_data_batch(train_w_class, batch_size, data_dim),\n",
    "            epsilon: np.random.uniform(low=0.0, high=1.0, size=(batch_size, 1))\n",
    "        })\n",
    "\n",
    "        return d_l\n",
    "\n",
    "    if generator_model_path:\n",
    "        generator_model.load_weights(generator_model_path, by_name=True)\n",
    "    if discriminator_model_path:\n",
    "        discriminator_model.load_weights(discriminator_model_path, by_name=True)\n",
    "    else:\n",
    "        print('pre-training the critic...')\n",
    "        K.set_learning_phase(1) # 1 = train\n",
    "        for i in range(critic_pre_train_steps):\n",
    "            print('Step: {} of {} critic pre-training.'.format(i, critic_pre_train_steps))\n",
    "            loss = train_discriminator_step()\n",
    "\n",
    "        print('Last batch of critic pre-training disc_loss: {}.'.format(loss))\n",
    "        discriminator_model.save(os.path.join(cache_dir, 'WGAN_discriminator_model_pre_trained.h5'))\n",
    "\n",
    "    \n",
    "    for i in range(nb_steps):\n",
    "        print('Step: {} of {}.'.format(i, nb_steps))\n",
    "        K.set_learning_phase(1) # 1 = train\n",
    "        # train the discriminator\n",
    "        for _ in range(k_d):\n",
    "#                 print('train the discriminator')\n",
    "            # when plotting loss we will have to take `k_d` and `k_g` into account so the two plots align\n",
    "            loss = train_discriminator_step()\n",
    "            disc_loss.append(loss)\n",
    "        # train the generator\n",
    "        for _ in range(k_g):\n",
    "#                 print('train the generator')\n",
    "            z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, rand_dim))\n",
    "            # update θ by taking an SGD step on mini-batch loss LG(θ)\n",
    "            loss = combined_model.train_on_batch(z, [-np.ones(batch_size)])\n",
    "            combined_loss.append(loss)\n",
    "\n",
    "        if not i % log_interval and i != 0:\n",
    "            K.set_learning_phase(0) # 0 = test\n",
    "                        \n",
    "            # log loss summary\n",
    "            print('Generator model loss: {}.'.format(np.mean(np.asarray(combined_loss[-log_interval:]), axis=0)))\n",
    "            print('Discriminator model loss: {}.'.format(np.mean(np.asarray(disc_loss[-log_interval:]), axis=0)))\n",
    "\n",
    "            xgb_loss = CheckAccuracy( generator_model, 100, train_w_class )\n",
    "            xgb_losses = np.append(xgb_losses, xgb_loss)\n",
    "            print('xgboost accuracy: {}'.format(xgb_loss) )\n",
    "\n",
    "            # save model checkpoints\n",
    "            model_checkpoint_base_name = os.path.join(cache_dir, 'WCGAN_{}_model_weights_step_{}.h5')\n",
    "            generator_model.save_weights(model_checkpoint_base_name.format('generator', i))\n",
    "            discriminator_model.save_weights(model_checkpoint_base_name.format('discriminator', i))\n",
    "    \n",
    "    pickle.dump([combined_loss, disc_loss, xgb_losses], \n",
    "                open(os.path.join(cache_dir, 'WCGAN_losses.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_139 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_140 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 29)                957       \n",
      "=================================================================\n",
      "Total params: 3,069\n",
      "Trainable params: 3,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_61 (InputLayer)        (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_141 (LeakyReLU)  (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 32)                960       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_142 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_143 (LeakyReLU)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,919\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,919\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            multiple                  3069      \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        multiple                  2919      \n",
      "=================================================================\n",
      "Total params: 5,988\n",
      "Trainable params: 3,069\n",
      "Non-trainable params: 2,919\n",
      "_________________________________________________________________\n",
      "None\n",
      "pre-training the critic...\n",
      "Step: 0 of 100 critic pre-training.\n",
      "Step: 1 of 100 critic pre-training.\n",
      "Step: 2 of 100 critic pre-training.\n",
      "Step: 3 of 100 critic pre-training.\n",
      "Step: 4 of 100 critic pre-training.\n",
      "Step: 5 of 100 critic pre-training.\n",
      "Step: 6 of 100 critic pre-training.\n",
      "Step: 7 of 100 critic pre-training.\n",
      "Step: 8 of 100 critic pre-training.\n",
      "Step: 9 of 100 critic pre-training.\n",
      "Step: 10 of 100 critic pre-training.\n",
      "Step: 11 of 100 critic pre-training.\n",
      "Step: 12 of 100 critic pre-training.\n",
      "Step: 13 of 100 critic pre-training.\n",
      "Step: 14 of 100 critic pre-training.\n",
      "Step: 15 of 100 critic pre-training.\n",
      "Step: 16 of 100 critic pre-training.\n",
      "Step: 17 of 100 critic pre-training.\n",
      "Step: 18 of 100 critic pre-training.\n",
      "Step: 19 of 100 critic pre-training.\n",
      "Step: 20 of 100 critic pre-training.\n",
      "Step: 21 of 100 critic pre-training.\n",
      "Step: 22 of 100 critic pre-training.\n",
      "Step: 23 of 100 critic pre-training.\n",
      "Step: 24 of 100 critic pre-training.\n",
      "Step: 25 of 100 critic pre-training.\n",
      "Step: 26 of 100 critic pre-training.\n",
      "Step: 27 of 100 critic pre-training.\n",
      "Step: 28 of 100 critic pre-training.\n",
      "Step: 29 of 100 critic pre-training.\n",
      "Step: 30 of 100 critic pre-training.\n",
      "Step: 31 of 100 critic pre-training.\n",
      "Step: 32 of 100 critic pre-training.\n",
      "Step: 33 of 100 critic pre-training.\n",
      "Step: 34 of 100 critic pre-training.\n",
      "Step: 35 of 100 critic pre-training.\n",
      "Step: 36 of 100 critic pre-training.\n",
      "Step: 37 of 100 critic pre-training.\n",
      "Step: 38 of 100 critic pre-training.\n",
      "Step: 39 of 100 critic pre-training.\n",
      "Step: 40 of 100 critic pre-training.\n",
      "Step: 41 of 100 critic pre-training.\n",
      "Step: 42 of 100 critic pre-training.\n",
      "Step: 43 of 100 critic pre-training.\n",
      "Step: 44 of 100 critic pre-training.\n",
      "Step: 45 of 100 critic pre-training.\n",
      "Step: 46 of 100 critic pre-training.\n",
      "Step: 47 of 100 critic pre-training.\n",
      "Step: 48 of 100 critic pre-training.\n",
      "Step: 49 of 100 critic pre-training.\n",
      "Step: 50 of 100 critic pre-training.\n",
      "Step: 51 of 100 critic pre-training.\n",
      "Step: 52 of 100 critic pre-training.\n",
      "Step: 53 of 100 critic pre-training.\n",
      "Step: 54 of 100 critic pre-training.\n",
      "Step: 55 of 100 critic pre-training.\n",
      "Step: 56 of 100 critic pre-training.\n",
      "Step: 57 of 100 critic pre-training.\n",
      "Step: 58 of 100 critic pre-training.\n",
      "Step: 59 of 100 critic pre-training.\n",
      "Step: 60 of 100 critic pre-training.\n",
      "Step: 61 of 100 critic pre-training.\n",
      "Step: 62 of 100 critic pre-training.\n",
      "Step: 63 of 100 critic pre-training.\n",
      "Step: 64 of 100 critic pre-training.\n",
      "Step: 65 of 100 critic pre-training.\n",
      "Step: 66 of 100 critic pre-training.\n",
      "Step: 67 of 100 critic pre-training.\n",
      "Step: 68 of 100 critic pre-training.\n",
      "Step: 69 of 100 critic pre-training.\n",
      "Step: 70 of 100 critic pre-training.\n",
      "Step: 71 of 100 critic pre-training.\n",
      "Step: 72 of 100 critic pre-training.\n",
      "Step: 73 of 100 critic pre-training.\n",
      "Step: 74 of 100 critic pre-training.\n",
      "Step: 75 of 100 critic pre-training.\n",
      "Step: 76 of 100 critic pre-training.\n",
      "Step: 77 of 100 critic pre-training.\n",
      "Step: 78 of 100 critic pre-training.\n",
      "Step: 79 of 100 critic pre-training.\n",
      "Step: 80 of 100 critic pre-training.\n",
      "Step: 81 of 100 critic pre-training.\n",
      "Step: 82 of 100 critic pre-training.\n",
      "Step: 83 of 100 critic pre-training.\n",
      "Step: 84 of 100 critic pre-training.\n",
      "Step: 85 of 100 critic pre-training.\n",
      "Step: 86 of 100 critic pre-training.\n",
      "Step: 87 of 100 critic pre-training.\n",
      "Step: 88 of 100 critic pre-training.\n",
      "Step: 89 of 100 critic pre-training.\n",
      "Step: 90 of 100 critic pre-training.\n",
      "Step: 91 of 100 critic pre-training.\n",
      "Step: 92 of 100 critic pre-training.\n",
      "Step: 93 of 100 critic pre-training.\n",
      "Step: 94 of 100 critic pre-training.\n",
      "Step: 95 of 100 critic pre-training.\n",
      "Step: 96 of 100 critic pre-training.\n",
      "Step: 97 of 100 critic pre-training.\n",
      "Step: 98 of 100 critic pre-training.\n",
      "Step: 99 of 100 critic pre-training.\n",
      "Last batch of critic pre-training disc_loss: 223.26651000976562.\n",
      "Step: 0 of 5001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.4-py3.6.egg/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 of 5001.\n",
      "Step: 2 of 5001.\n",
      "Step: 3 of 5001.\n",
      "Step: 4 of 5001.\n",
      "Step: 5 of 5001.\n",
      "Step: 6 of 5001.\n",
      "Step: 7 of 5001.\n",
      "Step: 8 of 5001.\n",
      "Step: 9 of 5001.\n",
      "Step: 10 of 5001.\n",
      "Generator model loss: -0.07931115478277206.\n",
      "Discriminator model loss: 144.3812255859375.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 11 of 5001.\n",
      "Step: 12 of 5001.\n",
      "Step: 13 of 5001.\n",
      "Step: 14 of 5001.\n",
      "Step: 15 of 5001.\n",
      "Step: 16 of 5001.\n",
      "Step: 17 of 5001.\n",
      "Step: 18 of 5001.\n",
      "Step: 19 of 5001.\n",
      "Step: 20 of 5001.\n",
      "Generator model loss: -0.10240743309259415.\n",
      "Discriminator model loss: 107.94306945800781.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 21 of 5001.\n",
      "Step: 22 of 5001.\n",
      "Step: 23 of 5001.\n",
      "Step: 24 of 5001.\n",
      "Step: 25 of 5001.\n",
      "Step: 26 of 5001.\n",
      "Step: 27 of 5001.\n",
      "Step: 28 of 5001.\n",
      "Step: 29 of 5001.\n",
      "Step: 30 of 5001.\n",
      "Generator model loss: -0.05425948649644852.\n",
      "Discriminator model loss: 82.80374908447266.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 31 of 5001.\n",
      "Step: 32 of 5001.\n",
      "Step: 33 of 5001.\n",
      "Step: 34 of 5001.\n",
      "Step: 35 of 5001.\n",
      "Step: 36 of 5001.\n",
      "Step: 37 of 5001.\n",
      "Step: 38 of 5001.\n",
      "Step: 39 of 5001.\n",
      "Step: 40 of 5001.\n",
      "Generator model loss: -0.06737031042575836.\n",
      "Discriminator model loss: 64.23979187011719.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 41 of 5001.\n",
      "Step: 42 of 5001.\n",
      "Step: 43 of 5001.\n",
      "Step: 44 of 5001.\n",
      "Step: 45 of 5001.\n",
      "Step: 46 of 5001.\n",
      "Step: 47 of 5001.\n",
      "Step: 48 of 5001.\n",
      "Step: 49 of 5001.\n",
      "Step: 50 of 5001.\n",
      "Generator model loss: -0.05639881640672684.\n",
      "Discriminator model loss: 46.4306755065918.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 51 of 5001.\n",
      "Step: 52 of 5001.\n",
      "Step: 53 of 5001.\n",
      "Step: 54 of 5001.\n",
      "Step: 55 of 5001.\n",
      "Step: 56 of 5001.\n",
      "Step: 57 of 5001.\n",
      "Step: 58 of 5001.\n",
      "Step: 59 of 5001.\n",
      "Step: 60 of 5001.\n",
      "Generator model loss: -0.06535790115594864.\n",
      "Discriminator model loss: 35.88617706298828.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 61 of 5001.\n",
      "Step: 62 of 5001.\n",
      "Step: 63 of 5001.\n",
      "Step: 64 of 5001.\n",
      "Step: 65 of 5001.\n",
      "Step: 66 of 5001.\n",
      "Step: 67 of 5001.\n",
      "Step: 68 of 5001.\n",
      "Step: 69 of 5001.\n",
      "Step: 70 of 5001.\n",
      "Generator model loss: -0.07600218802690506.\n",
      "Discriminator model loss: 27.265644073486328.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 71 of 5001.\n",
      "Step: 72 of 5001.\n",
      "Step: 73 of 5001.\n",
      "Step: 74 of 5001.\n",
      "Step: 75 of 5001.\n",
      "Step: 76 of 5001.\n",
      "Step: 77 of 5001.\n",
      "Step: 78 of 5001.\n",
      "Step: 79 of 5001.\n",
      "Step: 80 of 5001.\n",
      "Generator model loss: -0.04196116328239441.\n",
      "Discriminator model loss: 21.520919799804688.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 81 of 5001.\n",
      "Step: 82 of 5001.\n",
      "Step: 83 of 5001.\n",
      "Step: 84 of 5001.\n",
      "Step: 85 of 5001.\n",
      "Step: 86 of 5001.\n",
      "Step: 87 of 5001.\n",
      "Step: 88 of 5001.\n",
      "Step: 89 of 5001.\n",
      "Step: 90 of 5001.\n",
      "Generator model loss: -0.03831296041607857.\n",
      "Discriminator model loss: 14.900837898254395.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 91 of 5001.\n",
      "Step: 92 of 5001.\n",
      "Step: 93 of 5001.\n",
      "Step: 94 of 5001.\n",
      "Step: 95 of 5001.\n",
      "Step: 96 of 5001.\n",
      "Step: 97 of 5001.\n",
      "Step: 98 of 5001.\n",
      "Step: 99 of 5001.\n",
      "Step: 100 of 5001.\n",
      "Generator model loss: -0.0426037572324276.\n",
      "Discriminator model loss: 10.611077308654785.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 101 of 5001.\n",
      "Step: 102 of 5001.\n",
      "Step: 103 of 5001.\n",
      "Step: 104 of 5001.\n",
      "Step: 105 of 5001.\n",
      "Step: 106 of 5001.\n",
      "Step: 107 of 5001.\n",
      "Step: 108 of 5001.\n",
      "Step: 109 of 5001.\n",
      "Step: 110 of 5001.\n",
      "Generator model loss: -0.03275652974843979.\n",
      "Discriminator model loss: 6.880329132080078.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 111 of 5001.\n",
      "Step: 112 of 5001.\n",
      "Step: 113 of 5001.\n",
      "Step: 114 of 5001.\n",
      "Step: 115 of 5001.\n",
      "Step: 116 of 5001.\n",
      "Step: 117 of 5001.\n",
      "Step: 118 of 5001.\n",
      "Step: 119 of 5001.\n",
      "Step: 120 of 5001.\n",
      "Generator model loss: -0.03211206942796707.\n",
      "Discriminator model loss: 4.9720869064331055.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 121 of 5001.\n",
      "Step: 122 of 5001.\n",
      "Step: 123 of 5001.\n",
      "Step: 124 of 5001.\n",
      "Step: 125 of 5001.\n",
      "Step: 126 of 5001.\n",
      "Step: 127 of 5001.\n",
      "Step: 128 of 5001.\n",
      "Step: 129 of 5001.\n",
      "Step: 130 of 5001.\n",
      "Generator model loss: -0.02684757485985756.\n",
      "Discriminator model loss: 2.3669841289520264.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 131 of 5001.\n",
      "Step: 132 of 5001.\n",
      "Step: 133 of 5001.\n",
      "Step: 134 of 5001.\n",
      "Step: 135 of 5001.\n",
      "Step: 136 of 5001.\n",
      "Step: 137 of 5001.\n",
      "Step: 138 of 5001.\n",
      "Step: 139 of 5001.\n",
      "Step: 140 of 5001.\n",
      "Generator model loss: -0.036776043474674225.\n",
      "Discriminator model loss: 1.4047162532806396.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 141 of 5001.\n",
      "Step: 142 of 5001.\n",
      "Step: 143 of 5001.\n",
      "Step: 144 of 5001.\n",
      "Step: 145 of 5001.\n",
      "Step: 146 of 5001.\n",
      "Step: 147 of 5001.\n",
      "Step: 148 of 5001.\n",
      "Step: 149 of 5001.\n",
      "Step: 150 of 5001.\n",
      "Generator model loss: -0.024939462542533875.\n",
      "Discriminator model loss: 0.8446885943412781.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 151 of 5001.\n",
      "Step: 152 of 5001.\n",
      "Step: 153 of 5001.\n",
      "Step: 154 of 5001.\n",
      "Step: 155 of 5001.\n",
      "Step: 156 of 5001.\n",
      "Step: 157 of 5001.\n",
      "Step: 158 of 5001.\n",
      "Step: 159 of 5001.\n",
      "Step: 160 of 5001.\n",
      "Generator model loss: -0.024764548987150192.\n",
      "Discriminator model loss: 0.2956273853778839.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 161 of 5001.\n",
      "Step: 162 of 5001.\n",
      "Step: 163 of 5001.\n",
      "Step: 164 of 5001.\n",
      "Step: 165 of 5001.\n",
      "Step: 166 of 5001.\n",
      "Step: 167 of 5001.\n",
      "Step: 168 of 5001.\n",
      "Step: 169 of 5001.\n",
      "Step: 170 of 5001.\n",
      "Generator model loss: -0.026083454489707947.\n",
      "Discriminator model loss: 0.059276480227708817.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 171 of 5001.\n",
      "Step: 172 of 5001.\n",
      "Step: 173 of 5001.\n",
      "Step: 174 of 5001.\n",
      "Step: 175 of 5001.\n",
      "Step: 176 of 5001.\n",
      "Step: 177 of 5001.\n",
      "Step: 178 of 5001.\n",
      "Step: 179 of 5001.\n",
      "Step: 180 of 5001.\n",
      "Generator model loss: -0.023049402981996536.\n",
      "Discriminator model loss: -0.12400506436824799.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 181 of 5001.\n",
      "Step: 182 of 5001.\n",
      "Step: 183 of 5001.\n",
      "Step: 184 of 5001.\n",
      "Step: 185 of 5001.\n",
      "Step: 186 of 5001.\n",
      "Step: 187 of 5001.\n",
      "Step: 188 of 5001.\n",
      "Step: 189 of 5001.\n",
      "Step: 190 of 5001.\n",
      "Generator model loss: -0.042609818279743195.\n",
      "Discriminator model loss: -0.18055257201194763.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 191 of 5001.\n",
      "Step: 192 of 5001.\n",
      "Step: 193 of 5001.\n",
      "Step: 194 of 5001.\n",
      "Step: 195 of 5001.\n",
      "Step: 196 of 5001.\n",
      "Step: 197 of 5001.\n",
      "Step: 198 of 5001.\n",
      "Step: 199 of 5001.\n",
      "Step: 200 of 5001.\n",
      "Generator model loss: -0.04722095653414726.\n",
      "Discriminator model loss: -0.36047467589378357.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 201 of 5001.\n",
      "Step: 202 of 5001.\n",
      "Step: 203 of 5001.\n",
      "Step: 204 of 5001.\n",
      "Step: 205 of 5001.\n",
      "Step: 206 of 5001.\n",
      "Step: 207 of 5001.\n",
      "Step: 208 of 5001.\n",
      "Step: 209 of 5001.\n",
      "Step: 210 of 5001.\n",
      "Generator model loss: -0.046950750052928925.\n",
      "Discriminator model loss: -0.4610416293144226.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 211 of 5001.\n",
      "Step: 212 of 5001.\n",
      "Step: 213 of 5001.\n",
      "Step: 214 of 5001.\n",
      "Step: 215 of 5001.\n",
      "Step: 216 of 5001.\n",
      "Step: 217 of 5001.\n",
      "Step: 218 of 5001.\n",
      "Step: 219 of 5001.\n",
      "Step: 220 of 5001.\n",
      "Generator model loss: -0.06242210790514946.\n",
      "Discriminator model loss: -0.5049002766609192.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 221 of 5001.\n",
      "Step: 222 of 5001.\n",
      "Step: 223 of 5001.\n",
      "Step: 224 of 5001.\n",
      "Step: 225 of 5001.\n",
      "Step: 226 of 5001.\n",
      "Step: 227 of 5001.\n",
      "Step: 228 of 5001.\n",
      "Step: 229 of 5001.\n",
      "Step: 230 of 5001.\n",
      "Generator model loss: -0.06538879871368408.\n",
      "Discriminator model loss: -0.6482199430465698.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 231 of 5001.\n",
      "Step: 232 of 5001.\n",
      "Step: 233 of 5001.\n",
      "Step: 234 of 5001.\n",
      "Step: 235 of 5001.\n",
      "Step: 236 of 5001.\n",
      "Step: 237 of 5001.\n",
      "Step: 238 of 5001.\n",
      "Step: 239 of 5001.\n",
      "Step: 240 of 5001.\n",
      "Generator model loss: -0.0800207257270813.\n",
      "Discriminator model loss: -0.7059254050254822.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 241 of 5001.\n",
      "Step: 242 of 5001.\n",
      "Step: 243 of 5001.\n",
      "Step: 244 of 5001.\n",
      "Step: 245 of 5001.\n",
      "Step: 246 of 5001.\n",
      "Step: 247 of 5001.\n",
      "Step: 248 of 5001.\n",
      "Step: 249 of 5001.\n",
      "Step: 250 of 5001.\n",
      "Generator model loss: -0.09297429025173187.\n",
      "Discriminator model loss: -0.7581892013549805.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 251 of 5001.\n",
      "Step: 252 of 5001.\n",
      "Step: 253 of 5001.\n",
      "Step: 254 of 5001.\n",
      "Step: 255 of 5001.\n",
      "Step: 256 of 5001.\n",
      "Step: 257 of 5001.\n",
      "Step: 258 of 5001.\n",
      "Step: 259 of 5001.\n",
      "Step: 260 of 5001.\n",
      "Generator model loss: -0.09073550999164581.\n",
      "Discriminator model loss: -0.7788773775100708.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 261 of 5001.\n",
      "Step: 262 of 5001.\n",
      "Step: 263 of 5001.\n",
      "Step: 264 of 5001.\n",
      "Step: 265 of 5001.\n",
      "Step: 266 of 5001.\n",
      "Step: 267 of 5001.\n",
      "Step: 268 of 5001.\n",
      "Step: 269 of 5001.\n",
      "Step: 270 of 5001.\n",
      "Generator model loss: -0.09729596227407455.\n",
      "Discriminator model loss: -0.842437744140625.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 271 of 5001.\n",
      "Step: 272 of 5001.\n",
      "Step: 273 of 5001.\n",
      "Step: 274 of 5001.\n",
      "Step: 275 of 5001.\n",
      "Step: 276 of 5001.\n",
      "Step: 277 of 5001.\n",
      "Step: 278 of 5001.\n",
      "Step: 279 of 5001.\n",
      "Step: 280 of 5001.\n",
      "Generator model loss: -0.10067329555749893.\n",
      "Discriminator model loss: -0.9103583097457886.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 281 of 5001.\n",
      "Step: 282 of 5001.\n",
      "Step: 283 of 5001.\n",
      "Step: 284 of 5001.\n",
      "Step: 285 of 5001.\n",
      "Step: 286 of 5001.\n",
      "Step: 287 of 5001.\n",
      "Step: 288 of 5001.\n",
      "Step: 289 of 5001.\n",
      "Step: 290 of 5001.\n",
      "Generator model loss: -0.11331041157245636.\n",
      "Discriminator model loss: -0.9571119546890259.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 291 of 5001.\n",
      "Step: 292 of 5001.\n",
      "Step: 293 of 5001.\n",
      "Step: 294 of 5001.\n",
      "Step: 295 of 5001.\n",
      "Step: 296 of 5001.\n",
      "Step: 297 of 5001.\n",
      "Step: 298 of 5001.\n",
      "Step: 299 of 5001.\n",
      "Step: 300 of 5001.\n",
      "Generator model loss: -0.11456461250782013.\n",
      "Discriminator model loss: -0.9852490425109863.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 301 of 5001.\n",
      "Step: 302 of 5001.\n",
      "Step: 303 of 5001.\n",
      "Step: 304 of 5001.\n",
      "Step: 305 of 5001.\n",
      "Step: 306 of 5001.\n",
      "Step: 307 of 5001.\n",
      "Step: 308 of 5001.\n",
      "Step: 309 of 5001.\n",
      "Step: 310 of 5001.\n",
      "Generator model loss: -0.13452386856079102.\n",
      "Discriminator model loss: -0.9224739074707031.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 311 of 5001.\n",
      "Step: 312 of 5001.\n",
      "Step: 313 of 5001.\n",
      "Step: 314 of 5001.\n",
      "Step: 315 of 5001.\n",
      "Step: 316 of 5001.\n",
      "Step: 317 of 5001.\n",
      "Step: 318 of 5001.\n",
      "Step: 319 of 5001.\n",
      "Step: 320 of 5001.\n",
      "Generator model loss: -0.1292884647846222.\n",
      "Discriminator model loss: -0.8981372714042664.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 321 of 5001.\n",
      "Step: 322 of 5001.\n",
      "Step: 323 of 5001.\n",
      "Step: 324 of 5001.\n",
      "Step: 325 of 5001.\n",
      "Step: 326 of 5001.\n",
      "Step: 327 of 5001.\n",
      "Step: 328 of 5001.\n",
      "Step: 329 of 5001.\n",
      "Step: 330 of 5001.\n",
      "Generator model loss: -0.14167824387550354.\n",
      "Discriminator model loss: -1.0334827899932861.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 331 of 5001.\n",
      "Step: 332 of 5001.\n",
      "Step: 333 of 5001.\n",
      "Step: 334 of 5001.\n",
      "Step: 335 of 5001.\n",
      "Step: 336 of 5001.\n",
      "Step: 337 of 5001.\n",
      "Step: 338 of 5001.\n",
      "Step: 339 of 5001.\n",
      "Step: 340 of 5001.\n",
      "Generator model loss: -0.14484834671020508.\n",
      "Discriminator model loss: -1.1009492874145508.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 341 of 5001.\n",
      "Step: 342 of 5001.\n",
      "Step: 343 of 5001.\n",
      "Step: 344 of 5001.\n",
      "Step: 345 of 5001.\n",
      "Step: 346 of 5001.\n",
      "Step: 347 of 5001.\n",
      "Step: 348 of 5001.\n",
      "Step: 349 of 5001.\n",
      "Step: 350 of 5001.\n",
      "Generator model loss: -0.15339097380638123.\n",
      "Discriminator model loss: -1.0274738073349.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 351 of 5001.\n",
      "Step: 352 of 5001.\n",
      "Step: 353 of 5001.\n",
      "Step: 354 of 5001.\n",
      "Step: 355 of 5001.\n",
      "Step: 356 of 5001.\n",
      "Step: 357 of 5001.\n",
      "Step: 358 of 5001.\n",
      "Step: 359 of 5001.\n",
      "Step: 360 of 5001.\n",
      "Generator model loss: -0.15416763722896576.\n",
      "Discriminator model loss: -1.120406985282898.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 361 of 5001.\n",
      "Step: 362 of 5001.\n",
      "Step: 363 of 5001.\n",
      "Step: 364 of 5001.\n",
      "Step: 365 of 5001.\n",
      "Step: 366 of 5001.\n",
      "Step: 367 of 5001.\n",
      "Step: 368 of 5001.\n",
      "Step: 369 of 5001.\n",
      "Step: 370 of 5001.\n",
      "Generator model loss: -0.1691848784685135.\n",
      "Discriminator model loss: -1.0735909938812256.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 371 of 5001.\n",
      "Step: 372 of 5001.\n",
      "Step: 373 of 5001.\n",
      "Step: 374 of 5001.\n",
      "Step: 375 of 5001.\n",
      "Step: 376 of 5001.\n",
      "Step: 377 of 5001.\n",
      "Step: 378 of 5001.\n",
      "Step: 379 of 5001.\n",
      "Step: 380 of 5001.\n",
      "Generator model loss: -0.16914328932762146.\n",
      "Discriminator model loss: -1.0571460723876953.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 381 of 5001.\n",
      "Step: 382 of 5001.\n",
      "Step: 383 of 5001.\n",
      "Step: 384 of 5001.\n",
      "Step: 385 of 5001.\n",
      "Step: 386 of 5001.\n",
      "Step: 387 of 5001.\n",
      "Step: 388 of 5001.\n",
      "Step: 389 of 5001.\n",
      "Step: 390 of 5001.\n",
      "Generator model loss: -0.17961230874061584.\n",
      "Discriminator model loss: -1.0105979442596436.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 391 of 5001.\n",
      "Step: 392 of 5001.\n",
      "Step: 393 of 5001.\n",
      "Step: 394 of 5001.\n",
      "Step: 395 of 5001.\n",
      "Step: 396 of 5001.\n",
      "Step: 397 of 5001.\n",
      "Step: 398 of 5001.\n",
      "Step: 399 of 5001.\n",
      "Step: 400 of 5001.\n",
      "Generator model loss: -0.1802123785018921.\n",
      "Discriminator model loss: -1.03624427318573.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 401 of 5001.\n",
      "Step: 402 of 5001.\n",
      "Step: 403 of 5001.\n",
      "Step: 404 of 5001.\n",
      "Step: 405 of 5001.\n",
      "Step: 406 of 5001.\n",
      "Step: 407 of 5001.\n",
      "Step: 408 of 5001.\n",
      "Step: 409 of 5001.\n",
      "Step: 410 of 5001.\n",
      "Generator model loss: -0.18980446457862854.\n",
      "Discriminator model loss: -1.092794418334961.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 411 of 5001.\n",
      "Step: 412 of 5001.\n",
      "Step: 413 of 5001.\n",
      "Step: 414 of 5001.\n",
      "Step: 415 of 5001.\n",
      "Step: 416 of 5001.\n",
      "Step: 417 of 5001.\n",
      "Step: 418 of 5001.\n",
      "Step: 419 of 5001.\n",
      "Step: 420 of 5001.\n",
      "Generator model loss: -0.1912282407283783.\n",
      "Discriminator model loss: -1.063096523284912.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 421 of 5001.\n",
      "Step: 422 of 5001.\n",
      "Step: 423 of 5001.\n",
      "Step: 424 of 5001.\n",
      "Step: 425 of 5001.\n",
      "Step: 426 of 5001.\n",
      "Step: 427 of 5001.\n",
      "Step: 428 of 5001.\n",
      "Step: 429 of 5001.\n",
      "Step: 430 of 5001.\n",
      "Generator model loss: -0.19931182265281677.\n",
      "Discriminator model loss: -1.0351766347885132.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 431 of 5001.\n",
      "Step: 432 of 5001.\n",
      "Step: 433 of 5001.\n",
      "Step: 434 of 5001.\n",
      "Step: 435 of 5001.\n",
      "Step: 436 of 5001.\n",
      "Step: 437 of 5001.\n",
      "Step: 438 of 5001.\n",
      "Step: 439 of 5001.\n",
      "Step: 440 of 5001.\n",
      "Generator model loss: -0.20259210467338562.\n",
      "Discriminator model loss: -1.0870037078857422.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 441 of 5001.\n",
      "Step: 442 of 5001.\n",
      "Step: 443 of 5001.\n",
      "Step: 444 of 5001.\n",
      "Step: 445 of 5001.\n",
      "Step: 446 of 5001.\n",
      "Step: 447 of 5001.\n",
      "Step: 448 of 5001.\n",
      "Step: 449 of 5001.\n",
      "Step: 450 of 5001.\n",
      "Generator model loss: -0.21244756877422333.\n",
      "Discriminator model loss: -1.0505812168121338.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 451 of 5001.\n",
      "Step: 452 of 5001.\n",
      "Step: 453 of 5001.\n",
      "Step: 454 of 5001.\n",
      "Step: 455 of 5001.\n",
      "Step: 456 of 5001.\n",
      "Step: 457 of 5001.\n",
      "Step: 458 of 5001.\n",
      "Step: 459 of 5001.\n",
      "Step: 460 of 5001.\n",
      "Generator model loss: -0.2169744223356247.\n",
      "Discriminator model loss: -1.09531831741333.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 461 of 5001.\n",
      "Step: 462 of 5001.\n",
      "Step: 463 of 5001.\n",
      "Step: 464 of 5001.\n",
      "Step: 465 of 5001.\n",
      "Step: 466 of 5001.\n",
      "Step: 467 of 5001.\n",
      "Step: 468 of 5001.\n",
      "Step: 469 of 5001.\n",
      "Step: 470 of 5001.\n",
      "Generator model loss: -0.22026577591896057.\n",
      "Discriminator model loss: -1.00726318359375.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 471 of 5001.\n",
      "Step: 472 of 5001.\n",
      "Step: 473 of 5001.\n",
      "Step: 474 of 5001.\n",
      "Step: 475 of 5001.\n",
      "Step: 476 of 5001.\n",
      "Step: 477 of 5001.\n",
      "Step: 478 of 5001.\n",
      "Step: 479 of 5001.\n",
      "Step: 480 of 5001.\n",
      "Generator model loss: -0.22255563735961914.\n",
      "Discriminator model loss: -1.0720081329345703.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 481 of 5001.\n",
      "Step: 482 of 5001.\n",
      "Step: 483 of 5001.\n",
      "Step: 484 of 5001.\n",
      "Step: 485 of 5001.\n",
      "Step: 486 of 5001.\n",
      "Step: 487 of 5001.\n",
      "Step: 488 of 5001.\n",
      "Step: 489 of 5001.\n",
      "Step: 490 of 5001.\n",
      "Generator model loss: -0.23019559681415558.\n",
      "Discriminator model loss: -1.0624656677246094.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 491 of 5001.\n",
      "Step: 492 of 5001.\n",
      "Step: 493 of 5001.\n",
      "Step: 494 of 5001.\n",
      "Step: 495 of 5001.\n",
      "Step: 496 of 5001.\n",
      "Step: 497 of 5001.\n",
      "Step: 498 of 5001.\n",
      "Step: 499 of 5001.\n",
      "Step: 500 of 5001.\n",
      "Generator model loss: -0.2354568988084793.\n",
      "Discriminator model loss: -1.07822585105896.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 501 of 5001.\n",
      "Step: 502 of 5001.\n",
      "Step: 503 of 5001.\n",
      "Step: 504 of 5001.\n",
      "Step: 505 of 5001.\n",
      "Step: 506 of 5001.\n",
      "Step: 507 of 5001.\n",
      "Step: 508 of 5001.\n",
      "Step: 509 of 5001.\n",
      "Step: 510 of 5001.\n",
      "Generator model loss: -0.24673601984977722.\n",
      "Discriminator model loss: -1.1286342144012451.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 511 of 5001.\n",
      "Step: 512 of 5001.\n",
      "Step: 513 of 5001.\n",
      "Step: 514 of 5001.\n",
      "Step: 515 of 5001.\n",
      "Step: 516 of 5001.\n",
      "Step: 517 of 5001.\n",
      "Step: 518 of 5001.\n",
      "Step: 519 of 5001.\n",
      "Step: 520 of 5001.\n",
      "Generator model loss: -0.25344306230545044.\n",
      "Discriminator model loss: -1.1239031553268433.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 521 of 5001.\n",
      "Step: 522 of 5001.\n",
      "Step: 523 of 5001.\n",
      "Step: 524 of 5001.\n",
      "Step: 525 of 5001.\n",
      "Step: 526 of 5001.\n",
      "Step: 527 of 5001.\n",
      "Step: 528 of 5001.\n",
      "Step: 529 of 5001.\n",
      "Step: 530 of 5001.\n",
      "Generator model loss: -0.2597672641277313.\n",
      "Discriminator model loss: -1.016987681388855.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 531 of 5001.\n",
      "Step: 532 of 5001.\n",
      "Step: 533 of 5001.\n",
      "Step: 534 of 5001.\n",
      "Step: 535 of 5001.\n",
      "Step: 536 of 5001.\n",
      "Step: 537 of 5001.\n",
      "Step: 538 of 5001.\n",
      "Step: 539 of 5001.\n",
      "Step: 540 of 5001.\n",
      "Generator model loss: -0.2598845958709717.\n",
      "Discriminator model loss: -1.095833659172058.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 541 of 5001.\n",
      "Step: 542 of 5001.\n",
      "Step: 543 of 5001.\n",
      "Step: 544 of 5001.\n",
      "Step: 545 of 5001.\n",
      "Step: 546 of 5001.\n",
      "Step: 547 of 5001.\n",
      "Step: 548 of 5001.\n",
      "Step: 549 of 5001.\n",
      "Step: 550 of 5001.\n",
      "Generator model loss: -0.26379185914993286.\n",
      "Discriminator model loss: -1.0880119800567627.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 551 of 5001.\n",
      "Step: 552 of 5001.\n",
      "Step: 553 of 5001.\n",
      "Step: 554 of 5001.\n",
      "Step: 555 of 5001.\n",
      "Step: 556 of 5001.\n",
      "Step: 557 of 5001.\n",
      "Step: 558 of 5001.\n",
      "Step: 559 of 5001.\n",
      "Step: 560 of 5001.\n",
      "Generator model loss: -0.27250614762306213.\n",
      "Discriminator model loss: -1.1243205070495605.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 561 of 5001.\n",
      "Step: 562 of 5001.\n",
      "Step: 563 of 5001.\n",
      "Step: 564 of 5001.\n",
      "Step: 565 of 5001.\n",
      "Step: 566 of 5001.\n",
      "Step: 567 of 5001.\n",
      "Step: 568 of 5001.\n",
      "Step: 569 of 5001.\n",
      "Step: 570 of 5001.\n",
      "Generator model loss: -0.2861884534358978.\n",
      "Discriminator model loss: -1.0355021953582764.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 571 of 5001.\n",
      "Step: 572 of 5001.\n",
      "Step: 573 of 5001.\n",
      "Step: 574 of 5001.\n",
      "Step: 575 of 5001.\n",
      "Step: 576 of 5001.\n",
      "Step: 577 of 5001.\n",
      "Step: 578 of 5001.\n",
      "Step: 579 of 5001.\n",
      "Step: 580 of 5001.\n",
      "Generator model loss: -0.287842333316803.\n",
      "Discriminator model loss: -1.1005668640136719.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 581 of 5001.\n",
      "Step: 582 of 5001.\n",
      "Step: 583 of 5001.\n",
      "Step: 584 of 5001.\n",
      "Step: 585 of 5001.\n",
      "Step: 586 of 5001.\n",
      "Step: 587 of 5001.\n",
      "Step: 588 of 5001.\n",
      "Step: 589 of 5001.\n",
      "Step: 590 of 5001.\n",
      "Generator model loss: -0.29299044609069824.\n",
      "Discriminator model loss: -1.0840637683868408.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 591 of 5001.\n",
      "Step: 592 of 5001.\n",
      "Step: 593 of 5001.\n",
      "Step: 594 of 5001.\n",
      "Step: 595 of 5001.\n",
      "Step: 596 of 5001.\n",
      "Step: 597 of 5001.\n",
      "Step: 598 of 5001.\n",
      "Step: 599 of 5001.\n",
      "Step: 600 of 5001.\n",
      "Generator model loss: -0.3121700584888458.\n",
      "Discriminator model loss: -1.1288468837738037.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 601 of 5001.\n",
      "Step: 602 of 5001.\n",
      "Step: 603 of 5001.\n",
      "Step: 604 of 5001.\n",
      "Step: 605 of 5001.\n",
      "Step: 606 of 5001.\n",
      "Step: 607 of 5001.\n",
      "Step: 608 of 5001.\n",
      "Step: 609 of 5001.\n",
      "Step: 610 of 5001.\n",
      "Generator model loss: -0.31422895193099976.\n",
      "Discriminator model loss: -1.081918478012085.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 611 of 5001.\n",
      "Step: 612 of 5001.\n",
      "Step: 613 of 5001.\n",
      "Step: 614 of 5001.\n",
      "Step: 615 of 5001.\n",
      "Step: 616 of 5001.\n",
      "Step: 617 of 5001.\n",
      "Step: 618 of 5001.\n",
      "Step: 619 of 5001.\n",
      "Step: 620 of 5001.\n",
      "Generator model loss: -0.3197416365146637.\n",
      "Discriminator model loss: -1.0779180526733398.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 621 of 5001.\n",
      "Step: 622 of 5001.\n",
      "Step: 623 of 5001.\n",
      "Step: 624 of 5001.\n",
      "Step: 625 of 5001.\n",
      "Step: 626 of 5001.\n",
      "Step: 627 of 5001.\n",
      "Step: 628 of 5001.\n",
      "Step: 629 of 5001.\n",
      "Step: 630 of 5001.\n",
      "Generator model loss: -0.32002541422843933.\n",
      "Discriminator model loss: -1.0702743530273438.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 631 of 5001.\n",
      "Step: 632 of 5001.\n",
      "Step: 633 of 5001.\n",
      "Step: 634 of 5001.\n",
      "Step: 635 of 5001.\n",
      "Step: 636 of 5001.\n",
      "Step: 637 of 5001.\n",
      "Step: 638 of 5001.\n",
      "Step: 639 of 5001.\n",
      "Step: 640 of 5001.\n",
      "Generator model loss: -0.32811880111694336.\n",
      "Discriminator model loss: -1.0963289737701416.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 641 of 5001.\n",
      "Step: 642 of 5001.\n",
      "Step: 643 of 5001.\n",
      "Step: 644 of 5001.\n",
      "Step: 645 of 5001.\n",
      "Step: 646 of 5001.\n",
      "Step: 647 of 5001.\n",
      "Step: 648 of 5001.\n",
      "Step: 649 of 5001.\n",
      "Step: 650 of 5001.\n",
      "Generator model loss: -0.3419683575630188.\n",
      "Discriminator model loss: -1.020169734954834.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 651 of 5001.\n",
      "Step: 652 of 5001.\n",
      "Step: 653 of 5001.\n",
      "Step: 654 of 5001.\n",
      "Step: 655 of 5001.\n",
      "Step: 656 of 5001.\n",
      "Step: 657 of 5001.\n",
      "Step: 658 of 5001.\n",
      "Step: 659 of 5001.\n",
      "Step: 660 of 5001.\n",
      "Generator model loss: -0.3511952757835388.\n",
      "Discriminator model loss: -1.041083574295044.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 661 of 5001.\n",
      "Step: 662 of 5001.\n",
      "Step: 663 of 5001.\n",
      "Step: 664 of 5001.\n",
      "Step: 665 of 5001.\n",
      "Step: 666 of 5001.\n",
      "Step: 667 of 5001.\n",
      "Step: 668 of 5001.\n",
      "Step: 669 of 5001.\n",
      "Step: 670 of 5001.\n",
      "Generator model loss: -0.3562624454498291.\n",
      "Discriminator model loss: -1.0263609886169434.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 671 of 5001.\n",
      "Step: 672 of 5001.\n",
      "Step: 673 of 5001.\n",
      "Step: 674 of 5001.\n",
      "Step: 675 of 5001.\n",
      "Step: 676 of 5001.\n",
      "Step: 677 of 5001.\n",
      "Step: 678 of 5001.\n",
      "Step: 679 of 5001.\n",
      "Step: 680 of 5001.\n",
      "Generator model loss: -0.3508736193180084.\n",
      "Discriminator model loss: -0.9847875833511353.\n",
      "xgboost accuracy: 0.97\n",
      "Step: 681 of 5001.\n",
      "Step: 682 of 5001.\n",
      "Step: 683 of 5001.\n",
      "Step: 684 of 5001.\n",
      "Step: 685 of 5001.\n",
      "Step: 686 of 5001.\n",
      "Step: 687 of 5001.\n",
      "Step: 688 of 5001.\n",
      "Step: 689 of 5001.\n",
      "Step: 690 of 5001.\n",
      "Generator model loss: -0.3705065846443176.\n",
      "Discriminator model loss: -1.030242919921875.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 691 of 5001.\n",
      "Step: 692 of 5001.\n",
      "Step: 693 of 5001.\n",
      "Step: 694 of 5001.\n",
      "Step: 695 of 5001.\n",
      "Step: 696 of 5001.\n",
      "Step: 697 of 5001.\n",
      "Step: 698 of 5001.\n",
      "Step: 699 of 5001.\n",
      "Step: 700 of 5001.\n",
      "Generator model loss: -0.37769538164138794.\n",
      "Discriminator model loss: -1.0469849109649658.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 701 of 5001.\n",
      "Step: 702 of 5001.\n",
      "Step: 703 of 5001.\n",
      "Step: 704 of 5001.\n",
      "Step: 705 of 5001.\n",
      "Step: 706 of 5001.\n",
      "Step: 707 of 5001.\n",
      "Step: 708 of 5001.\n",
      "Step: 709 of 5001.\n",
      "Step: 710 of 5001.\n",
      "Generator model loss: -0.3956938683986664.\n",
      "Discriminator model loss: -1.0522596836090088.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 711 of 5001.\n",
      "Step: 712 of 5001.\n",
      "Step: 713 of 5001.\n",
      "Step: 714 of 5001.\n",
      "Step: 715 of 5001.\n",
      "Step: 716 of 5001.\n",
      "Step: 717 of 5001.\n",
      "Step: 718 of 5001.\n",
      "Step: 719 of 5001.\n",
      "Step: 720 of 5001.\n",
      "Generator model loss: -0.4084095358848572.\n",
      "Discriminator model loss: -1.0309213399887085.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 721 of 5001.\n",
      "Step: 722 of 5001.\n",
      "Step: 723 of 5001.\n",
      "Step: 724 of 5001.\n",
      "Step: 725 of 5001.\n",
      "Step: 726 of 5001.\n",
      "Step: 727 of 5001.\n",
      "Step: 728 of 5001.\n",
      "Step: 729 of 5001.\n",
      "Step: 730 of 5001.\n",
      "Generator model loss: -0.3899628520011902.\n",
      "Discriminator model loss: -0.9996687769889832.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 731 of 5001.\n",
      "Step: 732 of 5001.\n",
      "Step: 733 of 5001.\n",
      "Step: 734 of 5001.\n",
      "Step: 735 of 5001.\n",
      "Step: 736 of 5001.\n",
      "Step: 737 of 5001.\n",
      "Step: 738 of 5001.\n",
      "Step: 739 of 5001.\n",
      "Step: 740 of 5001.\n",
      "Generator model loss: -0.4206981658935547.\n",
      "Discriminator model loss: -0.9934032559394836.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 741 of 5001.\n",
      "Step: 742 of 5001.\n",
      "Step: 743 of 5001.\n",
      "Step: 744 of 5001.\n",
      "Step: 745 of 5001.\n",
      "Step: 746 of 5001.\n",
      "Step: 747 of 5001.\n",
      "Step: 748 of 5001.\n",
      "Step: 749 of 5001.\n",
      "Step: 750 of 5001.\n",
      "Generator model loss: -0.4287486672401428.\n",
      "Discriminator model loss: -0.9884171485900879.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 751 of 5001.\n",
      "Step: 752 of 5001.\n",
      "Step: 753 of 5001.\n",
      "Step: 754 of 5001.\n",
      "Step: 755 of 5001.\n",
      "Step: 756 of 5001.\n",
      "Step: 757 of 5001.\n",
      "Step: 758 of 5001.\n",
      "Step: 759 of 5001.\n",
      "Step: 760 of 5001.\n",
      "Generator model loss: -0.4249171316623688.\n",
      "Discriminator model loss: -1.0154114961624146.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 761 of 5001.\n",
      "Step: 762 of 5001.\n",
      "Step: 763 of 5001.\n",
      "Step: 764 of 5001.\n",
      "Step: 765 of 5001.\n",
      "Step: 766 of 5001.\n",
      "Step: 767 of 5001.\n",
      "Step: 768 of 5001.\n",
      "Step: 769 of 5001.\n",
      "Step: 770 of 5001.\n",
      "Generator model loss: -0.4310205578804016.\n",
      "Discriminator model loss: -0.9472061395645142.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 771 of 5001.\n",
      "Step: 772 of 5001.\n",
      "Step: 773 of 5001.\n",
      "Step: 774 of 5001.\n",
      "Step: 775 of 5001.\n",
      "Step: 776 of 5001.\n",
      "Step: 777 of 5001.\n",
      "Step: 778 of 5001.\n",
      "Step: 779 of 5001.\n",
      "Step: 780 of 5001.\n",
      "Generator model loss: -0.46661752462387085.\n",
      "Discriminator model loss: -0.9454349279403687.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 781 of 5001.\n",
      "Step: 782 of 5001.\n",
      "Step: 783 of 5001.\n",
      "Step: 784 of 5001.\n",
      "Step: 785 of 5001.\n",
      "Step: 786 of 5001.\n",
      "Step: 787 of 5001.\n",
      "Step: 788 of 5001.\n",
      "Step: 789 of 5001.\n",
      "Step: 790 of 5001.\n",
      "Generator model loss: -0.4552393853664398.\n",
      "Discriminator model loss: -0.9191017150878906.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 791 of 5001.\n",
      "Step: 792 of 5001.\n",
      "Step: 793 of 5001.\n",
      "Step: 794 of 5001.\n",
      "Step: 795 of 5001.\n",
      "Step: 796 of 5001.\n",
      "Step: 797 of 5001.\n",
      "Step: 798 of 5001.\n",
      "Step: 799 of 5001.\n",
      "Step: 800 of 5001.\n",
      "Generator model loss: -0.4702188968658447.\n",
      "Discriminator model loss: -0.945303738117218.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 801 of 5001.\n",
      "Step: 802 of 5001.\n",
      "Step: 803 of 5001.\n",
      "Step: 804 of 5001.\n",
      "Step: 805 of 5001.\n",
      "Step: 806 of 5001.\n",
      "Step: 807 of 5001.\n",
      "Step: 808 of 5001.\n",
      "Step: 809 of 5001.\n",
      "Step: 810 of 5001.\n",
      "Generator model loss: -0.4748728275299072.\n",
      "Discriminator model loss: -0.971397876739502.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 811 of 5001.\n",
      "Step: 812 of 5001.\n",
      "Step: 813 of 5001.\n",
      "Step: 814 of 5001.\n",
      "Step: 815 of 5001.\n",
      "Step: 816 of 5001.\n",
      "Step: 817 of 5001.\n",
      "Step: 818 of 5001.\n",
      "Step: 819 of 5001.\n",
      "Step: 820 of 5001.\n",
      "Generator model loss: -0.48499903082847595.\n",
      "Discriminator model loss: -0.9458349347114563.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 821 of 5001.\n",
      "Step: 822 of 5001.\n",
      "Step: 823 of 5001.\n",
      "Step: 824 of 5001.\n",
      "Step: 825 of 5001.\n",
      "Step: 826 of 5001.\n",
      "Step: 827 of 5001.\n",
      "Step: 828 of 5001.\n",
      "Step: 829 of 5001.\n",
      "Step: 830 of 5001.\n",
      "Generator model loss: -0.48555317521095276.\n",
      "Discriminator model loss: -0.9587261080741882.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 831 of 5001.\n",
      "Step: 832 of 5001.\n",
      "Step: 833 of 5001.\n",
      "Step: 834 of 5001.\n",
      "Step: 835 of 5001.\n",
      "Step: 836 of 5001.\n",
      "Step: 837 of 5001.\n",
      "Step: 838 of 5001.\n",
      "Step: 839 of 5001.\n",
      "Step: 840 of 5001.\n",
      "Generator model loss: -0.49643081426620483.\n",
      "Discriminator model loss: -0.847405731678009.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 841 of 5001.\n",
      "Step: 842 of 5001.\n",
      "Step: 843 of 5001.\n",
      "Step: 844 of 5001.\n",
      "Step: 845 of 5001.\n",
      "Step: 846 of 5001.\n",
      "Step: 847 of 5001.\n",
      "Step: 848 of 5001.\n",
      "Step: 849 of 5001.\n",
      "Step: 850 of 5001.\n",
      "Generator model loss: -0.4988366663455963.\n",
      "Discriminator model loss: -0.9127765893936157.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 851 of 5001.\n",
      "Step: 852 of 5001.\n",
      "Step: 853 of 5001.\n",
      "Step: 854 of 5001.\n",
      "Step: 855 of 5001.\n",
      "Step: 856 of 5001.\n",
      "Step: 857 of 5001.\n",
      "Step: 858 of 5001.\n",
      "Step: 859 of 5001.\n",
      "Step: 860 of 5001.\n",
      "Generator model loss: -0.5277379751205444.\n",
      "Discriminator model loss: -0.9003709554672241.\n",
      "xgboost accuracy: 0.96\n",
      "Step: 861 of 5001.\n",
      "Step: 862 of 5001.\n",
      "Step: 863 of 5001.\n",
      "Step: 864 of 5001.\n",
      "Step: 865 of 5001.\n",
      "Step: 866 of 5001.\n",
      "Step: 867 of 5001.\n",
      "Step: 868 of 5001.\n",
      "Step: 869 of 5001.\n",
      "Step: 870 of 5001.\n",
      "Generator model loss: -0.5282672643661499.\n",
      "Discriminator model loss: -0.8979450464248657.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 871 of 5001.\n",
      "Step: 872 of 5001.\n",
      "Step: 873 of 5001.\n",
      "Step: 874 of 5001.\n",
      "Step: 875 of 5001.\n",
      "Step: 876 of 5001.\n",
      "Step: 877 of 5001.\n",
      "Step: 878 of 5001.\n",
      "Step: 879 of 5001.\n",
      "Step: 880 of 5001.\n",
      "Generator model loss: -0.5585721135139465.\n",
      "Discriminator model loss: -0.8876090049743652.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 881 of 5001.\n",
      "Step: 882 of 5001.\n",
      "Step: 883 of 5001.\n",
      "Step: 884 of 5001.\n",
      "Step: 885 of 5001.\n",
      "Step: 886 of 5001.\n",
      "Step: 887 of 5001.\n",
      "Step: 888 of 5001.\n",
      "Step: 889 of 5001.\n",
      "Step: 890 of 5001.\n",
      "Generator model loss: -0.5605157613754272.\n",
      "Discriminator model loss: -0.8647156953811646.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 891 of 5001.\n",
      "Step: 892 of 5001.\n",
      "Step: 893 of 5001.\n",
      "Step: 894 of 5001.\n",
      "Step: 895 of 5001.\n",
      "Step: 896 of 5001.\n",
      "Step: 897 of 5001.\n",
      "Step: 898 of 5001.\n",
      "Step: 899 of 5001.\n",
      "Step: 900 of 5001.\n",
      "Generator model loss: -0.5333796739578247.\n",
      "Discriminator model loss: -0.8186357617378235.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 901 of 5001.\n",
      "Step: 902 of 5001.\n",
      "Step: 903 of 5001.\n",
      "Step: 904 of 5001.\n",
      "Step: 905 of 5001.\n",
      "Step: 906 of 5001.\n",
      "Step: 907 of 5001.\n",
      "Step: 908 of 5001.\n",
      "Step: 909 of 5001.\n",
      "Step: 910 of 5001.\n",
      "Generator model loss: -0.5538700819015503.\n",
      "Discriminator model loss: -0.8365448117256165.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 911 of 5001.\n",
      "Step: 912 of 5001.\n",
      "Step: 913 of 5001.\n",
      "Step: 914 of 5001.\n",
      "Step: 915 of 5001.\n",
      "Step: 916 of 5001.\n",
      "Step: 917 of 5001.\n",
      "Step: 918 of 5001.\n",
      "Step: 919 of 5001.\n",
      "Step: 920 of 5001.\n",
      "Generator model loss: -0.5787104368209839.\n",
      "Discriminator model loss: -0.9021318554878235.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 921 of 5001.\n",
      "Step: 922 of 5001.\n",
      "Step: 923 of 5001.\n",
      "Step: 924 of 5001.\n",
      "Step: 925 of 5001.\n",
      "Step: 926 of 5001.\n",
      "Step: 927 of 5001.\n",
      "Step: 928 of 5001.\n",
      "Step: 929 of 5001.\n",
      "Step: 930 of 5001.\n",
      "Generator model loss: -0.574227511882782.\n",
      "Discriminator model loss: -0.8605431318283081.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 931 of 5001.\n",
      "Step: 932 of 5001.\n",
      "Step: 933 of 5001.\n",
      "Step: 934 of 5001.\n",
      "Step: 935 of 5001.\n",
      "Step: 936 of 5001.\n",
      "Step: 937 of 5001.\n",
      "Step: 938 of 5001.\n",
      "Step: 939 of 5001.\n",
      "Step: 940 of 5001.\n",
      "Generator model loss: -0.5851383209228516.\n",
      "Discriminator model loss: -0.909587025642395.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 941 of 5001.\n",
      "Step: 942 of 5001.\n",
      "Step: 943 of 5001.\n",
      "Step: 944 of 5001.\n",
      "Step: 945 of 5001.\n",
      "Step: 946 of 5001.\n",
      "Step: 947 of 5001.\n",
      "Step: 948 of 5001.\n",
      "Step: 949 of 5001.\n",
      "Step: 950 of 5001.\n",
      "Generator model loss: -0.5698271989822388.\n",
      "Discriminator model loss: -0.8217641711235046.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 951 of 5001.\n",
      "Step: 952 of 5001.\n",
      "Step: 953 of 5001.\n",
      "Step: 954 of 5001.\n",
      "Step: 955 of 5001.\n",
      "Step: 956 of 5001.\n",
      "Step: 957 of 5001.\n",
      "Step: 958 of 5001.\n",
      "Step: 959 of 5001.\n",
      "Step: 960 of 5001.\n",
      "Generator model loss: -0.5821101069450378.\n",
      "Discriminator model loss: -0.8143883943557739.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 961 of 5001.\n",
      "Step: 962 of 5001.\n",
      "Step: 963 of 5001.\n",
      "Step: 964 of 5001.\n",
      "Step: 965 of 5001.\n",
      "Step: 966 of 5001.\n",
      "Step: 967 of 5001.\n",
      "Step: 968 of 5001.\n",
      "Step: 969 of 5001.\n",
      "Step: 970 of 5001.\n",
      "Generator model loss: -0.582846999168396.\n",
      "Discriminator model loss: -0.8042462468147278.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 971 of 5001.\n",
      "Step: 972 of 5001.\n",
      "Step: 973 of 5001.\n",
      "Step: 974 of 5001.\n",
      "Step: 975 of 5001.\n",
      "Step: 976 of 5001.\n",
      "Step: 977 of 5001.\n",
      "Step: 978 of 5001.\n",
      "Step: 979 of 5001.\n",
      "Step: 980 of 5001.\n",
      "Generator model loss: -0.6170516014099121.\n",
      "Discriminator model loss: -0.8166214823722839.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 981 of 5001.\n",
      "Step: 982 of 5001.\n",
      "Step: 983 of 5001.\n",
      "Step: 984 of 5001.\n",
      "Step: 985 of 5001.\n",
      "Step: 986 of 5001.\n",
      "Step: 987 of 5001.\n",
      "Step: 988 of 5001.\n",
      "Step: 989 of 5001.\n",
      "Step: 990 of 5001.\n",
      "Generator model loss: -0.6042855978012085.\n",
      "Discriminator model loss: -0.8205640912055969.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 991 of 5001.\n",
      "Step: 992 of 5001.\n",
      "Step: 993 of 5001.\n",
      "Step: 994 of 5001.\n",
      "Step: 995 of 5001.\n",
      "Step: 996 of 5001.\n",
      "Step: 997 of 5001.\n",
      "Step: 998 of 5001.\n",
      "Step: 999 of 5001.\n",
      "Step: 1000 of 5001.\n",
      "Generator model loss: -0.6081633567810059.\n",
      "Discriminator model loss: -0.8010233044624329.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1001 of 5001.\n",
      "Step: 1002 of 5001.\n",
      "Step: 1003 of 5001.\n",
      "Step: 1004 of 5001.\n",
      "Step: 1005 of 5001.\n",
      "Step: 1006 of 5001.\n",
      "Step: 1007 of 5001.\n",
      "Step: 1008 of 5001.\n",
      "Step: 1009 of 5001.\n",
      "Step: 1010 of 5001.\n",
      "Generator model loss: -0.6321691274642944.\n",
      "Discriminator model loss: -0.7998303174972534.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1011 of 5001.\n",
      "Step: 1012 of 5001.\n",
      "Step: 1013 of 5001.\n",
      "Step: 1014 of 5001.\n",
      "Step: 1015 of 5001.\n",
      "Step: 1016 of 5001.\n",
      "Step: 1017 of 5001.\n",
      "Step: 1018 of 5001.\n",
      "Step: 1019 of 5001.\n",
      "Step: 1020 of 5001.\n",
      "Generator model loss: -0.6258103251457214.\n",
      "Discriminator model loss: -0.8569134473800659.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1021 of 5001.\n",
      "Step: 1022 of 5001.\n",
      "Step: 1023 of 5001.\n",
      "Step: 1024 of 5001.\n",
      "Step: 1025 of 5001.\n",
      "Step: 1026 of 5001.\n",
      "Step: 1027 of 5001.\n",
      "Step: 1028 of 5001.\n",
      "Step: 1029 of 5001.\n",
      "Step: 1030 of 5001.\n",
      "Generator model loss: -0.6473668217658997.\n",
      "Discriminator model loss: -0.8157790899276733.\n",
      "xgboost accuracy: 0.95\n",
      "Step: 1031 of 5001.\n",
      "Step: 1032 of 5001.\n",
      "Step: 1033 of 5001.\n",
      "Step: 1034 of 5001.\n",
      "Step: 1035 of 5001.\n",
      "Step: 1036 of 5001.\n",
      "Step: 1037 of 5001.\n",
      "Step: 1038 of 5001.\n",
      "Step: 1039 of 5001.\n",
      "Step: 1040 of 5001.\n",
      "Generator model loss: -0.6516803503036499.\n",
      "Discriminator model loss: -0.817355751991272.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1041 of 5001.\n",
      "Step: 1042 of 5001.\n",
      "Step: 1043 of 5001.\n",
      "Step: 1044 of 5001.\n",
      "Step: 1045 of 5001.\n",
      "Step: 1046 of 5001.\n",
      "Step: 1047 of 5001.\n",
      "Step: 1048 of 5001.\n",
      "Step: 1049 of 5001.\n",
      "Step: 1050 of 5001.\n",
      "Generator model loss: -0.6416260600090027.\n",
      "Discriminator model loss: -0.8450008630752563.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1051 of 5001.\n",
      "Step: 1052 of 5001.\n",
      "Step: 1053 of 5001.\n",
      "Step: 1054 of 5001.\n",
      "Step: 1055 of 5001.\n",
      "Step: 1056 of 5001.\n",
      "Step: 1057 of 5001.\n",
      "Step: 1058 of 5001.\n",
      "Step: 1059 of 5001.\n",
      "Step: 1060 of 5001.\n",
      "Generator model loss: -0.6442811489105225.\n",
      "Discriminator model loss: -0.7587555646896362.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1061 of 5001.\n",
      "Step: 1062 of 5001.\n",
      "Step: 1063 of 5001.\n",
      "Step: 1064 of 5001.\n",
      "Step: 1065 of 5001.\n",
      "Step: 1066 of 5001.\n",
      "Step: 1067 of 5001.\n",
      "Step: 1068 of 5001.\n",
      "Step: 1069 of 5001.\n",
      "Step: 1070 of 5001.\n",
      "Generator model loss: -0.6511419415473938.\n",
      "Discriminator model loss: -0.7658528089523315.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1071 of 5001.\n",
      "Step: 1072 of 5001.\n",
      "Step: 1073 of 5001.\n",
      "Step: 1074 of 5001.\n",
      "Step: 1075 of 5001.\n",
      "Step: 1076 of 5001.\n",
      "Step: 1077 of 5001.\n",
      "Step: 1078 of 5001.\n",
      "Step: 1079 of 5001.\n",
      "Step: 1080 of 5001.\n",
      "Generator model loss: -0.6606531143188477.\n",
      "Discriminator model loss: -0.8022173047065735.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1081 of 5001.\n",
      "Step: 1082 of 5001.\n",
      "Step: 1083 of 5001.\n",
      "Step: 1084 of 5001.\n",
      "Step: 1085 of 5001.\n",
      "Step: 1086 of 5001.\n",
      "Step: 1087 of 5001.\n",
      "Step: 1088 of 5001.\n",
      "Step: 1089 of 5001.\n",
      "Step: 1090 of 5001.\n",
      "Generator model loss: -0.674756646156311.\n",
      "Discriminator model loss: -0.8407783508300781.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1091 of 5001.\n",
      "Step: 1092 of 5001.\n",
      "Step: 1093 of 5001.\n",
      "Step: 1094 of 5001.\n",
      "Step: 1095 of 5001.\n",
      "Step: 1096 of 5001.\n",
      "Step: 1097 of 5001.\n",
      "Step: 1098 of 5001.\n",
      "Step: 1099 of 5001.\n",
      "Step: 1100 of 5001.\n",
      "Generator model loss: -0.6694520115852356.\n",
      "Discriminator model loss: -0.8383908271789551.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1101 of 5001.\n",
      "Step: 1102 of 5001.\n",
      "Step: 1103 of 5001.\n",
      "Step: 1104 of 5001.\n",
      "Step: 1105 of 5001.\n",
      "Step: 1106 of 5001.\n",
      "Step: 1107 of 5001.\n",
      "Step: 1108 of 5001.\n",
      "Step: 1109 of 5001.\n",
      "Step: 1110 of 5001.\n",
      "Generator model loss: -0.6686627864837646.\n",
      "Discriminator model loss: -0.7647221088409424.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1111 of 5001.\n",
      "Step: 1112 of 5001.\n",
      "Step: 1113 of 5001.\n",
      "Step: 1114 of 5001.\n",
      "Step: 1115 of 5001.\n",
      "Step: 1116 of 5001.\n",
      "Step: 1117 of 5001.\n",
      "Step: 1118 of 5001.\n",
      "Step: 1119 of 5001.\n",
      "Step: 1120 of 5001.\n",
      "Generator model loss: -0.6579262018203735.\n",
      "Discriminator model loss: -0.8246033787727356.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1121 of 5001.\n",
      "Step: 1122 of 5001.\n",
      "Step: 1123 of 5001.\n",
      "Step: 1124 of 5001.\n",
      "Step: 1125 of 5001.\n",
      "Step: 1126 of 5001.\n",
      "Step: 1127 of 5001.\n",
      "Step: 1128 of 5001.\n",
      "Step: 1129 of 5001.\n",
      "Step: 1130 of 5001.\n",
      "Generator model loss: -0.6906634569168091.\n",
      "Discriminator model loss: -0.7859921455383301.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1131 of 5001.\n",
      "Step: 1132 of 5001.\n",
      "Step: 1133 of 5001.\n",
      "Step: 1134 of 5001.\n",
      "Step: 1135 of 5001.\n",
      "Step: 1136 of 5001.\n",
      "Step: 1137 of 5001.\n",
      "Step: 1138 of 5001.\n",
      "Step: 1139 of 5001.\n",
      "Step: 1140 of 5001.\n",
      "Generator model loss: -0.7020038366317749.\n",
      "Discriminator model loss: -0.7740572690963745.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1141 of 5001.\n",
      "Step: 1142 of 5001.\n",
      "Step: 1143 of 5001.\n",
      "Step: 1144 of 5001.\n",
      "Step: 1145 of 5001.\n",
      "Step: 1146 of 5001.\n",
      "Step: 1147 of 5001.\n",
      "Step: 1148 of 5001.\n",
      "Step: 1149 of 5001.\n",
      "Step: 1150 of 5001.\n",
      "Generator model loss: -0.6683086156845093.\n",
      "Discriminator model loss: -0.830567479133606.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1151 of 5001.\n",
      "Step: 1152 of 5001.\n",
      "Step: 1153 of 5001.\n",
      "Step: 1154 of 5001.\n",
      "Step: 1155 of 5001.\n",
      "Step: 1156 of 5001.\n",
      "Step: 1157 of 5001.\n",
      "Step: 1158 of 5001.\n",
      "Step: 1159 of 5001.\n",
      "Step: 1160 of 5001.\n",
      "Generator model loss: -0.7070462703704834.\n",
      "Discriminator model loss: -0.7996240854263306.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1161 of 5001.\n",
      "Step: 1162 of 5001.\n",
      "Step: 1163 of 5001.\n",
      "Step: 1164 of 5001.\n",
      "Step: 1165 of 5001.\n",
      "Step: 1166 of 5001.\n",
      "Step: 1167 of 5001.\n",
      "Step: 1168 of 5001.\n",
      "Step: 1169 of 5001.\n",
      "Step: 1170 of 5001.\n",
      "Generator model loss: -0.7085221409797668.\n",
      "Discriminator model loss: -0.8082262873649597.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1171 of 5001.\n",
      "Step: 1172 of 5001.\n",
      "Step: 1173 of 5001.\n",
      "Step: 1174 of 5001.\n",
      "Step: 1175 of 5001.\n",
      "Step: 1176 of 5001.\n",
      "Step: 1177 of 5001.\n",
      "Step: 1178 of 5001.\n",
      "Step: 1179 of 5001.\n",
      "Step: 1180 of 5001.\n",
      "Generator model loss: -0.7013261914253235.\n",
      "Discriminator model loss: -0.7753545045852661.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1181 of 5001.\n",
      "Step: 1182 of 5001.\n",
      "Step: 1183 of 5001.\n",
      "Step: 1184 of 5001.\n",
      "Step: 1185 of 5001.\n",
      "Step: 1186 of 5001.\n",
      "Step: 1187 of 5001.\n",
      "Step: 1188 of 5001.\n",
      "Step: 1189 of 5001.\n",
      "Step: 1190 of 5001.\n",
      "Generator model loss: -0.7163035273551941.\n",
      "Discriminator model loss: -0.7831344604492188.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1191 of 5001.\n",
      "Step: 1192 of 5001.\n",
      "Step: 1193 of 5001.\n",
      "Step: 1194 of 5001.\n",
      "Step: 1195 of 5001.\n",
      "Step: 1196 of 5001.\n",
      "Step: 1197 of 5001.\n",
      "Step: 1198 of 5001.\n",
      "Step: 1199 of 5001.\n",
      "Step: 1200 of 5001.\n",
      "Generator model loss: -0.6857975721359253.\n",
      "Discriminator model loss: -0.7223359942436218.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1201 of 5001.\n",
      "Step: 1202 of 5001.\n",
      "Step: 1203 of 5001.\n",
      "Step: 1204 of 5001.\n",
      "Step: 1205 of 5001.\n",
      "Step: 1206 of 5001.\n",
      "Step: 1207 of 5001.\n",
      "Step: 1208 of 5001.\n",
      "Step: 1209 of 5001.\n",
      "Step: 1210 of 5001.\n",
      "Generator model loss: -0.6949115991592407.\n",
      "Discriminator model loss: -0.8223792910575867.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1211 of 5001.\n",
      "Step: 1212 of 5001.\n",
      "Step: 1213 of 5001.\n",
      "Step: 1214 of 5001.\n",
      "Step: 1215 of 5001.\n",
      "Step: 1216 of 5001.\n",
      "Step: 1217 of 5001.\n",
      "Step: 1218 of 5001.\n",
      "Step: 1219 of 5001.\n",
      "Step: 1220 of 5001.\n",
      "Generator model loss: -0.7202448844909668.\n",
      "Discriminator model loss: -0.8682385683059692.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1221 of 5001.\n",
      "Step: 1222 of 5001.\n",
      "Step: 1223 of 5001.\n",
      "Step: 1224 of 5001.\n",
      "Step: 1225 of 5001.\n",
      "Step: 1226 of 5001.\n",
      "Step: 1227 of 5001.\n",
      "Step: 1228 of 5001.\n",
      "Step: 1229 of 5001.\n",
      "Step: 1230 of 5001.\n",
      "Generator model loss: -0.7084150314331055.\n",
      "Discriminator model loss: -0.7781853079795837.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1231 of 5001.\n",
      "Step: 1232 of 5001.\n",
      "Step: 1233 of 5001.\n",
      "Step: 1234 of 5001.\n",
      "Step: 1235 of 5001.\n",
      "Step: 1236 of 5001.\n",
      "Step: 1237 of 5001.\n",
      "Step: 1238 of 5001.\n",
      "Step: 1239 of 5001.\n",
      "Step: 1240 of 5001.\n",
      "Generator model loss: -0.7011208534240723.\n",
      "Discriminator model loss: -0.7516065835952759.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1241 of 5001.\n",
      "Step: 1242 of 5001.\n",
      "Step: 1243 of 5001.\n",
      "Step: 1244 of 5001.\n",
      "Step: 1245 of 5001.\n",
      "Step: 1246 of 5001.\n",
      "Step: 1247 of 5001.\n",
      "Step: 1248 of 5001.\n",
      "Step: 1249 of 5001.\n",
      "Step: 1250 of 5001.\n",
      "Generator model loss: -0.7118299007415771.\n",
      "Discriminator model loss: -0.7724910974502563.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1251 of 5001.\n",
      "Step: 1252 of 5001.\n",
      "Step: 1253 of 5001.\n",
      "Step: 1254 of 5001.\n",
      "Step: 1255 of 5001.\n",
      "Step: 1256 of 5001.\n",
      "Step: 1257 of 5001.\n",
      "Step: 1258 of 5001.\n",
      "Step: 1259 of 5001.\n",
      "Step: 1260 of 5001.\n",
      "Generator model loss: -0.7263280153274536.\n",
      "Discriminator model loss: -0.8030993342399597.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1261 of 5001.\n",
      "Step: 1262 of 5001.\n",
      "Step: 1263 of 5001.\n",
      "Step: 1264 of 5001.\n",
      "Step: 1265 of 5001.\n",
      "Step: 1266 of 5001.\n",
      "Step: 1267 of 5001.\n",
      "Step: 1268 of 5001.\n",
      "Step: 1269 of 5001.\n",
      "Step: 1270 of 5001.\n",
      "Generator model loss: -0.7306209206581116.\n",
      "Discriminator model loss: -0.8057225942611694.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1271 of 5001.\n",
      "Step: 1272 of 5001.\n",
      "Step: 1273 of 5001.\n",
      "Step: 1274 of 5001.\n",
      "Step: 1275 of 5001.\n",
      "Step: 1276 of 5001.\n",
      "Step: 1277 of 5001.\n",
      "Step: 1278 of 5001.\n",
      "Step: 1279 of 5001.\n",
      "Step: 1280 of 5001.\n",
      "Generator model loss: -0.7099520564079285.\n",
      "Discriminator model loss: -0.7851094007492065.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1281 of 5001.\n",
      "Step: 1282 of 5001.\n",
      "Step: 1283 of 5001.\n",
      "Step: 1284 of 5001.\n",
      "Step: 1285 of 5001.\n",
      "Step: 1286 of 5001.\n",
      "Step: 1287 of 5001.\n",
      "Step: 1288 of 5001.\n",
      "Step: 1289 of 5001.\n",
      "Step: 1290 of 5001.\n",
      "Generator model loss: -0.728198766708374.\n",
      "Discriminator model loss: -0.8283810615539551.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1291 of 5001.\n",
      "Step: 1292 of 5001.\n",
      "Step: 1293 of 5001.\n",
      "Step: 1294 of 5001.\n",
      "Step: 1295 of 5001.\n",
      "Step: 1296 of 5001.\n",
      "Step: 1297 of 5001.\n",
      "Step: 1298 of 5001.\n",
      "Step: 1299 of 5001.\n",
      "Step: 1300 of 5001.\n",
      "Generator model loss: -0.7295666933059692.\n",
      "Discriminator model loss: -0.7703030109405518.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1301 of 5001.\n",
      "Step: 1302 of 5001.\n",
      "Step: 1303 of 5001.\n",
      "Step: 1304 of 5001.\n",
      "Step: 1305 of 5001.\n",
      "Step: 1306 of 5001.\n",
      "Step: 1307 of 5001.\n",
      "Step: 1308 of 5001.\n",
      "Step: 1309 of 5001.\n",
      "Step: 1310 of 5001.\n",
      "Generator model loss: -0.7246517539024353.\n",
      "Discriminator model loss: -0.7718977928161621.\n",
      "xgboost accuracy: 0.93\n",
      "Step: 1311 of 5001.\n",
      "Step: 1312 of 5001.\n",
      "Step: 1313 of 5001.\n",
      "Step: 1314 of 5001.\n",
      "Step: 1315 of 5001.\n",
      "Step: 1316 of 5001.\n",
      "Step: 1317 of 5001.\n",
      "Step: 1318 of 5001.\n",
      "Step: 1319 of 5001.\n",
      "Step: 1320 of 5001.\n",
      "Generator model loss: -0.7147098779678345.\n",
      "Discriminator model loss: -0.8057729601860046.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1321 of 5001.\n",
      "Step: 1322 of 5001.\n",
      "Step: 1323 of 5001.\n",
      "Step: 1324 of 5001.\n",
      "Step: 1325 of 5001.\n",
      "Step: 1326 of 5001.\n",
      "Step: 1327 of 5001.\n",
      "Step: 1328 of 5001.\n",
      "Step: 1329 of 5001.\n",
      "Step: 1330 of 5001.\n",
      "Generator model loss: -0.7207888960838318.\n",
      "Discriminator model loss: -0.7756695747375488.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1331 of 5001.\n",
      "Step: 1332 of 5001.\n",
      "Step: 1333 of 5001.\n",
      "Step: 1334 of 5001.\n",
      "Step: 1335 of 5001.\n",
      "Step: 1336 of 5001.\n",
      "Step: 1337 of 5001.\n",
      "Step: 1338 of 5001.\n",
      "Step: 1339 of 5001.\n",
      "Step: 1340 of 5001.\n",
      "Generator model loss: -0.7440172433853149.\n",
      "Discriminator model loss: -0.8067474365234375.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1341 of 5001.\n",
      "Step: 1342 of 5001.\n",
      "Step: 1343 of 5001.\n",
      "Step: 1344 of 5001.\n",
      "Step: 1345 of 5001.\n",
      "Step: 1346 of 5001.\n",
      "Step: 1347 of 5001.\n",
      "Step: 1348 of 5001.\n",
      "Step: 1349 of 5001.\n",
      "Step: 1350 of 5001.\n",
      "Generator model loss: -0.7263486385345459.\n",
      "Discriminator model loss: -0.798180103302002.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1351 of 5001.\n",
      "Step: 1352 of 5001.\n",
      "Step: 1353 of 5001.\n",
      "Step: 1354 of 5001.\n",
      "Step: 1355 of 5001.\n",
      "Step: 1356 of 5001.\n",
      "Step: 1357 of 5001.\n",
      "Step: 1358 of 5001.\n",
      "Step: 1359 of 5001.\n",
      "Step: 1360 of 5001.\n",
      "Generator model loss: -0.7431005239486694.\n",
      "Discriminator model loss: -0.7699903845787048.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1361 of 5001.\n",
      "Step: 1362 of 5001.\n",
      "Step: 1363 of 5001.\n",
      "Step: 1364 of 5001.\n",
      "Step: 1365 of 5001.\n",
      "Step: 1366 of 5001.\n",
      "Step: 1367 of 5001.\n",
      "Step: 1368 of 5001.\n",
      "Step: 1369 of 5001.\n",
      "Step: 1370 of 5001.\n",
      "Generator model loss: -0.7556614875793457.\n",
      "Discriminator model loss: -0.7913507223129272.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1371 of 5001.\n",
      "Step: 1372 of 5001.\n",
      "Step: 1373 of 5001.\n",
      "Step: 1374 of 5001.\n",
      "Step: 1375 of 5001.\n",
      "Step: 1376 of 5001.\n",
      "Step: 1377 of 5001.\n",
      "Step: 1378 of 5001.\n",
      "Step: 1379 of 5001.\n",
      "Step: 1380 of 5001.\n",
      "Generator model loss: -0.7660517692565918.\n",
      "Discriminator model loss: -0.8269227743148804.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1381 of 5001.\n",
      "Step: 1382 of 5001.\n",
      "Step: 1383 of 5001.\n",
      "Step: 1384 of 5001.\n",
      "Step: 1385 of 5001.\n",
      "Step: 1386 of 5001.\n",
      "Step: 1387 of 5001.\n",
      "Step: 1388 of 5001.\n",
      "Step: 1389 of 5001.\n",
      "Step: 1390 of 5001.\n",
      "Generator model loss: -0.7794598340988159.\n",
      "Discriminator model loss: -0.8047785758972168.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1391 of 5001.\n",
      "Step: 1392 of 5001.\n",
      "Step: 1393 of 5001.\n",
      "Step: 1394 of 5001.\n",
      "Step: 1395 of 5001.\n",
      "Step: 1396 of 5001.\n",
      "Step: 1397 of 5001.\n",
      "Step: 1398 of 5001.\n",
      "Step: 1399 of 5001.\n",
      "Step: 1400 of 5001.\n",
      "Generator model loss: -0.7548352479934692.\n",
      "Discriminator model loss: -0.7750633358955383.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1401 of 5001.\n",
      "Step: 1402 of 5001.\n",
      "Step: 1403 of 5001.\n",
      "Step: 1404 of 5001.\n",
      "Step: 1405 of 5001.\n",
      "Step: 1406 of 5001.\n",
      "Step: 1407 of 5001.\n",
      "Step: 1408 of 5001.\n",
      "Step: 1409 of 5001.\n",
      "Step: 1410 of 5001.\n",
      "Generator model loss: -0.785647988319397.\n",
      "Discriminator model loss: -0.7261980175971985.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1411 of 5001.\n",
      "Step: 1412 of 5001.\n",
      "Step: 1413 of 5001.\n",
      "Step: 1414 of 5001.\n",
      "Step: 1415 of 5001.\n",
      "Step: 1416 of 5001.\n",
      "Step: 1417 of 5001.\n",
      "Step: 1418 of 5001.\n",
      "Step: 1419 of 5001.\n",
      "Step: 1420 of 5001.\n",
      "Generator model loss: -0.7994810342788696.\n",
      "Discriminator model loss: -0.7506008148193359.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1421 of 5001.\n",
      "Step: 1422 of 5001.\n",
      "Step: 1423 of 5001.\n",
      "Step: 1424 of 5001.\n",
      "Step: 1425 of 5001.\n",
      "Step: 1426 of 5001.\n",
      "Step: 1427 of 5001.\n",
      "Step: 1428 of 5001.\n",
      "Step: 1429 of 5001.\n",
      "Step: 1430 of 5001.\n",
      "Generator model loss: -0.7926058173179626.\n",
      "Discriminator model loss: -0.8099009394645691.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1431 of 5001.\n",
      "Step: 1432 of 5001.\n",
      "Step: 1433 of 5001.\n",
      "Step: 1434 of 5001.\n",
      "Step: 1435 of 5001.\n",
      "Step: 1436 of 5001.\n",
      "Step: 1437 of 5001.\n",
      "Step: 1438 of 5001.\n",
      "Step: 1439 of 5001.\n",
      "Step: 1440 of 5001.\n",
      "Generator model loss: -0.8044607043266296.\n",
      "Discriminator model loss: -0.703689455986023.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1441 of 5001.\n",
      "Step: 1442 of 5001.\n",
      "Step: 1443 of 5001.\n",
      "Step: 1444 of 5001.\n",
      "Step: 1445 of 5001.\n",
      "Step: 1446 of 5001.\n",
      "Step: 1447 of 5001.\n",
      "Step: 1448 of 5001.\n",
      "Step: 1449 of 5001.\n",
      "Step: 1450 of 5001.\n",
      "Generator model loss: -0.7985719442367554.\n",
      "Discriminator model loss: -0.7992530465126038.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1451 of 5001.\n",
      "Step: 1452 of 5001.\n",
      "Step: 1453 of 5001.\n",
      "Step: 1454 of 5001.\n",
      "Step: 1455 of 5001.\n",
      "Step: 1456 of 5001.\n",
      "Step: 1457 of 5001.\n",
      "Step: 1458 of 5001.\n",
      "Step: 1459 of 5001.\n",
      "Step: 1460 of 5001.\n",
      "Generator model loss: -0.8285886645317078.\n",
      "Discriminator model loss: -0.7787300944328308.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1461 of 5001.\n",
      "Step: 1462 of 5001.\n",
      "Step: 1463 of 5001.\n",
      "Step: 1464 of 5001.\n",
      "Step: 1465 of 5001.\n",
      "Step: 1466 of 5001.\n",
      "Step: 1467 of 5001.\n",
      "Step: 1468 of 5001.\n",
      "Step: 1469 of 5001.\n",
      "Step: 1470 of 5001.\n",
      "Generator model loss: -0.823377251625061.\n",
      "Discriminator model loss: -0.8213784098625183.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1471 of 5001.\n",
      "Step: 1472 of 5001.\n",
      "Step: 1473 of 5001.\n",
      "Step: 1474 of 5001.\n",
      "Step: 1475 of 5001.\n",
      "Step: 1476 of 5001.\n",
      "Step: 1477 of 5001.\n",
      "Step: 1478 of 5001.\n",
      "Step: 1479 of 5001.\n",
      "Step: 1480 of 5001.\n",
      "Generator model loss: -0.8278913497924805.\n",
      "Discriminator model loss: -0.7605316638946533.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1481 of 5001.\n",
      "Step: 1482 of 5001.\n",
      "Step: 1483 of 5001.\n",
      "Step: 1484 of 5001.\n",
      "Step: 1485 of 5001.\n",
      "Step: 1486 of 5001.\n",
      "Step: 1487 of 5001.\n",
      "Step: 1488 of 5001.\n",
      "Step: 1489 of 5001.\n",
      "Step: 1490 of 5001.\n",
      "Generator model loss: -0.854569137096405.\n",
      "Discriminator model loss: -0.7439900040626526.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1491 of 5001.\n",
      "Step: 1492 of 5001.\n",
      "Step: 1493 of 5001.\n",
      "Step: 1494 of 5001.\n",
      "Step: 1495 of 5001.\n",
      "Step: 1496 of 5001.\n",
      "Step: 1497 of 5001.\n",
      "Step: 1498 of 5001.\n",
      "Step: 1499 of 5001.\n",
      "Step: 1500 of 5001.\n",
      "Generator model loss: -0.821269690990448.\n",
      "Discriminator model loss: -0.799045741558075.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1501 of 5001.\n",
      "Step: 1502 of 5001.\n",
      "Step: 1503 of 5001.\n",
      "Step: 1504 of 5001.\n",
      "Step: 1505 of 5001.\n",
      "Step: 1506 of 5001.\n",
      "Step: 1507 of 5001.\n",
      "Step: 1508 of 5001.\n",
      "Step: 1509 of 5001.\n",
      "Step: 1510 of 5001.\n",
      "Generator model loss: -0.8452679514884949.\n",
      "Discriminator model loss: -0.8059155344963074.\n",
      "xgboost accuracy: 0.91\n",
      "Step: 1511 of 5001.\n",
      "Step: 1512 of 5001.\n",
      "Step: 1513 of 5001.\n",
      "Step: 1514 of 5001.\n",
      "Step: 1515 of 5001.\n",
      "Step: 1516 of 5001.\n",
      "Step: 1517 of 5001.\n",
      "Step: 1518 of 5001.\n",
      "Step: 1519 of 5001.\n",
      "Step: 1520 of 5001.\n",
      "Generator model loss: -0.8898685574531555.\n",
      "Discriminator model loss: -0.7744030952453613.\n",
      "xgboost accuracy: 0.94\n",
      "Step: 1521 of 5001.\n",
      "Step: 1522 of 5001.\n",
      "Step: 1523 of 5001.\n",
      "Step: 1524 of 5001.\n",
      "Step: 1525 of 5001.\n",
      "Step: 1526 of 5001.\n",
      "Step: 1527 of 5001.\n",
      "Step: 1528 of 5001.\n",
      "Step: 1529 of 5001.\n",
      "Step: 1530 of 5001.\n",
      "Generator model loss: -0.8742173314094543.\n",
      "Discriminator model loss: -0.7403731346130371.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1531 of 5001.\n",
      "Step: 1532 of 5001.\n",
      "Step: 1533 of 5001.\n",
      "Step: 1534 of 5001.\n",
      "Step: 1535 of 5001.\n",
      "Step: 1536 of 5001.\n",
      "Step: 1537 of 5001.\n",
      "Step: 1538 of 5001.\n",
      "Step: 1539 of 5001.\n",
      "Step: 1540 of 5001.\n",
      "Generator model loss: -0.8896802067756653.\n",
      "Discriminator model loss: -0.7703907489776611.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1541 of 5001.\n",
      "Step: 1542 of 5001.\n",
      "Step: 1543 of 5001.\n",
      "Step: 1544 of 5001.\n",
      "Step: 1545 of 5001.\n",
      "Step: 1546 of 5001.\n",
      "Step: 1547 of 5001.\n",
      "Step: 1548 of 5001.\n",
      "Step: 1549 of 5001.\n",
      "Step: 1550 of 5001.\n",
      "Generator model loss: -0.9255692362785339.\n",
      "Discriminator model loss: -0.814734935760498.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1551 of 5001.\n",
      "Step: 1552 of 5001.\n",
      "Step: 1553 of 5001.\n",
      "Step: 1554 of 5001.\n",
      "Step: 1555 of 5001.\n",
      "Step: 1556 of 5001.\n",
      "Step: 1557 of 5001.\n",
      "Step: 1558 of 5001.\n",
      "Step: 1559 of 5001.\n",
      "Step: 1560 of 5001.\n",
      "Generator model loss: -0.8983961343765259.\n",
      "Discriminator model loss: -0.7963929772377014.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1561 of 5001.\n",
      "Step: 1562 of 5001.\n",
      "Step: 1563 of 5001.\n",
      "Step: 1564 of 5001.\n",
      "Step: 1565 of 5001.\n",
      "Step: 1566 of 5001.\n",
      "Step: 1567 of 5001.\n",
      "Step: 1568 of 5001.\n",
      "Step: 1569 of 5001.\n",
      "Step: 1570 of 5001.\n",
      "Generator model loss: -0.9229234457015991.\n",
      "Discriminator model loss: -0.7774916291236877.\n",
      "xgboost accuracy: 0.92\n",
      "Step: 1571 of 5001.\n",
      "Step: 1572 of 5001.\n",
      "Step: 1573 of 5001.\n",
      "Step: 1574 of 5001.\n",
      "Step: 1575 of 5001.\n",
      "Step: 1576 of 5001.\n",
      "Step: 1577 of 5001.\n",
      "Step: 1578 of 5001.\n",
      "Step: 1579 of 5001.\n",
      "Step: 1580 of 5001.\n",
      "Generator model loss: -0.9473820924758911.\n",
      "Discriminator model loss: -0.746268630027771.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1581 of 5001.\n",
      "Step: 1582 of 5001.\n",
      "Step: 1583 of 5001.\n",
      "Step: 1584 of 5001.\n",
      "Step: 1585 of 5001.\n",
      "Step: 1586 of 5001.\n",
      "Step: 1587 of 5001.\n",
      "Step: 1588 of 5001.\n",
      "Step: 1589 of 5001.\n",
      "Step: 1590 of 5001.\n",
      "Generator model loss: -0.9424431920051575.\n",
      "Discriminator model loss: -0.752869725227356.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1591 of 5001.\n",
      "Step: 1592 of 5001.\n",
      "Step: 1593 of 5001.\n",
      "Step: 1594 of 5001.\n",
      "Step: 1595 of 5001.\n",
      "Step: 1596 of 5001.\n",
      "Step: 1597 of 5001.\n",
      "Step: 1598 of 5001.\n",
      "Step: 1599 of 5001.\n",
      "Step: 1600 of 5001.\n",
      "Generator model loss: -0.9784381985664368.\n",
      "Discriminator model loss: -0.7371121644973755.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1601 of 5001.\n",
      "Step: 1602 of 5001.\n",
      "Step: 1603 of 5001.\n",
      "Step: 1604 of 5001.\n",
      "Step: 1605 of 5001.\n",
      "Step: 1606 of 5001.\n",
      "Step: 1607 of 5001.\n",
      "Step: 1608 of 5001.\n",
      "Step: 1609 of 5001.\n",
      "Step: 1610 of 5001.\n",
      "Generator model loss: -0.9748595952987671.\n",
      "Discriminator model loss: -0.7268377542495728.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1611 of 5001.\n",
      "Step: 1612 of 5001.\n",
      "Step: 1613 of 5001.\n",
      "Step: 1614 of 5001.\n",
      "Step: 1615 of 5001.\n",
      "Step: 1616 of 5001.\n",
      "Step: 1617 of 5001.\n",
      "Step: 1618 of 5001.\n",
      "Step: 1619 of 5001.\n",
      "Step: 1620 of 5001.\n",
      "Generator model loss: -0.9713042974472046.\n",
      "Discriminator model loss: -0.7879196405410767.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1621 of 5001.\n",
      "Step: 1622 of 5001.\n",
      "Step: 1623 of 5001.\n",
      "Step: 1624 of 5001.\n",
      "Step: 1625 of 5001.\n",
      "Step: 1626 of 5001.\n",
      "Step: 1627 of 5001.\n",
      "Step: 1628 of 5001.\n",
      "Step: 1629 of 5001.\n",
      "Step: 1630 of 5001.\n",
      "Generator model loss: -0.9854834675788879.\n",
      "Discriminator model loss: -0.7493783831596375.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 1631 of 5001.\n",
      "Step: 1632 of 5001.\n",
      "Step: 1633 of 5001.\n",
      "Step: 1634 of 5001.\n",
      "Step: 1635 of 5001.\n",
      "Step: 1636 of 5001.\n",
      "Step: 1637 of 5001.\n",
      "Step: 1638 of 5001.\n",
      "Step: 1639 of 5001.\n",
      "Step: 1640 of 5001.\n",
      "Generator model loss: -0.9941407442092896.\n",
      "Discriminator model loss: -0.6943073272705078.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1641 of 5001.\n",
      "Step: 1642 of 5001.\n",
      "Step: 1643 of 5001.\n",
      "Step: 1644 of 5001.\n",
      "Step: 1645 of 5001.\n",
      "Step: 1646 of 5001.\n",
      "Step: 1647 of 5001.\n",
      "Step: 1648 of 5001.\n",
      "Step: 1649 of 5001.\n",
      "Step: 1650 of 5001.\n",
      "Generator model loss: -1.0041464567184448.\n",
      "Discriminator model loss: -0.8092764019966125.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1651 of 5001.\n",
      "Step: 1652 of 5001.\n",
      "Step: 1653 of 5001.\n",
      "Step: 1654 of 5001.\n",
      "Step: 1655 of 5001.\n",
      "Step: 1656 of 5001.\n",
      "Step: 1657 of 5001.\n",
      "Step: 1658 of 5001.\n",
      "Step: 1659 of 5001.\n",
      "Step: 1660 of 5001.\n",
      "Generator model loss: -0.9972760081291199.\n",
      "Discriminator model loss: -0.7152347564697266.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1661 of 5001.\n",
      "Step: 1662 of 5001.\n",
      "Step: 1663 of 5001.\n",
      "Step: 1664 of 5001.\n",
      "Step: 1665 of 5001.\n",
      "Step: 1666 of 5001.\n",
      "Step: 1667 of 5001.\n",
      "Step: 1668 of 5001.\n",
      "Step: 1669 of 5001.\n",
      "Step: 1670 of 5001.\n",
      "Generator model loss: -1.024566888809204.\n",
      "Discriminator model loss: -0.6719790697097778.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1671 of 5001.\n",
      "Step: 1672 of 5001.\n",
      "Step: 1673 of 5001.\n",
      "Step: 1674 of 5001.\n",
      "Step: 1675 of 5001.\n",
      "Step: 1676 of 5001.\n",
      "Step: 1677 of 5001.\n",
      "Step: 1678 of 5001.\n",
      "Step: 1679 of 5001.\n",
      "Step: 1680 of 5001.\n",
      "Generator model loss: -1.042080283164978.\n",
      "Discriminator model loss: -0.7113721370697021.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1681 of 5001.\n",
      "Step: 1682 of 5001.\n",
      "Step: 1683 of 5001.\n",
      "Step: 1684 of 5001.\n",
      "Step: 1685 of 5001.\n",
      "Step: 1686 of 5001.\n",
      "Step: 1687 of 5001.\n",
      "Step: 1688 of 5001.\n",
      "Step: 1689 of 5001.\n",
      "Step: 1690 of 5001.\n",
      "Generator model loss: -1.0373642444610596.\n",
      "Discriminator model loss: -0.7617090940475464.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1691 of 5001.\n",
      "Step: 1692 of 5001.\n",
      "Step: 1693 of 5001.\n",
      "Step: 1694 of 5001.\n",
      "Step: 1695 of 5001.\n",
      "Step: 1696 of 5001.\n",
      "Step: 1697 of 5001.\n",
      "Step: 1698 of 5001.\n",
      "Step: 1699 of 5001.\n",
      "Step: 1700 of 5001.\n",
      "Generator model loss: -1.0731797218322754.\n",
      "Discriminator model loss: -0.766695499420166.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1701 of 5001.\n",
      "Step: 1702 of 5001.\n",
      "Step: 1703 of 5001.\n",
      "Step: 1704 of 5001.\n",
      "Step: 1705 of 5001.\n",
      "Step: 1706 of 5001.\n",
      "Step: 1707 of 5001.\n",
      "Step: 1708 of 5001.\n",
      "Step: 1709 of 5001.\n",
      "Step: 1710 of 5001.\n",
      "Generator model loss: -1.0793129205703735.\n",
      "Discriminator model loss: -0.762881875038147.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1711 of 5001.\n",
      "Step: 1712 of 5001.\n",
      "Step: 1713 of 5001.\n",
      "Step: 1714 of 5001.\n",
      "Step: 1715 of 5001.\n",
      "Step: 1716 of 5001.\n",
      "Step: 1717 of 5001.\n",
      "Step: 1718 of 5001.\n",
      "Step: 1719 of 5001.\n",
      "Step: 1720 of 5001.\n",
      "Generator model loss: -1.0754824876785278.\n",
      "Discriminator model loss: -0.7545884847640991.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1721 of 5001.\n",
      "Step: 1722 of 5001.\n",
      "Step: 1723 of 5001.\n",
      "Step: 1724 of 5001.\n",
      "Step: 1725 of 5001.\n",
      "Step: 1726 of 5001.\n",
      "Step: 1727 of 5001.\n",
      "Step: 1728 of 5001.\n",
      "Step: 1729 of 5001.\n",
      "Step: 1730 of 5001.\n",
      "Generator model loss: -1.0653008222579956.\n",
      "Discriminator model loss: -0.7582374811172485.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1731 of 5001.\n",
      "Step: 1732 of 5001.\n",
      "Step: 1733 of 5001.\n",
      "Step: 1734 of 5001.\n",
      "Step: 1735 of 5001.\n",
      "Step: 1736 of 5001.\n",
      "Step: 1737 of 5001.\n",
      "Step: 1738 of 5001.\n",
      "Step: 1739 of 5001.\n",
      "Step: 1740 of 5001.\n",
      "Generator model loss: -1.091261625289917.\n",
      "Discriminator model loss: -0.7130979299545288.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1741 of 5001.\n",
      "Step: 1742 of 5001.\n",
      "Step: 1743 of 5001.\n",
      "Step: 1744 of 5001.\n",
      "Step: 1745 of 5001.\n",
      "Step: 1746 of 5001.\n",
      "Step: 1747 of 5001.\n",
      "Step: 1748 of 5001.\n",
      "Step: 1749 of 5001.\n",
      "Step: 1750 of 5001.\n",
      "Generator model loss: -1.1428217887878418.\n",
      "Discriminator model loss: -0.7441077828407288.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 1751 of 5001.\n",
      "Step: 1752 of 5001.\n",
      "Step: 1753 of 5001.\n",
      "Step: 1754 of 5001.\n",
      "Step: 1755 of 5001.\n",
      "Step: 1756 of 5001.\n",
      "Step: 1757 of 5001.\n",
      "Step: 1758 of 5001.\n",
      "Step: 1759 of 5001.\n",
      "Step: 1760 of 5001.\n",
      "Generator model loss: -1.1137535572052002.\n",
      "Discriminator model loss: -0.7233967781066895.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1761 of 5001.\n",
      "Step: 1762 of 5001.\n",
      "Step: 1763 of 5001.\n",
      "Step: 1764 of 5001.\n",
      "Step: 1765 of 5001.\n",
      "Step: 1766 of 5001.\n",
      "Step: 1767 of 5001.\n",
      "Step: 1768 of 5001.\n",
      "Step: 1769 of 5001.\n",
      "Step: 1770 of 5001.\n",
      "Generator model loss: -1.0930882692337036.\n",
      "Discriminator model loss: -0.7460018396377563.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1771 of 5001.\n",
      "Step: 1772 of 5001.\n",
      "Step: 1773 of 5001.\n",
      "Step: 1774 of 5001.\n",
      "Step: 1775 of 5001.\n",
      "Step: 1776 of 5001.\n",
      "Step: 1777 of 5001.\n",
      "Step: 1778 of 5001.\n",
      "Step: 1779 of 5001.\n",
      "Step: 1780 of 5001.\n",
      "Generator model loss: -1.0886090993881226.\n",
      "Discriminator model loss: -0.7035879492759705.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1781 of 5001.\n",
      "Step: 1782 of 5001.\n",
      "Step: 1783 of 5001.\n",
      "Step: 1784 of 5001.\n",
      "Step: 1785 of 5001.\n",
      "Step: 1786 of 5001.\n",
      "Step: 1787 of 5001.\n",
      "Step: 1788 of 5001.\n",
      "Step: 1789 of 5001.\n",
      "Step: 1790 of 5001.\n",
      "Generator model loss: -1.0928789377212524.\n",
      "Discriminator model loss: -0.7371796369552612.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 1791 of 5001.\n",
      "Step: 1792 of 5001.\n",
      "Step: 1793 of 5001.\n",
      "Step: 1794 of 5001.\n",
      "Step: 1795 of 5001.\n",
      "Step: 1796 of 5001.\n",
      "Step: 1797 of 5001.\n",
      "Step: 1798 of 5001.\n",
      "Step: 1799 of 5001.\n",
      "Step: 1800 of 5001.\n",
      "Generator model loss: -1.1326122283935547.\n",
      "Discriminator model loss: -0.7155048847198486.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 1801 of 5001.\n",
      "Step: 1802 of 5001.\n",
      "Step: 1803 of 5001.\n",
      "Step: 1804 of 5001.\n",
      "Step: 1805 of 5001.\n",
      "Step: 1806 of 5001.\n",
      "Step: 1807 of 5001.\n",
      "Step: 1808 of 5001.\n",
      "Step: 1809 of 5001.\n",
      "Step: 1810 of 5001.\n",
      "Generator model loss: -1.1256730556488037.\n",
      "Discriminator model loss: -0.6611985564231873.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1811 of 5001.\n",
      "Step: 1812 of 5001.\n",
      "Step: 1813 of 5001.\n",
      "Step: 1814 of 5001.\n",
      "Step: 1815 of 5001.\n",
      "Step: 1816 of 5001.\n",
      "Step: 1817 of 5001.\n",
      "Step: 1818 of 5001.\n",
      "Step: 1819 of 5001.\n",
      "Step: 1820 of 5001.\n",
      "Generator model loss: -1.16939115524292.\n",
      "Discriminator model loss: -0.5991017818450928.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1821 of 5001.\n",
      "Step: 1822 of 5001.\n",
      "Step: 1823 of 5001.\n",
      "Step: 1824 of 5001.\n",
      "Step: 1825 of 5001.\n",
      "Step: 1826 of 5001.\n",
      "Step: 1827 of 5001.\n",
      "Step: 1828 of 5001.\n",
      "Step: 1829 of 5001.\n",
      "Step: 1830 of 5001.\n",
      "Generator model loss: -1.1755168437957764.\n",
      "Discriminator model loss: -0.7024427652359009.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1831 of 5001.\n",
      "Step: 1832 of 5001.\n",
      "Step: 1833 of 5001.\n",
      "Step: 1834 of 5001.\n",
      "Step: 1835 of 5001.\n",
      "Step: 1836 of 5001.\n",
      "Step: 1837 of 5001.\n",
      "Step: 1838 of 5001.\n",
      "Step: 1839 of 5001.\n",
      "Step: 1840 of 5001.\n",
      "Generator model loss: -1.1725058555603027.\n",
      "Discriminator model loss: -0.6366897225379944.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 1841 of 5001.\n",
      "Step: 1842 of 5001.\n",
      "Step: 1843 of 5001.\n",
      "Step: 1844 of 5001.\n",
      "Step: 1845 of 5001.\n",
      "Step: 1846 of 5001.\n",
      "Step: 1847 of 5001.\n",
      "Step: 1848 of 5001.\n",
      "Step: 1849 of 5001.\n",
      "Step: 1850 of 5001.\n",
      "Generator model loss: -1.1895182132720947.\n",
      "Discriminator model loss: -0.7542613744735718.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 1851 of 5001.\n",
      "Step: 1852 of 5001.\n",
      "Step: 1853 of 5001.\n",
      "Step: 1854 of 5001.\n",
      "Step: 1855 of 5001.\n",
      "Step: 1856 of 5001.\n",
      "Step: 1857 of 5001.\n",
      "Step: 1858 of 5001.\n",
      "Step: 1859 of 5001.\n",
      "Step: 1860 of 5001.\n",
      "Generator model loss: -1.2195168733596802.\n",
      "Discriminator model loss: -0.6942048072814941.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 1861 of 5001.\n",
      "Step: 1862 of 5001.\n",
      "Step: 1863 of 5001.\n",
      "Step: 1864 of 5001.\n",
      "Step: 1865 of 5001.\n",
      "Step: 1866 of 5001.\n",
      "Step: 1867 of 5001.\n",
      "Step: 1868 of 5001.\n",
      "Step: 1869 of 5001.\n",
      "Step: 1870 of 5001.\n",
      "Generator model loss: -1.2064369916915894.\n",
      "Discriminator model loss: -0.7007626891136169.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1871 of 5001.\n",
      "Step: 1872 of 5001.\n",
      "Step: 1873 of 5001.\n",
      "Step: 1874 of 5001.\n",
      "Step: 1875 of 5001.\n",
      "Step: 1876 of 5001.\n",
      "Step: 1877 of 5001.\n",
      "Step: 1878 of 5001.\n",
      "Step: 1879 of 5001.\n",
      "Step: 1880 of 5001.\n",
      "Generator model loss: -1.2481753826141357.\n",
      "Discriminator model loss: -0.648196280002594.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 1881 of 5001.\n",
      "Step: 1882 of 5001.\n",
      "Step: 1883 of 5001.\n",
      "Step: 1884 of 5001.\n",
      "Step: 1885 of 5001.\n",
      "Step: 1886 of 5001.\n",
      "Step: 1887 of 5001.\n",
      "Step: 1888 of 5001.\n",
      "Step: 1889 of 5001.\n",
      "Step: 1890 of 5001.\n",
      "Generator model loss: -1.2432130575180054.\n",
      "Discriminator model loss: -0.6026753187179565.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1891 of 5001.\n",
      "Step: 1892 of 5001.\n",
      "Step: 1893 of 5001.\n",
      "Step: 1894 of 5001.\n",
      "Step: 1895 of 5001.\n",
      "Step: 1896 of 5001.\n",
      "Step: 1897 of 5001.\n",
      "Step: 1898 of 5001.\n",
      "Step: 1899 of 5001.\n",
      "Step: 1900 of 5001.\n",
      "Generator model loss: -1.2778346538543701.\n",
      "Discriminator model loss: -0.6837340593338013.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1901 of 5001.\n",
      "Step: 1902 of 5001.\n",
      "Step: 1903 of 5001.\n",
      "Step: 1904 of 5001.\n",
      "Step: 1905 of 5001.\n",
      "Step: 1906 of 5001.\n",
      "Step: 1907 of 5001.\n",
      "Step: 1908 of 5001.\n",
      "Step: 1909 of 5001.\n",
      "Step: 1910 of 5001.\n",
      "Generator model loss: -1.233730435371399.\n",
      "Discriminator model loss: -0.6986773014068604.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 1911 of 5001.\n",
      "Step: 1912 of 5001.\n",
      "Step: 1913 of 5001.\n",
      "Step: 1914 of 5001.\n",
      "Step: 1915 of 5001.\n",
      "Step: 1916 of 5001.\n",
      "Step: 1917 of 5001.\n",
      "Step: 1918 of 5001.\n",
      "Step: 1919 of 5001.\n",
      "Step: 1920 of 5001.\n",
      "Generator model loss: -1.291836142539978.\n",
      "Discriminator model loss: -0.7377325296401978.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1921 of 5001.\n",
      "Step: 1922 of 5001.\n",
      "Step: 1923 of 5001.\n",
      "Step: 1924 of 5001.\n",
      "Step: 1925 of 5001.\n",
      "Step: 1926 of 5001.\n",
      "Step: 1927 of 5001.\n",
      "Step: 1928 of 5001.\n",
      "Step: 1929 of 5001.\n",
      "Step: 1930 of 5001.\n",
      "Generator model loss: -1.279150128364563.\n",
      "Discriminator model loss: -0.6371278166770935.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 1931 of 5001.\n",
      "Step: 1932 of 5001.\n",
      "Step: 1933 of 5001.\n",
      "Step: 1934 of 5001.\n",
      "Step: 1935 of 5001.\n",
      "Step: 1936 of 5001.\n",
      "Step: 1937 of 5001.\n",
      "Step: 1938 of 5001.\n",
      "Step: 1939 of 5001.\n",
      "Step: 1940 of 5001.\n",
      "Generator model loss: -1.2831436395645142.\n",
      "Discriminator model loss: -0.7156420350074768.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1941 of 5001.\n",
      "Step: 1942 of 5001.\n",
      "Step: 1943 of 5001.\n",
      "Step: 1944 of 5001.\n",
      "Step: 1945 of 5001.\n",
      "Step: 1946 of 5001.\n",
      "Step: 1947 of 5001.\n",
      "Step: 1948 of 5001.\n",
      "Step: 1949 of 5001.\n",
      "Step: 1950 of 5001.\n",
      "Generator model loss: -1.2937982082366943.\n",
      "Discriminator model loss: -0.6191522479057312.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 1951 of 5001.\n",
      "Step: 1952 of 5001.\n",
      "Step: 1953 of 5001.\n",
      "Step: 1954 of 5001.\n",
      "Step: 1955 of 5001.\n",
      "Step: 1956 of 5001.\n",
      "Step: 1957 of 5001.\n",
      "Step: 1958 of 5001.\n",
      "Step: 1959 of 5001.\n",
      "Step: 1960 of 5001.\n",
      "Generator model loss: -1.3099911212921143.\n",
      "Discriminator model loss: -0.6316162347793579.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1961 of 5001.\n",
      "Step: 1962 of 5001.\n",
      "Step: 1963 of 5001.\n",
      "Step: 1964 of 5001.\n",
      "Step: 1965 of 5001.\n",
      "Step: 1966 of 5001.\n",
      "Step: 1967 of 5001.\n",
      "Step: 1968 of 5001.\n",
      "Step: 1969 of 5001.\n",
      "Step: 1970 of 5001.\n",
      "Generator model loss: -1.3016812801361084.\n",
      "Discriminator model loss: -0.6608457565307617.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 1971 of 5001.\n",
      "Step: 1972 of 5001.\n",
      "Step: 1973 of 5001.\n",
      "Step: 1974 of 5001.\n",
      "Step: 1975 of 5001.\n",
      "Step: 1976 of 5001.\n",
      "Step: 1977 of 5001.\n",
      "Step: 1978 of 5001.\n",
      "Step: 1979 of 5001.\n",
      "Step: 1980 of 5001.\n",
      "Generator model loss: -1.3064550161361694.\n",
      "Discriminator model loss: -0.5711492896080017.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 1981 of 5001.\n",
      "Step: 1982 of 5001.\n",
      "Step: 1983 of 5001.\n",
      "Step: 1984 of 5001.\n",
      "Step: 1985 of 5001.\n",
      "Step: 1986 of 5001.\n",
      "Step: 1987 of 5001.\n",
      "Step: 1988 of 5001.\n",
      "Step: 1989 of 5001.\n",
      "Step: 1990 of 5001.\n",
      "Generator model loss: -1.2940280437469482.\n",
      "Discriminator model loss: -0.5950647592544556.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 1991 of 5001.\n",
      "Step: 1992 of 5001.\n",
      "Step: 1993 of 5001.\n",
      "Step: 1994 of 5001.\n",
      "Step: 1995 of 5001.\n",
      "Step: 1996 of 5001.\n",
      "Step: 1997 of 5001.\n",
      "Step: 1998 of 5001.\n",
      "Step: 1999 of 5001.\n",
      "Step: 2000 of 5001.\n",
      "Generator model loss: -1.3829941749572754.\n",
      "Discriminator model loss: -0.6865569949150085.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2001 of 5001.\n",
      "Step: 2002 of 5001.\n",
      "Step: 2003 of 5001.\n",
      "Step: 2004 of 5001.\n",
      "Step: 2005 of 5001.\n",
      "Step: 2006 of 5001.\n",
      "Step: 2007 of 5001.\n",
      "Step: 2008 of 5001.\n",
      "Step: 2009 of 5001.\n",
      "Step: 2010 of 5001.\n",
      "Generator model loss: -1.333757996559143.\n",
      "Discriminator model loss: -0.6443156003952026.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2011 of 5001.\n",
      "Step: 2012 of 5001.\n",
      "Step: 2013 of 5001.\n",
      "Step: 2014 of 5001.\n",
      "Step: 2015 of 5001.\n",
      "Step: 2016 of 5001.\n",
      "Step: 2017 of 5001.\n",
      "Step: 2018 of 5001.\n",
      "Step: 2019 of 5001.\n",
      "Step: 2020 of 5001.\n",
      "Generator model loss: -1.3585212230682373.\n",
      "Discriminator model loss: -0.6187905073165894.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2021 of 5001.\n",
      "Step: 2022 of 5001.\n",
      "Step: 2023 of 5001.\n",
      "Step: 2024 of 5001.\n",
      "Step: 2025 of 5001.\n",
      "Step: 2026 of 5001.\n",
      "Step: 2027 of 5001.\n",
      "Step: 2028 of 5001.\n",
      "Step: 2029 of 5001.\n",
      "Step: 2030 of 5001.\n",
      "Generator model loss: -1.3310273885726929.\n",
      "Discriminator model loss: -0.6679233312606812.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2031 of 5001.\n",
      "Step: 2032 of 5001.\n",
      "Step: 2033 of 5001.\n",
      "Step: 2034 of 5001.\n",
      "Step: 2035 of 5001.\n",
      "Step: 2036 of 5001.\n",
      "Step: 2037 of 5001.\n",
      "Step: 2038 of 5001.\n",
      "Step: 2039 of 5001.\n",
      "Step: 2040 of 5001.\n",
      "Generator model loss: -1.3867690563201904.\n",
      "Discriminator model loss: -0.6728310585021973.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 2041 of 5001.\n",
      "Step: 2042 of 5001.\n",
      "Step: 2043 of 5001.\n",
      "Step: 2044 of 5001.\n",
      "Step: 2045 of 5001.\n",
      "Step: 2046 of 5001.\n",
      "Step: 2047 of 5001.\n",
      "Step: 2048 of 5001.\n",
      "Step: 2049 of 5001.\n",
      "Step: 2050 of 5001.\n",
      "Generator model loss: -1.3729383945465088.\n",
      "Discriminator model loss: -0.6928302645683289.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2051 of 5001.\n",
      "Step: 2052 of 5001.\n",
      "Step: 2053 of 5001.\n",
      "Step: 2054 of 5001.\n",
      "Step: 2055 of 5001.\n",
      "Step: 2056 of 5001.\n",
      "Step: 2057 of 5001.\n",
      "Step: 2058 of 5001.\n",
      "Step: 2059 of 5001.\n",
      "Step: 2060 of 5001.\n",
      "Generator model loss: -1.386183500289917.\n",
      "Discriminator model loss: -0.6142207384109497.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2061 of 5001.\n",
      "Step: 2062 of 5001.\n",
      "Step: 2063 of 5001.\n",
      "Step: 2064 of 5001.\n",
      "Step: 2065 of 5001.\n",
      "Step: 2066 of 5001.\n",
      "Step: 2067 of 5001.\n",
      "Step: 2068 of 5001.\n",
      "Step: 2069 of 5001.\n",
      "Step: 2070 of 5001.\n",
      "Generator model loss: -1.3862059116363525.\n",
      "Discriminator model loss: -0.5911675691604614.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2071 of 5001.\n",
      "Step: 2072 of 5001.\n",
      "Step: 2073 of 5001.\n",
      "Step: 2074 of 5001.\n",
      "Step: 2075 of 5001.\n",
      "Step: 2076 of 5001.\n",
      "Step: 2077 of 5001.\n",
      "Step: 2078 of 5001.\n",
      "Step: 2079 of 5001.\n",
      "Step: 2080 of 5001.\n",
      "Generator model loss: -1.410918116569519.\n",
      "Discriminator model loss: -0.6364095211029053.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2081 of 5001.\n",
      "Step: 2082 of 5001.\n",
      "Step: 2083 of 5001.\n",
      "Step: 2084 of 5001.\n",
      "Step: 2085 of 5001.\n",
      "Step: 2086 of 5001.\n",
      "Step: 2087 of 5001.\n",
      "Step: 2088 of 5001.\n",
      "Step: 2089 of 5001.\n",
      "Step: 2090 of 5001.\n",
      "Generator model loss: -1.3615666627883911.\n",
      "Discriminator model loss: -0.69843590259552.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2091 of 5001.\n",
      "Step: 2092 of 5001.\n",
      "Step: 2093 of 5001.\n",
      "Step: 2094 of 5001.\n",
      "Step: 2095 of 5001.\n",
      "Step: 2096 of 5001.\n",
      "Step: 2097 of 5001.\n",
      "Step: 2098 of 5001.\n",
      "Step: 2099 of 5001.\n",
      "Step: 2100 of 5001.\n",
      "Generator model loss: -1.4626408815383911.\n",
      "Discriminator model loss: -0.5862108469009399.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2101 of 5001.\n",
      "Step: 2102 of 5001.\n",
      "Step: 2103 of 5001.\n",
      "Step: 2104 of 5001.\n",
      "Step: 2105 of 5001.\n",
      "Step: 2106 of 5001.\n",
      "Step: 2107 of 5001.\n",
      "Step: 2108 of 5001.\n",
      "Step: 2109 of 5001.\n",
      "Step: 2110 of 5001.\n",
      "Generator model loss: -1.4222381114959717.\n",
      "Discriminator model loss: -0.5409704446792603.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2111 of 5001.\n",
      "Step: 2112 of 5001.\n",
      "Step: 2113 of 5001.\n",
      "Step: 2114 of 5001.\n",
      "Step: 2115 of 5001.\n",
      "Step: 2116 of 5001.\n",
      "Step: 2117 of 5001.\n",
      "Step: 2118 of 5001.\n",
      "Step: 2119 of 5001.\n",
      "Step: 2120 of 5001.\n",
      "Generator model loss: -1.4570660591125488.\n",
      "Discriminator model loss: -0.5665467977523804.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2121 of 5001.\n",
      "Step: 2122 of 5001.\n",
      "Step: 2123 of 5001.\n",
      "Step: 2124 of 5001.\n",
      "Step: 2125 of 5001.\n",
      "Step: 2126 of 5001.\n",
      "Step: 2127 of 5001.\n",
      "Step: 2128 of 5001.\n",
      "Step: 2129 of 5001.\n",
      "Step: 2130 of 5001.\n",
      "Generator model loss: -1.4816231727600098.\n",
      "Discriminator model loss: -0.6567094922065735.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2131 of 5001.\n",
      "Step: 2132 of 5001.\n",
      "Step: 2133 of 5001.\n",
      "Step: 2134 of 5001.\n",
      "Step: 2135 of 5001.\n",
      "Step: 2136 of 5001.\n",
      "Step: 2137 of 5001.\n",
      "Step: 2138 of 5001.\n",
      "Step: 2139 of 5001.\n",
      "Step: 2140 of 5001.\n",
      "Generator model loss: -1.4618961811065674.\n",
      "Discriminator model loss: -0.5669890642166138.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2141 of 5001.\n",
      "Step: 2142 of 5001.\n",
      "Step: 2143 of 5001.\n",
      "Step: 2144 of 5001.\n",
      "Step: 2145 of 5001.\n",
      "Step: 2146 of 5001.\n",
      "Step: 2147 of 5001.\n",
      "Step: 2148 of 5001.\n",
      "Step: 2149 of 5001.\n",
      "Step: 2150 of 5001.\n",
      "Generator model loss: -1.4480822086334229.\n",
      "Discriminator model loss: -0.44952601194381714.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2151 of 5001.\n",
      "Step: 2152 of 5001.\n",
      "Step: 2153 of 5001.\n",
      "Step: 2154 of 5001.\n",
      "Step: 2155 of 5001.\n",
      "Step: 2156 of 5001.\n",
      "Step: 2157 of 5001.\n",
      "Step: 2158 of 5001.\n",
      "Step: 2159 of 5001.\n",
      "Step: 2160 of 5001.\n",
      "Generator model loss: -1.4559680223464966.\n",
      "Discriminator model loss: -0.6007327437400818.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2161 of 5001.\n",
      "Step: 2162 of 5001.\n",
      "Step: 2163 of 5001.\n",
      "Step: 2164 of 5001.\n",
      "Step: 2165 of 5001.\n",
      "Step: 2166 of 5001.\n",
      "Step: 2167 of 5001.\n",
      "Step: 2168 of 5001.\n",
      "Step: 2169 of 5001.\n",
      "Step: 2170 of 5001.\n",
      "Generator model loss: -1.4565383195877075.\n",
      "Discriminator model loss: -0.5352017879486084.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2171 of 5001.\n",
      "Step: 2172 of 5001.\n",
      "Step: 2173 of 5001.\n",
      "Step: 2174 of 5001.\n",
      "Step: 2175 of 5001.\n",
      "Step: 2176 of 5001.\n",
      "Step: 2177 of 5001.\n",
      "Step: 2178 of 5001.\n",
      "Step: 2179 of 5001.\n",
      "Step: 2180 of 5001.\n",
      "Generator model loss: -1.4777600765228271.\n",
      "Discriminator model loss: -0.638593316078186.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2181 of 5001.\n",
      "Step: 2182 of 5001.\n",
      "Step: 2183 of 5001.\n",
      "Step: 2184 of 5001.\n",
      "Step: 2185 of 5001.\n",
      "Step: 2186 of 5001.\n",
      "Step: 2187 of 5001.\n",
      "Step: 2188 of 5001.\n",
      "Step: 2189 of 5001.\n",
      "Step: 2190 of 5001.\n",
      "Generator model loss: -1.4783486127853394.\n",
      "Discriminator model loss: -0.5846903324127197.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2191 of 5001.\n",
      "Step: 2192 of 5001.\n",
      "Step: 2193 of 5001.\n",
      "Step: 2194 of 5001.\n",
      "Step: 2195 of 5001.\n",
      "Step: 2196 of 5001.\n",
      "Step: 2197 of 5001.\n",
      "Step: 2198 of 5001.\n",
      "Step: 2199 of 5001.\n",
      "Step: 2200 of 5001.\n",
      "Generator model loss: -1.5274128913879395.\n",
      "Discriminator model loss: -0.5603370666503906.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2201 of 5001.\n",
      "Step: 2202 of 5001.\n",
      "Step: 2203 of 5001.\n",
      "Step: 2204 of 5001.\n",
      "Step: 2205 of 5001.\n",
      "Step: 2206 of 5001.\n",
      "Step: 2207 of 5001.\n",
      "Step: 2208 of 5001.\n",
      "Step: 2209 of 5001.\n",
      "Step: 2210 of 5001.\n",
      "Generator model loss: -1.5203206539154053.\n",
      "Discriminator model loss: -0.5574373006820679.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2211 of 5001.\n",
      "Step: 2212 of 5001.\n",
      "Step: 2213 of 5001.\n",
      "Step: 2214 of 5001.\n",
      "Step: 2215 of 5001.\n",
      "Step: 2216 of 5001.\n",
      "Step: 2217 of 5001.\n",
      "Step: 2218 of 5001.\n",
      "Step: 2219 of 5001.\n",
      "Step: 2220 of 5001.\n",
      "Generator model loss: -1.5268208980560303.\n",
      "Discriminator model loss: -0.5333675146102905.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2221 of 5001.\n",
      "Step: 2222 of 5001.\n",
      "Step: 2223 of 5001.\n",
      "Step: 2224 of 5001.\n",
      "Step: 2225 of 5001.\n",
      "Step: 2226 of 5001.\n",
      "Step: 2227 of 5001.\n",
      "Step: 2228 of 5001.\n",
      "Step: 2229 of 5001.\n",
      "Step: 2230 of 5001.\n",
      "Generator model loss: -1.520035982131958.\n",
      "Discriminator model loss: -0.5761260986328125.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2231 of 5001.\n",
      "Step: 2232 of 5001.\n",
      "Step: 2233 of 5001.\n",
      "Step: 2234 of 5001.\n",
      "Step: 2235 of 5001.\n",
      "Step: 2236 of 5001.\n",
      "Step: 2237 of 5001.\n",
      "Step: 2238 of 5001.\n",
      "Step: 2239 of 5001.\n",
      "Step: 2240 of 5001.\n",
      "Generator model loss: -1.5418565273284912.\n",
      "Discriminator model loss: -0.5353453159332275.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2241 of 5001.\n",
      "Step: 2242 of 5001.\n",
      "Step: 2243 of 5001.\n",
      "Step: 2244 of 5001.\n",
      "Step: 2245 of 5001.\n",
      "Step: 2246 of 5001.\n",
      "Step: 2247 of 5001.\n",
      "Step: 2248 of 5001.\n",
      "Step: 2249 of 5001.\n",
      "Step: 2250 of 5001.\n",
      "Generator model loss: -1.5356234312057495.\n",
      "Discriminator model loss: -0.5280725359916687.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2251 of 5001.\n",
      "Step: 2252 of 5001.\n",
      "Step: 2253 of 5001.\n",
      "Step: 2254 of 5001.\n",
      "Step: 2255 of 5001.\n",
      "Step: 2256 of 5001.\n",
      "Step: 2257 of 5001.\n",
      "Step: 2258 of 5001.\n",
      "Step: 2259 of 5001.\n",
      "Step: 2260 of 5001.\n",
      "Generator model loss: -1.5402292013168335.\n",
      "Discriminator model loss: -0.5691384077072144.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2261 of 5001.\n",
      "Step: 2262 of 5001.\n",
      "Step: 2263 of 5001.\n",
      "Step: 2264 of 5001.\n",
      "Step: 2265 of 5001.\n",
      "Step: 2266 of 5001.\n",
      "Step: 2267 of 5001.\n",
      "Step: 2268 of 5001.\n",
      "Step: 2269 of 5001.\n",
      "Step: 2270 of 5001.\n",
      "Generator model loss: -1.5339806079864502.\n",
      "Discriminator model loss: -0.5978946089744568.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2271 of 5001.\n",
      "Step: 2272 of 5001.\n",
      "Step: 2273 of 5001.\n",
      "Step: 2274 of 5001.\n",
      "Step: 2275 of 5001.\n",
      "Step: 2276 of 5001.\n",
      "Step: 2277 of 5001.\n",
      "Step: 2278 of 5001.\n",
      "Step: 2279 of 5001.\n",
      "Step: 2280 of 5001.\n",
      "Generator model loss: -1.574928879737854.\n",
      "Discriminator model loss: -0.5219197273254395.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2281 of 5001.\n",
      "Step: 2282 of 5001.\n",
      "Step: 2283 of 5001.\n",
      "Step: 2284 of 5001.\n",
      "Step: 2285 of 5001.\n",
      "Step: 2286 of 5001.\n",
      "Step: 2287 of 5001.\n",
      "Step: 2288 of 5001.\n",
      "Step: 2289 of 5001.\n",
      "Step: 2290 of 5001.\n",
      "Generator model loss: -1.5160585641860962.\n",
      "Discriminator model loss: -0.5134955048561096.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2291 of 5001.\n",
      "Step: 2292 of 5001.\n",
      "Step: 2293 of 5001.\n",
      "Step: 2294 of 5001.\n",
      "Step: 2295 of 5001.\n",
      "Step: 2296 of 5001.\n",
      "Step: 2297 of 5001.\n",
      "Step: 2298 of 5001.\n",
      "Step: 2299 of 5001.\n",
      "Step: 2300 of 5001.\n",
      "Generator model loss: -1.586498498916626.\n",
      "Discriminator model loss: -0.4560665190219879.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2301 of 5001.\n",
      "Step: 2302 of 5001.\n",
      "Step: 2303 of 5001.\n",
      "Step: 2304 of 5001.\n",
      "Step: 2305 of 5001.\n",
      "Step: 2306 of 5001.\n",
      "Step: 2307 of 5001.\n",
      "Step: 2308 of 5001.\n",
      "Step: 2309 of 5001.\n",
      "Step: 2310 of 5001.\n",
      "Generator model loss: -1.5774999856948853.\n",
      "Discriminator model loss: -0.5966234803199768.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2311 of 5001.\n",
      "Step: 2312 of 5001.\n",
      "Step: 2313 of 5001.\n",
      "Step: 2314 of 5001.\n",
      "Step: 2315 of 5001.\n",
      "Step: 2316 of 5001.\n",
      "Step: 2317 of 5001.\n",
      "Step: 2318 of 5001.\n",
      "Step: 2319 of 5001.\n",
      "Step: 2320 of 5001.\n",
      "Generator model loss: -1.5689160823822021.\n",
      "Discriminator model loss: -0.5758780837059021.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2321 of 5001.\n",
      "Step: 2322 of 5001.\n",
      "Step: 2323 of 5001.\n",
      "Step: 2324 of 5001.\n",
      "Step: 2325 of 5001.\n",
      "Step: 2326 of 5001.\n",
      "Step: 2327 of 5001.\n",
      "Step: 2328 of 5001.\n",
      "Step: 2329 of 5001.\n",
      "Step: 2330 of 5001.\n",
      "Generator model loss: -1.569549322128296.\n",
      "Discriminator model loss: -0.5057247281074524.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2331 of 5001.\n",
      "Step: 2332 of 5001.\n",
      "Step: 2333 of 5001.\n",
      "Step: 2334 of 5001.\n",
      "Step: 2335 of 5001.\n",
      "Step: 2336 of 5001.\n",
      "Step: 2337 of 5001.\n",
      "Step: 2338 of 5001.\n",
      "Step: 2339 of 5001.\n",
      "Step: 2340 of 5001.\n",
      "Generator model loss: -1.5302610397338867.\n",
      "Discriminator model loss: -0.4406288266181946.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2341 of 5001.\n",
      "Step: 2342 of 5001.\n",
      "Step: 2343 of 5001.\n",
      "Step: 2344 of 5001.\n",
      "Step: 2345 of 5001.\n",
      "Step: 2346 of 5001.\n",
      "Step: 2347 of 5001.\n",
      "Step: 2348 of 5001.\n",
      "Step: 2349 of 5001.\n",
      "Step: 2350 of 5001.\n",
      "Generator model loss: -1.549145221710205.\n",
      "Discriminator model loss: -0.5096362829208374.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2351 of 5001.\n",
      "Step: 2352 of 5001.\n",
      "Step: 2353 of 5001.\n",
      "Step: 2354 of 5001.\n",
      "Step: 2355 of 5001.\n",
      "Step: 2356 of 5001.\n",
      "Step: 2357 of 5001.\n",
      "Step: 2358 of 5001.\n",
      "Step: 2359 of 5001.\n",
      "Step: 2360 of 5001.\n",
      "Generator model loss: -1.5704265832901.\n",
      "Discriminator model loss: -0.4269568920135498.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2361 of 5001.\n",
      "Step: 2362 of 5001.\n",
      "Step: 2363 of 5001.\n",
      "Step: 2364 of 5001.\n",
      "Step: 2365 of 5001.\n",
      "Step: 2366 of 5001.\n",
      "Step: 2367 of 5001.\n",
      "Step: 2368 of 5001.\n",
      "Step: 2369 of 5001.\n",
      "Step: 2370 of 5001.\n",
      "Generator model loss: -1.6291128396987915.\n",
      "Discriminator model loss: -0.4570449888706207.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2371 of 5001.\n",
      "Step: 2372 of 5001.\n",
      "Step: 2373 of 5001.\n",
      "Step: 2374 of 5001.\n",
      "Step: 2375 of 5001.\n",
      "Step: 2376 of 5001.\n",
      "Step: 2377 of 5001.\n",
      "Step: 2378 of 5001.\n",
      "Step: 2379 of 5001.\n",
      "Step: 2380 of 5001.\n",
      "Generator model loss: -1.590381383895874.\n",
      "Discriminator model loss: -0.41801294684410095.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2381 of 5001.\n",
      "Step: 2382 of 5001.\n",
      "Step: 2383 of 5001.\n",
      "Step: 2384 of 5001.\n",
      "Step: 2385 of 5001.\n",
      "Step: 2386 of 5001.\n",
      "Step: 2387 of 5001.\n",
      "Step: 2388 of 5001.\n",
      "Step: 2389 of 5001.\n",
      "Step: 2390 of 5001.\n",
      "Generator model loss: -1.6200050115585327.\n",
      "Discriminator model loss: -0.45764440298080444.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2391 of 5001.\n",
      "Step: 2392 of 5001.\n",
      "Step: 2393 of 5001.\n",
      "Step: 2394 of 5001.\n",
      "Step: 2395 of 5001.\n",
      "Step: 2396 of 5001.\n",
      "Step: 2397 of 5001.\n",
      "Step: 2398 of 5001.\n",
      "Step: 2399 of 5001.\n",
      "Step: 2400 of 5001.\n",
      "Generator model loss: -1.5887991189956665.\n",
      "Discriminator model loss: -0.4483601152896881.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2401 of 5001.\n",
      "Step: 2402 of 5001.\n",
      "Step: 2403 of 5001.\n",
      "Step: 2404 of 5001.\n",
      "Step: 2405 of 5001.\n",
      "Step: 2406 of 5001.\n",
      "Step: 2407 of 5001.\n",
      "Step: 2408 of 5001.\n",
      "Step: 2409 of 5001.\n",
      "Step: 2410 of 5001.\n",
      "Generator model loss: -1.5938304662704468.\n",
      "Discriminator model loss: -0.5189682841300964.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2411 of 5001.\n",
      "Step: 2412 of 5001.\n",
      "Step: 2413 of 5001.\n",
      "Step: 2414 of 5001.\n",
      "Step: 2415 of 5001.\n",
      "Step: 2416 of 5001.\n",
      "Step: 2417 of 5001.\n",
      "Step: 2418 of 5001.\n",
      "Step: 2419 of 5001.\n",
      "Step: 2420 of 5001.\n",
      "Generator model loss: -1.6271432638168335.\n",
      "Discriminator model loss: -0.41578125953674316.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2421 of 5001.\n",
      "Step: 2422 of 5001.\n",
      "Step: 2423 of 5001.\n",
      "Step: 2424 of 5001.\n",
      "Step: 2425 of 5001.\n",
      "Step: 2426 of 5001.\n",
      "Step: 2427 of 5001.\n",
      "Step: 2428 of 5001.\n",
      "Step: 2429 of 5001.\n",
      "Step: 2430 of 5001.\n",
      "Generator model loss: -1.6427971124649048.\n",
      "Discriminator model loss: -0.449533611536026.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2431 of 5001.\n",
      "Step: 2432 of 5001.\n",
      "Step: 2433 of 5001.\n",
      "Step: 2434 of 5001.\n",
      "Step: 2435 of 5001.\n",
      "Step: 2436 of 5001.\n",
      "Step: 2437 of 5001.\n",
      "Step: 2438 of 5001.\n",
      "Step: 2439 of 5001.\n",
      "Step: 2440 of 5001.\n",
      "Generator model loss: -1.614202857017517.\n",
      "Discriminator model loss: -0.5014101266860962.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 2441 of 5001.\n",
      "Step: 2442 of 5001.\n",
      "Step: 2443 of 5001.\n",
      "Step: 2444 of 5001.\n",
      "Step: 2445 of 5001.\n",
      "Step: 2446 of 5001.\n",
      "Step: 2447 of 5001.\n",
      "Step: 2448 of 5001.\n",
      "Step: 2449 of 5001.\n",
      "Step: 2450 of 5001.\n",
      "Generator model loss: -1.631487488746643.\n",
      "Discriminator model loss: -0.4622281491756439.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2451 of 5001.\n",
      "Step: 2452 of 5001.\n",
      "Step: 2453 of 5001.\n",
      "Step: 2454 of 5001.\n",
      "Step: 2455 of 5001.\n",
      "Step: 2456 of 5001.\n",
      "Step: 2457 of 5001.\n",
      "Step: 2458 of 5001.\n",
      "Step: 2459 of 5001.\n",
      "Step: 2460 of 5001.\n",
      "Generator model loss: -1.6234734058380127.\n",
      "Discriminator model loss: -0.4332153797149658.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2461 of 5001.\n",
      "Step: 2462 of 5001.\n",
      "Step: 2463 of 5001.\n",
      "Step: 2464 of 5001.\n",
      "Step: 2465 of 5001.\n",
      "Step: 2466 of 5001.\n",
      "Step: 2467 of 5001.\n",
      "Step: 2468 of 5001.\n",
      "Step: 2469 of 5001.\n",
      "Step: 2470 of 5001.\n",
      "Generator model loss: -1.6317808628082275.\n",
      "Discriminator model loss: -0.3925015330314636.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2471 of 5001.\n",
      "Step: 2472 of 5001.\n",
      "Step: 2473 of 5001.\n",
      "Step: 2474 of 5001.\n",
      "Step: 2475 of 5001.\n",
      "Step: 2476 of 5001.\n",
      "Step: 2477 of 5001.\n",
      "Step: 2478 of 5001.\n",
      "Step: 2479 of 5001.\n",
      "Step: 2480 of 5001.\n",
      "Generator model loss: -1.6282581090927124.\n",
      "Discriminator model loss: -0.3490919768810272.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2481 of 5001.\n",
      "Step: 2482 of 5001.\n",
      "Step: 2483 of 5001.\n",
      "Step: 2484 of 5001.\n",
      "Step: 2485 of 5001.\n",
      "Step: 2486 of 5001.\n",
      "Step: 2487 of 5001.\n",
      "Step: 2488 of 5001.\n",
      "Step: 2489 of 5001.\n",
      "Step: 2490 of 5001.\n",
      "Generator model loss: -1.62972092628479.\n",
      "Discriminator model loss: -0.44764280319213867.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2491 of 5001.\n",
      "Step: 2492 of 5001.\n",
      "Step: 2493 of 5001.\n",
      "Step: 2494 of 5001.\n",
      "Step: 2495 of 5001.\n",
      "Step: 2496 of 5001.\n",
      "Step: 2497 of 5001.\n",
      "Step: 2498 of 5001.\n",
      "Step: 2499 of 5001.\n",
      "Step: 2500 of 5001.\n",
      "Generator model loss: -1.6591720581054688.\n",
      "Discriminator model loss: -0.47014766931533813.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 2501 of 5001.\n",
      "Step: 2502 of 5001.\n",
      "Step: 2503 of 5001.\n",
      "Step: 2504 of 5001.\n",
      "Step: 2505 of 5001.\n",
      "Step: 2506 of 5001.\n",
      "Step: 2507 of 5001.\n",
      "Step: 2508 of 5001.\n",
      "Step: 2509 of 5001.\n",
      "Step: 2510 of 5001.\n",
      "Generator model loss: -1.6604093313217163.\n",
      "Discriminator model loss: -0.4360005259513855.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2511 of 5001.\n",
      "Step: 2512 of 5001.\n",
      "Step: 2513 of 5001.\n",
      "Step: 2514 of 5001.\n",
      "Step: 2515 of 5001.\n",
      "Step: 2516 of 5001.\n",
      "Step: 2517 of 5001.\n",
      "Step: 2518 of 5001.\n",
      "Step: 2519 of 5001.\n",
      "Step: 2520 of 5001.\n",
      "Generator model loss: -1.656338095664978.\n",
      "Discriminator model loss: -0.44490891695022583.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2521 of 5001.\n",
      "Step: 2522 of 5001.\n",
      "Step: 2523 of 5001.\n",
      "Step: 2524 of 5001.\n",
      "Step: 2525 of 5001.\n",
      "Step: 2526 of 5001.\n",
      "Step: 2527 of 5001.\n",
      "Step: 2528 of 5001.\n",
      "Step: 2529 of 5001.\n",
      "Step: 2530 of 5001.\n",
      "Generator model loss: -1.6363023519515991.\n",
      "Discriminator model loss: -0.5006375908851624.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2531 of 5001.\n",
      "Step: 2532 of 5001.\n",
      "Step: 2533 of 5001.\n",
      "Step: 2534 of 5001.\n",
      "Step: 2535 of 5001.\n",
      "Step: 2536 of 5001.\n",
      "Step: 2537 of 5001.\n",
      "Step: 2538 of 5001.\n",
      "Step: 2539 of 5001.\n",
      "Step: 2540 of 5001.\n",
      "Generator model loss: -1.6566355228424072.\n",
      "Discriminator model loss: -0.46804484724998474.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2541 of 5001.\n",
      "Step: 2542 of 5001.\n",
      "Step: 2543 of 5001.\n",
      "Step: 2544 of 5001.\n",
      "Step: 2545 of 5001.\n",
      "Step: 2546 of 5001.\n",
      "Step: 2547 of 5001.\n",
      "Step: 2548 of 5001.\n",
      "Step: 2549 of 5001.\n",
      "Step: 2550 of 5001.\n",
      "Generator model loss: -1.684488296508789.\n",
      "Discriminator model loss: -0.39870694279670715.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2551 of 5001.\n",
      "Step: 2552 of 5001.\n",
      "Step: 2553 of 5001.\n",
      "Step: 2554 of 5001.\n",
      "Step: 2555 of 5001.\n",
      "Step: 2556 of 5001.\n",
      "Step: 2557 of 5001.\n",
      "Step: 2558 of 5001.\n",
      "Step: 2559 of 5001.\n",
      "Step: 2560 of 5001.\n",
      "Generator model loss: -1.694082260131836.\n",
      "Discriminator model loss: -0.320941686630249.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2561 of 5001.\n",
      "Step: 2562 of 5001.\n",
      "Step: 2563 of 5001.\n",
      "Step: 2564 of 5001.\n",
      "Step: 2565 of 5001.\n",
      "Step: 2566 of 5001.\n",
      "Step: 2567 of 5001.\n",
      "Step: 2568 of 5001.\n",
      "Step: 2569 of 5001.\n",
      "Step: 2570 of 5001.\n",
      "Generator model loss: -1.680736780166626.\n",
      "Discriminator model loss: -0.4368060529232025.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2571 of 5001.\n",
      "Step: 2572 of 5001.\n",
      "Step: 2573 of 5001.\n",
      "Step: 2574 of 5001.\n",
      "Step: 2575 of 5001.\n",
      "Step: 2576 of 5001.\n",
      "Step: 2577 of 5001.\n",
      "Step: 2578 of 5001.\n",
      "Step: 2579 of 5001.\n",
      "Step: 2580 of 5001.\n",
      "Generator model loss: -1.6770257949829102.\n",
      "Discriminator model loss: -0.44569310545921326.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 2581 of 5001.\n",
      "Step: 2582 of 5001.\n",
      "Step: 2583 of 5001.\n",
      "Step: 2584 of 5001.\n",
      "Step: 2585 of 5001.\n",
      "Step: 2586 of 5001.\n",
      "Step: 2587 of 5001.\n",
      "Step: 2588 of 5001.\n",
      "Step: 2589 of 5001.\n",
      "Step: 2590 of 5001.\n",
      "Generator model loss: -1.6883375644683838.\n",
      "Discriminator model loss: -0.42615827918052673.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2591 of 5001.\n",
      "Step: 2592 of 5001.\n",
      "Step: 2593 of 5001.\n",
      "Step: 2594 of 5001.\n",
      "Step: 2595 of 5001.\n",
      "Step: 2596 of 5001.\n",
      "Step: 2597 of 5001.\n",
      "Step: 2598 of 5001.\n",
      "Step: 2599 of 5001.\n",
      "Step: 2600 of 5001.\n",
      "Generator model loss: -1.7379602193832397.\n",
      "Discriminator model loss: -0.4063292443752289.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2601 of 5001.\n",
      "Step: 2602 of 5001.\n",
      "Step: 2603 of 5001.\n",
      "Step: 2604 of 5001.\n",
      "Step: 2605 of 5001.\n",
      "Step: 2606 of 5001.\n",
      "Step: 2607 of 5001.\n",
      "Step: 2608 of 5001.\n",
      "Step: 2609 of 5001.\n",
      "Step: 2610 of 5001.\n",
      "Generator model loss: -1.702172040939331.\n",
      "Discriminator model loss: -0.39954209327697754.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2611 of 5001.\n",
      "Step: 2612 of 5001.\n",
      "Step: 2613 of 5001.\n",
      "Step: 2614 of 5001.\n",
      "Step: 2615 of 5001.\n",
      "Step: 2616 of 5001.\n",
      "Step: 2617 of 5001.\n",
      "Step: 2618 of 5001.\n",
      "Step: 2619 of 5001.\n",
      "Step: 2620 of 5001.\n",
      "Generator model loss: -1.7180116176605225.\n",
      "Discriminator model loss: -0.36568862199783325.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2621 of 5001.\n",
      "Step: 2622 of 5001.\n",
      "Step: 2623 of 5001.\n",
      "Step: 2624 of 5001.\n",
      "Step: 2625 of 5001.\n",
      "Step: 2626 of 5001.\n",
      "Step: 2627 of 5001.\n",
      "Step: 2628 of 5001.\n",
      "Step: 2629 of 5001.\n",
      "Step: 2630 of 5001.\n",
      "Generator model loss: -1.6887069940567017.\n",
      "Discriminator model loss: -0.40956273674964905.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2631 of 5001.\n",
      "Step: 2632 of 5001.\n",
      "Step: 2633 of 5001.\n",
      "Step: 2634 of 5001.\n",
      "Step: 2635 of 5001.\n",
      "Step: 2636 of 5001.\n",
      "Step: 2637 of 5001.\n",
      "Step: 2638 of 5001.\n",
      "Step: 2639 of 5001.\n",
      "Step: 2640 of 5001.\n",
      "Generator model loss: -1.7522140741348267.\n",
      "Discriminator model loss: -0.3605116009712219.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2641 of 5001.\n",
      "Step: 2642 of 5001.\n",
      "Step: 2643 of 5001.\n",
      "Step: 2644 of 5001.\n",
      "Step: 2645 of 5001.\n",
      "Step: 2646 of 5001.\n",
      "Step: 2647 of 5001.\n",
      "Step: 2648 of 5001.\n",
      "Step: 2649 of 5001.\n",
      "Step: 2650 of 5001.\n",
      "Generator model loss: -1.7226505279541016.\n",
      "Discriminator model loss: -0.3964729607105255.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2651 of 5001.\n",
      "Step: 2652 of 5001.\n",
      "Step: 2653 of 5001.\n",
      "Step: 2654 of 5001.\n",
      "Step: 2655 of 5001.\n",
      "Step: 2656 of 5001.\n",
      "Step: 2657 of 5001.\n",
      "Step: 2658 of 5001.\n",
      "Step: 2659 of 5001.\n",
      "Step: 2660 of 5001.\n",
      "Generator model loss: -1.7258554697036743.\n",
      "Discriminator model loss: -0.40384212136268616.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2661 of 5001.\n",
      "Step: 2662 of 5001.\n",
      "Step: 2663 of 5001.\n",
      "Step: 2664 of 5001.\n",
      "Step: 2665 of 5001.\n",
      "Step: 2666 of 5001.\n",
      "Step: 2667 of 5001.\n",
      "Step: 2668 of 5001.\n",
      "Step: 2669 of 5001.\n",
      "Step: 2670 of 5001.\n",
      "Generator model loss: -1.7201521396636963.\n",
      "Discriminator model loss: -0.3149169087409973.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2671 of 5001.\n",
      "Step: 2672 of 5001.\n",
      "Step: 2673 of 5001.\n",
      "Step: 2674 of 5001.\n",
      "Step: 2675 of 5001.\n",
      "Step: 2676 of 5001.\n",
      "Step: 2677 of 5001.\n",
      "Step: 2678 of 5001.\n",
      "Step: 2679 of 5001.\n",
      "Step: 2680 of 5001.\n",
      "Generator model loss: -1.7192847728729248.\n",
      "Discriminator model loss: -0.39333122968673706.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2681 of 5001.\n",
      "Step: 2682 of 5001.\n",
      "Step: 2683 of 5001.\n",
      "Step: 2684 of 5001.\n",
      "Step: 2685 of 5001.\n",
      "Step: 2686 of 5001.\n",
      "Step: 2687 of 5001.\n",
      "Step: 2688 of 5001.\n",
      "Step: 2689 of 5001.\n",
      "Step: 2690 of 5001.\n",
      "Generator model loss: -1.7593027353286743.\n",
      "Discriminator model loss: -0.3530866801738739.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2691 of 5001.\n",
      "Step: 2692 of 5001.\n",
      "Step: 2693 of 5001.\n",
      "Step: 2694 of 5001.\n",
      "Step: 2695 of 5001.\n",
      "Step: 2696 of 5001.\n",
      "Step: 2697 of 5001.\n",
      "Step: 2698 of 5001.\n",
      "Step: 2699 of 5001.\n",
      "Step: 2700 of 5001.\n",
      "Generator model loss: -1.7084436416625977.\n",
      "Discriminator model loss: -0.29066628217697144.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2701 of 5001.\n",
      "Step: 2702 of 5001.\n",
      "Step: 2703 of 5001.\n",
      "Step: 2704 of 5001.\n",
      "Step: 2705 of 5001.\n",
      "Step: 2706 of 5001.\n",
      "Step: 2707 of 5001.\n",
      "Step: 2708 of 5001.\n",
      "Step: 2709 of 5001.\n",
      "Step: 2710 of 5001.\n",
      "Generator model loss: -1.7575042247772217.\n",
      "Discriminator model loss: -0.4119885563850403.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2711 of 5001.\n",
      "Step: 2712 of 5001.\n",
      "Step: 2713 of 5001.\n",
      "Step: 2714 of 5001.\n",
      "Step: 2715 of 5001.\n",
      "Step: 2716 of 5001.\n",
      "Step: 2717 of 5001.\n",
      "Step: 2718 of 5001.\n",
      "Step: 2719 of 5001.\n",
      "Step: 2720 of 5001.\n",
      "Generator model loss: -1.7617864608764648.\n",
      "Discriminator model loss: -0.3293306827545166.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2721 of 5001.\n",
      "Step: 2722 of 5001.\n",
      "Step: 2723 of 5001.\n",
      "Step: 2724 of 5001.\n",
      "Step: 2725 of 5001.\n",
      "Step: 2726 of 5001.\n",
      "Step: 2727 of 5001.\n",
      "Step: 2728 of 5001.\n",
      "Step: 2729 of 5001.\n",
      "Step: 2730 of 5001.\n",
      "Generator model loss: -1.7555618286132812.\n",
      "Discriminator model loss: -0.4201676845550537.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2731 of 5001.\n",
      "Step: 2732 of 5001.\n",
      "Step: 2733 of 5001.\n",
      "Step: 2734 of 5001.\n",
      "Step: 2735 of 5001.\n",
      "Step: 2736 of 5001.\n",
      "Step: 2737 of 5001.\n",
      "Step: 2738 of 5001.\n",
      "Step: 2739 of 5001.\n",
      "Step: 2740 of 5001.\n",
      "Generator model loss: -1.813197374343872.\n",
      "Discriminator model loss: -0.28526192903518677.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2741 of 5001.\n",
      "Step: 2742 of 5001.\n",
      "Step: 2743 of 5001.\n",
      "Step: 2744 of 5001.\n",
      "Step: 2745 of 5001.\n",
      "Step: 2746 of 5001.\n",
      "Step: 2747 of 5001.\n",
      "Step: 2748 of 5001.\n",
      "Step: 2749 of 5001.\n",
      "Step: 2750 of 5001.\n",
      "Generator model loss: -1.7840425968170166.\n",
      "Discriminator model loss: -0.3385876417160034.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2751 of 5001.\n",
      "Step: 2752 of 5001.\n",
      "Step: 2753 of 5001.\n",
      "Step: 2754 of 5001.\n",
      "Step: 2755 of 5001.\n",
      "Step: 2756 of 5001.\n",
      "Step: 2757 of 5001.\n",
      "Step: 2758 of 5001.\n",
      "Step: 2759 of 5001.\n",
      "Step: 2760 of 5001.\n",
      "Generator model loss: -1.7640018463134766.\n",
      "Discriminator model loss: -0.3230087161064148.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2761 of 5001.\n",
      "Step: 2762 of 5001.\n",
      "Step: 2763 of 5001.\n",
      "Step: 2764 of 5001.\n",
      "Step: 2765 of 5001.\n",
      "Step: 2766 of 5001.\n",
      "Step: 2767 of 5001.\n",
      "Step: 2768 of 5001.\n",
      "Step: 2769 of 5001.\n",
      "Step: 2770 of 5001.\n",
      "Generator model loss: -1.7268632650375366.\n",
      "Discriminator model loss: -0.35586073994636536.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2771 of 5001.\n",
      "Step: 2772 of 5001.\n",
      "Step: 2773 of 5001.\n",
      "Step: 2774 of 5001.\n",
      "Step: 2775 of 5001.\n",
      "Step: 2776 of 5001.\n",
      "Step: 2777 of 5001.\n",
      "Step: 2778 of 5001.\n",
      "Step: 2779 of 5001.\n",
      "Step: 2780 of 5001.\n",
      "Generator model loss: -1.7644941806793213.\n",
      "Discriminator model loss: -0.3907313942909241.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2781 of 5001.\n",
      "Step: 2782 of 5001.\n",
      "Step: 2783 of 5001.\n",
      "Step: 2784 of 5001.\n",
      "Step: 2785 of 5001.\n",
      "Step: 2786 of 5001.\n",
      "Step: 2787 of 5001.\n",
      "Step: 2788 of 5001.\n",
      "Step: 2789 of 5001.\n",
      "Step: 2790 of 5001.\n",
      "Generator model loss: -1.7421438694000244.\n",
      "Discriminator model loss: -0.35596126317977905.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 2791 of 5001.\n",
      "Step: 2792 of 5001.\n",
      "Step: 2793 of 5001.\n",
      "Step: 2794 of 5001.\n",
      "Step: 2795 of 5001.\n",
      "Step: 2796 of 5001.\n",
      "Step: 2797 of 5001.\n",
      "Step: 2798 of 5001.\n",
      "Step: 2799 of 5001.\n",
      "Step: 2800 of 5001.\n",
      "Generator model loss: -1.7581628561019897.\n",
      "Discriminator model loss: -0.43713298439979553.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2801 of 5001.\n",
      "Step: 2802 of 5001.\n",
      "Step: 2803 of 5001.\n",
      "Step: 2804 of 5001.\n",
      "Step: 2805 of 5001.\n",
      "Step: 2806 of 5001.\n",
      "Step: 2807 of 5001.\n",
      "Step: 2808 of 5001.\n",
      "Step: 2809 of 5001.\n",
      "Step: 2810 of 5001.\n",
      "Generator model loss: -1.8078778982162476.\n",
      "Discriminator model loss: -0.3234855532646179.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2811 of 5001.\n",
      "Step: 2812 of 5001.\n",
      "Step: 2813 of 5001.\n",
      "Step: 2814 of 5001.\n",
      "Step: 2815 of 5001.\n",
      "Step: 2816 of 5001.\n",
      "Step: 2817 of 5001.\n",
      "Step: 2818 of 5001.\n",
      "Step: 2819 of 5001.\n",
      "Step: 2820 of 5001.\n",
      "Generator model loss: -1.8178447484970093.\n",
      "Discriminator model loss: -0.37743228673934937.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2821 of 5001.\n",
      "Step: 2822 of 5001.\n",
      "Step: 2823 of 5001.\n",
      "Step: 2824 of 5001.\n",
      "Step: 2825 of 5001.\n",
      "Step: 2826 of 5001.\n",
      "Step: 2827 of 5001.\n",
      "Step: 2828 of 5001.\n",
      "Step: 2829 of 5001.\n",
      "Step: 2830 of 5001.\n",
      "Generator model loss: -1.7620763778686523.\n",
      "Discriminator model loss: -0.264697402715683.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2831 of 5001.\n",
      "Step: 2832 of 5001.\n",
      "Step: 2833 of 5001.\n",
      "Step: 2834 of 5001.\n",
      "Step: 2835 of 5001.\n",
      "Step: 2836 of 5001.\n",
      "Step: 2837 of 5001.\n",
      "Step: 2838 of 5001.\n",
      "Step: 2839 of 5001.\n",
      "Step: 2840 of 5001.\n",
      "Generator model loss: -1.7878859043121338.\n",
      "Discriminator model loss: -0.26716718077659607.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 2841 of 5001.\n",
      "Step: 2842 of 5001.\n",
      "Step: 2843 of 5001.\n",
      "Step: 2844 of 5001.\n",
      "Step: 2845 of 5001.\n",
      "Step: 2846 of 5001.\n",
      "Step: 2847 of 5001.\n",
      "Step: 2848 of 5001.\n",
      "Step: 2849 of 5001.\n",
      "Step: 2850 of 5001.\n",
      "Generator model loss: -1.7644681930541992.\n",
      "Discriminator model loss: -0.40746694803237915.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2851 of 5001.\n",
      "Step: 2852 of 5001.\n",
      "Step: 2853 of 5001.\n",
      "Step: 2854 of 5001.\n",
      "Step: 2855 of 5001.\n",
      "Step: 2856 of 5001.\n",
      "Step: 2857 of 5001.\n",
      "Step: 2858 of 5001.\n",
      "Step: 2859 of 5001.\n",
      "Step: 2860 of 5001.\n",
      "Generator model loss: -1.8035147190093994.\n",
      "Discriminator model loss: -0.33017081022262573.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 2861 of 5001.\n",
      "Step: 2862 of 5001.\n",
      "Step: 2863 of 5001.\n",
      "Step: 2864 of 5001.\n",
      "Step: 2865 of 5001.\n",
      "Step: 2866 of 5001.\n",
      "Step: 2867 of 5001.\n",
      "Step: 2868 of 5001.\n",
      "Step: 2869 of 5001.\n",
      "Step: 2870 of 5001.\n",
      "Generator model loss: -1.8192335367202759.\n",
      "Discriminator model loss: -0.37984350323677063.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2871 of 5001.\n",
      "Step: 2872 of 5001.\n",
      "Step: 2873 of 5001.\n",
      "Step: 2874 of 5001.\n",
      "Step: 2875 of 5001.\n",
      "Step: 2876 of 5001.\n",
      "Step: 2877 of 5001.\n",
      "Step: 2878 of 5001.\n",
      "Step: 2879 of 5001.\n",
      "Step: 2880 of 5001.\n",
      "Generator model loss: -1.813140630722046.\n",
      "Discriminator model loss: -0.32062309980392456.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2881 of 5001.\n",
      "Step: 2882 of 5001.\n",
      "Step: 2883 of 5001.\n",
      "Step: 2884 of 5001.\n",
      "Step: 2885 of 5001.\n",
      "Step: 2886 of 5001.\n",
      "Step: 2887 of 5001.\n",
      "Step: 2888 of 5001.\n",
      "Step: 2889 of 5001.\n",
      "Step: 2890 of 5001.\n",
      "Generator model loss: -1.8251653909683228.\n",
      "Discriminator model loss: -0.374201238155365.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 2891 of 5001.\n",
      "Step: 2892 of 5001.\n",
      "Step: 2893 of 5001.\n",
      "Step: 2894 of 5001.\n",
      "Step: 2895 of 5001.\n",
      "Step: 2896 of 5001.\n",
      "Step: 2897 of 5001.\n",
      "Step: 2898 of 5001.\n",
      "Step: 2899 of 5001.\n",
      "Step: 2900 of 5001.\n",
      "Generator model loss: -1.8134123086929321.\n",
      "Discriminator model loss: -0.3484656512737274.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 2901 of 5001.\n",
      "Step: 2902 of 5001.\n",
      "Step: 2903 of 5001.\n",
      "Step: 2904 of 5001.\n",
      "Step: 2905 of 5001.\n",
      "Step: 2906 of 5001.\n",
      "Step: 2907 of 5001.\n",
      "Step: 2908 of 5001.\n",
      "Step: 2909 of 5001.\n",
      "Step: 2910 of 5001.\n",
      "Generator model loss: -1.8247512578964233.\n",
      "Discriminator model loss: -0.34348344802856445.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2911 of 5001.\n",
      "Step: 2912 of 5001.\n",
      "Step: 2913 of 5001.\n",
      "Step: 2914 of 5001.\n",
      "Step: 2915 of 5001.\n",
      "Step: 2916 of 5001.\n",
      "Step: 2917 of 5001.\n",
      "Step: 2918 of 5001.\n",
      "Step: 2919 of 5001.\n",
      "Step: 2920 of 5001.\n",
      "Generator model loss: -1.841591238975525.\n",
      "Discriminator model loss: -0.4143986105918884.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2921 of 5001.\n",
      "Step: 2922 of 5001.\n",
      "Step: 2923 of 5001.\n",
      "Step: 2924 of 5001.\n",
      "Step: 2925 of 5001.\n",
      "Step: 2926 of 5001.\n",
      "Step: 2927 of 5001.\n",
      "Step: 2928 of 5001.\n",
      "Step: 2929 of 5001.\n",
      "Step: 2930 of 5001.\n",
      "Generator model loss: -1.8343956470489502.\n",
      "Discriminator model loss: -0.2815289795398712.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 2931 of 5001.\n",
      "Step: 2932 of 5001.\n",
      "Step: 2933 of 5001.\n",
      "Step: 2934 of 5001.\n",
      "Step: 2935 of 5001.\n",
      "Step: 2936 of 5001.\n",
      "Step: 2937 of 5001.\n",
      "Step: 2938 of 5001.\n",
      "Step: 2939 of 5001.\n",
      "Step: 2940 of 5001.\n",
      "Generator model loss: -1.8481934070587158.\n",
      "Discriminator model loss: -0.3727143406867981.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 2941 of 5001.\n",
      "Step: 2942 of 5001.\n",
      "Step: 2943 of 5001.\n",
      "Step: 2944 of 5001.\n",
      "Step: 2945 of 5001.\n",
      "Step: 2946 of 5001.\n",
      "Step: 2947 of 5001.\n",
      "Step: 2948 of 5001.\n",
      "Step: 2949 of 5001.\n",
      "Step: 2950 of 5001.\n",
      "Generator model loss: -1.814898133277893.\n",
      "Discriminator model loss: -0.3028166890144348.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 2951 of 5001.\n",
      "Step: 2952 of 5001.\n",
      "Step: 2953 of 5001.\n",
      "Step: 2954 of 5001.\n",
      "Step: 2955 of 5001.\n",
      "Step: 2956 of 5001.\n",
      "Step: 2957 of 5001.\n",
      "Step: 2958 of 5001.\n",
      "Step: 2959 of 5001.\n",
      "Step: 2960 of 5001.\n",
      "Generator model loss: -1.8818480968475342.\n",
      "Discriminator model loss: -0.2980479896068573.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 2961 of 5001.\n",
      "Step: 2962 of 5001.\n",
      "Step: 2963 of 5001.\n",
      "Step: 2964 of 5001.\n",
      "Step: 2965 of 5001.\n",
      "Step: 2966 of 5001.\n",
      "Step: 2967 of 5001.\n",
      "Step: 2968 of 5001.\n",
      "Step: 2969 of 5001.\n",
      "Step: 2970 of 5001.\n",
      "Generator model loss: -1.8850208520889282.\n",
      "Discriminator model loss: -0.29102426767349243.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 2971 of 5001.\n",
      "Step: 2972 of 5001.\n",
      "Step: 2973 of 5001.\n",
      "Step: 2974 of 5001.\n",
      "Step: 2975 of 5001.\n",
      "Step: 2976 of 5001.\n",
      "Step: 2977 of 5001.\n",
      "Step: 2978 of 5001.\n",
      "Step: 2979 of 5001.\n",
      "Step: 2980 of 5001.\n",
      "Generator model loss: -1.819141149520874.\n",
      "Discriminator model loss: -0.2578977346420288.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 2981 of 5001.\n",
      "Step: 2982 of 5001.\n",
      "Step: 2983 of 5001.\n",
      "Step: 2984 of 5001.\n",
      "Step: 2985 of 5001.\n",
      "Step: 2986 of 5001.\n",
      "Step: 2987 of 5001.\n",
      "Step: 2988 of 5001.\n",
      "Step: 2989 of 5001.\n",
      "Step: 2990 of 5001.\n",
      "Generator model loss: -1.8608636856079102.\n",
      "Discriminator model loss: -0.3326965868473053.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 2991 of 5001.\n",
      "Step: 2992 of 5001.\n",
      "Step: 2993 of 5001.\n",
      "Step: 2994 of 5001.\n",
      "Step: 2995 of 5001.\n",
      "Step: 2996 of 5001.\n",
      "Step: 2997 of 5001.\n",
      "Step: 2998 of 5001.\n",
      "Step: 2999 of 5001.\n",
      "Step: 3000 of 5001.\n",
      "Generator model loss: -1.8469951152801514.\n",
      "Discriminator model loss: -0.31341344118118286.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3001 of 5001.\n",
      "Step: 3002 of 5001.\n",
      "Step: 3003 of 5001.\n",
      "Step: 3004 of 5001.\n",
      "Step: 3005 of 5001.\n",
      "Step: 3006 of 5001.\n",
      "Step: 3007 of 5001.\n",
      "Step: 3008 of 5001.\n",
      "Step: 3009 of 5001.\n",
      "Step: 3010 of 5001.\n",
      "Generator model loss: -1.775896668434143.\n",
      "Discriminator model loss: -0.3591476082801819.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3011 of 5001.\n",
      "Step: 3012 of 5001.\n",
      "Step: 3013 of 5001.\n",
      "Step: 3014 of 5001.\n",
      "Step: 3015 of 5001.\n",
      "Step: 3016 of 5001.\n",
      "Step: 3017 of 5001.\n",
      "Step: 3018 of 5001.\n",
      "Step: 3019 of 5001.\n",
      "Step: 3020 of 5001.\n",
      "Generator model loss: -1.8686565160751343.\n",
      "Discriminator model loss: -0.3265800178050995.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 3021 of 5001.\n",
      "Step: 3022 of 5001.\n",
      "Step: 3023 of 5001.\n",
      "Step: 3024 of 5001.\n",
      "Step: 3025 of 5001.\n",
      "Step: 3026 of 5001.\n",
      "Step: 3027 of 5001.\n",
      "Step: 3028 of 5001.\n",
      "Step: 3029 of 5001.\n",
      "Step: 3030 of 5001.\n",
      "Generator model loss: -1.8517115116119385.\n",
      "Discriminator model loss: -0.3494138717651367.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3031 of 5001.\n",
      "Step: 3032 of 5001.\n",
      "Step: 3033 of 5001.\n",
      "Step: 3034 of 5001.\n",
      "Step: 3035 of 5001.\n",
      "Step: 3036 of 5001.\n",
      "Step: 3037 of 5001.\n",
      "Step: 3038 of 5001.\n",
      "Step: 3039 of 5001.\n",
      "Step: 3040 of 5001.\n",
      "Generator model loss: -1.8438361883163452.\n",
      "Discriminator model loss: -0.4012452960014343.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3041 of 5001.\n",
      "Step: 3042 of 5001.\n",
      "Step: 3043 of 5001.\n",
      "Step: 3044 of 5001.\n",
      "Step: 3045 of 5001.\n",
      "Step: 3046 of 5001.\n",
      "Step: 3047 of 5001.\n",
      "Step: 3048 of 5001.\n",
      "Step: 3049 of 5001.\n",
      "Step: 3050 of 5001.\n",
      "Generator model loss: -1.8840593099594116.\n",
      "Discriminator model loss: -0.3007703721523285.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3051 of 5001.\n",
      "Step: 3052 of 5001.\n",
      "Step: 3053 of 5001.\n",
      "Step: 3054 of 5001.\n",
      "Step: 3055 of 5001.\n",
      "Step: 3056 of 5001.\n",
      "Step: 3057 of 5001.\n",
      "Step: 3058 of 5001.\n",
      "Step: 3059 of 5001.\n",
      "Step: 3060 of 5001.\n",
      "Generator model loss: -1.9210894107818604.\n",
      "Discriminator model loss: -0.41897183656692505.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3061 of 5001.\n",
      "Step: 3062 of 5001.\n",
      "Step: 3063 of 5001.\n",
      "Step: 3064 of 5001.\n",
      "Step: 3065 of 5001.\n",
      "Step: 3066 of 5001.\n",
      "Step: 3067 of 5001.\n",
      "Step: 3068 of 5001.\n",
      "Step: 3069 of 5001.\n",
      "Step: 3070 of 5001.\n",
      "Generator model loss: -1.914907455444336.\n",
      "Discriminator model loss: -0.33485299348831177.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3071 of 5001.\n",
      "Step: 3072 of 5001.\n",
      "Step: 3073 of 5001.\n",
      "Step: 3074 of 5001.\n",
      "Step: 3075 of 5001.\n",
      "Step: 3076 of 5001.\n",
      "Step: 3077 of 5001.\n",
      "Step: 3078 of 5001.\n",
      "Step: 3079 of 5001.\n",
      "Step: 3080 of 5001.\n",
      "Generator model loss: -1.8661270141601562.\n",
      "Discriminator model loss: -0.3089713454246521.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3081 of 5001.\n",
      "Step: 3082 of 5001.\n",
      "Step: 3083 of 5001.\n",
      "Step: 3084 of 5001.\n",
      "Step: 3085 of 5001.\n",
      "Step: 3086 of 5001.\n",
      "Step: 3087 of 5001.\n",
      "Step: 3088 of 5001.\n",
      "Step: 3089 of 5001.\n",
      "Step: 3090 of 5001.\n",
      "Generator model loss: -1.8837753534317017.\n",
      "Discriminator model loss: -0.3416709303855896.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3091 of 5001.\n",
      "Step: 3092 of 5001.\n",
      "Step: 3093 of 5001.\n",
      "Step: 3094 of 5001.\n",
      "Step: 3095 of 5001.\n",
      "Step: 3096 of 5001.\n",
      "Step: 3097 of 5001.\n",
      "Step: 3098 of 5001.\n",
      "Step: 3099 of 5001.\n",
      "Step: 3100 of 5001.\n",
      "Generator model loss: -1.8767238855361938.\n",
      "Discriminator model loss: -0.4689270853996277.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3101 of 5001.\n",
      "Step: 3102 of 5001.\n",
      "Step: 3103 of 5001.\n",
      "Step: 3104 of 5001.\n",
      "Step: 3105 of 5001.\n",
      "Step: 3106 of 5001.\n",
      "Step: 3107 of 5001.\n",
      "Step: 3108 of 5001.\n",
      "Step: 3109 of 5001.\n",
      "Step: 3110 of 5001.\n",
      "Generator model loss: -1.8844267129898071.\n",
      "Discriminator model loss: -0.3721175789833069.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3111 of 5001.\n",
      "Step: 3112 of 5001.\n",
      "Step: 3113 of 5001.\n",
      "Step: 3114 of 5001.\n",
      "Step: 3115 of 5001.\n",
      "Step: 3116 of 5001.\n",
      "Step: 3117 of 5001.\n",
      "Step: 3118 of 5001.\n",
      "Step: 3119 of 5001.\n",
      "Step: 3120 of 5001.\n",
      "Generator model loss: -1.913848638534546.\n",
      "Discriminator model loss: -0.3607310652732849.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3121 of 5001.\n",
      "Step: 3122 of 5001.\n",
      "Step: 3123 of 5001.\n",
      "Step: 3124 of 5001.\n",
      "Step: 3125 of 5001.\n",
      "Step: 3126 of 5001.\n",
      "Step: 3127 of 5001.\n",
      "Step: 3128 of 5001.\n",
      "Step: 3129 of 5001.\n",
      "Step: 3130 of 5001.\n",
      "Generator model loss: -1.8838164806365967.\n",
      "Discriminator model loss: -0.40966200828552246.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3131 of 5001.\n",
      "Step: 3132 of 5001.\n",
      "Step: 3133 of 5001.\n",
      "Step: 3134 of 5001.\n",
      "Step: 3135 of 5001.\n",
      "Step: 3136 of 5001.\n",
      "Step: 3137 of 5001.\n",
      "Step: 3138 of 5001.\n",
      "Step: 3139 of 5001.\n",
      "Step: 3140 of 5001.\n",
      "Generator model loss: -1.8472347259521484.\n",
      "Discriminator model loss: -0.34982094168663025.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3141 of 5001.\n",
      "Step: 3142 of 5001.\n",
      "Step: 3143 of 5001.\n",
      "Step: 3144 of 5001.\n",
      "Step: 3145 of 5001.\n",
      "Step: 3146 of 5001.\n",
      "Step: 3147 of 5001.\n",
      "Step: 3148 of 5001.\n",
      "Step: 3149 of 5001.\n",
      "Step: 3150 of 5001.\n",
      "Generator model loss: -1.8850462436676025.\n",
      "Discriminator model loss: -0.3684350252151489.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3151 of 5001.\n",
      "Step: 3152 of 5001.\n",
      "Step: 3153 of 5001.\n",
      "Step: 3154 of 5001.\n",
      "Step: 3155 of 5001.\n",
      "Step: 3156 of 5001.\n",
      "Step: 3157 of 5001.\n",
      "Step: 3158 of 5001.\n",
      "Step: 3159 of 5001.\n",
      "Step: 3160 of 5001.\n",
      "Generator model loss: -1.8557058572769165.\n",
      "Discriminator model loss: -0.34595826268196106.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 3161 of 5001.\n",
      "Step: 3162 of 5001.\n",
      "Step: 3163 of 5001.\n",
      "Step: 3164 of 5001.\n",
      "Step: 3165 of 5001.\n",
      "Step: 3166 of 5001.\n",
      "Step: 3167 of 5001.\n",
      "Step: 3168 of 5001.\n",
      "Step: 3169 of 5001.\n",
      "Step: 3170 of 5001.\n",
      "Generator model loss: -1.863612174987793.\n",
      "Discriminator model loss: -0.4576188027858734.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3171 of 5001.\n",
      "Step: 3172 of 5001.\n",
      "Step: 3173 of 5001.\n",
      "Step: 3174 of 5001.\n",
      "Step: 3175 of 5001.\n",
      "Step: 3176 of 5001.\n",
      "Step: 3177 of 5001.\n",
      "Step: 3178 of 5001.\n",
      "Step: 3179 of 5001.\n",
      "Step: 3180 of 5001.\n",
      "Generator model loss: -1.8786300420761108.\n",
      "Discriminator model loss: -0.4007478654384613.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3181 of 5001.\n",
      "Step: 3182 of 5001.\n",
      "Step: 3183 of 5001.\n",
      "Step: 3184 of 5001.\n",
      "Step: 3185 of 5001.\n",
      "Step: 3186 of 5001.\n",
      "Step: 3187 of 5001.\n",
      "Step: 3188 of 5001.\n",
      "Step: 3189 of 5001.\n",
      "Step: 3190 of 5001.\n",
      "Generator model loss: -1.8992685079574585.\n",
      "Discriminator model loss: -0.3581414520740509.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3191 of 5001.\n",
      "Step: 3192 of 5001.\n",
      "Step: 3193 of 5001.\n",
      "Step: 3194 of 5001.\n",
      "Step: 3195 of 5001.\n",
      "Step: 3196 of 5001.\n",
      "Step: 3197 of 5001.\n",
      "Step: 3198 of 5001.\n",
      "Step: 3199 of 5001.\n",
      "Step: 3200 of 5001.\n",
      "Generator model loss: -1.9060838222503662.\n",
      "Discriminator model loss: -0.44011640548706055.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3201 of 5001.\n",
      "Step: 3202 of 5001.\n",
      "Step: 3203 of 5001.\n",
      "Step: 3204 of 5001.\n",
      "Step: 3205 of 5001.\n",
      "Step: 3206 of 5001.\n",
      "Step: 3207 of 5001.\n",
      "Step: 3208 of 5001.\n",
      "Step: 3209 of 5001.\n",
      "Step: 3210 of 5001.\n",
      "Generator model loss: -1.8510385751724243.\n",
      "Discriminator model loss: -0.3685128390789032.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3211 of 5001.\n",
      "Step: 3212 of 5001.\n",
      "Step: 3213 of 5001.\n",
      "Step: 3214 of 5001.\n",
      "Step: 3215 of 5001.\n",
      "Step: 3216 of 5001.\n",
      "Step: 3217 of 5001.\n",
      "Step: 3218 of 5001.\n",
      "Step: 3219 of 5001.\n",
      "Step: 3220 of 5001.\n",
      "Generator model loss: -1.8795092105865479.\n",
      "Discriminator model loss: -0.33653518557548523.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3221 of 5001.\n",
      "Step: 3222 of 5001.\n",
      "Step: 3223 of 5001.\n",
      "Step: 3224 of 5001.\n",
      "Step: 3225 of 5001.\n",
      "Step: 3226 of 5001.\n",
      "Step: 3227 of 5001.\n",
      "Step: 3228 of 5001.\n",
      "Step: 3229 of 5001.\n",
      "Step: 3230 of 5001.\n",
      "Generator model loss: -1.8171972036361694.\n",
      "Discriminator model loss: -0.45845118165016174.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3231 of 5001.\n",
      "Step: 3232 of 5001.\n",
      "Step: 3233 of 5001.\n",
      "Step: 3234 of 5001.\n",
      "Step: 3235 of 5001.\n",
      "Step: 3236 of 5001.\n",
      "Step: 3237 of 5001.\n",
      "Step: 3238 of 5001.\n",
      "Step: 3239 of 5001.\n",
      "Step: 3240 of 5001.\n",
      "Generator model loss: -1.879328966140747.\n",
      "Discriminator model loss: -0.4287664294242859.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3241 of 5001.\n",
      "Step: 3242 of 5001.\n",
      "Step: 3243 of 5001.\n",
      "Step: 3244 of 5001.\n",
      "Step: 3245 of 5001.\n",
      "Step: 3246 of 5001.\n",
      "Step: 3247 of 5001.\n",
      "Step: 3248 of 5001.\n",
      "Step: 3249 of 5001.\n",
      "Step: 3250 of 5001.\n",
      "Generator model loss: -1.8022677898406982.\n",
      "Discriminator model loss: -0.43091827630996704.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 3251 of 5001.\n",
      "Step: 3252 of 5001.\n",
      "Step: 3253 of 5001.\n",
      "Step: 3254 of 5001.\n",
      "Step: 3255 of 5001.\n",
      "Step: 3256 of 5001.\n",
      "Step: 3257 of 5001.\n",
      "Step: 3258 of 5001.\n",
      "Step: 3259 of 5001.\n",
      "Step: 3260 of 5001.\n",
      "Generator model loss: -1.8710130453109741.\n",
      "Discriminator model loss: -0.3841725289821625.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3261 of 5001.\n",
      "Step: 3262 of 5001.\n",
      "Step: 3263 of 5001.\n",
      "Step: 3264 of 5001.\n",
      "Step: 3265 of 5001.\n",
      "Step: 3266 of 5001.\n",
      "Step: 3267 of 5001.\n",
      "Step: 3268 of 5001.\n",
      "Step: 3269 of 5001.\n",
      "Step: 3270 of 5001.\n",
      "Generator model loss: -1.8373234272003174.\n",
      "Discriminator model loss: -0.396818071603775.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3271 of 5001.\n",
      "Step: 3272 of 5001.\n",
      "Step: 3273 of 5001.\n",
      "Step: 3274 of 5001.\n",
      "Step: 3275 of 5001.\n",
      "Step: 3276 of 5001.\n",
      "Step: 3277 of 5001.\n",
      "Step: 3278 of 5001.\n",
      "Step: 3279 of 5001.\n",
      "Step: 3280 of 5001.\n",
      "Generator model loss: -1.842172622680664.\n",
      "Discriminator model loss: -0.4191175103187561.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3281 of 5001.\n",
      "Step: 3282 of 5001.\n",
      "Step: 3283 of 5001.\n",
      "Step: 3284 of 5001.\n",
      "Step: 3285 of 5001.\n",
      "Step: 3286 of 5001.\n",
      "Step: 3287 of 5001.\n",
      "Step: 3288 of 5001.\n",
      "Step: 3289 of 5001.\n",
      "Step: 3290 of 5001.\n",
      "Generator model loss: -1.9147131443023682.\n",
      "Discriminator model loss: -0.33183056116104126.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3291 of 5001.\n",
      "Step: 3292 of 5001.\n",
      "Step: 3293 of 5001.\n",
      "Step: 3294 of 5001.\n",
      "Step: 3295 of 5001.\n",
      "Step: 3296 of 5001.\n",
      "Step: 3297 of 5001.\n",
      "Step: 3298 of 5001.\n",
      "Step: 3299 of 5001.\n",
      "Step: 3300 of 5001.\n",
      "Generator model loss: -1.8397777080535889.\n",
      "Discriminator model loss: -0.4149637222290039.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3301 of 5001.\n",
      "Step: 3302 of 5001.\n",
      "Step: 3303 of 5001.\n",
      "Step: 3304 of 5001.\n",
      "Step: 3305 of 5001.\n",
      "Step: 3306 of 5001.\n",
      "Step: 3307 of 5001.\n",
      "Step: 3308 of 5001.\n",
      "Step: 3309 of 5001.\n",
      "Step: 3310 of 5001.\n",
      "Generator model loss: -1.7462812662124634.\n",
      "Discriminator model loss: -0.38470375537872314.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3311 of 5001.\n",
      "Step: 3312 of 5001.\n",
      "Step: 3313 of 5001.\n",
      "Step: 3314 of 5001.\n",
      "Step: 3315 of 5001.\n",
      "Step: 3316 of 5001.\n",
      "Step: 3317 of 5001.\n",
      "Step: 3318 of 5001.\n",
      "Step: 3319 of 5001.\n",
      "Step: 3320 of 5001.\n",
      "Generator model loss: -1.7973158359527588.\n",
      "Discriminator model loss: -0.4847998023033142.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3321 of 5001.\n",
      "Step: 3322 of 5001.\n",
      "Step: 3323 of 5001.\n",
      "Step: 3324 of 5001.\n",
      "Step: 3325 of 5001.\n",
      "Step: 3326 of 5001.\n",
      "Step: 3327 of 5001.\n",
      "Step: 3328 of 5001.\n",
      "Step: 3329 of 5001.\n",
      "Step: 3330 of 5001.\n",
      "Generator model loss: -1.759552240371704.\n",
      "Discriminator model loss: -0.4036460816860199.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3331 of 5001.\n",
      "Step: 3332 of 5001.\n",
      "Step: 3333 of 5001.\n",
      "Step: 3334 of 5001.\n",
      "Step: 3335 of 5001.\n",
      "Step: 3336 of 5001.\n",
      "Step: 3337 of 5001.\n",
      "Step: 3338 of 5001.\n",
      "Step: 3339 of 5001.\n",
      "Step: 3340 of 5001.\n",
      "Generator model loss: -1.8385404348373413.\n",
      "Discriminator model loss: -0.4391748309135437.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3341 of 5001.\n",
      "Step: 3342 of 5001.\n",
      "Step: 3343 of 5001.\n",
      "Step: 3344 of 5001.\n",
      "Step: 3345 of 5001.\n",
      "Step: 3346 of 5001.\n",
      "Step: 3347 of 5001.\n",
      "Step: 3348 of 5001.\n",
      "Step: 3349 of 5001.\n",
      "Step: 3350 of 5001.\n",
      "Generator model loss: -1.7755241394042969.\n",
      "Discriminator model loss: -0.4177244305610657.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3351 of 5001.\n",
      "Step: 3352 of 5001.\n",
      "Step: 3353 of 5001.\n",
      "Step: 3354 of 5001.\n",
      "Step: 3355 of 5001.\n",
      "Step: 3356 of 5001.\n",
      "Step: 3357 of 5001.\n",
      "Step: 3358 of 5001.\n",
      "Step: 3359 of 5001.\n",
      "Step: 3360 of 5001.\n",
      "Generator model loss: -1.8219854831695557.\n",
      "Discriminator model loss: -0.4859342575073242.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3361 of 5001.\n",
      "Step: 3362 of 5001.\n",
      "Step: 3363 of 5001.\n",
      "Step: 3364 of 5001.\n",
      "Step: 3365 of 5001.\n",
      "Step: 3366 of 5001.\n",
      "Step: 3367 of 5001.\n",
      "Step: 3368 of 5001.\n",
      "Step: 3369 of 5001.\n",
      "Step: 3370 of 5001.\n",
      "Generator model loss: -1.8157718181610107.\n",
      "Discriminator model loss: -0.4811438024044037.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3371 of 5001.\n",
      "Step: 3372 of 5001.\n",
      "Step: 3373 of 5001.\n",
      "Step: 3374 of 5001.\n",
      "Step: 3375 of 5001.\n",
      "Step: 3376 of 5001.\n",
      "Step: 3377 of 5001.\n",
      "Step: 3378 of 5001.\n",
      "Step: 3379 of 5001.\n",
      "Step: 3380 of 5001.\n",
      "Generator model loss: -1.8062732219696045.\n",
      "Discriminator model loss: -0.5042270421981812.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3381 of 5001.\n",
      "Step: 3382 of 5001.\n",
      "Step: 3383 of 5001.\n",
      "Step: 3384 of 5001.\n",
      "Step: 3385 of 5001.\n",
      "Step: 3386 of 5001.\n",
      "Step: 3387 of 5001.\n",
      "Step: 3388 of 5001.\n",
      "Step: 3389 of 5001.\n",
      "Step: 3390 of 5001.\n",
      "Generator model loss: -1.8104168176651.\n",
      "Discriminator model loss: -0.4968639314174652.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3391 of 5001.\n",
      "Step: 3392 of 5001.\n",
      "Step: 3393 of 5001.\n",
      "Step: 3394 of 5001.\n",
      "Step: 3395 of 5001.\n",
      "Step: 3396 of 5001.\n",
      "Step: 3397 of 5001.\n",
      "Step: 3398 of 5001.\n",
      "Step: 3399 of 5001.\n",
      "Step: 3400 of 5001.\n",
      "Generator model loss: -1.7761856317520142.\n",
      "Discriminator model loss: -0.48291683197021484.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3401 of 5001.\n",
      "Step: 3402 of 5001.\n",
      "Step: 3403 of 5001.\n",
      "Step: 3404 of 5001.\n",
      "Step: 3405 of 5001.\n",
      "Step: 3406 of 5001.\n",
      "Step: 3407 of 5001.\n",
      "Step: 3408 of 5001.\n",
      "Step: 3409 of 5001.\n",
      "Step: 3410 of 5001.\n",
      "Generator model loss: -1.7770822048187256.\n",
      "Discriminator model loss: -0.39762163162231445.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 3411 of 5001.\n",
      "Step: 3412 of 5001.\n",
      "Step: 3413 of 5001.\n",
      "Step: 3414 of 5001.\n",
      "Step: 3415 of 5001.\n",
      "Step: 3416 of 5001.\n",
      "Step: 3417 of 5001.\n",
      "Step: 3418 of 5001.\n",
      "Step: 3419 of 5001.\n",
      "Step: 3420 of 5001.\n",
      "Generator model loss: -1.808558464050293.\n",
      "Discriminator model loss: -0.39328187704086304.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3421 of 5001.\n",
      "Step: 3422 of 5001.\n",
      "Step: 3423 of 5001.\n",
      "Step: 3424 of 5001.\n",
      "Step: 3425 of 5001.\n",
      "Step: 3426 of 5001.\n",
      "Step: 3427 of 5001.\n",
      "Step: 3428 of 5001.\n",
      "Step: 3429 of 5001.\n",
      "Step: 3430 of 5001.\n",
      "Generator model loss: -1.7804588079452515.\n",
      "Discriminator model loss: -0.4621039927005768.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 3431 of 5001.\n",
      "Step: 3432 of 5001.\n",
      "Step: 3433 of 5001.\n",
      "Step: 3434 of 5001.\n",
      "Step: 3435 of 5001.\n",
      "Step: 3436 of 5001.\n",
      "Step: 3437 of 5001.\n",
      "Step: 3438 of 5001.\n",
      "Step: 3439 of 5001.\n",
      "Step: 3440 of 5001.\n",
      "Generator model loss: -1.7935950756072998.\n",
      "Discriminator model loss: -0.40248626470565796.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3441 of 5001.\n",
      "Step: 3442 of 5001.\n",
      "Step: 3443 of 5001.\n",
      "Step: 3444 of 5001.\n",
      "Step: 3445 of 5001.\n",
      "Step: 3446 of 5001.\n",
      "Step: 3447 of 5001.\n",
      "Step: 3448 of 5001.\n",
      "Step: 3449 of 5001.\n",
      "Step: 3450 of 5001.\n",
      "Generator model loss: -1.7772281169891357.\n",
      "Discriminator model loss: -0.3978145718574524.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3451 of 5001.\n",
      "Step: 3452 of 5001.\n",
      "Step: 3453 of 5001.\n",
      "Step: 3454 of 5001.\n",
      "Step: 3455 of 5001.\n",
      "Step: 3456 of 5001.\n",
      "Step: 3457 of 5001.\n",
      "Step: 3458 of 5001.\n",
      "Step: 3459 of 5001.\n",
      "Step: 3460 of 5001.\n",
      "Generator model loss: -1.8140003681182861.\n",
      "Discriminator model loss: -0.5064648389816284.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3461 of 5001.\n",
      "Step: 3462 of 5001.\n",
      "Step: 3463 of 5001.\n",
      "Step: 3464 of 5001.\n",
      "Step: 3465 of 5001.\n",
      "Step: 3466 of 5001.\n",
      "Step: 3467 of 5001.\n",
      "Step: 3468 of 5001.\n",
      "Step: 3469 of 5001.\n",
      "Step: 3470 of 5001.\n",
      "Generator model loss: -1.7664721012115479.\n",
      "Discriminator model loss: -0.3400789499282837.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3471 of 5001.\n",
      "Step: 3472 of 5001.\n",
      "Step: 3473 of 5001.\n",
      "Step: 3474 of 5001.\n",
      "Step: 3475 of 5001.\n",
      "Step: 3476 of 5001.\n",
      "Step: 3477 of 5001.\n",
      "Step: 3478 of 5001.\n",
      "Step: 3479 of 5001.\n",
      "Step: 3480 of 5001.\n",
      "Generator model loss: -1.7744373083114624.\n",
      "Discriminator model loss: -0.37979063391685486.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3481 of 5001.\n",
      "Step: 3482 of 5001.\n",
      "Step: 3483 of 5001.\n",
      "Step: 3484 of 5001.\n",
      "Step: 3485 of 5001.\n",
      "Step: 3486 of 5001.\n",
      "Step: 3487 of 5001.\n",
      "Step: 3488 of 5001.\n",
      "Step: 3489 of 5001.\n",
      "Step: 3490 of 5001.\n",
      "Generator model loss: -1.7947756052017212.\n",
      "Discriminator model loss: -0.4557311534881592.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3491 of 5001.\n",
      "Step: 3492 of 5001.\n",
      "Step: 3493 of 5001.\n",
      "Step: 3494 of 5001.\n",
      "Step: 3495 of 5001.\n",
      "Step: 3496 of 5001.\n",
      "Step: 3497 of 5001.\n",
      "Step: 3498 of 5001.\n",
      "Step: 3499 of 5001.\n",
      "Step: 3500 of 5001.\n",
      "Generator model loss: -1.8084068298339844.\n",
      "Discriminator model loss: -0.49956125020980835.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3501 of 5001.\n",
      "Step: 3502 of 5001.\n",
      "Step: 3503 of 5001.\n",
      "Step: 3504 of 5001.\n",
      "Step: 3505 of 5001.\n",
      "Step: 3506 of 5001.\n",
      "Step: 3507 of 5001.\n",
      "Step: 3508 of 5001.\n",
      "Step: 3509 of 5001.\n",
      "Step: 3510 of 5001.\n",
      "Generator model loss: -1.7997915744781494.\n",
      "Discriminator model loss: -0.5015718340873718.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3511 of 5001.\n",
      "Step: 3512 of 5001.\n",
      "Step: 3513 of 5001.\n",
      "Step: 3514 of 5001.\n",
      "Step: 3515 of 5001.\n",
      "Step: 3516 of 5001.\n",
      "Step: 3517 of 5001.\n",
      "Step: 3518 of 5001.\n",
      "Step: 3519 of 5001.\n",
      "Step: 3520 of 5001.\n",
      "Generator model loss: -1.8429418802261353.\n",
      "Discriminator model loss: -0.350242018699646.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3521 of 5001.\n",
      "Step: 3522 of 5001.\n",
      "Step: 3523 of 5001.\n",
      "Step: 3524 of 5001.\n",
      "Step: 3525 of 5001.\n",
      "Step: 3526 of 5001.\n",
      "Step: 3527 of 5001.\n",
      "Step: 3528 of 5001.\n",
      "Step: 3529 of 5001.\n",
      "Step: 3530 of 5001.\n",
      "Generator model loss: -1.8359721899032593.\n",
      "Discriminator model loss: -0.395263135433197.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3531 of 5001.\n",
      "Step: 3532 of 5001.\n",
      "Step: 3533 of 5001.\n",
      "Step: 3534 of 5001.\n",
      "Step: 3535 of 5001.\n",
      "Step: 3536 of 5001.\n",
      "Step: 3537 of 5001.\n",
      "Step: 3538 of 5001.\n",
      "Step: 3539 of 5001.\n",
      "Step: 3540 of 5001.\n",
      "Generator model loss: -1.8504741191864014.\n",
      "Discriminator model loss: -0.46966248750686646.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3541 of 5001.\n",
      "Step: 3542 of 5001.\n",
      "Step: 3543 of 5001.\n",
      "Step: 3544 of 5001.\n",
      "Step: 3545 of 5001.\n",
      "Step: 3546 of 5001.\n",
      "Step: 3547 of 5001.\n",
      "Step: 3548 of 5001.\n",
      "Step: 3549 of 5001.\n",
      "Step: 3550 of 5001.\n",
      "Generator model loss: -1.8179073333740234.\n",
      "Discriminator model loss: -0.3896176517009735.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3551 of 5001.\n",
      "Step: 3552 of 5001.\n",
      "Step: 3553 of 5001.\n",
      "Step: 3554 of 5001.\n",
      "Step: 3555 of 5001.\n",
      "Step: 3556 of 5001.\n",
      "Step: 3557 of 5001.\n",
      "Step: 3558 of 5001.\n",
      "Step: 3559 of 5001.\n",
      "Step: 3560 of 5001.\n",
      "Generator model loss: -1.7769300937652588.\n",
      "Discriminator model loss: -0.36633405089378357.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3561 of 5001.\n",
      "Step: 3562 of 5001.\n",
      "Step: 3563 of 5001.\n",
      "Step: 3564 of 5001.\n",
      "Step: 3565 of 5001.\n",
      "Step: 3566 of 5001.\n",
      "Step: 3567 of 5001.\n",
      "Step: 3568 of 5001.\n",
      "Step: 3569 of 5001.\n",
      "Step: 3570 of 5001.\n",
      "Generator model loss: -1.8338844776153564.\n",
      "Discriminator model loss: -0.33211398124694824.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3571 of 5001.\n",
      "Step: 3572 of 5001.\n",
      "Step: 3573 of 5001.\n",
      "Step: 3574 of 5001.\n",
      "Step: 3575 of 5001.\n",
      "Step: 3576 of 5001.\n",
      "Step: 3577 of 5001.\n",
      "Step: 3578 of 5001.\n",
      "Step: 3579 of 5001.\n",
      "Step: 3580 of 5001.\n",
      "Generator model loss: -1.7741254568099976.\n",
      "Discriminator model loss: -0.4834108352661133.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3581 of 5001.\n",
      "Step: 3582 of 5001.\n",
      "Step: 3583 of 5001.\n",
      "Step: 3584 of 5001.\n",
      "Step: 3585 of 5001.\n",
      "Step: 3586 of 5001.\n",
      "Step: 3587 of 5001.\n",
      "Step: 3588 of 5001.\n",
      "Step: 3589 of 5001.\n",
      "Step: 3590 of 5001.\n",
      "Generator model loss: -1.7913240194320679.\n",
      "Discriminator model loss: -0.3507443070411682.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3591 of 5001.\n",
      "Step: 3592 of 5001.\n",
      "Step: 3593 of 5001.\n",
      "Step: 3594 of 5001.\n",
      "Step: 3595 of 5001.\n",
      "Step: 3596 of 5001.\n",
      "Step: 3597 of 5001.\n",
      "Step: 3598 of 5001.\n",
      "Step: 3599 of 5001.\n",
      "Step: 3600 of 5001.\n",
      "Generator model loss: -1.8293635845184326.\n",
      "Discriminator model loss: -0.4069577157497406.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 3601 of 5001.\n",
      "Step: 3602 of 5001.\n",
      "Step: 3603 of 5001.\n",
      "Step: 3604 of 5001.\n",
      "Step: 3605 of 5001.\n",
      "Step: 3606 of 5001.\n",
      "Step: 3607 of 5001.\n",
      "Step: 3608 of 5001.\n",
      "Step: 3609 of 5001.\n",
      "Step: 3610 of 5001.\n",
      "Generator model loss: -1.7774550914764404.\n",
      "Discriminator model loss: -0.4273243844509125.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3611 of 5001.\n",
      "Step: 3612 of 5001.\n",
      "Step: 3613 of 5001.\n",
      "Step: 3614 of 5001.\n",
      "Step: 3615 of 5001.\n",
      "Step: 3616 of 5001.\n",
      "Step: 3617 of 5001.\n",
      "Step: 3618 of 5001.\n",
      "Step: 3619 of 5001.\n",
      "Step: 3620 of 5001.\n",
      "Generator model loss: -1.7724252939224243.\n",
      "Discriminator model loss: -0.4407788813114166.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3621 of 5001.\n",
      "Step: 3622 of 5001.\n",
      "Step: 3623 of 5001.\n",
      "Step: 3624 of 5001.\n",
      "Step: 3625 of 5001.\n",
      "Step: 3626 of 5001.\n",
      "Step: 3627 of 5001.\n",
      "Step: 3628 of 5001.\n",
      "Step: 3629 of 5001.\n",
      "Step: 3630 of 5001.\n",
      "Generator model loss: -1.7929424047470093.\n",
      "Discriminator model loss: -0.4248403012752533.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3631 of 5001.\n",
      "Step: 3632 of 5001.\n",
      "Step: 3633 of 5001.\n",
      "Step: 3634 of 5001.\n",
      "Step: 3635 of 5001.\n",
      "Step: 3636 of 5001.\n",
      "Step: 3637 of 5001.\n",
      "Step: 3638 of 5001.\n",
      "Step: 3639 of 5001.\n",
      "Step: 3640 of 5001.\n",
      "Generator model loss: -1.7853847742080688.\n",
      "Discriminator model loss: -0.40814152359962463.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3641 of 5001.\n",
      "Step: 3642 of 5001.\n",
      "Step: 3643 of 5001.\n",
      "Step: 3644 of 5001.\n",
      "Step: 3645 of 5001.\n",
      "Step: 3646 of 5001.\n",
      "Step: 3647 of 5001.\n",
      "Step: 3648 of 5001.\n",
      "Step: 3649 of 5001.\n",
      "Step: 3650 of 5001.\n",
      "Generator model loss: -1.79380202293396.\n",
      "Discriminator model loss: -0.4466222822666168.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 3651 of 5001.\n",
      "Step: 3652 of 5001.\n",
      "Step: 3653 of 5001.\n",
      "Step: 3654 of 5001.\n",
      "Step: 3655 of 5001.\n",
      "Step: 3656 of 5001.\n",
      "Step: 3657 of 5001.\n",
      "Step: 3658 of 5001.\n",
      "Step: 3659 of 5001.\n",
      "Step: 3660 of 5001.\n",
      "Generator model loss: -1.701209306716919.\n",
      "Discriminator model loss: -0.41244253516197205.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3661 of 5001.\n",
      "Step: 3662 of 5001.\n",
      "Step: 3663 of 5001.\n",
      "Step: 3664 of 5001.\n",
      "Step: 3665 of 5001.\n",
      "Step: 3666 of 5001.\n",
      "Step: 3667 of 5001.\n",
      "Step: 3668 of 5001.\n",
      "Step: 3669 of 5001.\n",
      "Step: 3670 of 5001.\n",
      "Generator model loss: -1.7837632894515991.\n",
      "Discriminator model loss: -0.3874395489692688.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3671 of 5001.\n",
      "Step: 3672 of 5001.\n",
      "Step: 3673 of 5001.\n",
      "Step: 3674 of 5001.\n",
      "Step: 3675 of 5001.\n",
      "Step: 3676 of 5001.\n",
      "Step: 3677 of 5001.\n",
      "Step: 3678 of 5001.\n",
      "Step: 3679 of 5001.\n",
      "Step: 3680 of 5001.\n",
      "Generator model loss: -1.7858569622039795.\n",
      "Discriminator model loss: -0.41294145584106445.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3681 of 5001.\n",
      "Step: 3682 of 5001.\n",
      "Step: 3683 of 5001.\n",
      "Step: 3684 of 5001.\n",
      "Step: 3685 of 5001.\n",
      "Step: 3686 of 5001.\n",
      "Step: 3687 of 5001.\n",
      "Step: 3688 of 5001.\n",
      "Step: 3689 of 5001.\n",
      "Step: 3690 of 5001.\n",
      "Generator model loss: -1.8037563562393188.\n",
      "Discriminator model loss: -0.42987877130508423.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 3691 of 5001.\n",
      "Step: 3692 of 5001.\n",
      "Step: 3693 of 5001.\n",
      "Step: 3694 of 5001.\n",
      "Step: 3695 of 5001.\n",
      "Step: 3696 of 5001.\n",
      "Step: 3697 of 5001.\n",
      "Step: 3698 of 5001.\n",
      "Step: 3699 of 5001.\n",
      "Step: 3700 of 5001.\n",
      "Generator model loss: -1.7807867527008057.\n",
      "Discriminator model loss: -0.38696974515914917.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3701 of 5001.\n",
      "Step: 3702 of 5001.\n",
      "Step: 3703 of 5001.\n",
      "Step: 3704 of 5001.\n",
      "Step: 3705 of 5001.\n",
      "Step: 3706 of 5001.\n",
      "Step: 3707 of 5001.\n",
      "Step: 3708 of 5001.\n",
      "Step: 3709 of 5001.\n",
      "Step: 3710 of 5001.\n",
      "Generator model loss: -1.8041315078735352.\n",
      "Discriminator model loss: -0.4147855341434479.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3711 of 5001.\n",
      "Step: 3712 of 5001.\n",
      "Step: 3713 of 5001.\n",
      "Step: 3714 of 5001.\n",
      "Step: 3715 of 5001.\n",
      "Step: 3716 of 5001.\n",
      "Step: 3717 of 5001.\n",
      "Step: 3718 of 5001.\n",
      "Step: 3719 of 5001.\n",
      "Step: 3720 of 5001.\n",
      "Generator model loss: -1.7825839519500732.\n",
      "Discriminator model loss: -0.45267993211746216.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3721 of 5001.\n",
      "Step: 3722 of 5001.\n",
      "Step: 3723 of 5001.\n",
      "Step: 3724 of 5001.\n",
      "Step: 3725 of 5001.\n",
      "Step: 3726 of 5001.\n",
      "Step: 3727 of 5001.\n",
      "Step: 3728 of 5001.\n",
      "Step: 3729 of 5001.\n",
      "Step: 3730 of 5001.\n",
      "Generator model loss: -1.8180208206176758.\n",
      "Discriminator model loss: -0.4007582664489746.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3731 of 5001.\n",
      "Step: 3732 of 5001.\n",
      "Step: 3733 of 5001.\n",
      "Step: 3734 of 5001.\n",
      "Step: 3735 of 5001.\n",
      "Step: 3736 of 5001.\n",
      "Step: 3737 of 5001.\n",
      "Step: 3738 of 5001.\n",
      "Step: 3739 of 5001.\n",
      "Step: 3740 of 5001.\n",
      "Generator model loss: -1.7605911493301392.\n",
      "Discriminator model loss: -0.44643181562423706.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3741 of 5001.\n",
      "Step: 3742 of 5001.\n",
      "Step: 3743 of 5001.\n",
      "Step: 3744 of 5001.\n",
      "Step: 3745 of 5001.\n",
      "Step: 3746 of 5001.\n",
      "Step: 3747 of 5001.\n",
      "Step: 3748 of 5001.\n",
      "Step: 3749 of 5001.\n",
      "Step: 3750 of 5001.\n",
      "Generator model loss: -1.7748286724090576.\n",
      "Discriminator model loss: -0.4271155297756195.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 3751 of 5001.\n",
      "Step: 3752 of 5001.\n",
      "Step: 3753 of 5001.\n",
      "Step: 3754 of 5001.\n",
      "Step: 3755 of 5001.\n",
      "Step: 3756 of 5001.\n",
      "Step: 3757 of 5001.\n",
      "Step: 3758 of 5001.\n",
      "Step: 3759 of 5001.\n",
      "Step: 3760 of 5001.\n",
      "Generator model loss: -1.7502399682998657.\n",
      "Discriminator model loss: -0.41566506028175354.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3761 of 5001.\n",
      "Step: 3762 of 5001.\n",
      "Step: 3763 of 5001.\n",
      "Step: 3764 of 5001.\n",
      "Step: 3765 of 5001.\n",
      "Step: 3766 of 5001.\n",
      "Step: 3767 of 5001.\n",
      "Step: 3768 of 5001.\n",
      "Step: 3769 of 5001.\n",
      "Step: 3770 of 5001.\n",
      "Generator model loss: -1.8006948232650757.\n",
      "Discriminator model loss: -0.40223416686058044.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3771 of 5001.\n",
      "Step: 3772 of 5001.\n",
      "Step: 3773 of 5001.\n",
      "Step: 3774 of 5001.\n",
      "Step: 3775 of 5001.\n",
      "Step: 3776 of 5001.\n",
      "Step: 3777 of 5001.\n",
      "Step: 3778 of 5001.\n",
      "Step: 3779 of 5001.\n",
      "Step: 3780 of 5001.\n",
      "Generator model loss: -1.7944797277450562.\n",
      "Discriminator model loss: -0.46216756105422974.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3781 of 5001.\n",
      "Step: 3782 of 5001.\n",
      "Step: 3783 of 5001.\n",
      "Step: 3784 of 5001.\n",
      "Step: 3785 of 5001.\n",
      "Step: 3786 of 5001.\n",
      "Step: 3787 of 5001.\n",
      "Step: 3788 of 5001.\n",
      "Step: 3789 of 5001.\n",
      "Step: 3790 of 5001.\n",
      "Generator model loss: -1.7975921630859375.\n",
      "Discriminator model loss: -0.4194532036781311.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 3791 of 5001.\n",
      "Step: 3792 of 5001.\n",
      "Step: 3793 of 5001.\n",
      "Step: 3794 of 5001.\n",
      "Step: 3795 of 5001.\n",
      "Step: 3796 of 5001.\n",
      "Step: 3797 of 5001.\n",
      "Step: 3798 of 5001.\n",
      "Step: 3799 of 5001.\n",
      "Step: 3800 of 5001.\n",
      "Generator model loss: -1.8313137292861938.\n",
      "Discriminator model loss: -0.39718714356422424.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3801 of 5001.\n",
      "Step: 3802 of 5001.\n",
      "Step: 3803 of 5001.\n",
      "Step: 3804 of 5001.\n",
      "Step: 3805 of 5001.\n",
      "Step: 3806 of 5001.\n",
      "Step: 3807 of 5001.\n",
      "Step: 3808 of 5001.\n",
      "Step: 3809 of 5001.\n",
      "Step: 3810 of 5001.\n",
      "Generator model loss: -1.8341705799102783.\n",
      "Discriminator model loss: -0.41708630323410034.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3811 of 5001.\n",
      "Step: 3812 of 5001.\n",
      "Step: 3813 of 5001.\n",
      "Step: 3814 of 5001.\n",
      "Step: 3815 of 5001.\n",
      "Step: 3816 of 5001.\n",
      "Step: 3817 of 5001.\n",
      "Step: 3818 of 5001.\n",
      "Step: 3819 of 5001.\n",
      "Step: 3820 of 5001.\n",
      "Generator model loss: -1.842551827430725.\n",
      "Discriminator model loss: -0.5051617622375488.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3821 of 5001.\n",
      "Step: 3822 of 5001.\n",
      "Step: 3823 of 5001.\n",
      "Step: 3824 of 5001.\n",
      "Step: 3825 of 5001.\n",
      "Step: 3826 of 5001.\n",
      "Step: 3827 of 5001.\n",
      "Step: 3828 of 5001.\n",
      "Step: 3829 of 5001.\n",
      "Step: 3830 of 5001.\n",
      "Generator model loss: -1.8501828908920288.\n",
      "Discriminator model loss: -0.3527665138244629.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3831 of 5001.\n",
      "Step: 3832 of 5001.\n",
      "Step: 3833 of 5001.\n",
      "Step: 3834 of 5001.\n",
      "Step: 3835 of 5001.\n",
      "Step: 3836 of 5001.\n",
      "Step: 3837 of 5001.\n",
      "Step: 3838 of 5001.\n",
      "Step: 3839 of 5001.\n",
      "Step: 3840 of 5001.\n",
      "Generator model loss: -1.8591747283935547.\n",
      "Discriminator model loss: -0.49181851744651794.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3841 of 5001.\n",
      "Step: 3842 of 5001.\n",
      "Step: 3843 of 5001.\n",
      "Step: 3844 of 5001.\n",
      "Step: 3845 of 5001.\n",
      "Step: 3846 of 5001.\n",
      "Step: 3847 of 5001.\n",
      "Step: 3848 of 5001.\n",
      "Step: 3849 of 5001.\n",
      "Step: 3850 of 5001.\n",
      "Generator model loss: -1.765465497970581.\n",
      "Discriminator model loss: -0.4797302186489105.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3851 of 5001.\n",
      "Step: 3852 of 5001.\n",
      "Step: 3853 of 5001.\n",
      "Step: 3854 of 5001.\n",
      "Step: 3855 of 5001.\n",
      "Step: 3856 of 5001.\n",
      "Step: 3857 of 5001.\n",
      "Step: 3858 of 5001.\n",
      "Step: 3859 of 5001.\n",
      "Step: 3860 of 5001.\n",
      "Generator model loss: -1.8087228536605835.\n",
      "Discriminator model loss: -0.4202461242675781.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3861 of 5001.\n",
      "Step: 3862 of 5001.\n",
      "Step: 3863 of 5001.\n",
      "Step: 3864 of 5001.\n",
      "Step: 3865 of 5001.\n",
      "Step: 3866 of 5001.\n",
      "Step: 3867 of 5001.\n",
      "Step: 3868 of 5001.\n",
      "Step: 3869 of 5001.\n",
      "Step: 3870 of 5001.\n",
      "Generator model loss: -1.9146966934204102.\n",
      "Discriminator model loss: -0.3021935224533081.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 3871 of 5001.\n",
      "Step: 3872 of 5001.\n",
      "Step: 3873 of 5001.\n",
      "Step: 3874 of 5001.\n",
      "Step: 3875 of 5001.\n",
      "Step: 3876 of 5001.\n",
      "Step: 3877 of 5001.\n",
      "Step: 3878 of 5001.\n",
      "Step: 3879 of 5001.\n",
      "Step: 3880 of 5001.\n",
      "Generator model loss: -1.8201802968978882.\n",
      "Discriminator model loss: -0.376844584941864.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3881 of 5001.\n",
      "Step: 3882 of 5001.\n",
      "Step: 3883 of 5001.\n",
      "Step: 3884 of 5001.\n",
      "Step: 3885 of 5001.\n",
      "Step: 3886 of 5001.\n",
      "Step: 3887 of 5001.\n",
      "Step: 3888 of 5001.\n",
      "Step: 3889 of 5001.\n",
      "Step: 3890 of 5001.\n",
      "Generator model loss: -1.86260986328125.\n",
      "Discriminator model loss: -0.34717053174972534.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3891 of 5001.\n",
      "Step: 3892 of 5001.\n",
      "Step: 3893 of 5001.\n",
      "Step: 3894 of 5001.\n",
      "Step: 3895 of 5001.\n",
      "Step: 3896 of 5001.\n",
      "Step: 3897 of 5001.\n",
      "Step: 3898 of 5001.\n",
      "Step: 3899 of 5001.\n",
      "Step: 3900 of 5001.\n",
      "Generator model loss: -1.7903687953948975.\n",
      "Discriminator model loss: -0.4831106662750244.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3901 of 5001.\n",
      "Step: 3902 of 5001.\n",
      "Step: 3903 of 5001.\n",
      "Step: 3904 of 5001.\n",
      "Step: 3905 of 5001.\n",
      "Step: 3906 of 5001.\n",
      "Step: 3907 of 5001.\n",
      "Step: 3908 of 5001.\n",
      "Step: 3909 of 5001.\n",
      "Step: 3910 of 5001.\n",
      "Generator model loss: -1.9097845554351807.\n",
      "Discriminator model loss: -0.4446335732936859.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 3911 of 5001.\n",
      "Step: 3912 of 5001.\n",
      "Step: 3913 of 5001.\n",
      "Step: 3914 of 5001.\n",
      "Step: 3915 of 5001.\n",
      "Step: 3916 of 5001.\n",
      "Step: 3917 of 5001.\n",
      "Step: 3918 of 5001.\n",
      "Step: 3919 of 5001.\n",
      "Step: 3920 of 5001.\n",
      "Generator model loss: -1.8572601079940796.\n",
      "Discriminator model loss: -0.39609044790267944.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3921 of 5001.\n",
      "Step: 3922 of 5001.\n",
      "Step: 3923 of 5001.\n",
      "Step: 3924 of 5001.\n",
      "Step: 3925 of 5001.\n",
      "Step: 3926 of 5001.\n",
      "Step: 3927 of 5001.\n",
      "Step: 3928 of 5001.\n",
      "Step: 3929 of 5001.\n",
      "Step: 3930 of 5001.\n",
      "Generator model loss: -1.816288948059082.\n",
      "Discriminator model loss: -0.38560137152671814.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3931 of 5001.\n",
      "Step: 3932 of 5001.\n",
      "Step: 3933 of 5001.\n",
      "Step: 3934 of 5001.\n",
      "Step: 3935 of 5001.\n",
      "Step: 3936 of 5001.\n",
      "Step: 3937 of 5001.\n",
      "Step: 3938 of 5001.\n",
      "Step: 3939 of 5001.\n",
      "Step: 3940 of 5001.\n",
      "Generator model loss: -1.8268429040908813.\n",
      "Discriminator model loss: -0.42474523186683655.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 3941 of 5001.\n",
      "Step: 3942 of 5001.\n",
      "Step: 3943 of 5001.\n",
      "Step: 3944 of 5001.\n",
      "Step: 3945 of 5001.\n",
      "Step: 3946 of 5001.\n",
      "Step: 3947 of 5001.\n",
      "Step: 3948 of 5001.\n",
      "Step: 3949 of 5001.\n",
      "Step: 3950 of 5001.\n",
      "Generator model loss: -1.8507797718048096.\n",
      "Discriminator model loss: -0.4175122380256653.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3951 of 5001.\n",
      "Step: 3952 of 5001.\n",
      "Step: 3953 of 5001.\n",
      "Step: 3954 of 5001.\n",
      "Step: 3955 of 5001.\n",
      "Step: 3956 of 5001.\n",
      "Step: 3957 of 5001.\n",
      "Step: 3958 of 5001.\n",
      "Step: 3959 of 5001.\n",
      "Step: 3960 of 5001.\n",
      "Generator model loss: -1.8531700372695923.\n",
      "Discriminator model loss: -0.4860309660434723.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3961 of 5001.\n",
      "Step: 3962 of 5001.\n",
      "Step: 3963 of 5001.\n",
      "Step: 3964 of 5001.\n",
      "Step: 3965 of 5001.\n",
      "Step: 3966 of 5001.\n",
      "Step: 3967 of 5001.\n",
      "Step: 3968 of 5001.\n",
      "Step: 3969 of 5001.\n",
      "Step: 3970 of 5001.\n",
      "Generator model loss: -1.909034013748169.\n",
      "Discriminator model loss: -0.3579195439815521.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 3971 of 5001.\n",
      "Step: 3972 of 5001.\n",
      "Step: 3973 of 5001.\n",
      "Step: 3974 of 5001.\n",
      "Step: 3975 of 5001.\n",
      "Step: 3976 of 5001.\n",
      "Step: 3977 of 5001.\n",
      "Step: 3978 of 5001.\n",
      "Step: 3979 of 5001.\n",
      "Step: 3980 of 5001.\n",
      "Generator model loss: -1.8648271560668945.\n",
      "Discriminator model loss: -0.3656090497970581.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 3981 of 5001.\n",
      "Step: 3982 of 5001.\n",
      "Step: 3983 of 5001.\n",
      "Step: 3984 of 5001.\n",
      "Step: 3985 of 5001.\n",
      "Step: 3986 of 5001.\n",
      "Step: 3987 of 5001.\n",
      "Step: 3988 of 5001.\n",
      "Step: 3989 of 5001.\n",
      "Step: 3990 of 5001.\n",
      "Generator model loss: -1.8996562957763672.\n",
      "Discriminator model loss: -0.37296175956726074.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 3991 of 5001.\n",
      "Step: 3992 of 5001.\n",
      "Step: 3993 of 5001.\n",
      "Step: 3994 of 5001.\n",
      "Step: 3995 of 5001.\n",
      "Step: 3996 of 5001.\n",
      "Step: 3997 of 5001.\n",
      "Step: 3998 of 5001.\n",
      "Step: 3999 of 5001.\n",
      "Step: 4000 of 5001.\n",
      "Generator model loss: -1.8118854761123657.\n",
      "Discriminator model loss: -0.4574773907661438.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4001 of 5001.\n",
      "Step: 4002 of 5001.\n",
      "Step: 4003 of 5001.\n",
      "Step: 4004 of 5001.\n",
      "Step: 4005 of 5001.\n",
      "Step: 4006 of 5001.\n",
      "Step: 4007 of 5001.\n",
      "Step: 4008 of 5001.\n",
      "Step: 4009 of 5001.\n",
      "Step: 4010 of 5001.\n",
      "Generator model loss: -1.886757493019104.\n",
      "Discriminator model loss: -0.3756927251815796.\n",
      "xgboost accuracy: 0.89\n",
      "Step: 4011 of 5001.\n",
      "Step: 4012 of 5001.\n",
      "Step: 4013 of 5001.\n",
      "Step: 4014 of 5001.\n",
      "Step: 4015 of 5001.\n",
      "Step: 4016 of 5001.\n",
      "Step: 4017 of 5001.\n",
      "Step: 4018 of 5001.\n",
      "Step: 4019 of 5001.\n",
      "Step: 4020 of 5001.\n",
      "Generator model loss: -1.8931443691253662.\n",
      "Discriminator model loss: -0.4180367588996887.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4021 of 5001.\n",
      "Step: 4022 of 5001.\n",
      "Step: 4023 of 5001.\n",
      "Step: 4024 of 5001.\n",
      "Step: 4025 of 5001.\n",
      "Step: 4026 of 5001.\n",
      "Step: 4027 of 5001.\n",
      "Step: 4028 of 5001.\n",
      "Step: 4029 of 5001.\n",
      "Step: 4030 of 5001.\n",
      "Generator model loss: -1.8707141876220703.\n",
      "Discriminator model loss: -0.44016924500465393.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4031 of 5001.\n",
      "Step: 4032 of 5001.\n",
      "Step: 4033 of 5001.\n",
      "Step: 4034 of 5001.\n",
      "Step: 4035 of 5001.\n",
      "Step: 4036 of 5001.\n",
      "Step: 4037 of 5001.\n",
      "Step: 4038 of 5001.\n",
      "Step: 4039 of 5001.\n",
      "Step: 4040 of 5001.\n",
      "Generator model loss: -1.8104814291000366.\n",
      "Discriminator model loss: -0.4246225357055664.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4041 of 5001.\n",
      "Step: 4042 of 5001.\n",
      "Step: 4043 of 5001.\n",
      "Step: 4044 of 5001.\n",
      "Step: 4045 of 5001.\n",
      "Step: 4046 of 5001.\n",
      "Step: 4047 of 5001.\n",
      "Step: 4048 of 5001.\n",
      "Step: 4049 of 5001.\n",
      "Step: 4050 of 5001.\n",
      "Generator model loss: -1.8202422857284546.\n",
      "Discriminator model loss: -0.48182329535484314.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4051 of 5001.\n",
      "Step: 4052 of 5001.\n",
      "Step: 4053 of 5001.\n",
      "Step: 4054 of 5001.\n",
      "Step: 4055 of 5001.\n",
      "Step: 4056 of 5001.\n",
      "Step: 4057 of 5001.\n",
      "Step: 4058 of 5001.\n",
      "Step: 4059 of 5001.\n",
      "Step: 4060 of 5001.\n",
      "Generator model loss: -1.8626258373260498.\n",
      "Discriminator model loss: -0.3502781391143799.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4061 of 5001.\n",
      "Step: 4062 of 5001.\n",
      "Step: 4063 of 5001.\n",
      "Step: 4064 of 5001.\n",
      "Step: 4065 of 5001.\n",
      "Step: 4066 of 5001.\n",
      "Step: 4067 of 5001.\n",
      "Step: 4068 of 5001.\n",
      "Step: 4069 of 5001.\n",
      "Step: 4070 of 5001.\n",
      "Generator model loss: -1.8285999298095703.\n",
      "Discriminator model loss: -0.43503791093826294.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4071 of 5001.\n",
      "Step: 4072 of 5001.\n",
      "Step: 4073 of 5001.\n",
      "Step: 4074 of 5001.\n",
      "Step: 4075 of 5001.\n",
      "Step: 4076 of 5001.\n",
      "Step: 4077 of 5001.\n",
      "Step: 4078 of 5001.\n",
      "Step: 4079 of 5001.\n",
      "Step: 4080 of 5001.\n",
      "Generator model loss: -1.8782141208648682.\n",
      "Discriminator model loss: -0.41524043679237366.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4081 of 5001.\n",
      "Step: 4082 of 5001.\n",
      "Step: 4083 of 5001.\n",
      "Step: 4084 of 5001.\n",
      "Step: 4085 of 5001.\n",
      "Step: 4086 of 5001.\n",
      "Step: 4087 of 5001.\n",
      "Step: 4088 of 5001.\n",
      "Step: 4089 of 5001.\n",
      "Step: 4090 of 5001.\n",
      "Generator model loss: -1.8787351846694946.\n",
      "Discriminator model loss: -0.35050463676452637.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4091 of 5001.\n",
      "Step: 4092 of 5001.\n",
      "Step: 4093 of 5001.\n",
      "Step: 4094 of 5001.\n",
      "Step: 4095 of 5001.\n",
      "Step: 4096 of 5001.\n",
      "Step: 4097 of 5001.\n",
      "Step: 4098 of 5001.\n",
      "Step: 4099 of 5001.\n",
      "Step: 4100 of 5001.\n",
      "Generator model loss: -1.829764723777771.\n",
      "Discriminator model loss: -0.33842283487319946.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4101 of 5001.\n",
      "Step: 4102 of 5001.\n",
      "Step: 4103 of 5001.\n",
      "Step: 4104 of 5001.\n",
      "Step: 4105 of 5001.\n",
      "Step: 4106 of 5001.\n",
      "Step: 4107 of 5001.\n",
      "Step: 4108 of 5001.\n",
      "Step: 4109 of 5001.\n",
      "Step: 4110 of 5001.\n",
      "Generator model loss: -1.835785150527954.\n",
      "Discriminator model loss: -0.3149821162223816.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4111 of 5001.\n",
      "Step: 4112 of 5001.\n",
      "Step: 4113 of 5001.\n",
      "Step: 4114 of 5001.\n",
      "Step: 4115 of 5001.\n",
      "Step: 4116 of 5001.\n",
      "Step: 4117 of 5001.\n",
      "Step: 4118 of 5001.\n",
      "Step: 4119 of 5001.\n",
      "Step: 4120 of 5001.\n",
      "Generator model loss: -1.866140365600586.\n",
      "Discriminator model loss: -0.39019063115119934.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4121 of 5001.\n",
      "Step: 4122 of 5001.\n",
      "Step: 4123 of 5001.\n",
      "Step: 4124 of 5001.\n",
      "Step: 4125 of 5001.\n",
      "Step: 4126 of 5001.\n",
      "Step: 4127 of 5001.\n",
      "Step: 4128 of 5001.\n",
      "Step: 4129 of 5001.\n",
      "Step: 4130 of 5001.\n",
      "Generator model loss: -1.8524099588394165.\n",
      "Discriminator model loss: -0.48169833421707153.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4131 of 5001.\n",
      "Step: 4132 of 5001.\n",
      "Step: 4133 of 5001.\n",
      "Step: 4134 of 5001.\n",
      "Step: 4135 of 5001.\n",
      "Step: 4136 of 5001.\n",
      "Step: 4137 of 5001.\n",
      "Step: 4138 of 5001.\n",
      "Step: 4139 of 5001.\n",
      "Step: 4140 of 5001.\n",
      "Generator model loss: -1.8685119152069092.\n",
      "Discriminator model loss: -0.4794994294643402.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4141 of 5001.\n",
      "Step: 4142 of 5001.\n",
      "Step: 4143 of 5001.\n",
      "Step: 4144 of 5001.\n",
      "Step: 4145 of 5001.\n",
      "Step: 4146 of 5001.\n",
      "Step: 4147 of 5001.\n",
      "Step: 4148 of 5001.\n",
      "Step: 4149 of 5001.\n",
      "Step: 4150 of 5001.\n",
      "Generator model loss: -1.9127193689346313.\n",
      "Discriminator model loss: -0.4673641324043274.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4151 of 5001.\n",
      "Step: 4152 of 5001.\n",
      "Step: 4153 of 5001.\n",
      "Step: 4154 of 5001.\n",
      "Step: 4155 of 5001.\n",
      "Step: 4156 of 5001.\n",
      "Step: 4157 of 5001.\n",
      "Step: 4158 of 5001.\n",
      "Step: 4159 of 5001.\n",
      "Step: 4160 of 5001.\n",
      "Generator model loss: -1.8994554281234741.\n",
      "Discriminator model loss: -0.3471682071685791.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4161 of 5001.\n",
      "Step: 4162 of 5001.\n",
      "Step: 4163 of 5001.\n",
      "Step: 4164 of 5001.\n",
      "Step: 4165 of 5001.\n",
      "Step: 4166 of 5001.\n",
      "Step: 4167 of 5001.\n",
      "Step: 4168 of 5001.\n",
      "Step: 4169 of 5001.\n",
      "Step: 4170 of 5001.\n",
      "Generator model loss: -1.8579190969467163.\n",
      "Discriminator model loss: -0.3597799837589264.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4171 of 5001.\n",
      "Step: 4172 of 5001.\n",
      "Step: 4173 of 5001.\n",
      "Step: 4174 of 5001.\n",
      "Step: 4175 of 5001.\n",
      "Step: 4176 of 5001.\n",
      "Step: 4177 of 5001.\n",
      "Step: 4178 of 5001.\n",
      "Step: 4179 of 5001.\n",
      "Step: 4180 of 5001.\n",
      "Generator model loss: -1.906304955482483.\n",
      "Discriminator model loss: -0.3162756562232971.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4181 of 5001.\n",
      "Step: 4182 of 5001.\n",
      "Step: 4183 of 5001.\n",
      "Step: 4184 of 5001.\n",
      "Step: 4185 of 5001.\n",
      "Step: 4186 of 5001.\n",
      "Step: 4187 of 5001.\n",
      "Step: 4188 of 5001.\n",
      "Step: 4189 of 5001.\n",
      "Step: 4190 of 5001.\n",
      "Generator model loss: -1.898695707321167.\n",
      "Discriminator model loss: -0.3610169589519501.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4191 of 5001.\n",
      "Step: 4192 of 5001.\n",
      "Step: 4193 of 5001.\n",
      "Step: 4194 of 5001.\n",
      "Step: 4195 of 5001.\n",
      "Step: 4196 of 5001.\n",
      "Step: 4197 of 5001.\n",
      "Step: 4198 of 5001.\n",
      "Step: 4199 of 5001.\n",
      "Step: 4200 of 5001.\n",
      "Generator model loss: -1.952515959739685.\n",
      "Discriminator model loss: -0.40703409910202026.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4201 of 5001.\n",
      "Step: 4202 of 5001.\n",
      "Step: 4203 of 5001.\n",
      "Step: 4204 of 5001.\n",
      "Step: 4205 of 5001.\n",
      "Step: 4206 of 5001.\n",
      "Step: 4207 of 5001.\n",
      "Step: 4208 of 5001.\n",
      "Step: 4209 of 5001.\n",
      "Step: 4210 of 5001.\n",
      "Generator model loss: -1.9200977087020874.\n",
      "Discriminator model loss: -0.42046990990638733.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4211 of 5001.\n",
      "Step: 4212 of 5001.\n",
      "Step: 4213 of 5001.\n",
      "Step: 4214 of 5001.\n",
      "Step: 4215 of 5001.\n",
      "Step: 4216 of 5001.\n",
      "Step: 4217 of 5001.\n",
      "Step: 4218 of 5001.\n",
      "Step: 4219 of 5001.\n",
      "Step: 4220 of 5001.\n",
      "Generator model loss: -1.8987891674041748.\n",
      "Discriminator model loss: -0.4216361939907074.\n",
      "xgboost accuracy: 0.75\n",
      "Step: 4221 of 5001.\n",
      "Step: 4222 of 5001.\n",
      "Step: 4223 of 5001.\n",
      "Step: 4224 of 5001.\n",
      "Step: 4225 of 5001.\n",
      "Step: 4226 of 5001.\n",
      "Step: 4227 of 5001.\n",
      "Step: 4228 of 5001.\n",
      "Step: 4229 of 5001.\n",
      "Step: 4230 of 5001.\n",
      "Generator model loss: -1.9023761749267578.\n",
      "Discriminator model loss: -0.3346337676048279.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4231 of 5001.\n",
      "Step: 4232 of 5001.\n",
      "Step: 4233 of 5001.\n",
      "Step: 4234 of 5001.\n",
      "Step: 4235 of 5001.\n",
      "Step: 4236 of 5001.\n",
      "Step: 4237 of 5001.\n",
      "Step: 4238 of 5001.\n",
      "Step: 4239 of 5001.\n",
      "Step: 4240 of 5001.\n",
      "Generator model loss: -1.9144880771636963.\n",
      "Discriminator model loss: -0.4229569435119629.\n",
      "xgboost accuracy: 0.90\n",
      "Step: 4241 of 5001.\n",
      "Step: 4242 of 5001.\n",
      "Step: 4243 of 5001.\n",
      "Step: 4244 of 5001.\n",
      "Step: 4245 of 5001.\n",
      "Step: 4246 of 5001.\n",
      "Step: 4247 of 5001.\n",
      "Step: 4248 of 5001.\n",
      "Step: 4249 of 5001.\n",
      "Step: 4250 of 5001.\n",
      "Generator model loss: -1.8639466762542725.\n",
      "Discriminator model loss: -0.33807557821273804.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4251 of 5001.\n",
      "Step: 4252 of 5001.\n",
      "Step: 4253 of 5001.\n",
      "Step: 4254 of 5001.\n",
      "Step: 4255 of 5001.\n",
      "Step: 4256 of 5001.\n",
      "Step: 4257 of 5001.\n",
      "Step: 4258 of 5001.\n",
      "Step: 4259 of 5001.\n",
      "Step: 4260 of 5001.\n",
      "Generator model loss: -1.90325129032135.\n",
      "Discriminator model loss: -0.41045302152633667.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4261 of 5001.\n",
      "Step: 4262 of 5001.\n",
      "Step: 4263 of 5001.\n",
      "Step: 4264 of 5001.\n",
      "Step: 4265 of 5001.\n",
      "Step: 4266 of 5001.\n",
      "Step: 4267 of 5001.\n",
      "Step: 4268 of 5001.\n",
      "Step: 4269 of 5001.\n",
      "Step: 4270 of 5001.\n",
      "Generator model loss: -1.8369003534317017.\n",
      "Discriminator model loss: -0.4217435419559479.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4271 of 5001.\n",
      "Step: 4272 of 5001.\n",
      "Step: 4273 of 5001.\n",
      "Step: 4274 of 5001.\n",
      "Step: 4275 of 5001.\n",
      "Step: 4276 of 5001.\n",
      "Step: 4277 of 5001.\n",
      "Step: 4278 of 5001.\n",
      "Step: 4279 of 5001.\n",
      "Step: 4280 of 5001.\n",
      "Generator model loss: -1.828404188156128.\n",
      "Discriminator model loss: -0.36866495013237.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 4281 of 5001.\n",
      "Step: 4282 of 5001.\n",
      "Step: 4283 of 5001.\n",
      "Step: 4284 of 5001.\n",
      "Step: 4285 of 5001.\n",
      "Step: 4286 of 5001.\n",
      "Step: 4287 of 5001.\n",
      "Step: 4288 of 5001.\n",
      "Step: 4289 of 5001.\n",
      "Step: 4290 of 5001.\n",
      "Generator model loss: -1.8429819345474243.\n",
      "Discriminator model loss: -0.40120458602905273.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4291 of 5001.\n",
      "Step: 4292 of 5001.\n",
      "Step: 4293 of 5001.\n",
      "Step: 4294 of 5001.\n",
      "Step: 4295 of 5001.\n",
      "Step: 4296 of 5001.\n",
      "Step: 4297 of 5001.\n",
      "Step: 4298 of 5001.\n",
      "Step: 4299 of 5001.\n",
      "Step: 4300 of 5001.\n",
      "Generator model loss: -1.8509881496429443.\n",
      "Discriminator model loss: -0.4073341488838196.\n",
      "xgboost accuracy: 0.87\n",
      "Step: 4301 of 5001.\n",
      "Step: 4302 of 5001.\n",
      "Step: 4303 of 5001.\n",
      "Step: 4304 of 5001.\n",
      "Step: 4305 of 5001.\n",
      "Step: 4306 of 5001.\n",
      "Step: 4307 of 5001.\n",
      "Step: 4308 of 5001.\n",
      "Step: 4309 of 5001.\n",
      "Step: 4310 of 5001.\n",
      "Generator model loss: -1.7956876754760742.\n",
      "Discriminator model loss: -0.5034138560295105.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4311 of 5001.\n",
      "Step: 4312 of 5001.\n",
      "Step: 4313 of 5001.\n",
      "Step: 4314 of 5001.\n",
      "Step: 4315 of 5001.\n",
      "Step: 4316 of 5001.\n",
      "Step: 4317 of 5001.\n",
      "Step: 4318 of 5001.\n",
      "Step: 4319 of 5001.\n",
      "Step: 4320 of 5001.\n",
      "Generator model loss: -1.9188305139541626.\n",
      "Discriminator model loss: -0.45815879106521606.\n",
      "xgboost accuracy: 0.88\n",
      "Step: 4321 of 5001.\n",
      "Step: 4322 of 5001.\n",
      "Step: 4323 of 5001.\n",
      "Step: 4324 of 5001.\n",
      "Step: 4325 of 5001.\n",
      "Step: 4326 of 5001.\n",
      "Step: 4327 of 5001.\n",
      "Step: 4328 of 5001.\n",
      "Step: 4329 of 5001.\n",
      "Step: 4330 of 5001.\n",
      "Generator model loss: -1.8811542987823486.\n",
      "Discriminator model loss: -0.4789063036441803.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4331 of 5001.\n",
      "Step: 4332 of 5001.\n",
      "Step: 4333 of 5001.\n",
      "Step: 4334 of 5001.\n",
      "Step: 4335 of 5001.\n",
      "Step: 4336 of 5001.\n",
      "Step: 4337 of 5001.\n",
      "Step: 4338 of 5001.\n",
      "Step: 4339 of 5001.\n",
      "Step: 4340 of 5001.\n",
      "Generator model loss: -1.9125490188598633.\n",
      "Discriminator model loss: -0.420423686504364.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4341 of 5001.\n",
      "Step: 4342 of 5001.\n",
      "Step: 4343 of 5001.\n",
      "Step: 4344 of 5001.\n",
      "Step: 4345 of 5001.\n",
      "Step: 4346 of 5001.\n",
      "Step: 4347 of 5001.\n",
      "Step: 4348 of 5001.\n",
      "Step: 4349 of 5001.\n",
      "Step: 4350 of 5001.\n",
      "Generator model loss: -1.876137375831604.\n",
      "Discriminator model loss: -0.34071221947669983.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4351 of 5001.\n",
      "Step: 4352 of 5001.\n",
      "Step: 4353 of 5001.\n",
      "Step: 4354 of 5001.\n",
      "Step: 4355 of 5001.\n",
      "Step: 4356 of 5001.\n",
      "Step: 4357 of 5001.\n",
      "Step: 4358 of 5001.\n",
      "Step: 4359 of 5001.\n",
      "Step: 4360 of 5001.\n",
      "Generator model loss: -1.8072996139526367.\n",
      "Discriminator model loss: -0.33178988099098206.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4361 of 5001.\n",
      "Step: 4362 of 5001.\n",
      "Step: 4363 of 5001.\n",
      "Step: 4364 of 5001.\n",
      "Step: 4365 of 5001.\n",
      "Step: 4366 of 5001.\n",
      "Step: 4367 of 5001.\n",
      "Step: 4368 of 5001.\n",
      "Step: 4369 of 5001.\n",
      "Step: 4370 of 5001.\n",
      "Generator model loss: -1.8432962894439697.\n",
      "Discriminator model loss: -0.3927668333053589.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4371 of 5001.\n",
      "Step: 4372 of 5001.\n",
      "Step: 4373 of 5001.\n",
      "Step: 4374 of 5001.\n",
      "Step: 4375 of 5001.\n",
      "Step: 4376 of 5001.\n",
      "Step: 4377 of 5001.\n",
      "Step: 4378 of 5001.\n",
      "Step: 4379 of 5001.\n",
      "Step: 4380 of 5001.\n",
      "Generator model loss: -1.8038727045059204.\n",
      "Discriminator model loss: -0.3595874607563019.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 4381 of 5001.\n",
      "Step: 4382 of 5001.\n",
      "Step: 4383 of 5001.\n",
      "Step: 4384 of 5001.\n",
      "Step: 4385 of 5001.\n",
      "Step: 4386 of 5001.\n",
      "Step: 4387 of 5001.\n",
      "Step: 4388 of 5001.\n",
      "Step: 4389 of 5001.\n",
      "Step: 4390 of 5001.\n",
      "Generator model loss: -1.9100538492202759.\n",
      "Discriminator model loss: -0.39315953850746155.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4391 of 5001.\n",
      "Step: 4392 of 5001.\n",
      "Step: 4393 of 5001.\n",
      "Step: 4394 of 5001.\n",
      "Step: 4395 of 5001.\n",
      "Step: 4396 of 5001.\n",
      "Step: 4397 of 5001.\n",
      "Step: 4398 of 5001.\n",
      "Step: 4399 of 5001.\n",
      "Step: 4400 of 5001.\n",
      "Generator model loss: -1.8649049997329712.\n",
      "Discriminator model loss: -0.4135642945766449.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4401 of 5001.\n",
      "Step: 4402 of 5001.\n",
      "Step: 4403 of 5001.\n",
      "Step: 4404 of 5001.\n",
      "Step: 4405 of 5001.\n",
      "Step: 4406 of 5001.\n",
      "Step: 4407 of 5001.\n",
      "Step: 4408 of 5001.\n",
      "Step: 4409 of 5001.\n",
      "Step: 4410 of 5001.\n",
      "Generator model loss: -1.8870340585708618.\n",
      "Discriminator model loss: -0.4156835675239563.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4411 of 5001.\n",
      "Step: 4412 of 5001.\n",
      "Step: 4413 of 5001.\n",
      "Step: 4414 of 5001.\n",
      "Step: 4415 of 5001.\n",
      "Step: 4416 of 5001.\n",
      "Step: 4417 of 5001.\n",
      "Step: 4418 of 5001.\n",
      "Step: 4419 of 5001.\n",
      "Step: 4420 of 5001.\n",
      "Generator model loss: -1.8262630701065063.\n",
      "Discriminator model loss: -0.34703630208969116.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4421 of 5001.\n",
      "Step: 4422 of 5001.\n",
      "Step: 4423 of 5001.\n",
      "Step: 4424 of 5001.\n",
      "Step: 4425 of 5001.\n",
      "Step: 4426 of 5001.\n",
      "Step: 4427 of 5001.\n",
      "Step: 4428 of 5001.\n",
      "Step: 4429 of 5001.\n",
      "Step: 4430 of 5001.\n",
      "Generator model loss: -1.9015090465545654.\n",
      "Discriminator model loss: -0.4117988049983978.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4431 of 5001.\n",
      "Step: 4432 of 5001.\n",
      "Step: 4433 of 5001.\n",
      "Step: 4434 of 5001.\n",
      "Step: 4435 of 5001.\n",
      "Step: 4436 of 5001.\n",
      "Step: 4437 of 5001.\n",
      "Step: 4438 of 5001.\n",
      "Step: 4439 of 5001.\n",
      "Step: 4440 of 5001.\n",
      "Generator model loss: -1.9225835800170898.\n",
      "Discriminator model loss: -0.3660382330417633.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4441 of 5001.\n",
      "Step: 4442 of 5001.\n",
      "Step: 4443 of 5001.\n",
      "Step: 4444 of 5001.\n",
      "Step: 4445 of 5001.\n",
      "Step: 4446 of 5001.\n",
      "Step: 4447 of 5001.\n",
      "Step: 4448 of 5001.\n",
      "Step: 4449 of 5001.\n",
      "Step: 4450 of 5001.\n",
      "Generator model loss: -1.8537111282348633.\n",
      "Discriminator model loss: -0.35466572642326355.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4451 of 5001.\n",
      "Step: 4452 of 5001.\n",
      "Step: 4453 of 5001.\n",
      "Step: 4454 of 5001.\n",
      "Step: 4455 of 5001.\n",
      "Step: 4456 of 5001.\n",
      "Step: 4457 of 5001.\n",
      "Step: 4458 of 5001.\n",
      "Step: 4459 of 5001.\n",
      "Step: 4460 of 5001.\n",
      "Generator model loss: -1.8996769189834595.\n",
      "Discriminator model loss: -0.40123552083969116.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4461 of 5001.\n",
      "Step: 4462 of 5001.\n",
      "Step: 4463 of 5001.\n",
      "Step: 4464 of 5001.\n",
      "Step: 4465 of 5001.\n",
      "Step: 4466 of 5001.\n",
      "Step: 4467 of 5001.\n",
      "Step: 4468 of 5001.\n",
      "Step: 4469 of 5001.\n",
      "Step: 4470 of 5001.\n",
      "Generator model loss: -1.8968836069107056.\n",
      "Discriminator model loss: -0.2935757040977478.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 4471 of 5001.\n",
      "Step: 4472 of 5001.\n",
      "Step: 4473 of 5001.\n",
      "Step: 4474 of 5001.\n",
      "Step: 4475 of 5001.\n",
      "Step: 4476 of 5001.\n",
      "Step: 4477 of 5001.\n",
      "Step: 4478 of 5001.\n",
      "Step: 4479 of 5001.\n",
      "Step: 4480 of 5001.\n",
      "Generator model loss: -1.868958830833435.\n",
      "Discriminator model loss: -0.42422834038734436.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4481 of 5001.\n",
      "Step: 4482 of 5001.\n",
      "Step: 4483 of 5001.\n",
      "Step: 4484 of 5001.\n",
      "Step: 4485 of 5001.\n",
      "Step: 4486 of 5001.\n",
      "Step: 4487 of 5001.\n",
      "Step: 4488 of 5001.\n",
      "Step: 4489 of 5001.\n",
      "Step: 4490 of 5001.\n",
      "Generator model loss: -1.8498165607452393.\n",
      "Discriminator model loss: -0.39019575715065.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4491 of 5001.\n",
      "Step: 4492 of 5001.\n",
      "Step: 4493 of 5001.\n",
      "Step: 4494 of 5001.\n",
      "Step: 4495 of 5001.\n",
      "Step: 4496 of 5001.\n",
      "Step: 4497 of 5001.\n",
      "Step: 4498 of 5001.\n",
      "Step: 4499 of 5001.\n",
      "Step: 4500 of 5001.\n",
      "Generator model loss: -1.9310214519500732.\n",
      "Discriminator model loss: -0.4294108748435974.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4501 of 5001.\n",
      "Step: 4502 of 5001.\n",
      "Step: 4503 of 5001.\n",
      "Step: 4504 of 5001.\n",
      "Step: 4505 of 5001.\n",
      "Step: 4506 of 5001.\n",
      "Step: 4507 of 5001.\n",
      "Step: 4508 of 5001.\n",
      "Step: 4509 of 5001.\n",
      "Step: 4510 of 5001.\n",
      "Generator model loss: -1.8943560123443604.\n",
      "Discriminator model loss: -0.3482239842414856.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4511 of 5001.\n",
      "Step: 4512 of 5001.\n",
      "Step: 4513 of 5001.\n",
      "Step: 4514 of 5001.\n",
      "Step: 4515 of 5001.\n",
      "Step: 4516 of 5001.\n",
      "Step: 4517 of 5001.\n",
      "Step: 4518 of 5001.\n",
      "Step: 4519 of 5001.\n",
      "Step: 4520 of 5001.\n",
      "Generator model loss: -1.8624767065048218.\n",
      "Discriminator model loss: -0.3358885645866394.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4521 of 5001.\n",
      "Step: 4522 of 5001.\n",
      "Step: 4523 of 5001.\n",
      "Step: 4524 of 5001.\n",
      "Step: 4525 of 5001.\n",
      "Step: 4526 of 5001.\n",
      "Step: 4527 of 5001.\n",
      "Step: 4528 of 5001.\n",
      "Step: 4529 of 5001.\n",
      "Step: 4530 of 5001.\n",
      "Generator model loss: -1.9258304834365845.\n",
      "Discriminator model loss: -0.31149426102638245.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4531 of 5001.\n",
      "Step: 4532 of 5001.\n",
      "Step: 4533 of 5001.\n",
      "Step: 4534 of 5001.\n",
      "Step: 4535 of 5001.\n",
      "Step: 4536 of 5001.\n",
      "Step: 4537 of 5001.\n",
      "Step: 4538 of 5001.\n",
      "Step: 4539 of 5001.\n",
      "Step: 4540 of 5001.\n",
      "Generator model loss: -1.9356396198272705.\n",
      "Discriminator model loss: -0.48232442140579224.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4541 of 5001.\n",
      "Step: 4542 of 5001.\n",
      "Step: 4543 of 5001.\n",
      "Step: 4544 of 5001.\n",
      "Step: 4545 of 5001.\n",
      "Step: 4546 of 5001.\n",
      "Step: 4547 of 5001.\n",
      "Step: 4548 of 5001.\n",
      "Step: 4549 of 5001.\n",
      "Step: 4550 of 5001.\n",
      "Generator model loss: -1.8983075618743896.\n",
      "Discriminator model loss: -0.38611701130867004.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4551 of 5001.\n",
      "Step: 4552 of 5001.\n",
      "Step: 4553 of 5001.\n",
      "Step: 4554 of 5001.\n",
      "Step: 4555 of 5001.\n",
      "Step: 4556 of 5001.\n",
      "Step: 4557 of 5001.\n",
      "Step: 4558 of 5001.\n",
      "Step: 4559 of 5001.\n",
      "Step: 4560 of 5001.\n",
      "Generator model loss: -1.9010556936264038.\n",
      "Discriminator model loss: -0.362247109413147.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4561 of 5001.\n",
      "Step: 4562 of 5001.\n",
      "Step: 4563 of 5001.\n",
      "Step: 4564 of 5001.\n",
      "Step: 4565 of 5001.\n",
      "Step: 4566 of 5001.\n",
      "Step: 4567 of 5001.\n",
      "Step: 4568 of 5001.\n",
      "Step: 4569 of 5001.\n",
      "Step: 4570 of 5001.\n",
      "Generator model loss: -1.8916994333267212.\n",
      "Discriminator model loss: -0.4084828495979309.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4571 of 5001.\n",
      "Step: 4572 of 5001.\n",
      "Step: 4573 of 5001.\n",
      "Step: 4574 of 5001.\n",
      "Step: 4575 of 5001.\n",
      "Step: 4576 of 5001.\n",
      "Step: 4577 of 5001.\n",
      "Step: 4578 of 5001.\n",
      "Step: 4579 of 5001.\n",
      "Step: 4580 of 5001.\n",
      "Generator model loss: -1.895054817199707.\n",
      "Discriminator model loss: -0.27491381764411926.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4581 of 5001.\n",
      "Step: 4582 of 5001.\n",
      "Step: 4583 of 5001.\n",
      "Step: 4584 of 5001.\n",
      "Step: 4585 of 5001.\n",
      "Step: 4586 of 5001.\n",
      "Step: 4587 of 5001.\n",
      "Step: 4588 of 5001.\n",
      "Step: 4589 of 5001.\n",
      "Step: 4590 of 5001.\n",
      "Generator model loss: -1.9042799472808838.\n",
      "Discriminator model loss: -0.4001447558403015.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4591 of 5001.\n",
      "Step: 4592 of 5001.\n",
      "Step: 4593 of 5001.\n",
      "Step: 4594 of 5001.\n",
      "Step: 4595 of 5001.\n",
      "Step: 4596 of 5001.\n",
      "Step: 4597 of 5001.\n",
      "Step: 4598 of 5001.\n",
      "Step: 4599 of 5001.\n",
      "Step: 4600 of 5001.\n",
      "Generator model loss: -1.9823347330093384.\n",
      "Discriminator model loss: -0.31721198558807373.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4601 of 5001.\n",
      "Step: 4602 of 5001.\n",
      "Step: 4603 of 5001.\n",
      "Step: 4604 of 5001.\n",
      "Step: 4605 of 5001.\n",
      "Step: 4606 of 5001.\n",
      "Step: 4607 of 5001.\n",
      "Step: 4608 of 5001.\n",
      "Step: 4609 of 5001.\n",
      "Step: 4610 of 5001.\n",
      "Generator model loss: -1.9138879776000977.\n",
      "Discriminator model loss: -0.35227546095848083.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4611 of 5001.\n",
      "Step: 4612 of 5001.\n",
      "Step: 4613 of 5001.\n",
      "Step: 4614 of 5001.\n",
      "Step: 4615 of 5001.\n",
      "Step: 4616 of 5001.\n",
      "Step: 4617 of 5001.\n",
      "Step: 4618 of 5001.\n",
      "Step: 4619 of 5001.\n",
      "Step: 4620 of 5001.\n",
      "Generator model loss: -1.939599633216858.\n",
      "Discriminator model loss: -0.3300635516643524.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4621 of 5001.\n",
      "Step: 4622 of 5001.\n",
      "Step: 4623 of 5001.\n",
      "Step: 4624 of 5001.\n",
      "Step: 4625 of 5001.\n",
      "Step: 4626 of 5001.\n",
      "Step: 4627 of 5001.\n",
      "Step: 4628 of 5001.\n",
      "Step: 4629 of 5001.\n",
      "Step: 4630 of 5001.\n",
      "Generator model loss: -1.9342501163482666.\n",
      "Discriminator model loss: -0.2568167746067047.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4631 of 5001.\n",
      "Step: 4632 of 5001.\n",
      "Step: 4633 of 5001.\n",
      "Step: 4634 of 5001.\n",
      "Step: 4635 of 5001.\n",
      "Step: 4636 of 5001.\n",
      "Step: 4637 of 5001.\n",
      "Step: 4638 of 5001.\n",
      "Step: 4639 of 5001.\n",
      "Step: 4640 of 5001.\n",
      "Generator model loss: -1.9066028594970703.\n",
      "Discriminator model loss: -0.39649221301078796.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4641 of 5001.\n",
      "Step: 4642 of 5001.\n",
      "Step: 4643 of 5001.\n",
      "Step: 4644 of 5001.\n",
      "Step: 4645 of 5001.\n",
      "Step: 4646 of 5001.\n",
      "Step: 4647 of 5001.\n",
      "Step: 4648 of 5001.\n",
      "Step: 4649 of 5001.\n",
      "Step: 4650 of 5001.\n",
      "Generator model loss: -1.9326064586639404.\n",
      "Discriminator model loss: -0.25134992599487305.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4651 of 5001.\n",
      "Step: 4652 of 5001.\n",
      "Step: 4653 of 5001.\n",
      "Step: 4654 of 5001.\n",
      "Step: 4655 of 5001.\n",
      "Step: 4656 of 5001.\n",
      "Step: 4657 of 5001.\n",
      "Step: 4658 of 5001.\n",
      "Step: 4659 of 5001.\n",
      "Step: 4660 of 5001.\n",
      "Generator model loss: -1.9099889993667603.\n",
      "Discriminator model loss: -0.34620773792266846.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4661 of 5001.\n",
      "Step: 4662 of 5001.\n",
      "Step: 4663 of 5001.\n",
      "Step: 4664 of 5001.\n",
      "Step: 4665 of 5001.\n",
      "Step: 4666 of 5001.\n",
      "Step: 4667 of 5001.\n",
      "Step: 4668 of 5001.\n",
      "Step: 4669 of 5001.\n",
      "Step: 4670 of 5001.\n",
      "Generator model loss: -1.8952842950820923.\n",
      "Discriminator model loss: -0.4219394624233246.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4671 of 5001.\n",
      "Step: 4672 of 5001.\n",
      "Step: 4673 of 5001.\n",
      "Step: 4674 of 5001.\n",
      "Step: 4675 of 5001.\n",
      "Step: 4676 of 5001.\n",
      "Step: 4677 of 5001.\n",
      "Step: 4678 of 5001.\n",
      "Step: 4679 of 5001.\n",
      "Step: 4680 of 5001.\n",
      "Generator model loss: -1.9571113586425781.\n",
      "Discriminator model loss: -0.34716421365737915.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4681 of 5001.\n",
      "Step: 4682 of 5001.\n",
      "Step: 4683 of 5001.\n",
      "Step: 4684 of 5001.\n",
      "Step: 4685 of 5001.\n",
      "Step: 4686 of 5001.\n",
      "Step: 4687 of 5001.\n",
      "Step: 4688 of 5001.\n",
      "Step: 4689 of 5001.\n",
      "Step: 4690 of 5001.\n",
      "Generator model loss: -1.9182898998260498.\n",
      "Discriminator model loss: -0.3663552403450012.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4691 of 5001.\n",
      "Step: 4692 of 5001.\n",
      "Step: 4693 of 5001.\n",
      "Step: 4694 of 5001.\n",
      "Step: 4695 of 5001.\n",
      "Step: 4696 of 5001.\n",
      "Step: 4697 of 5001.\n",
      "Step: 4698 of 5001.\n",
      "Step: 4699 of 5001.\n",
      "Step: 4700 of 5001.\n",
      "Generator model loss: -1.9054410457611084.\n",
      "Discriminator model loss: -0.38005560636520386.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4701 of 5001.\n",
      "Step: 4702 of 5001.\n",
      "Step: 4703 of 5001.\n",
      "Step: 4704 of 5001.\n",
      "Step: 4705 of 5001.\n",
      "Step: 4706 of 5001.\n",
      "Step: 4707 of 5001.\n",
      "Step: 4708 of 5001.\n",
      "Step: 4709 of 5001.\n",
      "Step: 4710 of 5001.\n",
      "Generator model loss: -1.972435712814331.\n",
      "Discriminator model loss: -0.3838486969470978.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4711 of 5001.\n",
      "Step: 4712 of 5001.\n",
      "Step: 4713 of 5001.\n",
      "Step: 4714 of 5001.\n",
      "Step: 4715 of 5001.\n",
      "Step: 4716 of 5001.\n",
      "Step: 4717 of 5001.\n",
      "Step: 4718 of 5001.\n",
      "Step: 4719 of 5001.\n",
      "Step: 4720 of 5001.\n",
      "Generator model loss: -1.9241483211517334.\n",
      "Discriminator model loss: -0.45000725984573364.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4721 of 5001.\n",
      "Step: 4722 of 5001.\n",
      "Step: 4723 of 5001.\n",
      "Step: 4724 of 5001.\n",
      "Step: 4725 of 5001.\n",
      "Step: 4726 of 5001.\n",
      "Step: 4727 of 5001.\n",
      "Step: 4728 of 5001.\n",
      "Step: 4729 of 5001.\n",
      "Step: 4730 of 5001.\n",
      "Generator model loss: -1.8548133373260498.\n",
      "Discriminator model loss: -0.3834887146949768.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4731 of 5001.\n",
      "Step: 4732 of 5001.\n",
      "Step: 4733 of 5001.\n",
      "Step: 4734 of 5001.\n",
      "Step: 4735 of 5001.\n",
      "Step: 4736 of 5001.\n",
      "Step: 4737 of 5001.\n",
      "Step: 4738 of 5001.\n",
      "Step: 4739 of 5001.\n",
      "Step: 4740 of 5001.\n",
      "Generator model loss: -1.930624008178711.\n",
      "Discriminator model loss: -0.33254992961883545.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4741 of 5001.\n",
      "Step: 4742 of 5001.\n",
      "Step: 4743 of 5001.\n",
      "Step: 4744 of 5001.\n",
      "Step: 4745 of 5001.\n",
      "Step: 4746 of 5001.\n",
      "Step: 4747 of 5001.\n",
      "Step: 4748 of 5001.\n",
      "Step: 4749 of 5001.\n",
      "Step: 4750 of 5001.\n",
      "Generator model loss: -1.9145288467407227.\n",
      "Discriminator model loss: -0.36976101994514465.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4751 of 5001.\n",
      "Step: 4752 of 5001.\n",
      "Step: 4753 of 5001.\n",
      "Step: 4754 of 5001.\n",
      "Step: 4755 of 5001.\n",
      "Step: 4756 of 5001.\n",
      "Step: 4757 of 5001.\n",
      "Step: 4758 of 5001.\n",
      "Step: 4759 of 5001.\n",
      "Step: 4760 of 5001.\n",
      "Generator model loss: -1.841261625289917.\n",
      "Discriminator model loss: -0.31387653946876526.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4761 of 5001.\n",
      "Step: 4762 of 5001.\n",
      "Step: 4763 of 5001.\n",
      "Step: 4764 of 5001.\n",
      "Step: 4765 of 5001.\n",
      "Step: 4766 of 5001.\n",
      "Step: 4767 of 5001.\n",
      "Step: 4768 of 5001.\n",
      "Step: 4769 of 5001.\n",
      "Step: 4770 of 5001.\n",
      "Generator model loss: -1.8394654989242554.\n",
      "Discriminator model loss: -0.40444883704185486.\n",
      "xgboost accuracy: 0.84\n",
      "Step: 4771 of 5001.\n",
      "Step: 4772 of 5001.\n",
      "Step: 4773 of 5001.\n",
      "Step: 4774 of 5001.\n",
      "Step: 4775 of 5001.\n",
      "Step: 4776 of 5001.\n",
      "Step: 4777 of 5001.\n",
      "Step: 4778 of 5001.\n",
      "Step: 4779 of 5001.\n",
      "Step: 4780 of 5001.\n",
      "Generator model loss: -1.8711280822753906.\n",
      "Discriminator model loss: -0.3758098781108856.\n",
      "xgboost accuracy: 0.76\n",
      "Step: 4781 of 5001.\n",
      "Step: 4782 of 5001.\n",
      "Step: 4783 of 5001.\n",
      "Step: 4784 of 5001.\n",
      "Step: 4785 of 5001.\n",
      "Step: 4786 of 5001.\n",
      "Step: 4787 of 5001.\n",
      "Step: 4788 of 5001.\n",
      "Step: 4789 of 5001.\n",
      "Step: 4790 of 5001.\n",
      "Generator model loss: -1.8494523763656616.\n",
      "Discriminator model loss: -0.43987908959388733.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4791 of 5001.\n",
      "Step: 4792 of 5001.\n",
      "Step: 4793 of 5001.\n",
      "Step: 4794 of 5001.\n",
      "Step: 4795 of 5001.\n",
      "Step: 4796 of 5001.\n",
      "Step: 4797 of 5001.\n",
      "Step: 4798 of 5001.\n",
      "Step: 4799 of 5001.\n",
      "Step: 4800 of 5001.\n",
      "Generator model loss: -1.8395745754241943.\n",
      "Discriminator model loss: -0.32746511697769165.\n",
      "xgboost accuracy: 0.86\n",
      "Step: 4801 of 5001.\n",
      "Step: 4802 of 5001.\n",
      "Step: 4803 of 5001.\n",
      "Step: 4804 of 5001.\n",
      "Step: 4805 of 5001.\n",
      "Step: 4806 of 5001.\n",
      "Step: 4807 of 5001.\n",
      "Step: 4808 of 5001.\n",
      "Step: 4809 of 5001.\n",
      "Step: 4810 of 5001.\n",
      "Generator model loss: -1.8461534976959229.\n",
      "Discriminator model loss: -0.2836896777153015.\n",
      "xgboost accuracy: 0.74\n",
      "Step: 4811 of 5001.\n",
      "Step: 4812 of 5001.\n",
      "Step: 4813 of 5001.\n",
      "Step: 4814 of 5001.\n",
      "Step: 4815 of 5001.\n",
      "Step: 4816 of 5001.\n",
      "Step: 4817 of 5001.\n",
      "Step: 4818 of 5001.\n",
      "Step: 4819 of 5001.\n",
      "Step: 4820 of 5001.\n",
      "Generator model loss: -1.805621862411499.\n",
      "Discriminator model loss: -0.32779690623283386.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4821 of 5001.\n",
      "Step: 4822 of 5001.\n",
      "Step: 4823 of 5001.\n",
      "Step: 4824 of 5001.\n",
      "Step: 4825 of 5001.\n",
      "Step: 4826 of 5001.\n",
      "Step: 4827 of 5001.\n",
      "Step: 4828 of 5001.\n",
      "Step: 4829 of 5001.\n",
      "Step: 4830 of 5001.\n",
      "Generator model loss: -1.8778560161590576.\n",
      "Discriminator model loss: -0.3681519627571106.\n",
      "xgboost accuracy: 0.77\n",
      "Step: 4831 of 5001.\n",
      "Step: 4832 of 5001.\n",
      "Step: 4833 of 5001.\n",
      "Step: 4834 of 5001.\n",
      "Step: 4835 of 5001.\n",
      "Step: 4836 of 5001.\n",
      "Step: 4837 of 5001.\n",
      "Step: 4838 of 5001.\n",
      "Step: 4839 of 5001.\n",
      "Step: 4840 of 5001.\n",
      "Generator model loss: -1.8693790435791016.\n",
      "Discriminator model loss: -0.393449604511261.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4841 of 5001.\n",
      "Step: 4842 of 5001.\n",
      "Step: 4843 of 5001.\n",
      "Step: 4844 of 5001.\n",
      "Step: 4845 of 5001.\n",
      "Step: 4846 of 5001.\n",
      "Step: 4847 of 5001.\n",
      "Step: 4848 of 5001.\n",
      "Step: 4849 of 5001.\n",
      "Step: 4850 of 5001.\n",
      "Generator model loss: -1.8682857751846313.\n",
      "Discriminator model loss: -0.3362717926502228.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4851 of 5001.\n",
      "Step: 4852 of 5001.\n",
      "Step: 4853 of 5001.\n",
      "Step: 4854 of 5001.\n",
      "Step: 4855 of 5001.\n",
      "Step: 4856 of 5001.\n",
      "Step: 4857 of 5001.\n",
      "Step: 4858 of 5001.\n",
      "Step: 4859 of 5001.\n",
      "Step: 4860 of 5001.\n",
      "Generator model loss: -1.804064154624939.\n",
      "Discriminator model loss: -0.3954392671585083.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4861 of 5001.\n",
      "Step: 4862 of 5001.\n",
      "Step: 4863 of 5001.\n",
      "Step: 4864 of 5001.\n",
      "Step: 4865 of 5001.\n",
      "Step: 4866 of 5001.\n",
      "Step: 4867 of 5001.\n",
      "Step: 4868 of 5001.\n",
      "Step: 4869 of 5001.\n",
      "Step: 4870 of 5001.\n",
      "Generator model loss: -1.8680450916290283.\n",
      "Discriminator model loss: -0.3521694540977478.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4871 of 5001.\n",
      "Step: 4872 of 5001.\n",
      "Step: 4873 of 5001.\n",
      "Step: 4874 of 5001.\n",
      "Step: 4875 of 5001.\n",
      "Step: 4876 of 5001.\n",
      "Step: 4877 of 5001.\n",
      "Step: 4878 of 5001.\n",
      "Step: 4879 of 5001.\n",
      "Step: 4880 of 5001.\n",
      "Generator model loss: -1.8752931356430054.\n",
      "Discriminator model loss: -0.3508288562297821.\n",
      "xgboost accuracy: 0.78\n",
      "Step: 4881 of 5001.\n",
      "Step: 4882 of 5001.\n",
      "Step: 4883 of 5001.\n",
      "Step: 4884 of 5001.\n",
      "Step: 4885 of 5001.\n",
      "Step: 4886 of 5001.\n",
      "Step: 4887 of 5001.\n",
      "Step: 4888 of 5001.\n",
      "Step: 4889 of 5001.\n",
      "Step: 4890 of 5001.\n",
      "Generator model loss: -1.906766653060913.\n",
      "Discriminator model loss: -0.3227359652519226.\n",
      "xgboost accuracy: 0.80\n",
      "Step: 4891 of 5001.\n",
      "Step: 4892 of 5001.\n",
      "Step: 4893 of 5001.\n",
      "Step: 4894 of 5001.\n",
      "Step: 4895 of 5001.\n",
      "Step: 4896 of 5001.\n",
      "Step: 4897 of 5001.\n",
      "Step: 4898 of 5001.\n",
      "Step: 4899 of 5001.\n",
      "Step: 4900 of 5001.\n",
      "Generator model loss: -1.8074878454208374.\n",
      "Discriminator model loss: -0.3467545211315155.\n",
      "xgboost accuracy: 0.73\n",
      "Step: 4901 of 5001.\n",
      "Step: 4902 of 5001.\n",
      "Step: 4903 of 5001.\n",
      "Step: 4904 of 5001.\n",
      "Step: 4905 of 5001.\n",
      "Step: 4906 of 5001.\n",
      "Step: 4907 of 5001.\n",
      "Step: 4908 of 5001.\n",
      "Step: 4909 of 5001.\n",
      "Step: 4910 of 5001.\n",
      "Generator model loss: -1.8608554601669312.\n",
      "Discriminator model loss: -0.36423376202583313.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4911 of 5001.\n",
      "Step: 4912 of 5001.\n",
      "Step: 4913 of 5001.\n",
      "Step: 4914 of 5001.\n",
      "Step: 4915 of 5001.\n",
      "Step: 4916 of 5001.\n",
      "Step: 4917 of 5001.\n",
      "Step: 4918 of 5001.\n",
      "Step: 4919 of 5001.\n",
      "Step: 4920 of 5001.\n",
      "Generator model loss: -1.8217103481292725.\n",
      "Discriminator model loss: -0.3339272439479828.\n",
      "xgboost accuracy: 0.83\n",
      "Step: 4921 of 5001.\n",
      "Step: 4922 of 5001.\n",
      "Step: 4923 of 5001.\n",
      "Step: 4924 of 5001.\n",
      "Step: 4925 of 5001.\n",
      "Step: 4926 of 5001.\n",
      "Step: 4927 of 5001.\n",
      "Step: 4928 of 5001.\n",
      "Step: 4929 of 5001.\n",
      "Step: 4930 of 5001.\n",
      "Generator model loss: -1.9211320877075195.\n",
      "Discriminator model loss: -0.383556067943573.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4931 of 5001.\n",
      "Step: 4932 of 5001.\n",
      "Step: 4933 of 5001.\n",
      "Step: 4934 of 5001.\n",
      "Step: 4935 of 5001.\n",
      "Step: 4936 of 5001.\n",
      "Step: 4937 of 5001.\n",
      "Step: 4938 of 5001.\n",
      "Step: 4939 of 5001.\n",
      "Step: 4940 of 5001.\n",
      "Generator model loss: -1.8943275213241577.\n",
      "Discriminator model loss: -0.29238051176071167.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4941 of 5001.\n",
      "Step: 4942 of 5001.\n",
      "Step: 4943 of 5001.\n",
      "Step: 4944 of 5001.\n",
      "Step: 4945 of 5001.\n",
      "Step: 4946 of 5001.\n",
      "Step: 4947 of 5001.\n",
      "Step: 4948 of 5001.\n",
      "Step: 4949 of 5001.\n",
      "Step: 4950 of 5001.\n",
      "Generator model loss: -1.8671455383300781.\n",
      "Discriminator model loss: -0.3034469187259674.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4951 of 5001.\n",
      "Step: 4952 of 5001.\n",
      "Step: 4953 of 5001.\n",
      "Step: 4954 of 5001.\n",
      "Step: 4955 of 5001.\n",
      "Step: 4956 of 5001.\n",
      "Step: 4957 of 5001.\n",
      "Step: 4958 of 5001.\n",
      "Step: 4959 of 5001.\n",
      "Step: 4960 of 5001.\n",
      "Generator model loss: -1.8579515218734741.\n",
      "Discriminator model loss: -0.3647424578666687.\n",
      "xgboost accuracy: 0.81\n",
      "Step: 4961 of 5001.\n",
      "Step: 4962 of 5001.\n",
      "Step: 4963 of 5001.\n",
      "Step: 4964 of 5001.\n",
      "Step: 4965 of 5001.\n",
      "Step: 4966 of 5001.\n",
      "Step: 4967 of 5001.\n",
      "Step: 4968 of 5001.\n",
      "Step: 4969 of 5001.\n",
      "Step: 4970 of 5001.\n",
      "Generator model loss: -1.8912433385849.\n",
      "Discriminator model loss: -0.348364919424057.\n",
      "xgboost accuracy: 0.82\n",
      "Step: 4971 of 5001.\n",
      "Step: 4972 of 5001.\n",
      "Step: 4973 of 5001.\n",
      "Step: 4974 of 5001.\n",
      "Step: 4975 of 5001.\n",
      "Step: 4976 of 5001.\n",
      "Step: 4977 of 5001.\n",
      "Step: 4978 of 5001.\n",
      "Step: 4979 of 5001.\n",
      "Step: 4980 of 5001.\n",
      "Generator model loss: -1.8679301738739014.\n",
      "Discriminator model loss: -0.42062482237815857.\n",
      "xgboost accuracy: 0.85\n",
      "Step: 4981 of 5001.\n",
      "Step: 4982 of 5001.\n",
      "Step: 4983 of 5001.\n",
      "Step: 4984 of 5001.\n",
      "Step: 4985 of 5001.\n",
      "Step: 4986 of 5001.\n",
      "Step: 4987 of 5001.\n",
      "Step: 4988 of 5001.\n",
      "Step: 4989 of 5001.\n",
      "Step: 4990 of 5001.\n",
      "Generator model loss: -1.8915036916732788.\n",
      "Discriminator model loss: -0.34396401047706604.\n",
      "xgboost accuracy: 0.79\n",
      "Step: 4991 of 5001.\n",
      "Step: 4992 of 5001.\n",
      "Step: 4993 of 5001.\n",
      "Step: 4994 of 5001.\n",
      "Step: 4995 of 5001.\n",
      "Step: 4996 of 5001.\n",
      "Step: 4997 of 5001.\n",
      "Step: 4998 of 5001.\n",
      "Step: 4999 of 5001.\n",
      "Step: 5000 of 5001.\n",
      "Generator model loss: -1.8896989822387695.\n",
      "Discriminator model loss: -0.2759471535682678.\n",
      "xgboost accuracy: 0.76\n",
      "CPU times: user 7min 57s, sys: 32.3 s, total: 8min 29s\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K.set_learning_phase(1) # 1 = train\n",
    "adversarial_training('', None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for continued training\n",
    "# adversarial_training('', 'cache/WCGAN_generator_model_weights_step_100.h5', 'cache/WCGAN_discriminator_model_weights_step_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[combined_loss, disc_loss, xgb_losses] = pickle.load(open(os.path.join(cache_dir, 'WCGAN_losses.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naPPuPfdYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc7096400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( xgb_losses[1:] ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc39336a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc911bbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( combined_loss[1:], label='combined_loss' ) ; plt.legend() ; plt.show()\n",
    "\n",
    "plt.plot( disc_loss[600:], label='disc_loss' ) ; plt.legend() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.4-py3.6.egg/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "generated_image_tensor = generator_network(generator_input_tensor)\n",
    "generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "\n",
    "generator_model.load_weights('cache/WCGAN_generator_model_weights_step_5000.h5')\n",
    "\n",
    "temp_noise = np.random.normal(size=(batch_size, rand_dim))  # fixed noise to generate batches of generated images\n",
    "\n",
    "g_z = generator_model.predict(temp_noise)\n",
    "\n",
    "# g_z[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n"
     ]
    }
   ],
   "source": [
    "print( CheckAccuracy( generator_model, 100, train_w_class ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.86'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 100\n",
    "\n",
    "np.random.seed(0)\n",
    "temp_noise = np.random.normal(size=(n_samples*2, rand_dim))  # fixed noise to generate batches of generated images\n",
    "test_samples = generator_model.predict(temp_noise)\n",
    "test_samples = np.reshape(test_samples, (n_samples*2, data_dim))\n",
    "# test_samples = np.round(test_samples,3)\n",
    "test_samples = pd.DataFrame(test_samples,columns=train_w_class.columns)\n",
    "test_samples['syn_label'] = 1\n",
    "\n",
    "test_samples['Class'] = (test_samples['Class'] > 0.5)*1\n",
    "\n",
    "real_samples = train_w_class.sample(n_samples*2,replace=False)\n",
    "# real_samples = test_w_class.sample(n_samples*2,replace=False)\n",
    "real_samples['syn_label'] = 0\n",
    "\n",
    "train_df = pd.concat([real_samples[:n_samples],test_samples[:n_samples]],axis=0)\n",
    "test_df = pd.concat([real_samples[n_samples:],test_samples[n_samples:]],axis=0)\n",
    "\n",
    "X_col = test_df.columns[:-1]\n",
    "y_col = test_df.columns[-1]\n",
    "dtrain = xgb.DMatrix(train_df[X_col], train_df[y_col], feature_names=X_col)\n",
    "dtest = xgb.DMatrix(test_df[X_col], feature_names=X_col)\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 0 }\n",
    "xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "y_pred = np.round(xgb_test.predict(dtest))\n",
    "y_true = test_df['syn_label']\n",
    "'{:.2f}'.format(SimpleAccuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 30) (81, 30) (140, 30) (141, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.97'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing by class\n",
    "\n",
    "n = 1\n",
    "real_class = real_samples[ real_samples.Class == n ].reset_index(drop=True)\n",
    "test_class = test_samples[ test_samples.Class == n ].reset_index(drop=True)\n",
    "\n",
    "train_df = pd.concat( [ real_class[:len(real_class)//2], test_class[:len(test_class)//2] ],axis=0)\n",
    "test_df = pd.concat(  [ real_class[len(real_class)//2:], test_class[len(test_class)//2:] ],axis=0)\n",
    "print( real_class.shape, test_class.shape, train_df.shape, test_df.shape )\n",
    "\n",
    "X_col = test_df.columns[:-1]\n",
    "y_col = test_df.columns[-1]\n",
    "dtrain = xgb.DMatrix(train_df[X_col], train_df[y_col], feature_names=X_col)\n",
    "dtest = xgb.DMatrix(test_df[X_col], feature_names=X_col)\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 0 }\n",
    "xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "y_pred = np.round(xgb_test.predict(dtest))\n",
    "y_true = test_df['syn_label']\n",
    "'{:.2f}'.format(SimpleAccuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_w_class.head(3)\n",
    "# test_samples.head(3)\n",
    "# real_samples.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True 0</th>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 1</th>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pred 0  Pred 1\n",
       "True 0      84      16\n",
       "True 1      11      89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.865\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on validation set\n",
    "SimpleMetrics(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHwCAYAAAChTMYRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc979a12e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importances\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "xgb.plot_importance(xgb_test, max_num_features=20, height=0.5, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value\n",
    "# import operator\n",
    "# x = xgb_test.get_fscore()\n",
    "# sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# # sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for col, imp in sorted_x:\n",
    "# # for col in xgb_model_DCGAN.get_fscore().keys():\n",
    "# # for col in ['V1','V14','V3']:\n",
    "#     plt.hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "# #     plt.title( '{}: {}'.format(col, xgb_model_DCGAN.get_fscore()[col]) )\n",
    "#     plt.title( '{}: {}'.format(col, imp) )\n",
    "#     plt.legend() ; plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/figure.py:1742: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAALICAYAAADseNpmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS5IkSZJUgf8CpMjRPKwvkRkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc9776d080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for col in train.columns:\n",
    "#     plt.hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "#     plt.title( '{}'.format(col) )\n",
    "#     plt.legend() ; plt.show()\n",
    "    \n",
    "# plt.figure(figsize=(14,5))    \n",
    "f, axarr = plt.subplots(8, 4, figsize=(14,10) )\n",
    "for i in range(data_dim):\n",
    "    col = train_df.columns[i]\n",
    "#     axarr[i//4, i%4].hist( [train_df[col][:100], train_df[col][100:]], label=['real','syn'], bins=20 )\n",
    "    axarr[i//4, i%4].hist( [ train_df.loc[train_df['syn_label']==0, col], train_df.loc[train_df['syn_label']==1, col]], \n",
    "                          label=['real','syn'], bins=20) #, normed=True )\n",
    "    axarr[i//4, i%4].set_title( '{}'.format(col) )\n",
    "    if i == 0: axarr[i//4, i%4].legend()\n",
    "#     axarr[i//4, i%4].set_xlim([-0.1,1.1])\n",
    "#     axarr[i//4, i%4].set_ylim([0,40])\n",
    "f.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_df.groupby('syn_label')['V2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Summary\"><h1>Summary</h1></a>\n",
    "\n",
    "<a href='#TOC'>Table of contents</a>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[combined_loss, disc_loss_real, disc_loss_generated, xgb_losses] = pickle.load(open(os.path.join(cache_dir, 'GAN_losses.pkl'),'rb'))\n",
    "GAN_losses = [combined_loss, disc_loss_real, disc_loss_generated, xgb_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[combined_loss, disc_loss_real, disc_loss_generated, xgb_losses] = pickle.load(open(os.path.join(cache_dir, 'CGAN_losses.pkl'),'rb'))\n",
    "CGAN_losses = [combined_loss, disc_loss_real, disc_loss_generated, xgb_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[combined_loss, disc_loss, xgb_losses] = pickle.load(open(os.path.join(cache_dir, 'WGAN_losses.pkl'),'rb'))\n",
    "WGAN_losses = [combined_loss, disc_loss, xgb_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[combined_loss, disc_loss, xgb_losses] = pickle.load(open(os.path.join(cache_dir, 'WCGAN_losses.pkl'),'rb'))\n",
    "WCGAN_losses = [combined_loss, disc_loss, xgb_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nARQMpjBK8xUgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbcede9470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( GAN_losses[-1], label='xgb_losses_GAN' )\n",
    "plt.plot( CGAN_losses[-1], label='xgb_losses_CGAN' )\n",
    "plt.plot( WGAN_losses[-1], label='xgb_losses_WGAN' )\n",
    "plt.plot( WCGAN_losses[-1], label='xgb_losses_WCGAN' )\n",
    "plt.ylim([0.7,1])\n",
    "plt.legend() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbceee1978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( GAN_losses[0], label='combined_losses_GAN' )\n",
    "plt.plot( CGAN_losses[0], label='combined_losses_CGAN' )\n",
    "plt.plot( WGAN_losses[0], label='combined_losses_WGAN' )\n",
    "plt.plot( WCGAN_losses[0], label='combined_losses_WCGAN' )\n",
    "plt.ylim([-3,3])\n",
    "plt.legend() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: pd.rolling_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: pd.rolling_mean is deprecated for ndarrays and will be removed in a future version\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: pd.rolling_mean is deprecated for ndarrays and will be removed in a future version\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: pd.rolling_mean is deprecated for ndarrays and will be removed in a future version\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7jA0TdM0i+gOQ9M0TbOI7jA0TdM0i/w/qMWcfLaoXGkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbcf008fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot( pd.rolling_mean(GAN_losses[0],10) )\n",
    "w = 20\n",
    "plt.plot( list(range(0,5001,10)), pd.rolling_mean(GAN_losses[-1],w), label='GAN' )\n",
    "plt.plot( list(range(0,5001,10)), pd.rolling_mean(CGAN_losses[-1],w), label='CGAN' )\n",
    "plt.plot( list(range(1,5001,10)), pd.rolling_mean(WGAN_losses[-1],w), label='WGAN' )\n",
    "plt.plot( list(range(1,5001,10)), pd.rolling_mean(WCGAN_losses[-1],w), label='WCGAN' )\n",
    "plt.ylim([0.7,1])\n",
    "plt.grid()\n",
    "plt.title('Accuracy of generated image detection')\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('xgboost accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.savefig('plots/GAN_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: pd.rolling_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: pd.rolling_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: pd.rolling_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: pd.rolling_mean is deprecated for ndarrays and will be removed in a future version\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbcf03ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( pd.rolling_mean(GAN_losses[0],10), label='combined_losses_GAN' )\n",
    "plt.plot( pd.rolling_mean(CGAN_losses[0],10), label='combined_losses_CGAN' )\n",
    "plt.plot( pd.rolling_mean(np.array(WGAN_losses[0]),10), label='combined_losses_WGAN' )\n",
    "plt.plot( pd.rolling_mean(np.array(WCGAN_losses[0]),10), label='combined_losses_WCGAN' )\n",
    "plt.ylim([-3,2])\n",
    "plt.grid()\n",
    "plt.legend() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
